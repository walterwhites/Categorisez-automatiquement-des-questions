{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d7013fb3d50c0d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dcc1f92ef9b0e28"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import gensim\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import spacy\n",
    "import time\n",
    "\n",
    "def evaluate_and_log_metrics(experiment_name, lda_model_title, corpus_test_title, lda_transformed_title_test):\n",
    "    \n",
    "    # Calculer la log-perplexité\n",
    "    log_perplexity_title = lda_model_title.log_perplexity(lda_transformed_title_test)\n",
    "    \n",
    "    # Calculer la perplexité à partir de la log-perplexité\n",
    "    perplexity_title = np.exp(-log_perplexity_title / len(corpus_test_title))\n",
    "    \n",
    "    print(f\"Log-Perplexity: {log_perplexity_title}\")\n",
    "    print(f\"Perplexity: {perplexity_title}\")\n",
    "\n",
    "    with mlflow.start_run():\n",
    "        mlflow.set_experiment(experiment_name)\n",
    "        mlflow.log_metric(\"Log-Perplexity\", log_perplexity_title)\n",
    "        mlflow.log_metric(\"Perplexity\", perplexity_title)\n",
    "\n",
    "    return log_perplexity_title, perplexity_title"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:43:29.798307Z",
     "start_time": "2024-01-15T11:43:27.490880Z"
    }
   },
   "id": "8ae869960cf0b7a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f675b5d911b4057a"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"dataset_cleaned.csv\")\n",
    "train_data, test_data = train_test_split(data, test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:43:29.883387Z",
     "start_time": "2024-01-15T11:43:29.798795Z"
    }
   },
   "id": "1b9c32568773dbe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## LDA (Latent Dirichlet allocation)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b27baf680552860"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Préparer LDA sur les titres (pour un modèle simple)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8070f3db02ad7da8"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mots associés à chaque topic pour le titre:\n",
      "Topic 1: 0.005*\"multiple\" + 0.005*\"data\" + 0.005*\"app\" + 0.005*\"using\" + 0.005*\"['use\" + 0.004*\"function\" + 0.004*\"error\" + 0.004*\"python\" + 0.003*\"file\" + 0.003*\"['django\"\n",
      "Topic 2: 0.007*\"image\" + 0.006*\"['create\" + 0.006*\"using\" + 0.006*\"['using\" + 0.005*\"vs\" + 0.005*\"error\" + 0.004*\"['make\" + 0.004*\"custom\" + 0.004*\"application\" + 0.004*\"data\"\n",
      "Topic 3: 0.010*\"using\" + 0.009*\"['get\" + 0.006*\"files\" + 0.006*\"file\" + 0.006*\"way\" + 0.005*\"code\" + 0.004*\"error\" + 0.004*\"cannot\" + 0.004*\"server\" + 0.003*\"studio\"\n",
      "Topic 4: 0.020*\"using\" + 0.007*\"array\" + 0.006*\"file\" + 0.006*\"string\" + 0.006*\"c\" + 0.005*\"c']\" + 0.004*\"server\" + 0.004*\"object\" + 0.004*\"json\" + 0.003*\"['convert\"\n",
      "Topic 5: 0.007*\"android\" + 0.004*\"type\" + 0.004*\"studio\" + 0.004*\"multiple\" + 0.004*\"file']\" + 0.003*\"database\" + 0.003*\"error\" + 0.003*\"run\" + 0.003*\"function\" + 0.003*\"vs\"\n",
      "Log-Perplexity: -25.75107479480978\n",
      "Perplexity: 1.0129587840270604\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "\n",
    "# train\n",
    "text_data_train_title = [text.split() for text in train_data['title_lemmatized']]\n",
    "dictionary_train_title = Dictionary(text_data_train_title)\n",
    "corpus_train_title = [dictionary_train_title.doc2bow(word_list) for word_list in text_data_train_title]\n",
    "\n",
    "# test\n",
    "text_data_test_title = [text.split() for text in test_data['title_lemmatized']]\n",
    "dictionary_test_title = Dictionary(text_data_test_title)\n",
    "corpus_test_title = [dictionary_test_title.doc2bow(word_list) for word_list in text_data_test_title]\n",
    "\n",
    "# Entraînement du modèle LDA sur l'ensemble d'entraînement\n",
    "lda_model_title = LdaModel(corpus_train_title, num_topics=5, id2word=dictionary_train_title, passes=10)\n",
    "\n",
    "# Afficher les mots associés à chaque topic pour le titre\n",
    "print(\"Mots associés à chaque topic pour le titre:\")\n",
    "for topic_idx, topic in lda_model_title.print_topics():\n",
    "    print(f\"Topic {topic_idx + 1}: {topic}\")\n",
    "\n",
    "# LDA pour transformer les données de test sur l'ensemble de test\n",
    "lda_transformed_title_test = lda_model_title[corpus_test_title]\n",
    "\n",
    "# Calculer la log-perplexité\n",
    "log_perplexity_title = lda_model_title.log_perplexity(lda_transformed_title_test)\n",
    "\n",
    "# Calculer la perplexité à partir de la log-perplexité\n",
    "perplexity_title = np.exp(-log_perplexity_title / len(corpus_test_title))\n",
    "\n",
    "print(f\"Log-Perplexity: {log_perplexity_title}\")\n",
    "print(f\"Perplexity: {perplexity_title}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:43:35.303280Z",
     "start_time": "2024-01-15T11:43:29.927954Z"
    }
   },
   "id": "13b762b354cdcefb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trouver le nombre de topics avec la Perplexité (Avec title seulement)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f441066803039d5"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0039885535836495\n",
      "1.0042789358906539\n",
      "1.0044769844880357\n",
      "1.004619701838748\n",
      "1.0047316753698625\n",
      "1.0048189650468928\n",
      "1.0048756610214797\n",
      "1.0049355958484012\n",
      "Le nombre optimal de topics est : 1\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "text_data_train_title = [text.split() for text in train_data['title_lemmatized']]\n",
    "text_data_test_title = [text.split() for text in test_data['title_lemmatized']]\n",
    "\n",
    "dictionary_train_title = Dictionary(text_data_train_title)\n",
    "dictionary_test_title = Dictionary(text_data_test_title)\n",
    "\n",
    "dictionary_train_title.filter_extremes(no_below=5, no_above=0.6)\n",
    "dictionary_test_title.filter_extremes(no_below=5, no_above=0.6)\n",
    "\n",
    "corpus_train_title = [dictionary_train_title.doc2bow(word_list) for word_list in text_data_train_title]\n",
    "corpus_test_title = [dictionary_test_title.doc2bow(word_list) for word_list in text_data_test_title]\n",
    "\n",
    "# Liste des nombres de topics à tester\n",
    "num_topics_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "# Calculer la perplexité pour différents nombres de topics\n",
    "perplexity_scores = []\n",
    "\n",
    "for num_topics in num_topics_list:\n",
    "    lda_model_title = LdaModel(corpus_train_title, num_topics=num_topics, id2word=dictionary_train_title, passes=10)\n",
    "    log_perplexity_title = lda_model_title.log_perplexity(corpus_test_title)\n",
    "    perplexity_title = np.exp(-log_perplexity_title / len(corpus_test_title))\n",
    "    print(perplexity_title)\n",
    "    perplexity_scores.append(perplexity_title)\n",
    "\n",
    "# nombre de topics avec la perplexité la plus basse\n",
    "best_num_topics = num_topics_list[np.argmin(perplexity_scores)]\n",
    "\n",
    "print(f\"Le nombre optimal de topics est : {best_num_topics}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:44:07.557557Z",
     "start_time": "2024-01-15T11:43:35.350277Z"
    }
   },
   "id": "bafc6e28bd51ad3a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Trouver le nombre de topics avec la Perplexité (Avec title et body)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23c0ebe1b68495bc"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165750\n",
      "54976\n",
      "11601\n",
      "4259\n",
      "1.0045971360282582\n",
      "1.0046617386295658\n",
      "1.0047139941609777\n",
      "1.0047445885498818\n",
      "1.004786085999776\n",
      "1.004816658726013\n",
      "1.0048456938822585\n",
      "1.0048652216406742\n",
      "Le nombre optimal de topics pour les mots combinés est : 1\n",
      "(0, [('line', 0.024931056), ('file', 0.018267043), ('def', 0.01282137), ('test', 0.01086217), ('method', 0.009485462), ('return', 0.009122204), ('call', 0.008327333), ('end', 0.007862711), ('event', 0.0074588945), ('function', 0.0067801434)])\n",
      "(1, [('like', 0.013032735), ('would', 0.011303859), ('use', 0.010486804), ('using', 0.0099492455), ('way', 0.007725866), ('im', 0.007699554), ('one', 0.0067669563), ('code', 0.0063188914), ('need', 0.0048392485), ('know', 0.0045391014)])\n",
      "(2, [('1', 0.04431643), ('0', 0.029987337), ('2', 0.024028843), ('3', 0.016465899), ('x', 0.011571607), ('data', 0.010405485), ('4', 0.009918827), ('import', 0.00852962), ('array', 0.007948), ('using', 0.007145466)])\n",
      "(3, [('int', 0.02178521), ('c', 0.018224802), ('function', 0.016445374), ('type', 0.014954423), ('const', 0.014287836), ('0', 0.014124729), ('return', 0.013674731), ('include', 0.010353468), ('b', 0.008757097), ('error', 0.00864138)])\n",
      "(4, [('public', 0.040269163), ('new', 0.03157825), ('class', 0.027137054), ('string', 0.024861638), ('return', 0.02455956), ('void', 0.014999806), ('private', 0.014839618), ('import', 0.011878102), ('var', 0.011573506), ('method', 0.010613281)])\n",
      "(5, [('user', 0.011605793), ('id', 0.010767017), ('select', 0.009419402), ('data', 0.009256593), ('using', 0.008574176), ('table', 0.0085638985), ('get', 0.008516973), ('info', 0.008309636), ('name', 0.007653495), ('request', 0.0069921175)])\n",
      "(6, [('error', 0.017143836), ('file', 0.016959608), ('app', 0.01029302), ('run', 0.009636107), ('using', 0.009248568), ('build', 0.008122636), ('project', 0.007991276), ('files', 0.007609971), ('version', 0.0074688867), ('get', 0.0057455194)])\n",
      "(7, [('div', 0.021894006), ('00', 0.01618504), ('view', 0.00996179), ('0', 0.009773252), ('image', 0.009138514), ('button', 0.0090301465), ('html', 0.008004721), ('var', 0.0077137966), ('text', 0.007416244), ('page', 0.0074098804)])\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "import numpy as np\n",
    "\n",
    "text_data_train_combined = [text.split() for text in train_data['title_lemmatized'] + train_data['body_lemmatized']]\n",
    "text_data_test_combined = [text.split() for text in test_data['title_lemmatized'] + test_data['body_lemmatized']]\n",
    "\n",
    "\n",
    "dictionary_train_combined = Dictionary(text_data_train_combined)\n",
    "dictionary_test_combined = Dictionary(text_data_test_combined)\n",
    "\n",
    "print(len(dictionary_train_combined))\n",
    "print(len(dictionary_test_combined))\n",
    "\n",
    "dictionary_train_combined.filter_extremes(no_below=5, no_above=0.6)\n",
    "dictionary_test_combined.filter_extremes(no_below=5, no_above=0.6)\n",
    "\n",
    "corpus_train_combined = [dictionary_train_combined.doc2bow(word_list) for word_list in text_data_train_combined]\n",
    "corpus_test_combined = [dictionary_test_combined.doc2bow(word_list) for word_list in text_data_test_combined]\n",
    "\n",
    "print(len(dictionary_train_combined))\n",
    "print(len(dictionary_test_combined))\n",
    "\n",
    "num_topics_list = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "perplexity_scores_combined = []\n",
    "\n",
    "for num_topics in num_topics_list:    \n",
    "    lda_model_combined = LdaModel(corpus_train_combined, num_topics=num_topics, id2word=dictionary_train_combined, passes=10)\n",
    "\n",
    "    log_perplexity_combined = lda_model_combined.log_perplexity(corpus_test_combined)\n",
    "    perplexity_combined = np.exp(-log_perplexity_combined / len(corpus_test_combined))\n",
    "    print(perplexity_combined)\n",
    "    perplexity_scores_combined.append(perplexity_combined)\n",
    "\n",
    "best_num_topics_combined = num_topics_list[np.argmin(perplexity_scores_combined)]\n",
    "print(f\"Le nombre optimal de topics pour les mots combinés est : {best_num_topics_combined}\")\n",
    "\n",
    "topics = lda_model_combined.show_topics(num_topics=num_topics, formatted=False)\n",
    "for topic in topics:\n",
    "    print(topic)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:46:00.782464Z",
     "start_time": "2024-01-15T11:44:07.602814Z"
    }
   },
   "id": "44cbf004b649518d"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_title_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 8\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# LDA sur le titre\u001B[39;00m\n\u001B[1;32m      7\u001B[0m lda_title \u001B[38;5;241m=\u001B[39m LatentDirichletAllocation(n_components\u001B[38;5;241m=\u001B[39mnum_topics, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n\u001B[0;32m----> 8\u001B[0m lda_title\u001B[38;5;241m.\u001B[39mfit(X_title_train)\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m# LDA sur le body\u001B[39;00m\n\u001B[1;32m     11\u001B[0m lda_body \u001B[38;5;241m=\u001B[39m LatentDirichletAllocation(n_components\u001B[38;5;241m=\u001B[39mnum_topics, random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m42\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'X_title_train' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Définir le nombre de topics\n",
    "num_topics = best_num_topics\n",
    "\n",
    "# LDA sur le titre\n",
    "lda_title = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_title.fit(X_title_train)\n",
    "\n",
    "# LDA sur le body\n",
    "lda_body = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "lda_body.fit(X_body_train)\n",
    "\n",
    "M_topics_words = lda_title.components_\n",
    "M_quest_topics_train = lda_title.transform(X_title_train)\n",
    "\n",
    "# Afficher les mots associés à chaque topic pour le titre\n",
    "print(\"Mots associés à chaque topic pour le titre:\")\n",
    "for topic_idx, topic in enumerate(lda_title.components_):\n",
    "    top_words_idx = topic.argsort()[:-10 - 1:-1]  # Sélectionner les 10 meilleurs mots pour chaque topic\n",
    "    top_words = [feature_names_title[i] for i in top_words_idx]\n",
    "    print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "\n",
    "# Afficher les mots associés à chaque topic pour le corps\n",
    "#print(\"\\nMots associés à chaque topic pour le corps:\")\n",
    "#for topic_idx, topic in enumerate(lda_body.components_):\n",
    " #   top_words_idx = topic.argsort()[:-10 - 1:-1]  # Sélectionner les 10 meilleurs mots pour #chaque topic\n",
    "   # top_words = [feature_names_body[i] for i in top_words_idx]\n",
    "    #print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n",
    "\n",
    "# Transformez les données de test en distributions de topics\n",
    "X_title_test_topics = lda_title.transform(X_title_test)\n",
    "X_body_test_topics = lda_body.transform(X_body_test)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:46:01.102254Z",
     "start_time": "2024-01-15T11:46:00.784664Z"
    }
   },
   "id": "fdca6ff85e8522f2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pyLDAvis\n",
    "import pyLDAvis.lda_model\n",
    "\n",
    "# Visualisation pour le titre\n",
    "pyLDAvis.enable_notebook()\n",
    "vis_title = pyLDAvis.lda_model.prepare(lda_title, X_title_test, vectorizer_title, mds='tsne')\n",
    "pyLDAvis.display(vis_title)\n",
    "\n",
    "# Visualisation pour le body\n",
    "# vis_body = pyLDAvis.sklearn.prepare(lda_body, X_body_test, vectorizer_body, mds='tsne')\n",
    "# pyLDAvis.display(vis_body)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-15T11:46:01.103326Z",
     "start_time": "2024-01-15T11:46:01.102718Z"
    }
   },
   "id": "f8592bca02c2f0b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_topics = M_topics_words.shape[0]\n",
    "num_top_words = 10\n",
    "\n",
    "for topic_idx in range(num_topics):\n",
    "    top_words_idx = M_topics_words[topic_idx].argsort()[:-num_top_words - 1:-1]\n",
    "    top_words = [feature_names_title[i] for i in top_words_idx]\n",
    "    print(f\"Topic {topic_idx + 1}: {', '.join(top_words)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T11:46:01.104171Z"
    }
   },
   "id": "c6ad72a1ddd9e31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_questions = M_quest_topics_train.shape[0]\n",
    "num_top_topics = 3\n",
    "\n",
    "for question_idx in range(num_questions):\n",
    "    top_topics_idx = M_quest_topics_train[question_idx].argsort()[:-num_top_topics - 1:-1]\n",
    "    print(f\"Question {question_idx + 1} - Topics Principaux : {', '.join(map(str, top_topics_idx))}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-15T11:46:01.104977Z"
    }
   },
   "id": "fe3367a660c4970c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
