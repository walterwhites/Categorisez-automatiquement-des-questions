{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook Exploration"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7d7013fb3d50c0d6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Functions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2dcc1f92ef9b0e28"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import spacy\n",
    "\n",
    "# Exemple de tâche d'apprentissage machine\n",
    "def train_and_evaluate(data):\n",
    "    # Chargez les données\n",
    "    X = data.drop('tags', axis=1)\n",
    "    y = data['tags']\n",
    "\n",
    "    # Divisez les données en ensemble d'entraînement et ensemble de test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialisation de MLflow\n",
    "    mlflow.start_run()\n",
    "\n",
    "    # Paramètres\n",
    "    param_max_depth = 10\n",
    "    param_n_estimators = 100\n",
    "\n",
    "    # Enregistrez les paramètres\n",
    "    mlflow.log_param(\"max_depth\", param_max_depth)\n",
    "    mlflow.log_param(\"n_estimators\", param_n_estimators)\n",
    "\n",
    "    # Créez et entraînez le modèle\n",
    "    model = RandomForestClassifier(max_depth=param_max_depth, n_estimators=param_n_estimators)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Faites des prédictions sur l'ensemble de test\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculez et enregistrez la métrique\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Enregistrez le modèle\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "\n",
    "    # Enregistrez un fichier artefact (par exemple, un fichier texte)\n",
    "    with open(\"artifact.txt\", \"w\") as artifact_file:\n",
    "        artifact_file.write(\"Contenu de l'artefact\")\n",
    "\n",
    "    mlflow.log_artifact(\"artifact.txt\")\n",
    "\n",
    "    # Fin de l'expérience MLflow\n",
    "    mlflow.end_run()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T19:47:12.076959Z",
     "start_time": "2023-12-12T19:47:12.058786Z"
    }
   },
   "id": "8ae869960cf0b7a8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Split dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f675b5d911b4057a"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"dataset.csv\")\n",
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T19:47:12.087232Z",
     "start_time": "2023-12-12T19:47:12.060317Z"
    }
   },
   "id": "1b9c32568773dbe"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Lemmatisation Title et Body"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9012ad4f75e3b29c"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Charger le modèle de langue spaCy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Lemmatisation pour le champ \"title\" dans l'ensemble d'entraînement\n",
    "train_data['title_lemmatized'] = train_data['title'].apply(lambda text: ' '.join([token.lemma_ for token in nlp(text)]))\n",
    "\n",
    "# Lemmatisation pour le champ \"body\" dans l'ensemble d'entraînement\n",
    "train_data['body_lemmatized'] = train_data['body'].apply(lambda text: ' '.join([token.lemma_ for token in nlp(text)]))\n",
    "\n",
    "# Lemmatisation pour le champ \"title\" dans l'ensemble de test\n",
    "test_data['title_lemmatized'] = test_data['title'].apply(lambda text: ' '.join([token.lemma_ for token in nlp(text)]))\n",
    "\n",
    "# Lemmatisation pour le champ \"body\" dans l'ensemble de test\n",
    "test_data['body_lemmatized'] = test_data['body'].apply(lambda text: ' '.join([token.lemma_ for token in nlp(text)]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T19:47:18.657677Z",
     "start_time": "2023-12-12T19:47:12.075085Z"
    }
   },
   "id": "d7ba1d10f6e0ec7f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CountVectorizer"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3004dc1385e6e67f"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer_title = CountVectorizer()\n",
    "X_title_train = vectorizer_title.fit_transform(train_data['title_lemmatized'])\n",
    "X_title_test = vectorizer_title.transform(test_data['title_lemmatized'])\n",
    "\n",
    "vectorizer_body = CountVectorizer()\n",
    "X_body_train = vectorizer_body.fit_transform(train_data['body_lemmatized'])\n",
    "X_body_test = vectorizer_body.transform(test_data['body_lemmatized'])\n",
    "\n",
    "# Afficher les caractéristiques (mots) apprises par le vectorizer pour le titre\n",
    "feature_names_title = vectorizer_title.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T19:47:18.669550Z",
     "start_time": "2023-12-12T19:47:18.665175Z"
    }
   },
   "id": "c4b0eaa0a6693545"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tf-idf"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "80f644ee32e09efc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "import spacy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "tfidf_vectorizer_title = TfidfVectorizer()\n",
    "X_title_train_tfidf = tfidf_vectorizer_title.fit_transform(train_data['title_lemmatized'])\n",
    "\n",
    "X_title_test_tfidf = tfidf_vectorizer_title.transform(test_data['title_lemmatized'])\n",
    "\n",
    "tfidf_vectorizer_body = TfidfVectorizer()\n",
    "X_body_train_tfidf = tfidf_vectorizer_body.fit_transform(train_data['body_lemmatized'])\n",
    "\n",
    "X_body_test_tfidf = tfidf_vectorizer_body.transform(test_data['body_lemmatized'])\n",
    "\n",
    "feature_names_title = tfidf_vectorizer_title.get_feature_names_out()\n",
    "print(\"Caractéristiques (mots) apprises par le vectorizer pour 'title':\")\n",
    "print(feature_names_title)\n",
    "\n",
    "print(\"Matrice TF-IDF pour 'title' dans l'ensemble d'entraînement:\")\n",
    "print(X_title_train_tfidf.toarray())\n",
    "\n",
    "print(\"Matrice TF-IDF pour 'title' dans l'ensemble de test:\")\n",
    "print(X_title_test_tfidf.toarray())\n",
    "\n",
    "feature_names_body = tfidf_vectorizer_body.get_feature_names_out()\n",
    "print(\"Caractéristiques (mots) apprises par le vectorizer pour 'body':\")\n",
    "print(feature_names_body)\n",
    "\n",
    "print(\"Matrice TF-IDF pour 'body' dans l'ensemble d'entraînement:\")\n",
    "print(X_body_train_tfidf.toarray())\n",
    "\n",
    "print(\"Matrice TF-IDF pour 'body' dans l'ensemble de test:\")\n",
    "print(X_body_test_tfidf.toarray())\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eb7f25a77d26abe7"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "# Exécutez la tâche d'apprentissage machine avec le chemin de votre jeu de données\n",
    "# train_and_evaluate(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T19:47:18.672467Z",
     "start_time": "2023-12-12T19:47:18.670683Z"
    }
   },
   "id": "3240f234e92fe52f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
