{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Notebook Requêtes API"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "11c7ec3c6e89a76b"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "What does this do, and why should one include the  if  statement? \n",
      " if __name__ == \"__main__\":\n",
      "    print(\"Hello, World!\")\n",
      " \n",
      " \n",
      " If you are trying to close a question where someone should be using this idiom and isn't, consider closing as a duplicate of  Why is Python running my module when I import it, and how do I stop it?  instead. For questions where someone simply hasn't called any functions, or incorrectly expects a function named  main  to be used as an entry point automatically, use  Why doesn't the main() function run when I start a Python script? Where does the script start running? . \n",
      "\n",
      "What are  metaclasses ? What are they used for? \n",
      "\n",
      "How do I call an external command within Python as if I had typed it in a shell or command prompt? \n",
      "\n",
      "How do I create a directory at a given path, and also create any missing parent directories along that path? For example, the Bash command  mkdir -p /path/to/nested/directory  does this. \n",
      "\n",
      "What is the difference between a method  decorated  with  @staticmethod  and one decorated with  @classmethod ? \n",
      "\n",
      "How do I copy a file in Python? \n",
      "\n",
      "What do  *args  and  **kwargs  mean in these function definitions? \n",
      " def foo(x, y, *args):\n",
      "    pass\n",
      "\n",
      "def bar(x, y, **kwargs):\n",
      "    pass\n",
      " \n",
      " \n",
      " See  What do ** (double star/asterisk) and * (star/asterisk) mean in a function call?  for the complementary question about arguments. \n",
      "\n",
      "Why is  super()  used? \n",
      " Is there a difference between using  Base.__init__  and  super().__init__ ? \n",
      " class Base(object):\n",
      "    def __init__(self):\n",
      "        print \"Base created\"\n",
      "        \n",
      "class ChildA(Base):\n",
      "    def __init__(self):\n",
      "        Base.__init__(self)\n",
      "        \n",
      "class ChildB(Base):\n",
      "    def __init__(self):\n",
      "        super(ChildB, self).__init__()\n",
      "        \n",
      "ChildA() \n",
      "ChildB()\n",
      " \n",
      "\n",
      "How do I change the size of figure drawn with Matplotlib? \n",
      "\n",
      "How do I make two decorators in Python that would do the following? \n",
      " @make_bold\n",
      "@make_italic\n",
      "def say():\n",
      "   return \"Hello\"\n",
      " \n",
      " Calling  say()  should return: \n",
      " \"<b><i>Hello</i></b>\"\n",
      " \n",
      "\n",
      "What's the difference between the list methods  append()  and  extend() ? \n",
      "\n",
      "It is my understanding that the  range()  function, which is actually  an object type in Python 3 , generates its contents on the fly, similar to a generator. \n",
      " This being the case, I would have expected the following line to take an inordinate amount of time because, in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated: \n",
      " 1_000_000_000_000_000 in range(1_000_000_000_000_001)\n",
      " \n",
      " Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous). \n",
      " I have also tried things like this, but the calculation is still almost instant: \n",
      " # count by tens\n",
      "1_000_000_000_000_000_000_000 in range(0,1_000_000_000_000_000_000_001,10)\n",
      " \n",
      " If I try to implement my own range function, the result is not so nice! \n",
      " def my_crappy_range(N):\n",
      "    i = 0\n",
      "    while i < N:\n",
      "        yield i\n",
      "        i += 1\n",
      "    return\n",
      " \n",
      " What is the  range()  object doing under the hood that makes it so fast? \n",
      " \n",
      " Martijn Pieters's answer  was chosen for its completeness, but also see  abarnert's first answer  for a good discussion of what it means for  range  to be a full-fledged  sequence  in Python 3, and some information/warning regarding potential inconsistency for  __contains__  function optimization across Python implementations.  abarnert's other answer  goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of  xrange  in Python 2). Answers  by poke  and  by wim  provide the relevant C source code and explanations for those who are interested. \n",
      "\n",
      "I want to change the column labels of a Pandas DataFrame from \n",
      " ['$a', '$b', '$c', '$d', '$e']\n",
      " \n",
      " to \n",
      " ['a', 'b', 'c', 'd', 'e']\n",
      " \n",
      "\n",
      "How do I sort a list of dictionaries by a specific key's value? Given: \n",
      " [{'name': 'Homer', 'age': 39}, {'name': 'Bart', 'age': 10}]\n",
      " \n",
      " When sorted by  name , it should become: \n",
      " [{'name': 'Bart', 'age': 10}, {'name': 'Homer', 'age': 39}]\n",
      " \n",
      "\n",
      "How can I convert an  str  to a  float ? \n",
      " \"545.2222\" -> 545.2222\n",
      " \n",
      " Or an  str  to a  int ? \n",
      " \"31\" -> 31\n",
      " \n",
      " \n",
      " For the reverse, see  Convert integer to string in Python  and  Converting a float to a string without rounding it . \n",
      " Please instead use  How can I read inputs as numbers?  to close duplicate questions where OP received a string  from user input  and immediately wants to convert it, or was hoping for  input  (in 3.x) to convert the type automatically. \n",
      "\n",
      "Non-working example: \n",
      " print(\" \\{ Hello \\} {0} \".format(42))\n",
      " \n",
      " Desired output: \n",
      "  {Hello} 42 \n",
      " \n",
      "\n",
      "How do I check if an object has some attribute? For example: \n",
      " >>> a = SomeClass()\n",
      ">>> a.property\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "AttributeError: SomeClass instance has no attribute 'property'\n",
      " \n",
      " How do I tell if  a  has the attribute  property  before using it? \n",
      "\n",
      "I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something. \n",
      " \n",
      " ( TLDR answer:  include the statement:  cin.sync_with_stdio(false)  or just use  fgets  instead. \n",
      " TLDR results:  scroll all the way down to the bottom of my question and look at the table.) \n",
      " \n",
      " C++ code: \n",
      " #include <iostream>\n",
      "#include <time.h>\n",
      "\n",
      "using namespace std;\n",
      "\n",
      "int main() {\n",
      "    string input_line;\n",
      "    long line_count = 0;\n",
      "    time_t start = time(NULL);\n",
      "    int sec;\n",
      "    int lps;\n",
      "\n",
      "    while (cin) {\n",
      "        getline(cin, input_line);\n",
      "        if (!cin.eof())\n",
      "            line_count++;\n",
      "    };\n",
      "\n",
      "    sec = (int) time(NULL) - start;\n",
      "    cerr << \"Read \" << line_count << \" lines in \" << sec << \" seconds.\";\n",
      "    if (sec > 0) {\n",
      "        lps = line_count / sec;\n",
      "        cerr << \" LPS: \" << lps << endl;\n",
      "    } else\n",
      "        cerr << endl;\n",
      "    return 0;\n",
      "}\n",
      "\n",
      "// Compiled with:\n",
      "// g++ -O3 -o readline_test_cpp foo.cpp\n",
      " \n",
      " Python Equivalent: \n",
      " #!/usr/bin/env python\n",
      "import time\n",
      "import sys\n",
      "\n",
      "count = 0\n",
      "start = time.time()\n",
      "\n",
      "for line in  sys.stdin:\n",
      "    count += 1\n",
      "\n",
      "delta_sec = int(time.time() - start_time)\n",
      "if delta_sec >= 0:\n",
      "    lines_per_sec = int(round(count/delta_sec))\n",
      "    print(\"Read {0} lines in {1} seconds. LPS: {2}\".format(count, delta_sec,\n",
      "       lines_per_sec))\n",
      " \n",
      " Here are my results: \n",
      " $ cat test_lines | ./readline_test_cpp\n",
      "Read 5570000 lines in 9 seconds. LPS: 618889\n",
      "\n",
      "$ cat test_lines | ./readline_test.py\n",
      "Read 5570000 lines in 1 seconds. LPS: 5570000\n",
      " \n",
      " I should note that I tried this both under Mac OS X v10.6.8 (Snow Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent. \n",
      " $ for i in {1..5}; do echo \"Test run $i at `date`\"; echo -n \"CPP:\"; cat test_lines | ./readline_test_cpp ; echo -n \"Python:\"; cat test_lines | ./readline_test.py ; done\n",
      " \n",
      " Test run 1 at Mon Feb 20 21:29:28 EST 2012\n",
      "CPP:   Read 5570001 lines in 9 seconds. LPS: 618889\n",
      "Python:Read 5570000 lines in 1 seconds. LPS: 5570000\n",
      "Test run 2 at Mon Feb 20 21:29:39 EST 2012\n",
      "CPP:   Read 5570001 lines in 9 seconds. LPS: 618889\n",
      "Python:Read 5570000 lines in 1 seconds. LPS: 5570000\n",
      "Test run 3 at Mon Feb 20 21:29:50 EST 2012\n",
      "CPP:   Read 5570001 lines in 9 seconds. LPS: 618889\n",
      "Python:Read 5570000 lines in 1 seconds. LPS: 5570000\n",
      "Test run 4 at Mon Feb 20 21:30:01 EST 2012\n",
      "CPP:   Read 5570001 lines in 9 seconds. LPS: 618889\n",
      "Python:Read 5570000 lines in 1 seconds. LPS: 5570000\n",
      "Test run 5 at Mon Feb 20 21:30:11 EST 2012\n",
      "CPP:   Read 5570001 lines in 10 seconds. LPS: 557000\n",
      "Python:Read 5570000 lines in  1 seconds. LPS: 5570000\n",
      " \n",
      " \n",
      " Tiny benchmark addendum and recap \n",
      " For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the comparison, with several solutions/approaches: \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " Implementation \n",
      " Lines per second \n",
      " \n",
      " \n",
      " \n",
      " \n",
      " python (default) \n",
      " 3,571,428 \n",
      " \n",
      " \n",
      " cin (default/naive) \n",
      " 819,672 \n",
      " \n",
      " \n",
      " cin (no sync) \n",
      " 12,500,000 \n",
      " \n",
      " \n",
      " fgets \n",
      " 14,285,714 \n",
      " \n",
      " \n",
      " wc (not fair comparison) \n",
      " 54,644,808 \n",
      " \n",
      " \n",
      " \n",
      "\n",
      "We are working on an  S60  version and this platform has a nice Python API.. \n",
      " However, there is nothing official about Python on Android, but since  Jython  exists, is there a way to let the snake and the robot work together?? \n",
      "\n",
      "Python 3.3 includes in its standard library the new package  venv . What does it do, and how does it differ from all the other packages that match the regex  (py)?(v|virtual|pip)?env ? \n",
      "\n",
      "I am trying to install version 1.2.2 of  MySQL_python , using a fresh virtualenv created with the  --no-site-packages  option. The current version shown in PyPi is  1.2.3 . Is there a way to install the older version? I have tried: \n",
      " pip install MySQL_python==1.2.2\n",
      " \n",
      " However, when installed, it still shows  MySQL_python-1.2.3-py2.6.egg-info  in the site packages. Is this a problem specific to this package, or am I doing something wrong? \n",
      "\n",
      "How do I select columns  a  and  b  from  df , and save them into a new dataframe  df1 ? \n",
      " index  a   b   c\n",
      "1      2   3   4\n",
      "2      3   4   5\n",
      " \n",
      " Unsuccessful attempt: \n",
      " df1 = df['a':'b']\n",
      "df1 = df.ix[:, 'a':'b']\n",
      " \n",
      "\n",
      "I've been here: \n",
      " \n",
      " PEP 328 – Imports: Multi-Line and Absolute/Relative \n",
      " Modules, Packages \n",
      " Python packages: relative imports \n",
      " Python relative import example code does not work \n",
      " Relative imports in Python 2.5 \n",
      " Relative imports in Python \n",
      " Python: Disabling relative import \n",
      " \n",
      " and plenty of URLs that I did not copy, some on SO, some on other sites, back when I thought I'd have the solution quickly. \n",
      " The forever-recurring question is this: how do I solve this \"Attempted relative import in non-package\" message? \n",
      " \n",
      " ImportError: attempted relative import with no known parent package \n",
      " \n",
      " I built an exact replica of the package on pep-0328: \n",
      " package/\n",
      "    __init__.py\n",
      "    subpackage1/\n",
      "        __init__.py\n",
      "        moduleX.py\n",
      "        moduleY.py\n",
      "    subpackage2/\n",
      "        __init__.py\n",
      "        moduleZ.py\n",
      "    moduleA.py\n",
      " \n",
      " The imports were done from the console. \n",
      " I did make functions named spam and eggs in their appropriate modules.  Naturally, it didn't work.  The answer is apparently in the 4th URL I listed, but it's all alumni to me. There was this response on one of the URLs I visited: \n",
      " \n",
      " Relative imports use a module's name attribute to determine that module's position in the package hierarchy. If the module's name does not contain any package information (e.g. it is set to 'main') then relative imports are resolved as if the module were a top level module, regardless of where the module is actually located on the file system. \n",
      " \n",
      " The above response looks promising, but it's all hieroglyphs to me. How do I make Python not return to me \"Attempted relative import in non-package\"? It has an answer that involves  -m , supposedly. \n",
      " Why does Python give that error message? What does by \"non-package\" mean? Why and how do you define a 'package'? \n",
      "\n",
      "Project Euler  and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to  __main__ . \n",
      " What is a good way to profile how long a Python program takes to run? \n",
      "\n",
      "Why does the following class declaration inherit from  object ? \n",
      " class MyClass(object):\n",
      "    ...\n",
      " \n",
      "\n",
      "This question is not for the discussion of whether or not the  singleton design pattern  is desirable, is an anti-pattern, or for any religious wars, but to discuss how this pattern is best implemented in Python in such a way that is most pythonic. In this instance I define 'most pythonic' to mean that it follows the 'principle of least astonishment' . \n",
      " I have multiple classes which would become singletons (my use-case is for a logger, but this is not important). I do not wish to clutter several classes with added gumph when I can simply inherit or decorate. \n",
      " Best methods: \n",
      " \n",
      " Method 1: A decorator \n",
      " def singleton(class_):\n",
      "    instances = {}\n",
      "    def getinstance(*args, **kwargs):\n",
      "        if class_ not in instances:\n",
      "            instances[class_] = class_(*args, **kwargs)\n",
      "        return instances[class_]\n",
      "    return getinstance\n",
      "\n",
      "@singleton\n",
      "class MyClass(BaseClass):\n",
      "    pass\n",
      " \n",
      " Pros \n",
      " \n",
      " Decorators are additive in a way that is often more intuitive than multiple inheritance. \n",
      " \n",
      " Cons \n",
      " \n",
      " While objects created using  MyClass()  would be true singleton objects,  MyClass  itself is a function, not a class, so you cannot call class methods from it. Also for \n",
      " x = MyClass();\n",
      "y = MyClass();\n",
      "t = type(n)();\n",
      " \n",
      " \n",
      " \n",
      " then  x == y  but  x != t && y != t \n",
      " \n",
      " Method 2: A base class \n",
      " class Singleton(object):\n",
      "    _instance = None\n",
      "    def __new__(class_, *args, **kwargs):\n",
      "        if not isinstance(class_._instance, class_):\n",
      "            class_._instance = object.__new__(class_, *args, **kwargs)\n",
      "        return class_._instance\n",
      "\n",
      "class MyClass(Singleton, BaseClass):\n",
      "    pass\n",
      " \n",
      " Pros \n",
      " \n",
      " It's a true class \n",
      " \n",
      " Cons \n",
      " \n",
      " Multiple inheritance - eugh!  __new__  could be overwritten during inheritance from a second base class? One has to think more than is necessary. \n",
      " \n",
      " \n",
      " Method 3: A  metaclass \n",
      " class Singleton(type):\n",
      "    _instances = {}\n",
      "    def __call__(cls, *args, **kwargs):\n",
      "        if cls not in cls._instances:\n",
      "            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
      "        return cls._instances[cls]\n",
      "\n",
      "#Python2\n",
      "class MyClass(BaseClass):\n",
      "    __metaclass__ = Singleton\n",
      "\n",
      "#Python3\n",
      "class MyClass(BaseClass, metaclass=Singleton):\n",
      "    pass\n",
      " \n",
      " Pros \n",
      " \n",
      " It's a true class \n",
      " Auto-magically covers inheritance \n",
      " Uses  __metaclass__  for its proper purpose (and made me aware of it) \n",
      " \n",
      " Cons \n",
      " \n",
      " Are there any? \n",
      " \n",
      " \n",
      " Method 4: decorator returning a class with the same name \n",
      " def singleton(class_):\n",
      "    class class_w(class_):\n",
      "        _instance = None\n",
      "        def __new__(class_, *args, **kwargs):\n",
      "            if class_w._instance is None:\n",
      "                class_w._instance = super(class_w,\n",
      "                                    class_).__new__(class_,\n",
      "                                                    *args,\n",
      "                                                    **kwargs)\n",
      "                class_w._instance._sealed = False\n",
      "            return class_w._instance\n",
      "        def __init__(self, *args, **kwargs):\n",
      "            if self._sealed:\n",
      "                return\n",
      "            super(class_w, self).__init__(*args, **kwargs)\n",
      "            self._sealed = True\n",
      "    class_w.__name__ = class_.__name__\n",
      "    return class_w\n",
      "\n",
      "@singleton\n",
      "class MyClass(BaseClass):\n",
      "    pass\n",
      " \n",
      " Pros \n",
      " \n",
      " It's a true class \n",
      " Auto-magically covers inheritance \n",
      " \n",
      " Cons \n",
      " \n",
      " Is there not an overhead for creating each new class? Here we are creating two classes for each class we wish to make a singleton. While this is fine in my case, I worry that this might not scale. Of course there is a matter of debate as to whether it aught to be too easy to scale this pattern... \n",
      " What is the point of the  _sealed  attribute \n",
      " Can't call methods of the same name on base classes using  super()  because they will recurse. This means you can't customize  __new__  and can't subclass a class that needs you to call up to  __init__ . \n",
      " \n",
      " \n",
      " Method 5: a module \n",
      " a module file  singleton.py \n",
      " Pros \n",
      " \n",
      " Simple is better than complex \n",
      " \n",
      " Cons \n",
      " \n",
      " Not lazily instantiated \n",
      " \n",
      "\n",
      "I have the following DataFrame ( df ): \n",
      " import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "df = pd.DataFrame(np.random.rand(10, 5))\n",
      " \n",
      " I add more column(s) by assignment: \n",
      " df['mean'] = df.mean(1)\n",
      " \n",
      " How can I move the column  mean  to the front, i.e. set it as first column leaving the order of the other columns untouched? \n",
      "\n",
      "I created a DataFrame from a list of lists: \n",
      " table = [\n",
      "    ['a',  '1.2',  '4.2' ],\n",
      "    ['b',  '70',   '0.03'],\n",
      "    ['x',  '5',    '0'   ],\n",
      "]\n",
      "\n",
      "df = pd.DataFrame(table)\n",
      " \n",
      " How do I convert the columns to specific types? In this case, I want to convert columns 2 and 3 into floats. \n",
      " Is there a way to specify the types while converting the list to DataFrame? Or is it better to create the DataFrame first and then loop through the columns to change the dtype for each column? Ideally I would like to do this in a dynamic way because there can be hundreds of columns, and I don't want to specify exactly which columns are of which type. All I can guarantee is that each column contains values of the same type. \n",
      "\n",
      "I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.  \n",
      " The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a  UnicodeEncodeError . I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error. \n",
      " One of the sections of code that is causing problems is shown below: \n",
      " agent_telno = agent.find('div', 'agent_contact_number')\n",
      "agent_telno = '' if agent_telno is None else agent_telno.contents[0]\n",
      "p.agent_info = str(agent_contact + ' ' + agent_telno).strip()\n",
      " \n",
      " Here is a stack trace produced on SOME strings when the snippet above is run: \n",
      " Traceback (most recent call last):\n",
      "  File \"foobar.py\", line 792, in <module>\n",
      "    p.agent_info = str(agent_contact + ' ' + agent_telno).strip()\n",
      "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)\n",
      " \n",
      " I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English. \n",
      " Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem? \n",
      "\n",
      "So what I'm looking for here is something like PHP's  print_r  function. \n",
      " This is so I can debug my scripts by seeing what's the state of the object in question. \n",
      "\n",
      "How can I check if a list has any duplicates and return a new list without duplicates? \n",
      "\n",
      "I have this DataFrame and want only the records whose EPS column is not NaN: \n",
      "                  STK_ID  EPS  cash\n",
      "STK_ID RPT_Date                   \n",
      "601166 20111231  601166  NaN   NaN\n",
      "600036 20111231  600036  NaN    12\n",
      "600016 20111231  600016  4.3   NaN\n",
      "601009 20111231  601009  NaN   NaN\n",
      "601939 20111231  601939  2.5   NaN\n",
      "000001 20111231  000001  NaN   NaN\n",
      " \n",
      " ...i.e. something like  df.drop(....)  to get this resulting dataframe: \n",
      "                   STK_ID  EPS  cash\n",
      "STK_ID RPT_Date                   \n",
      "600016 20111231  600016  4.3   NaN\n",
      "601939 20111231  601939  2.5   NaN\n",
      " \n",
      " How do I do that? \n",
      "\n",
      "Background \n",
      " I just upgraded my Pandas from 0.11 to 0.13.0rc1. Now, the application is popping out many new warnings. One of them like this: \n",
      " E:\\FinReporter\\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n",
      "  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE\n",
      " \n",
      " I want to know what exactly it means?  Do I need to change something? \n",
      " How should I suspend the warning if I insist to use  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE ? \n",
      " The function that gives warnings \n",
      " def _decode_stock_quote(list_of_150_stk_str):\n",
      "    \"\"\"decode the webpage and return dataframe\"\"\"\n",
      "\n",
      "    from cStringIO import StringIO\n",
      "\n",
      "    str_of_all = \"\".join(list_of_150_stk_str)\n",
      "\n",
      "    quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\n",
      "    quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\n",
      "    quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]\n",
      "    quote_df['TClose'] = quote_df['TPrice']\n",
      "    quote_df['RT']     = 100 * (quote_df['TPrice']/quote_df['TPCLOSE'] - 1)\n",
      "    quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE\n",
      "    quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE\n",
      "    quote_df['STK_ID'] = quote_df['STK'].str.slice(13,19)\n",
      "    quote_df['STK_Name'] = quote_df['STK'].str.slice(21,30)#.decode('gb2312')\n",
      "    quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])\n",
      "    \n",
      "    return quote_df\n",
      " \n",
      " More warning messages \n",
      " E:\\FinReporter\\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n",
      "  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE\n",
      "E:\\FinReporter\\FM_EXT.py:450: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n",
      "  quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE\n",
      "E:\\FinReporter\\FM_EXT.py:453: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n",
      "  quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])\n",
      " \n",
      "\n",
      "I would like to understand how the built-in function  property  works. What confuses me is that  property  can also be used as a decorator, but it only takes arguments when used as a built-in function and not when used as a decorator. \n",
      " This example is from the  documentation : \n",
      " class C:\n",
      "    def __init__(self):\n",
      "        self._x = None\n",
      "\n",
      "    def getx(self):\n",
      "        return self._x\n",
      "    def setx(self, value):\n",
      "        self._x = value\n",
      "    def delx(self):\n",
      "        del self._x\n",
      "    x = property(getx, setx, delx, \"I'm the 'x' property.\")\n",
      " \n",
      " property 's arguments are  getx ,  setx ,  delx  and a doc string. \n",
      " In the code below  property  is used as a decorator. The object of it is the  x  function, but in the code above there is no place for an object function in the arguments. \n",
      " class C:\n",
      "    def __init__(self):\n",
      "        self._x = None\n",
      "\n",
      "    @property\n",
      "    def x(self):\n",
      "        \"\"\"I'm the 'x' property.\"\"\"\n",
      "        return self._x\n",
      "\n",
      "    @x.setter\n",
      "    def x(self, value):\n",
      "        self._x = value\n",
      "\n",
      "    @x.deleter\n",
      "    def x(self):\n",
      "        del self._x\n",
      " \n",
      " How are the  x.setter  and  x.deleter  decorators created in this case? \n",
      "\n",
      "I want to get a list of the column headers from a Pandas DataFrame.  The DataFrame will come from user input, so I won't know how many columns there will be or what they will be called. \n",
      " For example, if I'm given a DataFrame like this: \n",
      "     y  gdp  cap\n",
      "0   1    2    5\n",
      "1   2    3    9\n",
      "2   8    7    2\n",
      "3   3    4    7\n",
      "4   6    7    7\n",
      "5   4    8    3\n",
      "6   8    2    8\n",
      "7   9    9   10\n",
      "8   6    6    4\n",
      "9  10   10    7\n",
      " \n",
      " I would get a list like this: \n",
      " ['y', 'gdp', 'cap']\n",
      " \n",
      "\n",
      "In  Programming Python , Mark Lutz mentions the term  mixin . I am from a C/C++/C# background and I have not heard the term before. What is a mixin? \n",
      " Reading between the lines of  this example  (which I have linked to because it is quite long), I am presuming it is a case of using multiple inheritance to extend a class as opposed to proper subclassing. Is this right? \n",
      " Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition? \n",
      " What separates a mixin from multiple inheritance? Is it just a matter of semantics? \n",
      "\n",
      "Two string variables are set to the same value.  s1 == s2  always returns  True , but  s1 is s2  sometimes returns  False . \n",
      " If I open my Python interpreter and do the same  is  comparison, it succeeds: \n",
      " >>> s1 = 'text'\n",
      ">>> s2 = 'text'\n",
      ">>> s1 is s2\n",
      "True\n",
      " \n",
      " Why is this? \n",
      "\n",
      "I have two lists in Python: \n",
      " temp1 = ['One', 'Two', 'Three', 'Four']\n",
      "temp2 = ['One', 'Two']\n",
      " \n",
      " Assuming the elements in each list are unique, I want to create a third list with items from the first list which are not in the second list: \n",
      " temp3 = ['Three', 'Four']\n",
      " \n",
      " Are there any fast ways without cycles and checking? \n",
      "\n",
      "I have the following code in Python 3: \n",
      " class Position:\n",
      "\n",
      "    def __init__(self, x: int, y: int):\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "\n",
      "    def __add__(self, other: Position) -> Position:\n",
      "        return Position(self.x + other.x, self.y + other.y)\n",
      " \n",
      " But my editor (PyCharm) says that the reference  Position  can not be resolved (in the  __add__  method). How should I specify that I expect the return type to be of type  Position ? \n",
      " Edit: I think this is actually a PyCharm issue. It actually uses the information in its warnings, and code completion. \n",
      " \n",
      " But correct me if I'm wrong, and need to use some other syntax. \n",
      "\n",
      "Is there a Python function that will trim whitespace (spaces and tabs) from a string? \n",
      " So that given input  \"  \\t example string\\t  \"  becomes  \"example string\" . \n",
      "\n",
      "\n",
      " What are named tuples and how do I use them? \n",
      " When should I use named tuples instead of normal tuples, or vice versa? \n",
      " Are there \"named lists\" too? (i.e. mutable named tuples) \n",
      " \n",
      " \n",
      " For the last question specifically, see also  Existence of mutable named tuple in Python? . \n",
      "\n",
      "I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons. \n",
      " One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive. \n",
      " My first thought is to use  HDFStore  to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this: \n",
      " What are some best-practice workflows for accomplishing the following: \n",
      " \n",
      " Loading flat files into a permanent, on-disk database structure \n",
      " Querying that database to retrieve data to feed into a pandas data structure \n",
      " Updating the database after manipulating pieces in pandas \n",
      " \n",
      " Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\". \n",
      " Edit -- an example of how I would like this to work: \n",
      " \n",
      " Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. \n",
      " In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. \n",
      " I would create new columns by performing various operations on the selected columns. \n",
      " I would then have to append these new columns into the database structure. \n",
      " \n",
      " I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem. \n",
      " Edit -- Responding to Jeff's questions specifically: \n",
      " \n",
      " I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. \n",
      " Typical operations involve combining several columns using conditional logic into a new, compound column. For example,  if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B' .  The result of these operations is a new column for every record in my dataset. \n",
      " Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. \n",
      " A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. \n",
      " It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. \n",
      " The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns. \n",
      " \n",
      " It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance). \n",
      "\n",
      "What is the difference between old style and new style classes in Python?  When should I use one or the other? \n",
      "\n",
      "I have a list that I want to filter by an attribute of the items. \n",
      " Which of the following is preferred (readability, performance, other reasons)? \n",
      " xs = [x for x in xs if x.attribute == value]\n",
      " \n",
      " xs = filter(lambda x: x.attribute == value, xs)\n",
      " \n",
      "\n",
      "I know  pip  is a package manager for python packages. However, I saw the installation on IPython's website use  conda  to install IPython. \n",
      " Can I use  pip  to install IPython? Why should I use  conda  as another python package manager when I already have  pip ? \n",
      " What is the difference between  pip  and  conda ? \n",
      "\n",
      "I am running Python 2.5. \n",
      " This is my folder tree: \n",
      " ptdraft/\n",
      "  nib.py\n",
      "  simulations/\n",
      "    life/\n",
      "      life.py\n",
      " \n",
      " (I also have  __init__.py  in each folder, omitted here for readability) \n",
      " How do I import the  nib  module from inside the  life  module? I am hoping it is possible to do without tinkering with sys.path. \n",
      " Note: The main module being run is in the  ptdraft  folder. \n",
      "\n",
      "Coming from a C# background the naming convention for variables and methods are usually either camelCase or PascalCase: \n",
      " // C# example\n",
      "string thisIsMyVariable = \"a\"\n",
      "public void ThisIsMyMethod()\n",
      " \n",
      " In Python, I have seen the above but I have also seen snake_case being used: \n",
      " # python example\n",
      "this_is_my_variable = 'a'\n",
      "def this_is_my_function():\n",
      " \n",
      " Is there a more preferable, definitive coding style for Python? \n",
      "\n",
      "How do I get the size occupied in memory by an object in Python? \n",
      "\n",
      "I'm trying to get a Python 3 program to do some manipulations with a text file filled with information. However, when trying to read the file I get the following error: \n",
      " Traceback (most recent call last):  \n",
      "  File \"SCRIPT LOCATION\", line NUMBER, in <module>  \n",
      "    text = file.read()\n",
      "  File \"C:\\Python31\\lib\\encodings\\cp1252.py\", line 23, in decode  \n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 2907500: character maps to `<undefined>`  \n",
      " \n",
      " \n",
      " After reading this Q&A, see  How to determine the encoding of text  if you need help figuring out the encoding of the file you are trying to open. \n",
      "\n",
      "How do I remove duplicates from a list, while preserving order? Using a set to remove duplicates destroys the original order.\n",
      "Is there a built-in or a Pythonic idiom? \n",
      "\n",
      "In Python, what are the differences between the  urllib ,  urllib2 ,  urllib3  and  requests  modules? Why are there three? They seem to do the same thing... \n",
      "\n",
      "I would like to list all files recursively in a directory. I currently have a directory structure like this: \n",
      " \n",
      " src/main.c \n",
      " src/dir/file1.c \n",
      " src/another-dir/file2.c \n",
      " src/another-dir/nested/files/file3.c \n",
      " \n",
      " I've tried to do the following: \n",
      " from glob import glob\n",
      "\n",
      "glob(os.path.join('src','*.c'))\n",
      " \n",
      " But this will only get be files directly in the  src  subfolder, e.g. I get  main.c  but I will not get  file1.c ,  file2.c  etc. \n",
      " from glob import glob\n",
      "\n",
      "glob(os.path.join('src','*.c'))\n",
      "glob(os.path.join('src','*','*.c'))\n",
      "glob(os.path.join('src','*','*','*.c'))\n",
      "glob(os.path.join('src','*','*','*','*.c'))\n",
      " \n",
      " But this is obviously limited and clunky, how can I do this properly? \n",
      "\n",
      "I have the following DataFrame: \n",
      "              daysago  line_race rating        rw    wrating\n",
      " line_date                                                 \n",
      "2007-03-31       62         11     56  1.000000  56.000000\n",
      "2007-03-10       83         11     67  1.000000  67.000000\n",
      "2007-02-10      111          9     66  1.000000  66.000000\n",
      "2007-01-13      139         10     83  0.880678  73.096278\n",
      "2006-12-23      160         10     88  0.793033  69.786942\n",
      "2006-11-09      204          9     52  0.636655  33.106077\n",
      "2006-10-22      222          8     66  0.581946  38.408408\n",
      "2006-09-29      245          9     70  0.518825  36.317752\n",
      "2006-09-16      258         11     68  0.486226  33.063381\n",
      "2006-08-30      275          8     72  0.446667  32.160051\n",
      "2006-02-11      475          5     65  0.164591  10.698423\n",
      "2006-01-13      504          0     70  0.142409   9.968634\n",
      "2006-01-02      515          0     64  0.134800   8.627219\n",
      "2005-12-06      542          0     70  0.117803   8.246238\n",
      "2005-11-29      549          0     70  0.113758   7.963072\n",
      "2005-11-22      556          0     -1  0.109852  -0.109852\n",
      "2005-11-01      577          0     -1  0.098919  -0.098919\n",
      "2005-10-20      589          0     -1  0.093168  -0.093168\n",
      "2005-09-27      612          0     -1  0.083063  -0.083063\n",
      "2005-09-07      632          0     -1  0.075171  -0.075171\n",
      "2005-06-12      719          0     69  0.048690   3.359623\n",
      "2005-05-29      733          0     -1  0.045404  -0.045404\n",
      "2005-05-02      760          0     -1  0.039679  -0.039679\n",
      "2005-04-02      790          0     -1  0.034160  -0.034160\n",
      "2005-03-13      810          0     -1  0.030915  -0.030915\n",
      "2004-11-09      934          0     -1  0.016647  -0.016647\n",
      " \n",
      " I need to remove the rows where  line_race  is equal to  0 . What's the most efficient way to do this? \n",
      "\n",
      "Is it possible to terminate a running thread without setting/checking any flags/semaphores/etc.? \n",
      "\n",
      "I would like to know what are all the possible values for the timezone argument in the Python library pytz. How to do it? \n",
      "\n",
      "A  tweet  reads:  \n",
      " \n",
      " Don't use easy_install, unless you\n",
      "  like stabbing yourself in the face.\n",
      "  Use pip. \n",
      " \n",
      " Why use pip over easy_install? Doesn't the  fault lie with PyPI and package authors mostly ? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to  strongly  favor pip over easy_install? \n",
      " (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community) \n",
      "\n",
      "How do I write a list to a file?  writelines()  doesn't insert newline characters, so I need to do: \n",
      " f.writelines([f\"{line}\\n\" for line in lines])\n",
      " \n",
      "\n",
      "I have a dataframe that looks like \n",
      " Year  quarter\n",
      "2000       q2\n",
      "2001       q3\n",
      " \n",
      " How do I add a new column by combining these columns to get the following dataframe? \n",
      " Year  quarter  period\n",
      "2000       q2  2000q2\n",
      "2001       q3  2001q3\n",
      " \n",
      "\n",
      "I am trying to use IPython notebook on MacOS X with Python 2.7.2 and IPython 1.1.0. \n",
      " I cannot get matplotlib graphics to show up inline. \n",
      " import matplotlib\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline  \n",
      " \n",
      " I have also tried  %pylab inline  and the ipython command line arguments  --pylab=inline  but this makes no difference. \n",
      " x = np.linspace(0, 3*np.pi, 500)\n",
      "plt.plot(x, np.sin(x**2))\n",
      "plt.title('A simple chirp')\n",
      "plt.show()\n",
      " \n",
      " Instead of inline graphics, I get this: \n",
      " <matplotlib.figure.Figure at 0x110b9c450>\n",
      " \n",
      " And  matplotlib.get_backend()  shows that I have the  'module://IPython.kernel.zmq.pylab.backend_inline'  backend. \n",
      "\n",
      "Can someone explain how these two methods of slicing are different? I've seen  the docs \n",
      "and I've seen previous similar questions ( 1 ,  2 ), but I still find myself unable to understand how they are different. To me, they seem interchangeable in large part, because they are at the lower levels of slicing. \n",
      " For example, say we want to get the first five rows of a  DataFrame .  How is it that these two work? \n",
      " df.loc[:5]\n",
      "df.iloc[:5]\n",
      " \n",
      " Can someone present cases where the distinction in uses are clearer? \n",
      " \n",
      " Once upon a time, I also wanted to know how these two functions differed from  df.ix[:5]  but  ix  has been removed from pandas 1.0, so I don't care anymore. \n",
      "\n",
      "def main():\n",
      "    for i in xrange(10**8):\n",
      "        pass\n",
      "main()\n",
      " \n",
      " This piece of code in Python runs in  (Note: The timing is done with the time function in BASH in Linux.) \n",
      " real    0m1.841s\n",
      "user    0m1.828s\n",
      "sys     0m0.012s\n",
      " \n",
      " However, if the for loop isn't placed within a function,  \n",
      " for i in xrange(10**8):\n",
      "    pass\n",
      " \n",
      " then it runs for a much longer time: \n",
      " real    0m4.543s\n",
      "user    0m4.524s\n",
      "sys     0m0.012s\n",
      " \n",
      " Why is this? \n",
      "\n",
      "I need to parse  RFC 3339  strings like  \"2008-09-03T20:56:35.450686Z\"  into Python's  datetime  type. \n",
      " I have found  strptime  in the Python standard library, but it is not very convenient. \n",
      " What is the best way to do this? \n",
      "\n",
      "\n",
      " How can I perform a ( INNER | ( LEFT | RIGHT | FULL )  OUTER )  JOIN  with pandas? \n",
      " How do I add NaNs for missing rows after a merge? \n",
      " How do I get rid of NaNs after merging? \n",
      " Can I merge on the index? \n",
      " How do I merge multiple DataFrames? \n",
      " Cross join with pandas \n",
      " merge ?  join ?  concat ?  update ? Who? What? Why?! \n",
      " \n",
      " ... and more. I've seen these recurring questions asking about various facets of the pandas merge functionality. Most of the information regarding merge and its various use cases today is fragmented across dozens of badly worded, unsearchable posts. The aim here is to collate some of the more important points for posterity. \n",
      " This Q&A is meant to be the next installment in a series of helpful user guides on common pandas idioms (see  this post on pivoting , and  this post on concatenation , which I will be touching on, later). \n",
      " Please note that this post is  not  meant to be a replacement for  the documentation , so please read that as well! Some of the examples are taken from there. \n",
      " \n",
      " Table of Contents \n",
      " For ease of access. \n",
      " \n",
      " Merging basics - basic types of joins  (read this first) \n",
      " \n",
      " Index-based joins \n",
      " \n",
      " Generalizing to multiple DataFrames \n",
      " \n",
      " Cross join \n",
      " \n",
      " \n",
      "\n",
      "import ftplib\n",
      "import urllib2\n",
      "import os\n",
      "import logging\n",
      "logger = logging.getLogger('ftpuploader')\n",
      "hdlr = logging.FileHandler('ftplog.log')\n",
      "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
      "hdlr.setFormatter(formatter)\n",
      "logger.addHandler(hdlr)\n",
      "logger.setLevel(logging.INFO)\n",
      "FTPADDR = \"some ftp address\"\n",
      "\n",
      "def upload_to_ftp(con, filepath):\n",
      "    try:\n",
      "        f = open(filepath,'rb')                # file to send\n",
      "        con.storbinary('STOR '+ filepath, f)         # Send the file\n",
      "        f.close()                                # Close file and FTP\n",
      "        logger.info('File successfully uploaded to '+ FTPADDR)\n",
      "    except, e:\n",
      "        logger.error('Failed to upload to ftp: '+ str(e))\n",
      " \n",
      " This doesn't seem to work, I get syntax error, what is the proper way of doing this for logging all kind of exceptions to a file \n",
      "\n",
      "I'm able to update pip-managed packages, but how do I update pip itself? According to  pip --version , I currently have pip 1.1 installed in my virtualenv and I want to update to the latest version.  \n",
      " What's the command for that? Do I need to use distribute or is there a native pip or virtualenv command? I've already tried  pip update  and  pip update pip  with no success. \n",
      "\n",
      "I want to find out the following:\n",
      "given a date ( datetime  object), what is the corresponding day of the week? \n",
      " For instance, Sunday is the first day, Monday: second day.. and so on \n",
      " And then if the input is something like today's date. \n",
      " Example \n",
      " >>> today = datetime.datetime(2017, 10, 20)\n",
      ">>> today.get_weekday()  # what I look for\n",
      " \n",
      " The output is maybe  6  (since it's Friday) \n",
      "\n",
      "I've very recently migrated to Python 3.5.\n",
      "This code was working properly in Python 2.7: \n",
      " with open(fname, 'rb') as f:\n",
      "    lines = [x.strip() for x in f.readlines()]\n",
      "\n",
      "for line in lines:\n",
      "    tmp = line.strip().lower()\n",
      "    if 'some-pattern' in tmp: continue\n",
      "    # ... code\n",
      " \n",
      " But in 3.5, on the  if 'some-pattern' in tmp: continue  line, I get an error which says: \n",
      " TypeError: a bytes-like object is required, not 'str'\n",
      " \n",
      " I was unable to fix the problem using  .decode()  on either side of the  in , nor could I fix it using \n",
      "     if tmp.find('some-pattern') != -1: continue\n",
      " \n",
      " What is wrong, and how do I fix it? \n",
      "\n",
      "I am creating a figure in Matplotlib like this: \n",
      " from matplotlib import pyplot as plt\n",
      "\n",
      "fig = plt.figure()\n",
      "plt.plot(data)\n",
      "fig.suptitle('test title')\n",
      "plt.xlabel('xlabel')\n",
      "plt.ylabel('ylabel')\n",
      "fig.savefig('test.jpg')\n",
      " \n",
      " I want to specify font sizes for the figure title and the axis labels. I need all three to be different font sizes, so setting a global font size ( mpl.rcParams['font.size']=x ) is not what I want. How do I set font sizes for the figure title and the axis labels individually? \n",
      "\n",
      "I tried to install the Python package  dulwich : \n",
      " pip install dulwich\n",
      " \n",
      " But I get a cryptic error message: \n",
      " error: Unable to find vcvarsall.bat\n",
      " \n",
      " The same happens if I try installing the package manually: \n",
      " > python setup.py install\n",
      "running build_ext\n",
      "building 'dulwich._objects' extension\n",
      "error: Unable to find vcvarsall.bat\n",
      " \n",
      "\n",
      "Sample code (in a  REPL ): \n",
      " import json\n",
      "json_string = json.dumps(\"ברי צקלה\")\n",
      "print(json_string)\n",
      " \n",
      " Output: \n",
      " \"\\u05d1\\u05e8\\u05d9 \\u05e6\\u05e7\\u05dc\\u05d4\"\n",
      " \n",
      " The problem: it's not human readable. My (smart) users want to verify or even edit text files with JSON dumps (and I’d rather not use XML). \n",
      " Is there a way to serialize objects into UTF-8 JSON strings (instead of  \\uXXXX )? \n",
      "\n",
      "I have a pandas DataFrame with a column of string values. I need to select rows based on partial string matches. \n",
      " Something like this idiom: \n",
      " re.search(pattern, cell_in_question) \n",
      " \n",
      " returning a boolean. I am familiar with the syntax of  df[df['A'] == \"hello world\"]  but can't seem to find a way to do the same with a partial string match, say  'hello' . \n",
      "\n",
      "Sometimes I want to just insert some print statements in my code, and see what gets printed out when I exercise it. My usual way to \"exercise\" it is with existing pytest tests. But when I run these, I don't seem able to see any standard output (at least from within PyCharm, my IDE). \n",
      " Is there a simple way to see standard output during a pytest run? \n",
      "\n",
      "I want to filter my dataframe with an  or  condition to keep rows with a particular column's values that are outside the range  [-0.25, 0.25] . I tried: \n",
      " df = df[(df['col'] < -0.25) or (df['col'] > 0.25)]\n",
      " \n",
      " But I get the error: \n",
      " \n",
      " ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). \n",
      " \n",
      "\n",
      "How can I achieve the equivalents of SQL's  IN  and  NOT IN ? \n",
      " I have a list with the required values. Here's the scenario: \n",
      " df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\n",
      "countries_to_keep = ['UK', 'China']\n",
      "\n",
      "# pseudo-code:\n",
      "df[df['country'] not in countries_to_keep]\n",
      " \n",
      " My current way of doing this is as follows: \n",
      " df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\n",
      "df2 = pd.DataFrame({'country': ['UK', 'China'], 'matched': True})\n",
      "\n",
      "# IN\n",
      "df.merge(df2, how='inner', on='country')\n",
      "\n",
      "# NOT IN\n",
      "not_in = df.merge(df2, how='left', on='country')\n",
      "not_in = not_in[pd.isnull(not_in['matched'])]\n",
      " \n",
      " But this seems like a horrible kludge. Can anyone improve on it? \n",
      "\n",
      "Apparently xrange is faster but I have no idea why it's faster (and no proof besides the anecdotal so far that it is faster) or what besides that is different about \n",
      " for i in range(0, 20):\n",
      "for i in xrange(0, 20):\n",
      " \n",
      "\n",
      "I'm trying to make a function that will compare multiple variables to an integer and output a string of three letters. I was wondering if there was a way to translate this into Python. So say: \n",
      " x = 0\n",
      "y = 1\n",
      "z = 3\n",
      "mylist = []\n",
      "\n",
      "if x or y or z == 0:\n",
      "    mylist.append(\"c\")\n",
      "if x or y or z == 1:\n",
      "    mylist.append(\"d\")\n",
      "if x or y or z == 2:\n",
      "    mylist.append(\"e\")\n",
      "if x or y or z == 3: \n",
      "    mylist.append(\"f\")\n",
      " \n",
      " which would return a list of: \n",
      " [\"c\", \"d\", \"f\"]\n",
      " \n",
      "\n",
      "What's the difference between a module and package in Python? \n",
      " See also:  What's the difference between \"package\" and \"module\"?  (for other languages) \n",
      "\n",
      "I have the following DataFrame: \n",
      "     Col1  Col2  Col3  Type\n",
      "0      1     2     3     1\n",
      "1      4     5     6     1\n",
      "...\n",
      "20     7     8     9     2\n",
      "21    10    11    12     2\n",
      "...\n",
      "45    13    14    15     3\n",
      "46    16    17    18     3\n",
      "...\n",
      " \n",
      " The DataFrame is read from a CSV file. All rows which have  Type  1 are on top, followed by the rows with  Type  2, followed by the rows with  Type  3, etc. \n",
      " I would like to shuffle the order of the DataFrame's rows so that all  Type 's are mixed. A possible result could be: \n",
      "     Col1  Col2  Col3  Type\n",
      "0      7     8     9     2\n",
      "1     13    14    15     3\n",
      "...\n",
      "20     1     2     3     1\n",
      "21    10    11    12     2\n",
      "...\n",
      "45     4     5     6     1\n",
      "46    16    17    18     3\n",
      "...\n",
      " \n",
      " How can I achieve this? \n",
      "\n",
      "I'm trying to follow  PEP 328 , with the following directory structure: \n",
      " pkg/\n",
      "  __init__.py\n",
      "  components/\n",
      "    core.py\n",
      "    __init__.py\n",
      "  tests/\n",
      "    core_test.py\n",
      "    __init__.py\n",
      " \n",
      " In  core_test.py  I have the following import statement \n",
      " from ..components.core import GameLoopEvents\n",
      " \n",
      " However, when I run, I get the following error: \n",
      " tests$ python core_test.py \n",
      "Traceback (most recent call last):\n",
      "  File \"core_test.py\", line 3, in <module>\n",
      "    from ..components.core import GameLoopEvents\n",
      "ValueError: Attempted relative import in non-package\n",
      " \n",
      " Searching around I found \" relative path not working even with __init__.py \" and \" Import a module from a relative path \" but they didn't help. \n",
      " Is there anything I'm missing here? \n",
      "\n",
      "I'm trying to build the search for a Django site I am building, and in that search, I am searching across three different models. And to get pagination on the search result list, I would like to use a generic object_list view to display the results. But to do that, I have to merge three QuerySets into one. \n",
      " How can I do that? I've tried this: \n",
      " result_list = []\n",
      "page_list = Page.objects.filter(\n",
      "    Q(title__icontains=cleaned_search_term) |\n",
      "    Q(body__icontains=cleaned_search_term))\n",
      "article_list = Article.objects.filter(\n",
      "    Q(title__icontains=cleaned_search_term) |\n",
      "    Q(body__icontains=cleaned_search_term) |\n",
      "    Q(tags__icontains=cleaned_search_term))\n",
      "post_list = Post.objects.filter(\n",
      "    Q(title__icontains=cleaned_search_term) |\n",
      "    Q(body__icontains=cleaned_search_term) |\n",
      "    Q(tags__icontains=cleaned_search_term))\n",
      "\n",
      "for x in page_list:\n",
      "    result_list.append(x)\n",
      "for x in article_list:\n",
      "    result_list.append(x)\n",
      "for x in post_list:\n",
      "    result_list.append(x)\n",
      "\n",
      "return object_list(\n",
      "    request,\n",
      "    queryset=result_list,\n",
      "    template_object_name='result',\n",
      "    paginate_by=10,\n",
      "    extra_context={\n",
      "        'search_term': search_term},\n",
      "    template_name=\"search/result_list.html\")\n",
      " \n",
      " But this doesn't work. I get an error when I try to use that list in the generic view. The list is missing the clone attribute. \n",
      " How can I merge the three lists,  page_list ,  article_list  and  post_list ? \n",
      "\n",
      "How to convert an index of a dataframe into a column? \n",
      " For example: \n",
      "         gi       ptt_loc\n",
      " 0  384444683      593  \n",
      " 1  384444684      594 \n",
      " 2  384444686      596  \n",
      " \n",
      " to \n",
      "     index1    gi       ptt_loc\n",
      " 0  0     384444683      593  \n",
      " 1  1     384444684      594 \n",
      " 2  2     384444686      596  \n",
      " \n",
      "\n",
      "How can I convert a string into uppercase in Python? \n",
      " When I tried to research the problem, I found something about  string.ascii_uppercase , but it couldn't solve the problem: \n",
      " >>> s = 'sdsd'\n",
      ">>> s.ascii_uppercase\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "AttributeError: 'str' object has no attribute 'ascii_uppercase'\n",
      " \n",
      " \n",
      " See  How do I lowercase a string in Python?  for the opposite. \n",
      "\n",
      "I've been hearing a lot about the  PyPy  project. They claim it is 6.3 times faster than the  CPython  interpreter on  their site . \n",
      " Whenever we talk about dynamic languages like Python, speed is one of the top issues. To solve this, they say PyPy is 6.3 times faster. \n",
      " The second issue is parallelism, the infamous  Global Interpreter Lock  (GIL). For this, PyPy says it  can give GIL-less Python . \n",
      " If PyPy can solve these great challenges, what are its weaknesses that are preventing wider adoption? That is to say, what's preventing someone like me, a typical Python developer, from switching to PyPy  right now ?  \n",
      "\n",
      "File \"C:\\Users\\Administrator\\Documents\\Mibot\\oops\\blinkserv.py\", line 82, in __init__\n",
      "    self.serv = socket(AF_INET,SOCK_STREAM)\n",
      "TypeError: 'module' object is not callable\n",
      " \n",
      " Why am I getting this error?\n",
      "I'm confused. \n",
      " How can I solve this error? \n",
      "\n",
      "I compared the processing speeds of  []  and  list()  on Python 3.11 \n",
      " $ python -m timeit '[]'\n",
      "20000000 loops, best of 5: 11.3 nsec per loop\n",
      "$ python -m timeit 'list()'\n",
      "10000000 loops, best of 5: 26.1 nsec per loop\n",
      " \n",
      " and was surprised to discover that  []  runs about two times faster than  list() . I got very similar results for  {}  and  dict() \n",
      " $ python -m timeit '{}'\n",
      "20000000 loops, best of 5: 11.6 nsec per loop\n",
      "$ python -m timeit 'dict()'\n",
      "10000000 loops, best of 5: 27.1 nsec per loop\n",
      " \n",
      " Why is this? Do  []  and  {}  (and probably  ()  and  '' , too) immediately pass back a copies of some empty stock literal while their explicitly-named counterparts ( list() ,  dict() ,  tuple() ,  str() ) fully go about creating an object, whether or not they actually have elements? \n",
      "\n",
      "When creating a simple object hierarchy in Python, I'd like to be able to invoke methods of the parent class from a derived class.  In Perl and Java, there is a keyword for this ( super ).  In Perl, I might do this: \n",
      " package Foo;\n",
      "\n",
      "sub frotz {\n",
      "    return \"Bamf\";\n",
      "}\n",
      "\n",
      "package Bar;\n",
      "@ISA = qw(Foo);\n",
      "\n",
      "sub frotz {\n",
      "   my $str = SUPER::frotz();\n",
      "   return uc($str);\n",
      "}\n",
      " \n",
      " In Python, it appears that I have to name the parent class explicitly from the child.\n",
      "In the example above, I'd have to do something like  Foo::frotz() .   \n",
      " This doesn't seem right since this behavior makes it hard to make deep hierarchies.  If children need to know what class defined an inherited method, then all sorts of information pain is created.   \n",
      " Is this an actual limitation in python, a gap in my understanding or both? \n",
      "\n",
      "I have two variables as follows. \n",
      " a = 2\n",
      "b = 3\n",
      " \n",
      " I want to construct a DataFrame from this: \n",
      " df2 = pd.DataFrame({'A':a, 'B':b})\n",
      " \n",
      " This generates an error: \n",
      " ValueError: If using all scalar values, you must pass an index\n",
      " \n",
      " I tried this also: \n",
      " df2 = (pd.DataFrame({'a':a, 'b':b})).reset_index()\n",
      " \n",
      " This gives the same error message. How do I do what I want? \n",
      "\n",
      "I have a Unicode string in Python, and I would like to remove all the accents (diacritics). \n",
      " I found on the web an elegant way to do this (in Java): \n",
      " \n",
      " convert the Unicode string to its  long normalized form  (with a separate character for letters and diacritics) \n",
      " remove all the characters whose Unicode type is \"diacritic\". \n",
      " \n",
      " Do I need to install a library such as pyICU or is this possible with just the Python standard library?  And what about python 3? \n",
      " Important note: I would like to avoid code with an explicit mapping from accented characters to their non-accented counterpart. \n",
      "\n",
      "In code like  zip(*x)  or  f(**k) , what do the  *  and  **  respectively mean? How does Python implement that behaviour, and what are the performance implications? \n",
      " \n",
      " See also:  Expanding tuples into arguments . Please use that one to close questions where OP needs to use  *  on an argument and doesn't know it exists. Similarly, use  Converting Python dict to kwargs?  for the case of using  ** . \n",
      " See  What does ** (double star/asterisk) and * (star/asterisk) do for parameters?  for the complementary question about parameters. \n",
      "\n",
      "I have a dataframe  df  and I use several columns from it to  groupby : \n",
      " df['col1','col2','col3','col4'].groupby(['col1','col2']).mean()\n",
      " \n",
      " In the above way, I almost get the table (dataframe) that I need. What is missing is an additional column that contains number of rows in each group. In other words, I have mean but I also would like to know how many were used to get these means. For example in the first group there are 8 values and in the second one 10 and so on. \n",
      " In short: How do I get  group-wise  statistics for a dataframe? \n",
      "\n",
      "I have two integer values  a  and  b , but I need their ratio in floating point.  I know that  a < b  and I want to calculate  a / b , so if I use integer division I'll always get 0 with a remainder of  a . \n",
      " How can I force  c  to be a floating point number in Python 2 in the following? \n",
      " c = a / b\n",
      " \n",
      " \n",
      " In 3.x, the behaviour is reversed; see  Why does integer division yield a float instead of another integer?  for the opposite, 3.x-specific problem. \n",
      "\n",
      "I have created a Pandas DataFrame \n",
      " df = DataFrame(index=['A','B','C'], columns=['x','y'])\n",
      " \n",
      " Now, I would like to assign a value to particular cell, for example to row  C  and column  x . In other words, I would like to perform the following transformation: \n",
      "      x    y             x    y\n",
      "A  NaN  NaN        A  NaN  NaN\n",
      "B  NaN  NaN   ⟶   B  NaN  NaN\n",
      "C  NaN  NaN        C   10  NaN\n",
      " \n",
      " with this code: \n",
      " df.xs('C')['x'] = 10\n",
      " \n",
      " However, the contents of  df  has not changed. The dataframe contains yet again only  NaN s. How do I what I want? \n",
      "\n",
      "Code: \n",
      " # coding=utf-8\n",
      "import pytest\n",
      "\n",
      "\n",
      "def whatever():\n",
      "    return 9/0\n",
      "\n",
      "def test_whatever():\n",
      "    try:\n",
      "        whatever()\n",
      "    except ZeroDivisionError as exc:\n",
      "        pytest.fail(exc, pytrace=True)\n",
      " \n",
      " Output: \n",
      " ================================ test session starts =================================\n",
      "platform linux2 -- Python 2.7.3 -- py-1.4.20 -- pytest-2.5.2\n",
      "plugins: django, cov\n",
      "collected 1 items \n",
      "\n",
      "pytest_test.py F\n",
      "\n",
      "====================================== FAILURES ======================================\n",
      "___________________________________ test_whatever ____________________________________\n",
      "\n",
      "    def test_whatever():\n",
      "        try:\n",
      "            whatever()\n",
      "        except ZeroDivisionError as exc:\n",
      ">           pytest.fail(exc, pytrace=True)\n",
      "E           Failed: integer division or modulo by zero\n",
      "\n",
      "pytest_test.py:12: Failed\n",
      "============================== 1 failed in 1.16 seconds ==============================\n",
      " \n",
      " How do I make pytest print traceback, so that I would see where in the  whatever  function that an exception was raised? \n",
      "\n",
      "I want to know the difference between  __init__  and  __call__  methods.   \n",
      " For example: \n",
      " class test:\n",
      "\n",
      "  def __init__(self):\n",
      "    self.a = 10\n",
      "\n",
      "  def __call__(self): \n",
      "    b = 20\n",
      " \n",
      "\n",
      "When I read Django code I often see in models what is called a \"slug\". I am not quite sure what this is, but I do know it has something to do with URLs. How and when is this slug-thing supposed to be used? \n",
      " I have read its definition below in  this glossary : \n",
      " \n",
      " Slug \n",
      "A short label for something, containing only letters, numbers,\n",
      "underscores or hyphens. They’re generally used in URLs. For example,\n",
      "in a typical blog entry URL: \n",
      " https://www.djangoproject.com/weblog/2008/apr/12/spring/  the last bit\n",
      "(spring) is the slug. \n",
      " \n",
      "\n",
      "I am trying to fix how python plots my data. Say: \n",
      " x = [0, 5, 9, 10, 15]\n",
      "y = [0, 1, 2, 3, 4]\n",
      "\n",
      "matplotlib.pyplot.plot(x, y)\n",
      "matplotlib.pyplot.show()\n",
      " \n",
      " The x axis' ticks are plotted in intervals of 5. Is there a way to make it show intervals of 1? \n",
      "\n",
      "I would like to read several CSV files from a directory into pandas and concatenate them into one big DataFrame. I have not been able to figure it out though. Here is what I have so far: \n",
      " import glob\n",
      "import pandas as pd\n",
      "\n",
      "# Get data file names\n",
      "path = r'C:\\DRO\\DCL_rawdata_files'\n",
      "filenames = glob.glob(path + \"/*.csv\")\n",
      "\n",
      "dfs = []\n",
      "for filename in filenames:\n",
      "    dfs.append(pd.read_csv(filename))\n",
      "\n",
      "# Concatenate all data into one DataFrame\n",
      "big_frame = pd.concat(dfs, ignore_index=True)\n",
      " \n",
      " I guess I need some help within the  for  loop? \n",
      "\n",
      "What's the difference between: \n",
      " class Child(SomeBaseClass):\n",
      "    def __init__(self):\n",
      "        super(Child, self).__init__()\n",
      "        \n",
      " \n",
      " and: \n",
      " class Child(SomeBaseClass):\n",
      "    def __init__(self):\n",
      "        SomeBaseClass.__init__(self)\n",
      "        \n",
      " \n",
      " I've seen  super  being used quite a lot in classes with only single inheritance. I can see why you'd use it in multiple inheritance but am unclear as to what the advantages are of using it in this kind of situation. \n",
      " \n",
      " This question is about technical implementation details and the distinction between different ways of accessing the base class  __init__  method. To close duplicate questions where OP is simply missing a  super  call and is asking why base class attributes aren't available, please use  Python class inheritance: AttributeError: '[SubClass]' object has no attribute 'xxx'  instead. \n",
      "\n",
      "I have taken  Problem #12  from  Project Euler  as a programming exercise and to compare my (surely not optimal) implementations in C, Python, Erlang and Haskell. In order to get some higher execution times, I search for the first triangle number with more than 1000 divisors instead of 500 as stated in the original problem. \n",
      " The result is the following: \n",
      " C: \n",
      " lorenzo@enzo:~/erlang$ gcc -lm -o euler12.bin euler12.c\n",
      "lorenzo@enzo:~/erlang$ time ./euler12.bin\n",
      "842161320\n",
      "\n",
      "real    0m11.074s\n",
      "user    0m11.070s\n",
      "sys 0m0.000s\n",
      " \n",
      " Python: \n",
      " lorenzo@enzo:~/erlang$ time ./euler12.py \n",
      "842161320\n",
      "\n",
      "real    1m16.632s\n",
      "user    1m16.370s\n",
      "sys 0m0.250s\n",
      " \n",
      " Python with PyPy: \n",
      " lorenzo@enzo:~/Downloads/pypy-c-jit-43780-b590cf6de419-linux64/bin$ time ./pypy /home/lorenzo/erlang/euler12.py \n",
      "842161320\n",
      "\n",
      "real    0m13.082s\n",
      "user    0m13.050s\n",
      "sys 0m0.020s\n",
      " \n",
      " Erlang: \n",
      " lorenzo@enzo:~/erlang$ erlc euler12.erl \n",
      "lorenzo@enzo:~/erlang$ time erl -s euler12 solve\n",
      "Erlang R13B03 (erts-5.7.4) [source] [64-bit] [smp:4:4] [rq:4] [async-threads:0] [hipe] [kernel-poll:false]\n",
      "\n",
      "Eshell V5.7.4  (abort with ^G)\n",
      "1> 842161320\n",
      "\n",
      "real    0m48.259s\n",
      "user    0m48.070s\n",
      "sys 0m0.020s\n",
      " \n",
      " Haskell: \n",
      " lorenzo@enzo:~/erlang$ ghc euler12.hs -o euler12.hsx\n",
      "[1 of 1] Compiling Main             ( euler12.hs, euler12.o )\n",
      "Linking euler12.hsx ...\n",
      "lorenzo@enzo:~/erlang$ time ./euler12.hsx \n",
      "842161320\n",
      "\n",
      "real    2m37.326s\n",
      "user    2m37.240s\n",
      "sys 0m0.080s\n",
      " \n",
      " Summary: \n",
      " \n",
      " C: 100% \n",
      " Python: 692% (118% with PyPy) \n",
      " Erlang: 436% (135% thanks to RichardC) \n",
      " Haskell: 1421% \n",
      " \n",
      " I suppose that C has a big advantage as it uses long for the calculations and not arbitrary length integers as the other three. Also it doesn't need to load a runtime first (Do the others?). \n",
      " Question 1: \n",
      "Do Erlang, Python and Haskell lose speed due to using arbitrary length integers or don't they as long as the values are less than  MAXINT ? \n",
      " Question 2: \n",
      "Why is Haskell so slow? Is there a compiler flag that turns off the brakes or is it my implementation? (The latter is quite probable as Haskell is a book with seven seals to me.) \n",
      " Question 3: \n",
      "Can you offer me some hints how to optimize these implementations without changing the way I determine the factors? Optimization in any way: nicer, faster, more \"native\" to the language. \n",
      " EDIT: \n",
      " Question 4: \n",
      "Do my functional implementations permit LCO (last call optimization, a.k.a tail recursion elimination) and hence avoid adding unnecessary frames onto the call stack? \n",
      " I really tried to implement the same algorithm as similar as possible in the four languages, although I have to admit that my Haskell and Erlang knowledge is very limited. \n",
      " \n",
      " Source codes used: \n",
      " #include <stdio.h>\n",
      "#include <math.h>\n",
      "\n",
      "int factorCount (long n)\n",
      "{\n",
      "    double square = sqrt (n);\n",
      "    int isquare = (int) square;\n",
      "    int count = isquare == square ? -1 : 0;\n",
      "    long candidate;\n",
      "    for (candidate = 1; candidate <= isquare; candidate ++)\n",
      "        if (0 == n % candidate) count += 2;\n",
      "    return count;\n",
      "}\n",
      "\n",
      "int main ()\n",
      "{\n",
      "    long triangle = 1;\n",
      "    int index = 1;\n",
      "    while (factorCount (triangle) < 1001)\n",
      "    {\n",
      "        index ++;\n",
      "        triangle += index;\n",
      "    }\n",
      "    printf (\"%ld\\n\", triangle);\n",
      "}\n",
      " \n",
      " \n",
      " #! /usr/bin/env python3.2\n",
      "\n",
      "import math\n",
      "\n",
      "def factorCount (n):\n",
      "    square = math.sqrt (n)\n",
      "    isquare = int (square)\n",
      "    count = -1 if isquare == square else 0\n",
      "    for candidate in range (1, isquare + 1):\n",
      "        if not n % candidate: count += 2\n",
      "    return count\n",
      "\n",
      "triangle = 1\n",
      "index = 1\n",
      "while factorCount (triangle) < 1001:\n",
      "    index += 1\n",
      "    triangle += index\n",
      "\n",
      "print (triangle)\n",
      " \n",
      " \n",
      " -module (euler12).\n",
      "-compile (export_all).\n",
      "\n",
      "factorCount (Number) -> factorCount (Number, math:sqrt (Number), 1, 0).\n",
      "\n",
      "factorCount (_, Sqrt, Candidate, Count) when Candidate > Sqrt -> Count;\n",
      "\n",
      "factorCount (_, Sqrt, Candidate, Count) when Candidate == Sqrt -> Count + 1;\n",
      "\n",
      "factorCount (Number, Sqrt, Candidate, Count) ->\n",
      "    case Number rem Candidate of\n",
      "        0 -> factorCount (Number, Sqrt, Candidate + 1, Count + 2);\n",
      "        _ -> factorCount (Number, Sqrt, Candidate + 1, Count)\n",
      "    end.\n",
      "\n",
      "nextTriangle (Index, Triangle) ->\n",
      "    Count = factorCount (Triangle),\n",
      "    if\n",
      "        Count > 1000 -> Triangle;\n",
      "        true -> nextTriangle (Index + 1, Triangle + Index + 1)  \n",
      "    end.\n",
      "\n",
      "solve () ->\n",
      "    io:format (\"~p~n\", [nextTriangle (1, 1) ] ),\n",
      "    halt (0).\n",
      " \n",
      " \n",
      " factorCount number = factorCount' number isquare 1 0 - (fromEnum $ square == fromIntegral isquare)\n",
      "    where square = sqrt $ fromIntegral number\n",
      "          isquare = floor square\n",
      "\n",
      "factorCount' number sqrt candidate count\n",
      "    | fromIntegral candidate > sqrt = count\n",
      "    | number `mod` candidate == 0 = factorCount' number sqrt (candidate + 1) (count + 2)\n",
      "    | otherwise = factorCount' number sqrt (candidate + 1) count\n",
      "\n",
      "nextTriangle index triangle\n",
      "    | factorCount triangle > 1000 = triangle\n",
      "    | otherwise = nextTriangle (index + 1) (triangle + index + 1)\n",
      "\n",
      "main = print $ nextTriangle 1 1\n",
      " \n",
      "\n",
      "Dictionaries are insertion ordered as of Python 3.6. It is described as a CPython implementation detail rather than a language feature. The  documentation  states: \n",
      " \n",
      " dict()  now uses a “compact” representation  pioneered by PyPy . The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5.  PEP 468  (Preserving the order of **kwargs in a function.) is implemented by this. The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5). (Contributed by INADA Naoki in  issue 27350 . Idea  originally suggested by Raymond Hettinger .) \n",
      " \n",
      " How does the new dictionary implementation perform better than the older one while preserving element order? \n",
      " \n",
      " Update December 2017:  dict s retaining insertion order is  guaranteed  for Python 3.7 \n",
      "\n",
      "Suppose I have a function and a dataframe defined as below: \n",
      " def get_sublist(sta, end):\n",
      "    return mylist[sta:end+1]\n",
      "\n",
      "df = pd.DataFrame({'ID':['1','2','3'], 'col_1': [0,2,3], 'col_2':[1,4,5]})\n",
      "mylist = ['a','b','c','d','e','f']\n",
      " \n",
      " Now I want to apply  get_sublist  to  df 's two columns  'col_1', 'col_2'  to element-wise calculate a new column  'col_3'  to get an output that looks like: \n",
      "   ID  col_1  col_2            col_3\n",
      "0  1      0      1       ['a', 'b']\n",
      "1  2      2      4  ['c', 'd', 'e']\n",
      "2  3      3      5  ['d', 'e', 'f']\n",
      " \n",
      " I tried \n",
      " df['col_3'] = df[['col_1','col_2']].apply(get_sublist, axis=1)\n",
      " \n",
      " but this results in \n",
      " TypeError: get_sublist() missing 1 required positional argument:\n",
      " \n",
      " How do I do it? \n",
      "\n",
      "I have a problem with the transfer of the variable  insurance_mode  by the decorator. I would do it by the following decorator statement: \n",
      " @execute_complete_reservation(True)\n",
      "def test_booking_gta_object(self):\n",
      "    self.test_select_gta_object()\n",
      " \n",
      " but unfortunately, this statement does not work. Perhaps maybe there is better way to solve this problem. \n",
      " def execute_complete_reservation(test_case,insurance_mode):\n",
      "    def inner_function(self,*args,**kwargs):\n",
      "        self.test_create_qsf_query()\n",
      "        test_case(self,*args,**kwargs)\n",
      "        self.test_select_room_option()\n",
      "        if insurance_mode:\n",
      "            self.test_accept_insurance_crosseling()\n",
      "        else:\n",
      "            self.test_decline_insurance_crosseling()\n",
      "        self.test_configure_pax_details()\n",
      "        self.test_configure_payer_details\n",
      "\n",
      "    return inner_function\n",
      " \n",
      "\n",
      "I have to use  Python  and  Django  for our application. So, I have two versions of Python, 2.6 and 2.7. Now I have installed Django. I could run the sample application for testing Django successfully. But how do I check whether Django uses the 2.6 or 2.7 version and what version of modules Django uses? \n",
      "\n",
      "How do I convert a pandas dataframe into a NumPy array? \n",
      " DataFrame: \n",
      " import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "index = [1, 2, 3, 4, 5, 6, 7]\n",
      "a = [np.nan, np.nan, np.nan, 0.1, 0.1, 0.1, 0.1]\n",
      "b = [0.2, np.nan, 0.2, 0.2, 0.2, np.nan, np.nan]\n",
      "c = [np.nan, 0.5, 0.5, np.nan, 0.5, 0.5, np.nan]\n",
      "df = pd.DataFrame({'A': a, 'B': b, 'C': c}, index=index)\n",
      "df = df.rename_axis('ID')\n",
      " \n",
      " gives \n",
      "       A    B    C\n",
      "ID                                 \n",
      "1   NaN  0.2  NaN\n",
      "2   NaN  NaN  0.5\n",
      "3   NaN  0.2  0.5\n",
      "4   0.1  0.2  NaN\n",
      "5   0.1  0.2  0.5\n",
      "6   0.1  NaN  0.5\n",
      "7   0.1  NaN  NaN\n",
      " \n",
      " I would like to convert this to a NumPy array, like so: \n",
      " array([[ nan,  0.2,  nan],\n",
      "       [ nan,  nan,  0.5],\n",
      "       [ nan,  0.2,  0.5],\n",
      "       [ 0.1,  0.2,  nan],\n",
      "       [ 0.1,  0.2,  0.5],\n",
      "       [ 0.1,  nan,  0.5],\n",
      "       [ 0.1,  nan,  nan]])\n",
      " \n",
      " \n",
      " Also, is it possible to preserve the dtypes, like this? \n",
      " array([[ 1, nan,  0.2,  nan],\n",
      "       [ 2, nan,  nan,  0.5],\n",
      "       [ 3, nan,  0.2,  0.5],\n",
      "       [ 4, 0.1,  0.2,  nan],\n",
      "       [ 5, 0.1,  0.2,  0.5],\n",
      "       [ 6, 0.1,  nan,  0.5],\n",
      "       [ 7, 0.1,  nan,  nan]],\n",
      "     dtype=[('ID', '<i4'), ('A', '<f8'), ('B', '<f8'), ('B', '<f8')])\n",
      " \n",
      "\n",
      "I'm running a program which is processing 30,000 similar files. A random number of them are stopping and producing this error... \n",
      "   File \"C:\\Importer\\src\\dfman\\importer.py\", line 26, in import_chr\n",
      "    data = pd.read_csv(filepath, names=fields)\n",
      "  File \"C:\\Python33\\lib\\site-packages\\pandas\\io\\parsers.py\", line 400, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Python33\\lib\\site-packages\\pandas\\io\\parsers.py\", line 205, in _read\n",
      "    return parser.read()\n",
      "  File \"C:\\Python33\\lib\\site-packages\\pandas\\io\\parsers.py\", line 608, in read\n",
      "    ret = self._engine.read(nrows)\n",
      "  File \"C:\\Python33\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1028, in read\n",
      "    data = self._reader.read(nrows)\n",
      "  File \"parser.pyx\", line 706, in pandas.parser.TextReader.read (pandas\\parser.c:6745)\n",
      "  File \"parser.pyx\", line 728, in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:6964)\n",
      "  File \"parser.pyx\", line 804, in pandas.parser.TextReader._read_rows (pandas\\parser.c:7780)\n",
      "  File \"parser.pyx\", line 890, in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:8793)\n",
      "  File \"parser.pyx\", line 950, in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:9484)\n",
      "  File \"parser.pyx\", line 1026, in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10642)\n",
      "  File \"parser.pyx\", line 1046, in pandas.parser.TextReader._string_convert (pandas\\parser.c:10853)\n",
      "  File \"parser.pyx\", line 1278, in pandas.parser._string_box_utf8 (pandas\\parser.c:15657)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xda in position 6: invalid    continuation byte\n",
      " \n",
      " The source/creation of these files all come from the same place. What's the best way to correct this to proceed with the import? \n",
      "\n",
      "How do I select columns  a  and  b  from  df , and save them into a new dataframe  df1 ? \n",
      " index  a   b   c\n",
      "1      2   3   4\n",
      "2      3   4   5\n",
      " \n",
      " Unsuccessful attempt: \n",
      " df1 = df['a':'b']\n",
      "df1 = df.ix[:, 'a':'b']\n",
      " \n",
      "\n",
      "I've been here: \n",
      " \n",
      " PEP 328 – Imports: Multi-Line and Absolute/Relative \n",
      " Modules, Packages \n",
      " Python packages: relative imports \n",
      " Python relative import example code does not work \n",
      " Relative imports in Python 2.5 \n",
      " Relative imports in Python \n",
      " Python: Disabling relative import \n",
      " \n",
      " and plenty of URLs that I did not copy, some on SO, some on other sites, back when I thought I'd have the solution quickly. \n",
      " The forever-recurring question is this: how do I solve this \"Attempted relative import in non-package\" message? \n",
      " \n",
      " ImportError: attempted relative import with no known parent package \n",
      " \n",
      " I built an exact replica of the package on pep-0328: \n",
      " package/\n",
      "    __init__.py\n",
      "    subpackage1/\n",
      "        __init__.py\n",
      "        moduleX.py\n",
      "        moduleY.py\n",
      "    subpackage2/\n",
      "        __init__.py\n",
      "        moduleZ.py\n",
      "    moduleA.py\n",
      " \n",
      " The imports were done from the console. \n",
      " I did make functions named spam and eggs in their appropriate modules.  Naturally, it didn't work.  The answer is apparently in the 4th URL I listed, but it's all alumni to me. There was this response on one of the URLs I visited: \n",
      " \n",
      " Relative imports use a module's name attribute to determine that module's position in the package hierarchy. If the module's name does not contain any package information (e.g. it is set to 'main') then relative imports are resolved as if the module were a top level module, regardless of where the module is actually located on the file system. \n",
      " \n",
      " The above response looks promising, but it's all hieroglyphs to me. How do I make Python not return to me \"Attempted relative import in non-package\"? It has an answer that involves  -m , supposedly. \n",
      " Why does Python give that error message? What does by \"non-package\" mean? Why and how do you define a 'package'? \n",
      "\n",
      "Project Euler  and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to  __main__ . \n",
      " What is a good way to profile how long a Python program takes to run? \n",
      "\n",
      "Why does the following class declaration inherit from  object ? \n",
      " class MyClass(object):\n",
      "    ...\n",
      " \n",
      "\n",
      "This question is not for the discussion of whether or not the  singleton design pattern  is desirable, is an anti-pattern, or for any religious wars, but to discuss how this pattern is best implemented in Python in such a way that is most pythonic. In this instance I define 'most pythonic' to mean that it follows the 'principle of least astonishment' . \n",
      " I have multiple classes which would become singletons (my use-case is for a logger, but this is not important). I do not wish to clutter several classes with added gumph when I can simply inherit or decorate. \n",
      " Best methods: \n",
      " \n",
      " Method 1: A decorator \n",
      " def singleton(class_):\n",
      "    instances = {}\n",
      "    def getinstance(*args, **kwargs):\n",
      "        if class_ not in instances:\n",
      "            instances[class_] = class_(*args, **kwargs)\n",
      "        return instances[class_]\n",
      "    return getinstance\n",
      "\n",
      "@singleton\n",
      "class MyClass(BaseClass):\n",
      "    pass\n",
      " \n",
      " Pros \n",
      " \n",
      " Decorators are additive in a way that is often more intuitive than multiple inheritance. \n",
      " \n",
      " Cons \n",
      " \n",
      " While objects created using  MyClass()  would be true singleton objects,  MyClass  itself is a function, not a class, so you cannot call class methods from it. Also for \n",
      " x = MyClass();\n",
      "y = MyClass();\n",
      "t = type(n)();\n",
      " \n",
      " \n",
      " \n",
      " then  x == y  but  x != t && y != t \n",
      " \n",
      " Method 2: A base class \n",
      " class Singleton(object):\n",
      "    _instance = None\n",
      "    def __new__(class_, *args, **kwargs):\n",
      "        if not isinstance(class_._instance, class_):\n",
      "            class_._instance = object.__new__(class_, *args, **kwargs)\n",
      "        return class_._instance\n",
      "\n",
      "class MyClass(Singleton, BaseClass):\n",
      "    pass\n",
      " \n",
      " Pros \n",
      " \n",
      " It's a true class \n",
      " \n",
      " Cons \n",
      " \n",
      " Multiple inheritance - eugh!  __new__  could be overwritten during inheritance from a second base class? One has to think more than is necessary. \n",
      " \n",
      " \n",
      " Method 3: A  metaclass \n",
      " class Singleton(type):\n",
      "    _instances = {}\n",
      "    def __call__(cls, *args, **kwargs):\n",
      "        if cls not in cls._instances:\n",
      "            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)\n",
      "        return cls._instances[cls]\n",
      "\n",
      "#Python2\n",
      "class MyClass(BaseClass):\n",
      "    __metaclass__ = Singleton\n",
      "\n",
      "#Python3\n",
      "class MyClass(BaseClass, metaclass=Singleton):\n",
      "    pass\n",
      " \n",
      " Pros \n",
      " \n",
      " It's a true class \n",
      " Auto-magically covers inheritance \n",
      " Uses  __metaclass__  for its proper purpose (and made me aware of it) \n",
      " \n",
      " Cons \n",
      " \n",
      " Are there any? \n",
      " \n",
      " \n",
      " Method 4: decorator returning a class with the same name \n",
      " def singleton(class_):\n",
      "    class class_w(class_):\n",
      "        _instance = None\n",
      "        def __new__(class_, *args, **kwargs):\n",
      "            if class_w._instance is None:\n",
      "                class_w._instance = super(class_w,\n",
      "                                    class_).__new__(class_,\n",
      "                                                    *args,\n",
      "                                                    **kwargs)\n",
      "                class_w._instance._sealed = False\n",
      "            return class_w._instance\n",
      "        def __init__(self, *args, **kwargs):\n",
      "            if self._sealed:\n",
      "                return\n",
      "            super(class_w, self).__init__(*args, **kwargs)\n",
      "            self._sealed = True\n",
      "    class_w.__name__ = class_.__name__\n",
      "    return class_w\n",
      "\n",
      "@singleton\n",
      "class MyClass(BaseClass):\n",
      "    pass\n",
      " \n",
      " Pros \n",
      " \n",
      " It's a true class \n",
      " Auto-magically covers inheritance \n",
      " \n",
      " Cons \n",
      " \n",
      " Is there not an overhead for creating each new class? Here we are creating two classes for each class we wish to make a singleton. While this is fine in my case, I worry that this might not scale. Of course there is a matter of debate as to whether it aught to be too easy to scale this pattern... \n",
      " What is the point of the  _sealed  attribute \n",
      " Can't call methods of the same name on base classes using  super()  because they will recurse. This means you can't customize  __new__  and can't subclass a class that needs you to call up to  __init__ . \n",
      " \n",
      " \n",
      " Method 5: a module \n",
      " a module file  singleton.py \n",
      " Pros \n",
      " \n",
      " Simple is better than complex \n",
      " \n",
      " Cons \n",
      " \n",
      " Not lazily instantiated \n",
      " \n",
      "\n",
      "I have the following DataFrame ( df ): \n",
      " import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "df = pd.DataFrame(np.random.rand(10, 5))\n",
      " \n",
      " I add more column(s) by assignment: \n",
      " df['mean'] = df.mean(1)\n",
      " \n",
      " How can I move the column  mean  to the front, i.e. set it as first column leaving the order of the other columns untouched? \n",
      "\n",
      "I created a DataFrame from a list of lists: \n",
      " table = [\n",
      "    ['a',  '1.2',  '4.2' ],\n",
      "    ['b',  '70',   '0.03'],\n",
      "    ['x',  '5',    '0'   ],\n",
      "]\n",
      "\n",
      "df = pd.DataFrame(table)\n",
      " \n",
      " How do I convert the columns to specific types? In this case, I want to convert columns 2 and 3 into floats. \n",
      " Is there a way to specify the types while converting the list to DataFrame? Or is it better to create the DataFrame first and then loop through the columns to change the dtype for each column? Ideally I would like to do this in a dynamic way because there can be hundreds of columns, and I don't want to specify exactly which columns are of which type. All I can guarantee is that each column contains values of the same type. \n",
      "\n",
      "I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.  \n",
      " The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a  UnicodeEncodeError . I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error. \n",
      " One of the sections of code that is causing problems is shown below: \n",
      " agent_telno = agent.find('div', 'agent_contact_number')\n",
      "agent_telno = '' if agent_telno is None else agent_telno.contents[0]\n",
      "p.agent_info = str(agent_contact + ' ' + agent_telno).strip()\n",
      " \n",
      " Here is a stack trace produced on SOME strings when the snippet above is run: \n",
      " Traceback (most recent call last):\n",
      "  File \"foobar.py\", line 792, in <module>\n",
      "    p.agent_info = str(agent_contact + ' ' + agent_telno).strip()\n",
      "UnicodeEncodeError: 'ascii' codec can't encode character u'\\xa0' in position 20: ordinal not in range(128)\n",
      " \n",
      " I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English. \n",
      " Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem? \n",
      "\n",
      "So what I'm looking for here is something like PHP's  print_r  function. \n",
      " This is so I can debug my scripts by seeing what's the state of the object in question. \n",
      "\n",
      "How can I check if a list has any duplicates and return a new list without duplicates? \n",
      "\n",
      "I have this DataFrame and want only the records whose EPS column is not NaN: \n",
      "                  STK_ID  EPS  cash\n",
      "STK_ID RPT_Date                   \n",
      "601166 20111231  601166  NaN   NaN\n",
      "600036 20111231  600036  NaN    12\n",
      "600016 20111231  600016  4.3   NaN\n",
      "601009 20111231  601009  NaN   NaN\n",
      "601939 20111231  601939  2.5   NaN\n",
      "000001 20111231  000001  NaN   NaN\n",
      " \n",
      " ...i.e. something like  df.drop(....)  to get this resulting dataframe: \n",
      "                   STK_ID  EPS  cash\n",
      "STK_ID RPT_Date                   \n",
      "600016 20111231  600016  4.3   NaN\n",
      "601939 20111231  601939  2.5   NaN\n",
      " \n",
      " How do I do that? \n",
      "\n",
      "Background \n",
      " I just upgraded my Pandas from 0.11 to 0.13.0rc1. Now, the application is popping out many new warnings. One of them like this: \n",
      " E:\\FinReporter\\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n",
      "  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE\n",
      " \n",
      " I want to know what exactly it means?  Do I need to change something? \n",
      " How should I suspend the warning if I insist to use  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE ? \n",
      " The function that gives warnings \n",
      " def _decode_stock_quote(list_of_150_stk_str):\n",
      "    \"\"\"decode the webpage and return dataframe\"\"\"\n",
      "\n",
      "    from cStringIO import StringIO\n",
      "\n",
      "    str_of_all = \"\".join(list_of_150_stk_str)\n",
      "\n",
      "    quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}\n",
      "    quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)\n",
      "    quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]\n",
      "    quote_df['TClose'] = quote_df['TPrice']\n",
      "    quote_df['RT']     = 100 * (quote_df['TPrice']/quote_df['TPCLOSE'] - 1)\n",
      "    quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE\n",
      "    quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE\n",
      "    quote_df['STK_ID'] = quote_df['STK'].str.slice(13,19)\n",
      "    quote_df['STK_Name'] = quote_df['STK'].str.slice(21,30)#.decode('gb2312')\n",
      "    quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])\n",
      "    \n",
      "    return quote_df\n",
      " \n",
      " More warning messages \n",
      " E:\\FinReporter\\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n",
      "  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE\n",
      "E:\\FinReporter\\FM_EXT.py:450: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n",
      "  quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE\n",
      "E:\\FinReporter\\FM_EXT.py:453: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_index,col_indexer] = value instead\n",
      "  quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])\n",
      " \n",
      "\n",
      "I would like to understand how the built-in function  property  works. What confuses me is that  property  can also be used as a decorator, but it only takes arguments when used as a built-in function and not when used as a decorator. \n",
      " This example is from the  documentation : \n",
      " class C:\n",
      "    def __init__(self):\n",
      "        self._x = None\n",
      "\n",
      "    def getx(self):\n",
      "        return self._x\n",
      "    def setx(self, value):\n",
      "        self._x = value\n",
      "    def delx(self):\n",
      "        del self._x\n",
      "    x = property(getx, setx, delx, \"I'm the 'x' property.\")\n",
      " \n",
      " property 's arguments are  getx ,  setx ,  delx  and a doc string. \n",
      " In the code below  property  is used as a decorator. The object of it is the  x  function, but in the code above there is no place for an object function in the arguments. \n",
      " class C:\n",
      "    def __init__(self):\n",
      "        self._x = None\n",
      "\n",
      "    @property\n",
      "    def x(self):\n",
      "        \"\"\"I'm the 'x' property.\"\"\"\n",
      "        return self._x\n",
      "\n",
      "    @x.setter\n",
      "    def x(self, value):\n",
      "        self._x = value\n",
      "\n",
      "    @x.deleter\n",
      "    def x(self):\n",
      "        del self._x\n",
      " \n",
      " How are the  x.setter  and  x.deleter  decorators created in this case? \n",
      "\n",
      "I want to get a list of the column headers from a Pandas DataFrame.  The DataFrame will come from user input, so I won't know how many columns there will be or what they will be called. \n",
      " For example, if I'm given a DataFrame like this: \n",
      "     y  gdp  cap\n",
      "0   1    2    5\n",
      "1   2    3    9\n",
      "2   8    7    2\n",
      "3   3    4    7\n",
      "4   6    7    7\n",
      "5   4    8    3\n",
      "6   8    2    8\n",
      "7   9    9   10\n",
      "8   6    6    4\n",
      "9  10   10    7\n",
      " \n",
      " I would get a list like this: \n",
      " ['y', 'gdp', 'cap']\n",
      " \n",
      "\n",
      "In  Programming Python , Mark Lutz mentions the term  mixin . I am from a C/C++/C# background and I have not heard the term before. What is a mixin? \n",
      " Reading between the lines of  this example  (which I have linked to because it is quite long), I am presuming it is a case of using multiple inheritance to extend a class as opposed to proper subclassing. Is this right? \n",
      " Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition? \n",
      " What separates a mixin from multiple inheritance? Is it just a matter of semantics? \n",
      "\n",
      "Two string variables are set to the same value.  s1 == s2  always returns  True , but  s1 is s2  sometimes returns  False . \n",
      " If I open my Python interpreter and do the same  is  comparison, it succeeds: \n",
      " >>> s1 = 'text'\n",
      ">>> s2 = 'text'\n",
      ">>> s1 is s2\n",
      "True\n",
      " \n",
      " Why is this? \n",
      "\n",
      "I have two lists in Python: \n",
      " temp1 = ['One', 'Two', 'Three', 'Four']\n",
      "temp2 = ['One', 'Two']\n",
      " \n",
      " Assuming the elements in each list are unique, I want to create a third list with items from the first list which are not in the second list: \n",
      " temp3 = ['Three', 'Four']\n",
      " \n",
      " Are there any fast ways without cycles and checking? \n",
      "\n",
      "I have the following code in Python 3: \n",
      " class Position:\n",
      "\n",
      "    def __init__(self, x: int, y: int):\n",
      "        self.x = x\n",
      "        self.y = y\n",
      "\n",
      "    def __add__(self, other: Position) -> Position:\n",
      "        return Position(self.x + other.x, self.y + other.y)\n",
      " \n",
      " But my editor (PyCharm) says that the reference  Position  can not be resolved (in the  __add__  method). How should I specify that I expect the return type to be of type  Position ? \n",
      " Edit: I think this is actually a PyCharm issue. It actually uses the information in its warnings, and code completion. \n",
      " \n",
      " But correct me if I'm wrong, and need to use some other syntax. \n",
      "\n",
      "Is there a Python function that will trim whitespace (spaces and tabs) from a string? \n",
      " So that given input  \"  \\t example string\\t  \"  becomes  \"example string\" . \n",
      "\n",
      "\n",
      " What are named tuples and how do I use them? \n",
      " When should I use named tuples instead of normal tuples, or vice versa? \n",
      " Are there \"named lists\" too? (i.e. mutable named tuples) \n",
      " \n",
      " \n",
      " For the last question specifically, see also  Existence of mutable named tuple in Python? . \n",
      "\n",
      "I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons. \n",
      " One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about \"big data\" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive. \n",
      " My first thought is to use  HDFStore  to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this: \n",
      " What are some best-practice workflows for accomplishing the following: \n",
      " \n",
      " Loading flat files into a permanent, on-disk database structure \n",
      " Querying that database to retrieve data to feed into a pandas data structure \n",
      " Updating the database after manipulating pieces in pandas \n",
      " \n",
      " Real-world examples would be much appreciated, especially from anyone who uses pandas on \"large data\". \n",
      " Edit -- an example of how I would like this to work: \n",
      " \n",
      " Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. \n",
      " In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. \n",
      " I would create new columns by performing various operations on the selected columns. \n",
      " I would then have to append these new columns into the database structure. \n",
      " \n",
      " I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem. \n",
      " Edit -- Responding to Jeff's questions specifically: \n",
      " \n",
      " I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. \n",
      " Typical operations involve combining several columns using conditional logic into a new, compound column. For example,  if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B' .  The result of these operations is a new column for every record in my dataset. \n",
      " Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. \n",
      " A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. \n",
      " It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. \n",
      " The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns. \n",
      " \n",
      " It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance). \n",
      "\n",
      "What is the difference between old style and new style classes in Python?  When should I use one or the other? \n",
      "\n",
      "I have a list that I want to filter by an attribute of the items. \n",
      " Which of the following is preferred (readability, performance, other reasons)? \n",
      " xs = [x for x in xs if x.attribute == value]\n",
      " \n",
      " xs = filter(lambda x: x.attribute == value, xs)\n",
      " \n",
      "\n",
      "I know  pip  is a package manager for python packages. However, I saw the installation on IPython's website use  conda  to install IPython. \n",
      " Can I use  pip  to install IPython? Why should I use  conda  as another python package manager when I already have  pip ? \n",
      " What is the difference between  pip  and  conda ? \n",
      "\n",
      "I am running Python 2.5. \n",
      " This is my folder tree: \n",
      " ptdraft/\n",
      "  nib.py\n",
      "  simulations/\n",
      "    life/\n",
      "      life.py\n",
      " \n",
      " (I also have  __init__.py  in each folder, omitted here for readability) \n",
      " How do I import the  nib  module from inside the  life  module? I am hoping it is possible to do without tinkering with sys.path. \n",
      " Note: The main module being run is in the  ptdraft  folder. \n",
      "\n",
      "Coming from a C# background the naming convention for variables and methods are usually either camelCase or PascalCase: \n",
      " // C# example\n",
      "string thisIsMyVariable = \"a\"\n",
      "public void ThisIsMyMethod()\n",
      " \n",
      " In Python, I have seen the above but I have also seen snake_case being used: \n",
      " # python example\n",
      "this_is_my_variable = 'a'\n",
      "def this_is_my_function():\n",
      " \n",
      " Is there a more preferable, definitive coding style for Python? \n",
      "\n",
      "How do I get the size occupied in memory by an object in Python? \n",
      "\n",
      "I'm trying to get a Python 3 program to do some manipulations with a text file filled with information. However, when trying to read the file I get the following error: \n",
      " Traceback (most recent call last):  \n",
      "  File \"SCRIPT LOCATION\", line NUMBER, in <module>  \n",
      "    text = file.read()\n",
      "  File \"C:\\Python31\\lib\\encodings\\cp1252.py\", line 23, in decode  \n",
      "    return codecs.charmap_decode(input,self.errors,decoding_table)[0]\n",
      "UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 2907500: character maps to `<undefined>`  \n",
      " \n",
      " \n",
      " After reading this Q&A, see  How to determine the encoding of text  if you need help figuring out the encoding of the file you are trying to open. \n",
      "\n",
      "How do I remove duplicates from a list, while preserving order? Using a set to remove duplicates destroys the original order.\n",
      "Is there a built-in or a Pythonic idiom? \n",
      "\n",
      "In Python, what are the differences between the  urllib ,  urllib2 ,  urllib3  and  requests  modules? Why are there three? They seem to do the same thing... \n",
      "\n",
      "I would like to list all files recursively in a directory. I currently have a directory structure like this: \n",
      " \n",
      " src/main.c \n",
      " src/dir/file1.c \n",
      " src/another-dir/file2.c \n",
      " src/another-dir/nested/files/file3.c \n",
      " \n",
      " I've tried to do the following: \n",
      " from glob import glob\n",
      "\n",
      "glob(os.path.join('src','*.c'))\n",
      " \n",
      " But this will only get be files directly in the  src  subfolder, e.g. I get  main.c  but I will not get  file1.c ,  file2.c  etc. \n",
      " from glob import glob\n",
      "\n",
      "glob(os.path.join('src','*.c'))\n",
      "glob(os.path.join('src','*','*.c'))\n",
      "glob(os.path.join('src','*','*','*.c'))\n",
      "glob(os.path.join('src','*','*','*','*.c'))\n",
      " \n",
      " But this is obviously limited and clunky, how can I do this properly? \n",
      "\n",
      "I have the following DataFrame: \n",
      "              daysago  line_race rating        rw    wrating\n",
      " line_date                                                 \n",
      "2007-03-31       62         11     56  1.000000  56.000000\n",
      "2007-03-10       83         11     67  1.000000  67.000000\n",
      "2007-02-10      111          9     66  1.000000  66.000000\n",
      "2007-01-13      139         10     83  0.880678  73.096278\n",
      "2006-12-23      160         10     88  0.793033  69.786942\n",
      "2006-11-09      204          9     52  0.636655  33.106077\n",
      "2006-10-22      222          8     66  0.581946  38.408408\n",
      "2006-09-29      245          9     70  0.518825  36.317752\n",
      "2006-09-16      258         11     68  0.486226  33.063381\n",
      "2006-08-30      275          8     72  0.446667  32.160051\n",
      "2006-02-11      475          5     65  0.164591  10.698423\n",
      "2006-01-13      504          0     70  0.142409   9.968634\n",
      "2006-01-02      515          0     64  0.134800   8.627219\n",
      "2005-12-06      542          0     70  0.117803   8.246238\n",
      "2005-11-29      549          0     70  0.113758   7.963072\n",
      "2005-11-22      556          0     -1  0.109852  -0.109852\n",
      "2005-11-01      577          0     -1  0.098919  -0.098919\n",
      "2005-10-20      589          0     -1  0.093168  -0.093168\n",
      "2005-09-27      612          0     -1  0.083063  -0.083063\n",
      "2005-09-07      632          0     -1  0.075171  -0.075171\n",
      "2005-06-12      719          0     69  0.048690   3.359623\n",
      "2005-05-29      733          0     -1  0.045404  -0.045404\n",
      "2005-05-02      760          0     -1  0.039679  -0.039679\n",
      "2005-04-02      790          0     -1  0.034160  -0.034160\n",
      "2005-03-13      810          0     -1  0.030915  -0.030915\n",
      "2004-11-09      934          0     -1  0.016647  -0.016647\n",
      " \n",
      " I need to remove the rows where  line_race  is equal to  0 . What's the most efficient way to do this? \n",
      "\n",
      "Is it possible to terminate a running thread without setting/checking any flags/semaphores/etc.? \n",
      "\n",
      "I would like to know what are all the possible values for the timezone argument in the Python library pytz. How to do it? \n",
      "\n",
      "A  tweet  reads:  \n",
      " \n",
      " Don't use easy_install, unless you\n",
      "  like stabbing yourself in the face.\n",
      "  Use pip. \n",
      " \n",
      " Why use pip over easy_install? Doesn't the  fault lie with PyPI and package authors mostly ? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to  strongly  favor pip over easy_install? \n",
      " (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community) \n",
      "\n",
      "How do I write a list to a file?  writelines()  doesn't insert newline characters, so I need to do: \n",
      " f.writelines([f\"{line}\\n\" for line in lines])\n",
      " \n",
      "\n",
      "I have a dataframe that looks like \n",
      " Year  quarter\n",
      "2000       q2\n",
      "2001       q3\n",
      " \n",
      " How do I add a new column by combining these columns to get the following dataframe? \n",
      " Year  quarter  period\n",
      "2000       q2  2000q2\n",
      "2001       q3  2001q3\n",
      " \n",
      "\n",
      "I am trying to use IPython notebook on MacOS X with Python 2.7.2 and IPython 1.1.0. \n",
      " I cannot get matplotlib graphics to show up inline. \n",
      " import matplotlib\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "%matplotlib inline  \n",
      " \n",
      " I have also tried  %pylab inline  and the ipython command line arguments  --pylab=inline  but this makes no difference. \n",
      " x = np.linspace(0, 3*np.pi, 500)\n",
      "plt.plot(x, np.sin(x**2))\n",
      "plt.title('A simple chirp')\n",
      "plt.show()\n",
      " \n",
      " Instead of inline graphics, I get this: \n",
      " <matplotlib.figure.Figure at 0x110b9c450>\n",
      " \n",
      " And  matplotlib.get_backend()  shows that I have the  'module://IPython.kernel.zmq.pylab.backend_inline'  backend. \n",
      "\n",
      "Can someone explain how these two methods of slicing are different? I've seen  the docs \n",
      "and I've seen previous similar questions ( 1 ,  2 ), but I still find myself unable to understand how they are different. To me, they seem interchangeable in large part, because they are at the lower levels of slicing. \n",
      " For example, say we want to get the first five rows of a  DataFrame .  How is it that these two work? \n",
      " df.loc[:5]\n",
      "df.iloc[:5]\n",
      " \n",
      " Can someone present cases where the distinction in uses are clearer? \n",
      " \n",
      " Once upon a time, I also wanted to know how these two functions differed from  df.ix[:5]  but  ix  has been removed from pandas 1.0, so I don't care anymore. \n",
      "\n",
      "def main():\n",
      "    for i in xrange(10**8):\n",
      "        pass\n",
      "main()\n",
      " \n",
      " This piece of code in Python runs in  (Note: The timing is done with the time function in BASH in Linux.) \n",
      " real    0m1.841s\n",
      "user    0m1.828s\n",
      "sys     0m0.012s\n",
      " \n",
      " However, if the for loop isn't placed within a function,  \n",
      " for i in xrange(10**8):\n",
      "    pass\n",
      " \n",
      " then it runs for a much longer time: \n",
      " real    0m4.543s\n",
      "user    0m4.524s\n",
      "sys     0m0.012s\n",
      " \n",
      " Why is this? \n",
      "\n",
      "I need to parse  RFC 3339  strings like  \"2008-09-03T20:56:35.450686Z\"  into Python's  datetime  type. \n",
      " I have found  strptime  in the Python standard library, but it is not very convenient. \n",
      " What is the best way to do this? \n",
      "\n",
      "\n",
      " How can I perform a ( INNER | ( LEFT | RIGHT | FULL )  OUTER )  JOIN  with pandas? \n",
      " How do I add NaNs for missing rows after a merge? \n",
      " How do I get rid of NaNs after merging? \n",
      " Can I merge on the index? \n",
      " How do I merge multiple DataFrames? \n",
      " Cross join with pandas \n",
      " merge ?  join ?  concat ?  update ? Who? What? Why?! \n",
      " \n",
      " ... and more. I've seen these recurring questions asking about various facets of the pandas merge functionality. Most of the information regarding merge and its various use cases today is fragmented across dozens of badly worded, unsearchable posts. The aim here is to collate some of the more important points for posterity. \n",
      " This Q&A is meant to be the next installment in a series of helpful user guides on common pandas idioms (see  this post on pivoting , and  this post on concatenation , which I will be touching on, later). \n",
      " Please note that this post is  not  meant to be a replacement for  the documentation , so please read that as well! Some of the examples are taken from there. \n",
      " \n",
      " Table of Contents \n",
      " For ease of access. \n",
      " \n",
      " Merging basics - basic types of joins  (read this first) \n",
      " \n",
      " Index-based joins \n",
      " \n",
      " Generalizing to multiple DataFrames \n",
      " \n",
      " Cross join \n",
      " \n",
      " \n",
      "\n",
      "import ftplib\n",
      "import urllib2\n",
      "import os\n",
      "import logging\n",
      "logger = logging.getLogger('ftpuploader')\n",
      "hdlr = logging.FileHandler('ftplog.log')\n",
      "formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')\n",
      "hdlr.setFormatter(formatter)\n",
      "logger.addHandler(hdlr)\n",
      "logger.setLevel(logging.INFO)\n",
      "FTPADDR = \"some ftp address\"\n",
      "\n",
      "def upload_to_ftp(con, filepath):\n",
      "    try:\n",
      "        f = open(filepath,'rb')                # file to send\n",
      "        con.storbinary('STOR '+ filepath, f)         # Send the file\n",
      "        f.close()                                # Close file and FTP\n",
      "        logger.info('File successfully uploaded to '+ FTPADDR)\n",
      "    except, e:\n",
      "        logger.error('Failed to upload to ftp: '+ str(e))\n",
      " \n",
      " This doesn't seem to work, I get syntax error, what is the proper way of doing this for logging all kind of exceptions to a file \n",
      "\n",
      "I'm able to update pip-managed packages, but how do I update pip itself? According to  pip --version , I currently have pip 1.1 installed in my virtualenv and I want to update to the latest version.  \n",
      " What's the command for that? Do I need to use distribute or is there a native pip or virtualenv command? I've already tried  pip update  and  pip update pip  with no success. \n",
      "\n",
      "I want to find out the following:\n",
      "given a date ( datetime  object), what is the corresponding day of the week? \n",
      " For instance, Sunday is the first day, Monday: second day.. and so on \n",
      " And then if the input is something like today's date. \n",
      " Example \n",
      " >>> today = datetime.datetime(2017, 10, 20)\n",
      ">>> today.get_weekday()  # what I look for\n",
      " \n",
      " The output is maybe  6  (since it's Friday) \n",
      "\n",
      "I've very recently migrated to Python 3.5.\n",
      "This code was working properly in Python 2.7: \n",
      " with open(fname, 'rb') as f:\n",
      "    lines = [x.strip() for x in f.readlines()]\n",
      "\n",
      "for line in lines:\n",
      "    tmp = line.strip().lower()\n",
      "    if 'some-pattern' in tmp: continue\n",
      "    # ... code\n",
      " \n",
      " But in 3.5, on the  if 'some-pattern' in tmp: continue  line, I get an error which says: \n",
      " TypeError: a bytes-like object is required, not 'str'\n",
      " \n",
      " I was unable to fix the problem using  .decode()  on either side of the  in , nor could I fix it using \n",
      "     if tmp.find('some-pattern') != -1: continue\n",
      " \n",
      " What is wrong, and how do I fix it? \n",
      "\n",
      "I am creating a figure in Matplotlib like this: \n",
      " from matplotlib import pyplot as plt\n",
      "\n",
      "fig = plt.figure()\n",
      "plt.plot(data)\n",
      "fig.suptitle('test title')\n",
      "plt.xlabel('xlabel')\n",
      "plt.ylabel('ylabel')\n",
      "fig.savefig('test.jpg')\n",
      " \n",
      " I want to specify font sizes for the figure title and the axis labels. I need all three to be different font sizes, so setting a global font size ( mpl.rcParams['font.size']=x ) is not what I want. How do I set font sizes for the figure title and the axis labels individually? \n",
      "\n",
      "I tried to install the Python package  dulwich : \n",
      " pip install dulwich\n",
      " \n",
      " But I get a cryptic error message: \n",
      " error: Unable to find vcvarsall.bat\n",
      " \n",
      " The same happens if I try installing the package manually: \n",
      " > python setup.py install\n",
      "running build_ext\n",
      "building 'dulwich._objects' extension\n",
      "error: Unable to find vcvarsall.bat\n",
      " \n",
      "\n",
      "Sample code (in a  REPL ): \n",
      " import json\n",
      "json_string = json.dumps(\"ברי צקלה\")\n",
      "print(json_string)\n",
      " \n",
      " Output: \n",
      " \"\\u05d1\\u05e8\\u05d9 \\u05e6\\u05e7\\u05dc\\u05d4\"\n",
      " \n",
      " The problem: it's not human readable. My (smart) users want to verify or even edit text files with JSON dumps (and I’d rather not use XML). \n",
      " Is there a way to serialize objects into UTF-8 JSON strings (instead of  \\uXXXX )? \n",
      "\n",
      "I have a pandas DataFrame with a column of string values. I need to select rows based on partial string matches. \n",
      " Something like this idiom: \n",
      " re.search(pattern, cell_in_question) \n",
      " \n",
      " returning a boolean. I am familiar with the syntax of  df[df['A'] == \"hello world\"]  but can't seem to find a way to do the same with a partial string match, say  'hello' . \n",
      "\n",
      "Sometimes I want to just insert some print statements in my code, and see what gets printed out when I exercise it. My usual way to \"exercise\" it is with existing pytest tests. But when I run these, I don't seem able to see any standard output (at least from within PyCharm, my IDE). \n",
      " Is there a simple way to see standard output during a pytest run? \n",
      "\n",
      "I want to filter my dataframe with an  or  condition to keep rows with a particular column's values that are outside the range  [-0.25, 0.25] . I tried: \n",
      " df = df[(df['col'] < -0.25) or (df['col'] > 0.25)]\n",
      " \n",
      " But I get the error: \n",
      " \n",
      " ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). \n",
      " \n",
      "\n",
      "How can I achieve the equivalents of SQL's  IN  and  NOT IN ? \n",
      " I have a list with the required values. Here's the scenario: \n",
      " df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\n",
      "countries_to_keep = ['UK', 'China']\n",
      "\n",
      "# pseudo-code:\n",
      "df[df['country'] not in countries_to_keep]\n",
      " \n",
      " My current way of doing this is as follows: \n",
      " df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})\n",
      "df2 = pd.DataFrame({'country': ['UK', 'China'], 'matched': True})\n",
      "\n",
      "# IN\n",
      "df.merge(df2, how='inner', on='country')\n",
      "\n",
      "# NOT IN\n",
      "not_in = df.merge(df2, how='left', on='country')\n",
      "not_in = not_in[pd.isnull(not_in['matched'])]\n",
      " \n",
      " But this seems like a horrible kludge. Can anyone improve on it? \n",
      "\n",
      "Apparently xrange is faster but I have no idea why it's faster (and no proof besides the anecdotal so far that it is faster) or what besides that is different about \n",
      " for i in range(0, 20):\n",
      "for i in xrange(0, 20):\n",
      " \n",
      "\n",
      "I'm trying to make a function that will compare multiple variables to an integer and output a string of three letters. I was wondering if there was a way to translate this into Python. So say: \n",
      " x = 0\n",
      "y = 1\n",
      "z = 3\n",
      "mylist = []\n",
      "\n",
      "if x or y or z == 0:\n",
      "    mylist.append(\"c\")\n",
      "if x or y or z == 1:\n",
      "    mylist.append(\"d\")\n",
      "if x or y or z == 2:\n",
      "    mylist.append(\"e\")\n",
      "if x or y or z == 3: \n",
      "    mylist.append(\"f\")\n",
      " \n",
      " which would return a list of: \n",
      " [\"c\", \"d\", \"f\"]\n",
      " \n",
      "\n",
      "What's the difference between a module and package in Python? \n",
      " See also:  What's the difference between \"package\" and \"module\"?  (for other languages) \n",
      "\n",
      "I have the following DataFrame: \n",
      "     Col1  Col2  Col3  Type\n",
      "0      1     2     3     1\n",
      "1      4     5     6     1\n",
      "...\n",
      "20     7     8     9     2\n",
      "21    10    11    12     2\n",
      "...\n",
      "45    13    14    15     3\n",
      "46    16    17    18     3\n",
      "...\n",
      " \n",
      " The DataFrame is read from a CSV file. All rows which have  Type  1 are on top, followed by the rows with  Type  2, followed by the rows with  Type  3, etc. \n",
      " I would like to shuffle the order of the DataFrame's rows so that all  Type 's are mixed. A possible result could be: \n",
      "     Col1  Col2  Col3  Type\n",
      "0      7     8     9     2\n",
      "1     13    14    15     3\n",
      "...\n",
      "20     1     2     3     1\n",
      "21    10    11    12     2\n",
      "...\n",
      "45     4     5     6     1\n",
      "46    16    17    18     3\n",
      "...\n",
      " \n",
      " How can I achieve this? \n",
      "\n",
      "I'm trying to follow  PEP 328 , with the following directory structure: \n",
      " pkg/\n",
      "  __init__.py\n",
      "  components/\n",
      "    core.py\n",
      "    __init__.py\n",
      "  tests/\n",
      "    core_test.py\n",
      "    __init__.py\n",
      " \n",
      " In  core_test.py  I have the following import statement \n",
      " from ..components.core import GameLoopEvents\n",
      " \n",
      " However, when I run, I get the following error: \n",
      " tests$ python core_test.py \n",
      "Traceback (most recent call last):\n",
      "  File \"core_test.py\", line 3, in <module>\n",
      "    from ..components.core import GameLoopEvents\n",
      "ValueError: Attempted relative import in non-package\n",
      " \n",
      " Searching around I found \" relative path not working even with __init__.py \" and \" Import a module from a relative path \" but they didn't help. \n",
      " Is there anything I'm missing here? \n",
      "\n",
      "I'm trying to build the search for a Django site I am building, and in that search, I am searching across three different models. And to get pagination on the search result list, I would like to use a generic object_list view to display the results. But to do that, I have to merge three QuerySets into one. \n",
      " How can I do that? I've tried this: \n",
      " result_list = []\n",
      "page_list = Page.objects.filter(\n",
      "    Q(title__icontains=cleaned_search_term) |\n",
      "    Q(body__icontains=cleaned_search_term))\n",
      "article_list = Article.objects.filter(\n",
      "    Q(title__icontains=cleaned_search_term) |\n",
      "    Q(body__icontains=cleaned_search_term) |\n",
      "    Q(tags__icontains=cleaned_search_term))\n",
      "post_list = Post.objects.filter(\n",
      "    Q(title__icontains=cleaned_search_term) |\n",
      "    Q(body__icontains=cleaned_search_term) |\n",
      "    Q(tags__icontains=cleaned_search_term))\n",
      "\n",
      "for x in page_list:\n",
      "    result_list.append(x)\n",
      "for x in article_list:\n",
      "    result_list.append(x)\n",
      "for x in post_list:\n",
      "    result_list.append(x)\n",
      "\n",
      "return object_list(\n",
      "    request,\n",
      "    queryset=result_list,\n",
      "    template_object_name='result',\n",
      "    paginate_by=10,\n",
      "    extra_context={\n",
      "        'search_term': search_term},\n",
      "    template_name=\"search/result_list.html\")\n",
      " \n",
      " But this doesn't work. I get an error when I try to use that list in the generic view. The list is missing the clone attribute. \n",
      " How can I merge the three lists,  page_list ,  article_list  and  post_list ? \n",
      "\n",
      "How to convert an index of a dataframe into a column? \n",
      " For example: \n",
      "         gi       ptt_loc\n",
      " 0  384444683      593  \n",
      " 1  384444684      594 \n",
      " 2  384444686      596  \n",
      " \n",
      " to \n",
      "     index1    gi       ptt_loc\n",
      " 0  0     384444683      593  \n",
      " 1  1     384444684      594 \n",
      " 2  2     384444686      596  \n",
      " \n",
      "\n",
      "How can I convert a string into uppercase in Python? \n",
      " When I tried to research the problem, I found something about  string.ascii_uppercase , but it couldn't solve the problem: \n",
      " >>> s = 'sdsd'\n",
      ">>> s.ascii_uppercase\n",
      "Traceback (most recent call last):\n",
      "  File \"<stdin>\", line 1, in <module>\n",
      "AttributeError: 'str' object has no attribute 'ascii_uppercase'\n",
      " \n",
      " \n",
      " See  How do I lowercase a string in Python?  for the opposite. \n",
      "\n",
      "I've been hearing a lot about the  PyPy  project. They claim it is 6.3 times faster than the  CPython  interpreter on  their site . \n",
      " Whenever we talk about dynamic languages like Python, speed is one of the top issues. To solve this, they say PyPy is 6.3 times faster. \n",
      " The second issue is parallelism, the infamous  Global Interpreter Lock  (GIL). For this, PyPy says it  can give GIL-less Python . \n",
      " If PyPy can solve these great challenges, what are its weaknesses that are preventing wider adoption? That is to say, what's preventing someone like me, a typical Python developer, from switching to PyPy  right now ?  \n",
      "\n",
      "File \"C:\\Users\\Administrator\\Documents\\Mibot\\oops\\blinkserv.py\", line 82, in __init__\n",
      "    self.serv = socket(AF_INET,SOCK_STREAM)\n",
      "TypeError: 'module' object is not callable\n",
      " \n",
      " Why am I getting this error?\n",
      "I'm confused. \n",
      " How can I solve this error? \n",
      "\n",
      "I compared the processing speeds of  []  and  list()  on Python 3.11 \n",
      " $ python -m timeit '[]'\n",
      "20000000 loops, best of 5: 11.3 nsec per loop\n",
      "$ python -m timeit 'list()'\n",
      "10000000 loops, best of 5: 26.1 nsec per loop\n",
      " \n",
      " and was surprised to discover that  []  runs about two times faster than  list() . I got very similar results for  {}  and  dict() \n",
      " $ python -m timeit '{}'\n",
      "20000000 loops, best of 5: 11.6 nsec per loop\n",
      "$ python -m timeit 'dict()'\n",
      "10000000 loops, best of 5: 27.1 nsec per loop\n",
      " \n",
      " Why is this? Do  []  and  {}  (and probably  ()  and  '' , too) immediately pass back a copies of some empty stock literal while their explicitly-named counterparts ( list() ,  dict() ,  tuple() ,  str() ) fully go about creating an object, whether or not they actually have elements? \n",
      "\n",
      "When creating a simple object hierarchy in Python, I'd like to be able to invoke methods of the parent class from a derived class.  In Perl and Java, there is a keyword for this ( super ).  In Perl, I might do this: \n",
      " package Foo;\n",
      "\n",
      "sub frotz {\n",
      "    return \"Bamf\";\n",
      "}\n",
      "\n",
      "package Bar;\n",
      "@ISA = qw(Foo);\n",
      "\n",
      "sub frotz {\n",
      "   my $str = SUPER::frotz();\n",
      "   return uc($str);\n",
      "}\n",
      " \n",
      " In Python, it appears that I have to name the parent class explicitly from the child.\n",
      "In the example above, I'd have to do something like  Foo::frotz() .   \n",
      " This doesn't seem right since this behavior makes it hard to make deep hierarchies.  If children need to know what class defined an inherited method, then all sorts of information pain is created.   \n",
      " Is this an actual limitation in python, a gap in my understanding or both? \n",
      "\n",
      "I have two variables as follows. \n",
      " a = 2\n",
      "b = 3\n",
      " \n",
      " I want to construct a DataFrame from this: \n",
      " df2 = pd.DataFrame({'A':a, 'B':b})\n",
      " \n",
      " This generates an error: \n",
      " ValueError: If using all scalar values, you must pass an index\n",
      " \n",
      " I tried this also: \n",
      " df2 = (pd.DataFrame({'a':a, 'b':b})).reset_index()\n",
      " \n",
      " This gives the same error message. How do I do what I want? \n",
      "\n",
      "I have a Unicode string in Python, and I would like to remove all the accents (diacritics). \n",
      " I found on the web an elegant way to do this (in Java): \n",
      " \n",
      " convert the Unicode string to its  long normalized form  (with a separate character for letters and diacritics) \n",
      " remove all the characters whose Unicode type is \"diacritic\". \n",
      " \n",
      " Do I need to install a library such as pyICU or is this possible with just the Python standard library?  And what about python 3? \n",
      " Important note: I would like to avoid code with an explicit mapping from accented characters to their non-accented counterpart. \n",
      "\n",
      "In code like  zip(*x)  or  f(**k) , what do the  *  and  **  respectively mean? How does Python implement that behaviour, and what are the performance implications? \n",
      " \n",
      " See also:  Expanding tuples into arguments . Please use that one to close questions where OP needs to use  *  on an argument and doesn't know it exists. Similarly, use  Converting Python dict to kwargs?  for the case of using  ** . \n",
      " See  What does ** (double star/asterisk) and * (star/asterisk) do for parameters?  for the complementary question about parameters. \n",
      "\n",
      "I have a dataframe  df  and I use several columns from it to  groupby : \n",
      " df['col1','col2','col3','col4'].groupby(['col1','col2']).mean()\n",
      " \n",
      " In the above way, I almost get the table (dataframe) that I need. What is missing is an additional column that contains number of rows in each group. In other words, I have mean but I also would like to know how many were used to get these means. For example in the first group there are 8 values and in the second one 10 and so on. \n",
      " In short: How do I get  group-wise  statistics for a dataframe? \n",
      "\n",
      "I have two integer values  a  and  b , but I need their ratio in floating point.  I know that  a < b  and I want to calculate  a / b , so if I use integer division I'll always get 0 with a remainder of  a . \n",
      " How can I force  c  to be a floating point number in Python 2 in the following? \n",
      " c = a / b\n",
      " \n",
      " \n",
      " In 3.x, the behaviour is reversed; see  Why does integer division yield a float instead of another integer?  for the opposite, 3.x-specific problem. \n",
      "\n",
      "I have created a Pandas DataFrame \n",
      " df = DataFrame(index=['A','B','C'], columns=['x','y'])\n",
      " \n",
      " Now, I would like to assign a value to particular cell, for example to row  C  and column  x . In other words, I would like to perform the following transformation: \n",
      "      x    y             x    y\n",
      "A  NaN  NaN        A  NaN  NaN\n",
      "B  NaN  NaN   ⟶   B  NaN  NaN\n",
      "C  NaN  NaN        C   10  NaN\n",
      " \n",
      " with this code: \n",
      " df.xs('C')['x'] = 10\n",
      " \n",
      " However, the contents of  df  has not changed. The dataframe contains yet again only  NaN s. How do I what I want? \n",
      "\n",
      "Code: \n",
      " # coding=utf-8\n",
      "import pytest\n",
      "\n",
      "\n",
      "def whatever():\n",
      "    return 9/0\n",
      "\n",
      "def test_whatever():\n",
      "    try:\n",
      "        whatever()\n",
      "    except ZeroDivisionError as exc:\n",
      "        pytest.fail(exc, pytrace=True)\n",
      " \n",
      " Output: \n",
      " ================================ test session starts =================================\n",
      "platform linux2 -- Python 2.7.3 -- py-1.4.20 -- pytest-2.5.2\n",
      "plugins: django, cov\n",
      "collected 1 items \n",
      "\n",
      "pytest_test.py F\n",
      "\n",
      "====================================== FAILURES ======================================\n",
      "___________________________________ test_whatever ____________________________________\n",
      "\n",
      "    def test_whatever():\n",
      "        try:\n",
      "            whatever()\n",
      "        except ZeroDivisionError as exc:\n",
      ">           pytest.fail(exc, pytrace=True)\n",
      "E           Failed: integer division or modulo by zero\n",
      "\n",
      "pytest_test.py:12: Failed\n",
      "============================== 1 failed in 1.16 seconds ==============================\n",
      " \n",
      " How do I make pytest print traceback, so that I would see where in the  whatever  function that an exception was raised? \n",
      "\n",
      "I want to know the difference between  __init__  and  __call__  methods.   \n",
      " For example: \n",
      " class test:\n",
      "\n",
      "  def __init__(self):\n",
      "    self.a = 10\n",
      "\n",
      "  def __call__(self): \n",
      "    b = 20\n",
      " \n",
      "\n",
      "When I read Django code I often see in models what is called a \"slug\". I am not quite sure what this is, but I do know it has something to do with URLs. How and when is this slug-thing supposed to be used? \n",
      " I have read its definition below in  this glossary : \n",
      " \n",
      " Slug \n",
      "A short label for something, containing only letters, numbers,\n",
      "underscores or hyphens. They’re generally used in URLs. For example,\n",
      "in a typical blog entry URL: \n",
      " https://www.djangoproject.com/weblog/2008/apr/12/spring/  the last bit\n",
      "(spring) is the slug. \n",
      " \n",
      "\n",
      "I am trying to fix how python plots my data. Say: \n",
      " x = [0, 5, 9, 10, 15]\n",
      "y = [0, 1, 2, 3, 4]\n",
      "\n",
      "matplotlib.pyplot.plot(x, y)\n",
      "matplotlib.pyplot.show()\n",
      " \n",
      " The x axis' ticks are plotted in intervals of 5. Is there a way to make it show intervals of 1? \n",
      "\n",
      "I would like to read several CSV files from a directory into pandas and concatenate them into one big DataFrame. I have not been able to figure it out though. Here is what I have so far: \n",
      " import glob\n",
      "import pandas as pd\n",
      "\n",
      "# Get data file names\n",
      "path = r'C:\\DRO\\DCL_rawdata_files'\n",
      "filenames = glob.glob(path + \"/*.csv\")\n",
      "\n",
      "dfs = []\n",
      "for filename in filenames:\n",
      "    dfs.append(pd.read_csv(filename))\n",
      "\n",
      "# Concatenate all data into one DataFrame\n",
      "big_frame = pd.concat(dfs, ignore_index=True)\n",
      " \n",
      " I guess I need some help within the  for  loop? \n",
      "\n",
      "What's the difference between: \n",
      " class Child(SomeBaseClass):\n",
      "    def __init__(self):\n",
      "        super(Child, self).__init__()\n",
      "        \n",
      " \n",
      " and: \n",
      " class Child(SomeBaseClass):\n",
      "    def __init__(self):\n",
      "        SomeBaseClass.__init__(self)\n",
      "        \n",
      " \n",
      " I've seen  super  being used quite a lot in classes with only single inheritance. I can see why you'd use it in multiple inheritance but am unclear as to what the advantages are of using it in this kind of situation. \n",
      " \n",
      " This question is about technical implementation details and the distinction between different ways of accessing the base class  __init__  method. To close duplicate questions where OP is simply missing a  super  call and is asking why base class attributes aren't available, please use  Python class inheritance: AttributeError: '[SubClass]' object has no attribute 'xxx'  instead. \n",
      "\n",
      "I have taken  Problem #12  from  Project Euler  as a programming exercise and to compare my (surely not optimal) implementations in C, Python, Erlang and Haskell. In order to get some higher execution times, I search for the first triangle number with more than 1000 divisors instead of 500 as stated in the original problem. \n",
      " The result is the following: \n",
      " C: \n",
      " lorenzo@enzo:~/erlang$ gcc -lm -o euler12.bin euler12.c\n",
      "lorenzo@enzo:~/erlang$ time ./euler12.bin\n",
      "842161320\n",
      "\n",
      "real    0m11.074s\n",
      "user    0m11.070s\n",
      "sys 0m0.000s\n",
      " \n",
      " Python: \n",
      " lorenzo@enzo:~/erlang$ time ./euler12.py \n",
      "842161320\n",
      "\n",
      "real    1m16.632s\n",
      "user    1m16.370s\n",
      "sys 0m0.250s\n",
      " \n",
      " Python with PyPy: \n",
      " lorenzo@enzo:~/Downloads/pypy-c-jit-43780-b590cf6de419-linux64/bin$ time ./pypy /home/lorenzo/erlang/euler12.py \n",
      "842161320\n",
      "\n",
      "real    0m13.082s\n",
      "user    0m13.050s\n",
      "sys 0m0.020s\n",
      " \n",
      " Erlang: \n",
      " lorenzo@enzo:~/erlang$ erlc euler12.erl \n",
      "lorenzo@enzo:~/erlang$ time erl -s euler12 solve\n",
      "Erlang R13B03 (erts-5.7.4) [source] [64-bit] [smp:4:4] [rq:4] [async-threads:0] [hipe] [kernel-poll:false]\n",
      "\n",
      "Eshell V5.7.4  (abort with ^G)\n",
      "1> 842161320\n",
      "\n",
      "real    0m48.259s\n",
      "user    0m48.070s\n",
      "sys 0m0.020s\n",
      " \n",
      " Haskell: \n",
      " lorenzo@enzo:~/erlang$ ghc euler12.hs -o euler12.hsx\n",
      "[1 of 1] Compiling Main             ( euler12.hs, euler12.o )\n",
      "Linking euler12.hsx ...\n",
      "lorenzo@enzo:~/erlang$ time ./euler12.hsx \n",
      "842161320\n",
      "\n",
      "real    2m37.326s\n",
      "user    2m37.240s\n",
      "sys 0m0.080s\n",
      " \n",
      " Summary: \n",
      " \n",
      " C: 100% \n",
      " Python: 692% (118% with PyPy) \n",
      " Erlang: 436% (135% thanks to RichardC) \n",
      " Haskell: 1421% \n",
      " \n",
      " I suppose that C has a big advantage as it uses long for the calculations and not arbitrary length integers as the other three. Also it doesn't need to load a runtime first (Do the others?). \n",
      " Question 1: \n",
      "Do Erlang, Python and Haskell lose speed due to using arbitrary length integers or don't they as long as the values are less than  MAXINT ? \n",
      " Question 2: \n",
      "Why is Haskell so slow? Is there a compiler flag that turns off the brakes or is it my implementation? (The latter is quite probable as Haskell is a book with seven seals to me.) \n",
      " Question 3: \n",
      "Can you offer me some hints how to optimize these implementations without changing the way I determine the factors? Optimization in any way: nicer, faster, more \"native\" to the language. \n",
      " EDIT: \n",
      " Question 4: \n",
      "Do my functional implementations permit LCO (last call optimization, a.k.a tail recursion elimination) and hence avoid adding unnecessary frames onto the call stack? \n",
      " I really tried to implement the same algorithm as similar as possible in the four languages, although I have to admit that my Haskell and Erlang knowledge is very limited. \n",
      " \n",
      " Source codes used: \n",
      " #include <stdio.h>\n",
      "#include <math.h>\n",
      "\n",
      "int factorCount (long n)\n",
      "{\n",
      "    double square = sqrt (n);\n",
      "    int isquare = (int) square;\n",
      "    int count = isquare == square ? -1 : 0;\n",
      "    long candidate;\n",
      "    for (candidate = 1; candidate <= isquare; candidate ++)\n",
      "        if (0 == n % candidate) count += 2;\n",
      "    return count;\n",
      "}\n",
      "\n",
      "int main ()\n",
      "{\n",
      "    long triangle = 1;\n",
      "    int index = 1;\n",
      "    while (factorCount (triangle) < 1001)\n",
      "    {\n",
      "        index ++;\n",
      "        triangle += index;\n",
      "    }\n",
      "    printf (\"%ld\\n\", triangle);\n",
      "}\n",
      " \n",
      " \n",
      " #! /usr/bin/env python3.2\n",
      "\n",
      "import math\n",
      "\n",
      "def factorCount (n):\n",
      "    square = math.sqrt (n)\n",
      "    isquare = int (square)\n",
      "    count = -1 if isquare == square else 0\n",
      "    for candidate in range (1, isquare + 1):\n",
      "        if not n % candidate: count += 2\n",
      "    return count\n",
      "\n",
      "triangle = 1\n",
      "index = 1\n",
      "while factorCount (triangle) < 1001:\n",
      "    index += 1\n",
      "    triangle += index\n",
      "\n",
      "print (triangle)\n",
      " \n",
      " \n",
      " -module (euler12).\n",
      "-compile (export_all).\n",
      "\n",
      "factorCount (Number) -> factorCount (Number, math:sqrt (Number), 1, 0).\n",
      "\n",
      "factorCount (_, Sqrt, Candidate, Count) when Candidate > Sqrt -> Count;\n",
      "\n",
      "factorCount (_, Sqrt, Candidate, Count) when Candidate == Sqrt -> Count + 1;\n",
      "\n",
      "factorCount (Number, Sqrt, Candidate, Count) ->\n",
      "    case Number rem Candidate of\n",
      "        0 -> factorCount (Number, Sqrt, Candidate + 1, Count + 2);\n",
      "        _ -> factorCount (Number, Sqrt, Candidate + 1, Count)\n",
      "    end.\n",
      "\n",
      "nextTriangle (Index, Triangle) ->\n",
      "    Count = factorCount (Triangle),\n",
      "    if\n",
      "        Count > 1000 -> Triangle;\n",
      "        true -> nextTriangle (Index + 1, Triangle + Index + 1)  \n",
      "    end.\n",
      "\n",
      "solve () ->\n",
      "    io:format (\"~p~n\", [nextTriangle (1, 1) ] ),\n",
      "    halt (0).\n",
      " \n",
      " \n",
      " factorCount number = factorCount' number isquare 1 0 - (fromEnum $ square == fromIntegral isquare)\n",
      "    where square = sqrt $ fromIntegral number\n",
      "          isquare = floor square\n",
      "\n",
      "factorCount' number sqrt candidate count\n",
      "    | fromIntegral candidate > sqrt = count\n",
      "    | number `mod` candidate == 0 = factorCount' number sqrt (candidate + 1) (count + 2)\n",
      "    | otherwise = factorCount' number sqrt (candidate + 1) count\n",
      "\n",
      "nextTriangle index triangle\n",
      "    | factorCount triangle > 1000 = triangle\n",
      "    | otherwise = nextTriangle (index + 1) (triangle + index + 1)\n",
      "\n",
      "main = print $ nextTriangle 1 1\n",
      " \n",
      "\n",
      "Dictionaries are insertion ordered as of Python 3.6. It is described as a CPython implementation detail rather than a language feature. The  documentation  states: \n",
      " \n",
      " dict()  now uses a “compact” representation  pioneered by PyPy . The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5.  PEP 468  (Preserving the order of **kwargs in a function.) is implemented by this. The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5). (Contributed by INADA Naoki in  issue 27350 . Idea  originally suggested by Raymond Hettinger .) \n",
      " \n",
      " How does the new dictionary implementation perform better than the older one while preserving element order? \n",
      " \n",
      " Update December 2017:  dict s retaining insertion order is  guaranteed  for Python 3.7 \n",
      "\n",
      "Suppose I have a function and a dataframe defined as below: \n",
      " def get_sublist(sta, end):\n",
      "    return mylist[sta:end+1]\n",
      "\n",
      "df = pd.DataFrame({'ID':['1','2','3'], 'col_1': [0,2,3], 'col_2':[1,4,5]})\n",
      "mylist = ['a','b','c','d','e','f']\n",
      " \n",
      " Now I want to apply  get_sublist  to  df 's two columns  'col_1', 'col_2'  to element-wise calculate a new column  'col_3'  to get an output that looks like: \n",
      "   ID  col_1  col_2            col_3\n",
      "0  1      0      1       ['a', 'b']\n",
      "1  2      2      4  ['c', 'd', 'e']\n",
      "2  3      3      5  ['d', 'e', 'f']\n",
      " \n",
      " I tried \n",
      " df['col_3'] = df[['col_1','col_2']].apply(get_sublist, axis=1)\n",
      " \n",
      " but this results in \n",
      " TypeError: get_sublist() missing 1 required positional argument:\n",
      " \n",
      " How do I do it? \n",
      "\n",
      "I have a problem with the transfer of the variable  insurance_mode  by the decorator. I would do it by the following decorator statement: \n",
      " @execute_complete_reservation(True)\n",
      "def test_booking_gta_object(self):\n",
      "    self.test_select_gta_object()\n",
      " \n",
      " but unfortunately, this statement does not work. Perhaps maybe there is better way to solve this problem. \n",
      " def execute_complete_reservation(test_case,insurance_mode):\n",
      "    def inner_function(self,*args,**kwargs):\n",
      "        self.test_create_qsf_query()\n",
      "        test_case(self,*args,**kwargs)\n",
      "        self.test_select_room_option()\n",
      "        if insurance_mode:\n",
      "            self.test_accept_insurance_crosseling()\n",
      "        else:\n",
      "            self.test_decline_insurance_crosseling()\n",
      "        self.test_configure_pax_details()\n",
      "        self.test_configure_payer_details\n",
      "\n",
      "    return inner_function\n",
      " \n",
      "\n",
      "I have to use  Python  and  Django  for our application. So, I have two versions of Python, 2.6 and 2.7. Now I have installed Django. I could run the sample application for testing Django successfully. But how do I check whether Django uses the 2.6 or 2.7 version and what version of modules Django uses? \n",
      "\n",
      "How do I convert a pandas dataframe into a NumPy array? \n",
      " DataFrame: \n",
      " import numpy as np\n",
      "import pandas as pd\n",
      "\n",
      "index = [1, 2, 3, 4, 5, 6, 7]\n",
      "a = [np.nan, np.nan, np.nan, 0.1, 0.1, 0.1, 0.1]\n",
      "b = [0.2, np.nan, 0.2, 0.2, 0.2, np.nan, np.nan]\n",
      "c = [np.nan, 0.5, 0.5, np.nan, 0.5, 0.5, np.nan]\n",
      "df = pd.DataFrame({'A': a, 'B': b, 'C': c}, index=index)\n",
      "df = df.rename_axis('ID')\n",
      " \n",
      " gives \n",
      "       A    B    C\n",
      "ID                                 \n",
      "1   NaN  0.2  NaN\n",
      "2   NaN  NaN  0.5\n",
      "3   NaN  0.2  0.5\n",
      "4   0.1  0.2  NaN\n",
      "5   0.1  0.2  0.5\n",
      "6   0.1  NaN  0.5\n",
      "7   0.1  NaN  NaN\n",
      " \n",
      " I would like to convert this to a NumPy array, like so: \n",
      " array([[ nan,  0.2,  nan],\n",
      "       [ nan,  nan,  0.5],\n",
      "       [ nan,  0.2,  0.5],\n",
      "       [ 0.1,  0.2,  nan],\n",
      "       [ 0.1,  0.2,  0.5],\n",
      "       [ 0.1,  nan,  0.5],\n",
      "       [ 0.1,  nan,  nan]])\n",
      " \n",
      " \n",
      " Also, is it possible to preserve the dtypes, like this? \n",
      " array([[ 1, nan,  0.2,  nan],\n",
      "       [ 2, nan,  nan,  0.5],\n",
      "       [ 3, nan,  0.2,  0.5],\n",
      "       [ 4, 0.1,  0.2,  nan],\n",
      "       [ 5, 0.1,  0.2,  0.5],\n",
      "       [ 6, 0.1,  nan,  0.5],\n",
      "       [ 7, 0.1,  nan,  nan]],\n",
      "     dtype=[('ID', '<i4'), ('A', '<f8'), ('B', '<f8'), ('B', '<f8')])\n",
      " \n",
      "\n",
      "I'm running a program which is processing 30,000 similar files. A random number of them are stopping and producing this error... \n",
      "   File \"C:\\Importer\\src\\dfman\\importer.py\", line 26, in import_chr\n",
      "    data = pd.read_csv(filepath, names=fields)\n",
      "  File \"C:\\Python33\\lib\\site-packages\\pandas\\io\\parsers.py\", line 400, in parser_f\n",
      "    return _read(filepath_or_buffer, kwds)\n",
      "  File \"C:\\Python33\\lib\\site-packages\\pandas\\io\\parsers.py\", line 205, in _read\n",
      "    return parser.read()\n",
      "  File \"C:\\Python33\\lib\\site-packages\\pandas\\io\\parsers.py\", line 608, in read\n",
      "    ret = self._engine.read(nrows)\n",
      "  File \"C:\\Python33\\lib\\site-packages\\pandas\\io\\parsers.py\", line 1028, in read\n",
      "    data = self._reader.read(nrows)\n",
      "  File \"parser.pyx\", line 706, in pandas.parser.TextReader.read (pandas\\parser.c:6745)\n",
      "  File \"parser.pyx\", line 728, in pandas.parser.TextReader._read_low_memory (pandas\\parser.c:6964)\n",
      "  File \"parser.pyx\", line 804, in pandas.parser.TextReader._read_rows (pandas\\parser.c:7780)\n",
      "  File \"parser.pyx\", line 890, in pandas.parser.TextReader._convert_column_data (pandas\\parser.c:8793)\n",
      "  File \"parser.pyx\", line 950, in pandas.parser.TextReader._convert_tokens (pandas\\parser.c:9484)\n",
      "  File \"parser.pyx\", line 1026, in pandas.parser.TextReader._convert_with_dtype (pandas\\parser.c:10642)\n",
      "  File \"parser.pyx\", line 1046, in pandas.parser.TextReader._string_convert (pandas\\parser.c:10853)\n",
      "  File \"parser.pyx\", line 1278, in pandas.parser._string_box_utf8 (pandas\\parser.c:15657)\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0xda in position 6: invalid    continuation byte\n",
      " \n",
      " The source/creation of these files all come from the same place. What's the best way to correct this to proceed with the import? \n",
      "\n",
      "I have a Python script which takes as input a list of integers, which I need to work with four integers at a time.  Unfortunately, I don't have control of the input, or I'd have it passed in as a list of four-element tuples.  Currently, I'm iterating over it this way: \n",
      " for i in range(0, len(ints), 4):\n",
      "    # dummy op for example code\n",
      "    foo += ints[i] * ints[i + 1] + ints[i + 2] * ints[i + 3]\n",
      " \n",
      " It looks a lot like \"C-think\", though, which makes me suspect there's a more pythonic way of dealing with this situation.  The list is discarded after iterating, so it needn't be preserved.  Perhaps something like this would be better? \n",
      " while ints:\n",
      "    foo += ints[0] * ints[1] + ints[2] * ints[3]\n",
      "    ints[0:4] = []\n",
      " \n",
      " Still doesn't quite \"feel\" right, though.  :-/ \n",
      " Update:  With the release of Python 1.12, I've changed the accepted answer. For anyone who has not (or cannot) make the jump to 1.12 yet, I encourage you to check out the  previous accepted answer  or any of the other excellent, backwards-compatible answers below. \n",
      " Related question:  How do you split a list into evenly sized chunks in Python? \n",
      "\n",
      "I want to install  pip . It should support Python 3, but it requires setuptools, which is available only for Python 2. \n",
      " How can I install pip with Python 3? \n",
      "\n",
      "I have a dataframe: \n",
      "    City     Name\n",
      "0   Seattle    Alice\n",
      "1   Seattle      Bob\n",
      "2  Portland  Mallory\n",
      "3   Seattle  Mallory\n",
      "4   Seattle      Bob\n",
      "5  Portland  Mallory\n",
      " \n",
      " I perform the following grouping: \n",
      " g1 = df1.groupby([\"Name\", \"City\"]).count()\n",
      " \n",
      " which when printed looks like: \n",
      "                   City  Name\n",
      "Name    City\n",
      "Alice   Seattle      1     1\n",
      "Bob     Seattle      2     2\n",
      "Mallory Portland     2     2\n",
      "        Seattle      1     1\n",
      " \n",
      " But what I want eventually is another DataFrame object that contains all the rows in the GroupBy object. In other words I want to get the following result: \n",
      "                   City  Name\n",
      "Name    City\n",
      "Alice   Seattle      1     1\n",
      "Bob     Seattle      2     2\n",
      "Mallory Portland     2     2\n",
      "Mallory Seattle      1     1\n",
      " \n",
      " How do I do it? \n",
      "\n",
      "What is the difference between the  search()  and  match()  functions in the Python  re  module? \n",
      " I've read the  Python 2 documentation  ( Python 3 documentation ), but I never seem to remember it. \n",
      "\n",
      "How do I find the arithmetic mean of a list in Python? For example: \n",
      " [1, 2, 3, 4]  ⟶  2.5\n",
      " \n",
      "\n",
      "I have a function in python that can either return a  bool  or a  list . Is there a way to specify the return types using type hints? \n",
      " For example, is this the correct way to do it? \n",
      " def foo(id) -> list or bool:\n",
      "    ...\n",
      " \n",
      "\n",
      "I'm using the Python bindings to run Selenium WebDriver: \n",
      " from selenium import webdriver\n",
      "wd = webdriver.Firefox()\n",
      " \n",
      " I know I can grab a webelement like so: \n",
      " elem = wd.find_element_by_css_selector('#my-id')\n",
      " \n",
      " And I know I can get the full page source with... \n",
      " wd.page_source\n",
      " \n",
      " But is there a way to get the \"element source\"? \n",
      " elem.source   # <-- returns the HTML as a string\n",
      " \n",
      " The Selenium WebDriver documentation for Python are basically non-existent and I don't see anything in the code that seems to enable that functionality. \n",
      " What is the best way to access the HTML of an element (and its children)? \n",
      "\n",
      "I have a dataframe like this: \n",
      "         0          1     2\n",
      "0   354.7      April   4.0\n",
      "1    55.4     August   8.0\n",
      "2   176.5   December  12.0\n",
      "3    95.5   February   2.0\n",
      "4    85.6    January   1.0\n",
      "5     152       July   7.0\n",
      "6   238.7       June   6.0\n",
      "7   104.8      March   3.0\n",
      "8   283.5        May   5.0\n",
      "9   278.8   November  11.0\n",
      "10  249.6    October  10.0\n",
      "11  212.7  September   9.0\n",
      " \n",
      " As you can see, months are not in calendar order. So I created a second column to get the month number corresponding to each month (1-12). From there, how can I sort this dataframe according to  calendar months' order? \n",
      "\n",
      "I'm looking for the Python equivalent of  \n",
      " String str = \"many   fancy word \\nhello    \\thi\";\n",
      "String whiteSpaceRegex = \"\\\\s\";\n",
      "String[] words = str.split(whiteSpaceRegex);\n",
      "\n",
      "[\"many\", \"fancy\", \"word\", \"hello\", \"hi\"]\n",
      " \n",
      "\n",
      "I'm using Python's logging module to log some debug strings to a file which works pretty well. Now in addition, I'd like to use this module to also print the strings out to stdout. How do I do this? In order to log my strings to a file I use following code: \n",
      " import logging\n",
      "import logging.handlers\n",
      "logger = logging.getLogger(\"\")\n",
      "logger.setLevel(logging.DEBUG)\n",
      "handler = logging.handlers.RotatingFileHandler(\n",
      "    LOGFILE, maxBytes=(1048576*5), backupCount=7\n",
      ")\n",
      "formatter = logging.Formatter(\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\")\n",
      "handler.setFormatter(formatter)\n",
      "logger.addHandler(handler)\n",
      " \n",
      " and then call a logger function like \n",
      " logger.debug(\"I am written to the file\")\n",
      " \n",
      " Thank you for some help here! \n",
      "\n",
      "The Situation \n",
      " I’m trying to port an open-source library to Python 3.  ( SymPy , if anyone is wondering.)  \n",
      " So, I need to run  2to3  automatically when building for Python 3. To do that, I need to use  distribute . Therefore, I need to port the current system, which (according to the doctest) is  distutils .  \n",
      " \n",
      " The Problem \n",
      " Unfortunately, I’m not sure what’s the difference between these modules— distutils ,  distribute ,  setuptools . The documentation is sketchy as best, as they all seem to be a fork of one another, intended to be compatible in most circumstances (but actually, not all)…and so on, and so forth.  \n",
      " \n",
      " The Question \n",
      " Could someone explain the differences?  What am I supposed to use?  What is the most modern solution? (As an aside, I’d also appreciate some guide on porting to  Distribute , but that’s a tad beyond the scope of the question…) \n",
      "\n",
      "How do I split a sentence and store each word in a list? e.g. \n",
      " \"these are words\"   ⟶   [\"these\", \"are\", \"words\"]\n",
      " \n",
      " \n",
      " To split on other delimiters, see  Split a string by a delimiter in python . \n",
      " To split into individual characters, see  How do I split a string into a list of characters? . \n",
      "\n",
      "I am going over Sweigart's  Automate the Boring Stuff with Python  text. I'm using  IDLE  and already installed the Selenium module and the Firefox browser. \n",
      " Whenever I tried to run the webdriver function, I get this: \n",
      " from selenium import webdriver\n",
      "browser = webdriver.Firefox()\n",
      " \n",
      " Exception: \n",
      " Exception ignored in: <bound method Service.__del__ of <selenium.webdriver.firefox.service.Service object at 0x00000249C0DA1080>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python\\Python35\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 163, in __del__\n",
      "    self.stop()\n",
      "  File \"C:\\Python\\Python35\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 135, in stop\n",
      "    if self.process is None:\n",
      "AttributeError: 'Service' object has no attribute 'process'\n",
      "Exception ignored in: <bound method Service.__del__ of <selenium.webdriver.firefox.service.Service object at 0x00000249C0E08128>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python\\Python35\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 163, in __del__\n",
      "    self.stop()\n",
      "  File \"C:\\Python\\Python35\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 135, in stop\n",
      "    if self.process is None:\n",
      "AttributeError: 'Service' object has no attribute 'process'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Python\\Python35\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 64, in start\n",
      "    stdout=self.log_file, stderr=self.log_file)\n",
      "  File \"C:\\Python\\Python35\\lib\\subprocess.py\", line 947, in __init__\n",
      "    restore_signals, start_new_session)\n",
      "  File \"C:\\Python\\Python35\\lib\\subprocess.py\", line 1224, in _execute_child\n",
      "    startupinfo)\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      " \n",
      " During handling of the above exception, another exception occurred: \n",
      " Traceback (most recent call last):\n",
      "  File \"<pyshell#11>\", line 1, in <module>\n",
      "    browser = webdriver.Firefox()\n",
      "  File \"C:\\Python\\Python35\\lib\\site-packages\\selenium\\webdriver\\firefox\\webdriver.py\", line 135, in __init__\n",
      "    self.service.start()\n",
      "  File \"C:\\Python\\Python35\\lib\\site-packages\\selenium\\webdriver\\common\\service.py\", line 71, in start\n",
      "    os.path.basename(self.path), self.start_error_message)\n",
      "selenium.common.exceptions.WebDriverException: Message: 'geckodriver' executable needs to be in PATH.\n",
      " \n",
      " I think I need to set the path for  geckodriver , but I am not sure how, so how would I do this? \n",
      "\n",
      "The function  foo  below returns a string  'foo' . How can I get the value  'foo'  which is returned from the thread's target? \n",
      " from threading import Thread\n",
      "\n",
      "def foo(bar):\n",
      "    print('hello {}'.format(bar))\n",
      "    return 'foo'\n",
      "    \n",
      "thread = Thread(target=foo, args=('world!',))\n",
      "thread.start()\n",
      "return_value = thread.join()\n",
      " \n",
      " The \"one obvious way to do it\", shown above, doesn't work:  thread.join()  returned  None . \n",
      "\n",
      "I have a Pandas Dataframe as below: \n",
      "       itm Date                  Amount \n",
      "67    420 2012-09-30 00:00:00   65211\n",
      "68    421 2012-09-09 00:00:00   29424\n",
      "69    421 2012-09-16 00:00:00   29877\n",
      "70    421 2012-09-23 00:00:00   30990\n",
      "71    421 2012-09-30 00:00:00   61303\n",
      "72    485 2012-09-09 00:00:00   71781\n",
      "73    485 2012-09-16 00:00:00     NaN\n",
      "74    485 2012-09-23 00:00:00   11072\n",
      "75    485 2012-09-30 00:00:00  113702\n",
      "76    489 2012-09-09 00:00:00   64731\n",
      "77    489 2012-09-16 00:00:00     NaN\n",
      " \n",
      " When I try to apply a function to the Amount column, I get the following error: \n",
      " ValueError: cannot convert float NaN to integer\n",
      " \n",
      " I have tried applying a function using  math.isnan , pandas'  .replace  method,  .sparse  data attribute from pandas 0.9, if  NaN == NaN  statement in a function; I have also looked at  this Q/A ; none of them works. \n",
      " How do I do it? \n",
      "\n",
      "I am currently defining regular expressions in order to capture parameters in a URL, as described in the tutorial. How do I access parameters from the URL as part the  HttpRequest  object? \n",
      " My  HttpRequest.GET  currently returns an empty  QueryDict  object. \n",
      " I'd like to learn how to do this without a library, so I can get to know Django better. \n",
      "\n",
      "I've been testing out Selenium with Chromedriver and I noticed that some pages can detect that you're using Selenium even though there's no automation at all. Even when I'm just browsing manually just using Chrome through Selenium and  Xephyr  I often get a page saying that suspicious activity was detected. I've checked my user agent, and my browser fingerprint, and they are all exactly identical to the normal Chrome browser. \n",
      " When I browse to these sites in normal Chrome everything works fine, but the moment I use Selenium I'm detected. \n",
      " In theory, chromedriver and Chrome should look literally exactly the same to any web server, but somehow they can detect it. \n",
      " If you want some test code try out this: \n",
      " from pyvirtualdisplay import Display\n",
      "from selenium import webdriver\n",
      "\n",
      "display = Display(visible=1, size=(1600, 902))\n",
      "display.start()\n",
      "chrome_options = webdriver.ChromeOptions()\n",
      "chrome_options.add_argument('--disable-extensions')\n",
      "chrome_options.add_argument('--profile-directory=Default')\n",
      "chrome_options.add_argument(\"--incognito\")\n",
      "chrome_options.add_argument(\"--disable-plugins-discovery\");\n",
      "chrome_options.add_argument(\"--start-maximized\")\n",
      "driver = webdriver.Chrome(chrome_options=chrome_options)\n",
      "driver.delete_all_cookies()\n",
      "driver.set_window_size(800,800)\n",
      "driver.set_window_position(0,0)\n",
      "print 'arguments done'\n",
      "driver.get('http://stubhub.com')\n",
      " \n",
      " If you browse around stubhub you'll get redirected and 'blocked' within one or two requests. I've been investigating this and I can't figure out how they can tell that a user is using Selenium. \n",
      " How do they do it? \n",
      " I installed the Selenium IDE plugin in Firefox and I got banned when I went to stubhub.com in the normal Firefox browser with only the additional plugin. \n",
      " When I use  Fiddler  to view the HTTP requests being sent back and forth I've noticed that the 'fake browser's' requests often have 'no-cache' in the response header. \n",
      " Results like this  Is there a way to detect that I'm in a Selenium Webdriver page from JavaScript?  suggest that there should be no way to detect when you are using a webdriver. But this evidence suggests otherwise. \n",
      " The site uploads a fingerprint to their servers, but I checked and the fingerprint of Selenium is identical to the fingerprint when using Chrome. \n",
      " This is one of the fingerprint payloads that they send to their servers: \n",
      " {\"appName\":\"Netscape\",\"platform\":\"Linuxx86_64\",\"cookies\":1,\"syslang\":\"en-US\",\"userlang\":\"en-\n",
      "US\",\"cpu\":\"\",\"productSub\":\"20030107\",\"setTimeout\":1,\"setInterval\":1,\"plugins\":\n",
      "{\"0\":\"ChromePDFViewer\",\"1\":\"ShockwaveFlash\",\"2\":\"WidevineContentDecryptionMo\n",
      "dule\",\"3\":\"NativeClient\",\"4\":\"ChromePDFViewer\"},\"mimeTypes\":\n",
      "{\"0\":\"application/pdf\",\"1\":\"ShockwaveFlashapplication/x-shockwave-\n",
      "flash\",\"2\":\"FutureSplashPlayerapplication/futuresplash\",\"3\":\"WidevineContent\n",
      "DecryptionModuleapplication/x-ppapi-widevine-\n",
      "cdm\",\"4\":\"NativeClientExecutableapplication/x-\n",
      "nacl\",\"5\":\"PortableNativeClientExecutableapplication/x-\n",
      "pnacl\",\"6\":\"PortableDocumentFormatapplication/x-google-chrome-\n",
      "pdf\"},\"screen\":{\"width\":1600,\"height\":900,\"colorDepth\":24},\"fonts\":\n",
      "{\"0\":\"monospace\",\"1\":\"DejaVuSerif\",\"2\":\"Georgia\",\"3\":\"DejaVuSans\",\"4\":\"Trebu\n",
      "chetMS\",\"5\":\"Verdana\",\"6\":\"AndaleMono\",\"7\":\"DejaVuSansMono\",\"8\":\"LiberationM\n",
      "ono\",\"9\":\"NimbusMonoL\",\"10\":\"CourierNew\",\"11\":\"Courier\"}}\n",
      " \n",
      " It's identical in Selenium and in Chrome. \n",
      " VPNs work for a single use, but they get detected after I load the first page. Clearly some JavaScript code is being run to detect Selenium. \n",
      "\n",
      "Why does the following behave unexpectedly in Python? \n",
      " >>> a = 256\n",
      ">>> b = 256\n",
      ">>> a is b\n",
      "True           # This is an expected result\n",
      ">>> a = 257\n",
      ">>> b = 257\n",
      ">>> a is b\n",
      "False          # What happened here? Why is this False?\n",
      ">>> 257 is 257\n",
      "True           # Yet the literal numbers compare properly\n",
      " \n",
      " I am using Python 2.5.2. Trying some different versions of Python, it appears that Python 2.3.3 shows the above behaviour between 99 and 100. \n",
      " Based on the above, I can hypothesize that Python is internally implemented such that \"small\" integers are stored in a different way than larger integers and the  is  operator can tell the difference. Why the leaky abstraction? What is a better way of comparing two arbitrary objects to see whether they are the same when I don't know in advance whether they are numbers or not? \n",
      "\n",
      "\n",
      " What is pivot? \n",
      " How do I pivot? \n",
      " Long format to wide format? \n",
      " \n",
      " I've seen a lot of questions that ask about pivot tables, even if they don't know it.  It is virtually impossible to write a  canonical question and answer  that encompasses all aspects of pivoting... But I'm going to give it a go. \n",
      " \n",
      " The problem with existing questions and answers is that often the question is focused on a nuance that the OP has trouble generalizing in order to use a number of the existing good answers.  However, none of the answers attempt to give a comprehensive explanation (because it's a daunting task). Look at a few examples from my  Google search : \n",
      " \n",
      " How to pivot a dataframe in Pandas?  - Good question and answer.  But the answer only answers the specific question with little explanation. \n",
      " pandas pivot table to data frame  - OP is concerned with the output of the pivot, namely how the columns look.  OP wanted it to look like R.  This isn't very helpful for pandas users. \n",
      " pandas pivoting a dataframe, duplicate rows  - Another decent question but the answer focuses on one method, namely  pd.DataFrame.pivot \n",
      " \n",
      " \n",
      " Setup \n",
      " I conspicuously named my columns and relevant column values to correspond with how I'm going to pivot in the answers below. \n",
      " import numpy as np\n",
      "import pandas as pd\n",
      "from numpy.core.defchararray import add\n",
      "\n",
      "np.random.seed([3,1415])\n",
      "n = 20\n",
      "\n",
      "cols = np.array(['key', 'row', 'item', 'col'])\n",
      "arr1 = (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)\n",
      "\n",
      "df = pd.DataFrame(\n",
      "    add(cols, arr1), columns=cols\n",
      ").join(\n",
      "    pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix('val')\n",
      ")\n",
      "print(df)\n",
      " \n",
      "      key   row   item   col  val0  val1\n",
      "0   key0  row3  item1  col3  0.81  0.04\n",
      "1   key1  row2  item1  col2  0.44  0.07\n",
      "2   key1  row0  item1  col0  0.77  0.01\n",
      "3   key0  row4  item0  col2  0.15  0.59\n",
      "4   key1  row0  item2  col1  0.81  0.64\n",
      "5   key1  row2  item2  col4  0.13  0.88\n",
      "6   key2  row4  item1  col3  0.88  0.39\n",
      "7   key1  row4  item1  col1  0.10  0.07\n",
      "8   key1  row0  item2  col4  0.65  0.02\n",
      "9   key1  row2  item0  col2  0.35  0.61\n",
      "10  key2  row0  item2  col1  0.40  0.85\n",
      "11  key2  row4  item1  col2  0.64  0.25\n",
      "12  key0  row2  item2  col3  0.50  0.44\n",
      "13  key0  row4  item1  col4  0.24  0.46\n",
      "14  key1  row3  item2  col3  0.28  0.11\n",
      "15  key0  row3  item1  col1  0.31  0.23\n",
      "16  key0  row0  item2  col3  0.86  0.01\n",
      "17  key0  row4  item0  col3  0.64  0.21\n",
      "18  key2  row2  item2  col0  0.13  0.45\n",
      "19  key0  row2  item0  col4  0.37  0.70\n",
      " \n",
      " Questions \n",
      " \n",
      " Why do I get  ValueError: Index contains duplicate entries, cannot reshape ? \n",
      " \n",
      " How do I pivot  df  such that the  col  values are columns,  row  values are the index, and mean of  val0  are the values? \n",
      " col   col0   col1   col2   col3  col4\n",
      "row\n",
      "row0  0.77  0.605    NaN  0.860  0.65\n",
      "row2  0.13    NaN  0.395  0.500  0.25\n",
      "row3   NaN  0.310    NaN  0.545   NaN\n",
      "row4   NaN  0.100  0.395  0.760  0.24\n",
      " \n",
      " \n",
      " How do I make it so that missing values are  0 ? \n",
      " col   col0   col1   col2   col3  col4\n",
      "row\n",
      "row0  0.77  0.605  0.000  0.860  0.65\n",
      "row2  0.13  0.000  0.395  0.500  0.25\n",
      "row3  0.00  0.310  0.000  0.545  0.00\n",
      "row4  0.00  0.100  0.395  0.760  0.24\n",
      " \n",
      " \n",
      " Can I get something other than  mean , like maybe  sum ? \n",
      " col   col0  col1  col2  col3  col4\n",
      "row\n",
      "row0  0.77  1.21  0.00  0.86  0.65\n",
      "row2  0.13  0.00  0.79  0.50  0.50\n",
      "row3  0.00  0.31  0.00  1.09  0.00\n",
      "row4  0.00  0.10  0.79  1.52  0.24\n",
      " \n",
      " \n",
      " Can I do more that one aggregation at a time? \n",
      "        sum                          mean\n",
      "col   col0  col1  col2  col3  col4  col0   col1   col2   col3  col4\n",
      "row\n",
      "row0  0.77  1.21  0.00  0.86  0.65  0.77  0.605  0.000  0.860  0.65\n",
      "row2  0.13  0.00  0.79  0.50  0.50  0.13  0.000  0.395  0.500  0.25\n",
      "row3  0.00  0.31  0.00  1.09  0.00  0.00  0.310  0.000  0.545  0.00\n",
      "row4  0.00  0.10  0.79  1.52  0.24  0.00  0.100  0.395  0.760  0.24\n",
      " \n",
      " \n",
      " Can I aggregate over multiple value columns? \n",
      "       val0                             val1\n",
      "col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4\n",
      "row\n",
      "row0  0.77  0.605  0.000  0.860  0.65  0.01  0.745  0.00  0.010  0.02\n",
      "row2  0.13  0.000  0.395  0.500  0.25  0.45  0.000  0.34  0.440  0.79\n",
      "row3  0.00  0.310  0.000  0.545  0.00  0.00  0.230  0.00  0.075  0.00\n",
      "row4  0.00  0.100  0.395  0.760  0.24  0.00  0.070  0.42  0.300  0.46\n",
      " \n",
      " \n",
      " Can I subdivide by multiple columns? \n",
      " item item0             item1                         item2\n",
      "col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4\n",
      "row\n",
      "row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.605  0.86  0.65\n",
      "row2  0.35  0.00  0.37  0.00  0.00  0.44  0.00  0.00  0.13  0.000  0.50  0.13\n",
      "row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.000  0.28  0.00\n",
      "row4  0.15  0.64  0.00  0.00  0.10  0.64  0.88  0.24  0.00  0.000  0.00  0.00\n",
      " \n",
      " \n",
      " Or \n",
      " item      item0             item1                         item2\n",
      "col        col2  col3  col4  col0  col1  col2  col3  col4  col0  col1  col3  col4\n",
      "key  row\n",
      "key0 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.86  0.00\n",
      "     row2  0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.50  0.00\n",
      "     row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.00  0.00  0.00\n",
      "     row4  0.15  0.64  0.00  0.00  0.00  0.00  0.00  0.24  0.00  0.00  0.00  0.00\n",
      "key1 row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.81  0.00  0.65\n",
      "     row2  0.35  0.00  0.00  0.00  0.00  0.44  0.00  0.00  0.00  0.00  0.00  0.13\n",
      "     row3  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.28  0.00\n",
      "     row4  0.00  0.00  0.00  0.00  0.10  0.00  0.00  0.00  0.00  0.00  0.00  0.00\n",
      "key2 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.40  0.00  0.00\n",
      "     row2  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.13  0.00  0.00  0.00\n",
      "     row4  0.00  0.00  0.00  0.00  0.00  0.64  0.88  0.00  0.00  0.00  0.00  0.00\n",
      " \n",
      " \n",
      " Can I aggregate the frequency in which the column and rows occur together, aka \"cross tabulation\"? \n",
      " col   col0  col1  col2  col3  col4\n",
      "row\n",
      "row0     1     2     0     1     1\n",
      "row2     1     0     2     1     2\n",
      "row3     0     1     0     2     0\n",
      "row4     0     1     2     2     1\n",
      " \n",
      " \n",
      " How do I convert a DataFrame from long to wide by pivoting on ONLY two columns? Given, \n",
      " np.random.seed([3, 1415])\n",
      "df2 = pd.DataFrame({'A': list('aaaabbbc'), 'B': np.random.choice(15, 8)})\n",
      "df2\n",
      "   A   B\n",
      "0  a   0\n",
      "1  a  11\n",
      "2  a   2\n",
      "3  a  11\n",
      "4  b  10\n",
      "5  b  10\n",
      "6  b  14\n",
      "7  c   7\n",
      " \n",
      " The expected should look something like \n",
      "       a     b    c\n",
      "0   0.0  10.0  7.0\n",
      "1  11.0  10.0  NaN\n",
      "2   2.0  14.0  NaN\n",
      "3  11.0   NaN  NaN\n",
      " \n",
      " \n",
      " How do I flatten the multiple index to single index after  pivot ? \n",
      " From \n",
      "    1  2\n",
      "   1  1  2\n",
      "a  2  1  1\n",
      "b  2  1  0\n",
      "c  1  0  0\n",
      " \n",
      " To \n",
      "    1|1  2|1  2|2\n",
      "a    2    1    1\n",
      "b    2    1    0\n",
      "c    1    0    0\n",
      " \n",
      " \n",
      " \n",
      "\n",
      "I want to apply my custom function (it uses an if-else ladder) to these six columns ( ERI_Hispanic ,  ERI_AmerInd_AKNatv ,  ERI_Asian ,  ERI_Black_Afr.Amer ,  ERI_HI_PacIsl ,  ERI_White ) in each row of my dataframe. \n",
      " I've tried different methods from other questions but still can't seem to find the right answer for my problem.  The critical piece of this is that if the person is counted as Hispanic they can't be counted as anything else.  Even if they have a \"1\" in another ethnicity column they still are counted as Hispanic not two or more races.  Similarly, if the sum of all the ERI columns is greater than 1 they are counted as two or more races and can't be counted as a unique ethnicity(except for Hispanic). \n",
      " It's almost like doing a for loop through each row and if each record meets a criterion they are added to one list and eliminated from the original. \n",
      " From the dataframe below I need to calculate a new column based on the following spec in SQL: \n",
      " CRITERIA \n",
      " IF [ERI_Hispanic] = 1 THEN RETURN “Hispanic”\n",
      "ELSE IF SUM([ERI_AmerInd_AKNatv] + [ERI_Asian] + [ERI_Black_Afr.Amer] + [ERI_HI_PacIsl] + [ERI_White]) > 1 THEN RETURN “Two or More”\n",
      "ELSE IF [ERI_AmerInd_AKNatv] = 1 THEN RETURN “A/I AK Native”\n",
      "ELSE IF [ERI_Asian] = 1 THEN RETURN “Asian”\n",
      "ELSE IF [ERI_Black_Afr.Amer] = 1 THEN RETURN “Black/AA”\n",
      "ELSE IF [ERI_HI_PacIsl] = 1 THEN RETURN “Haw/Pac Isl.”\n",
      "ELSE IF [ERI_White] = 1 THEN RETURN “White”\n",
      " \n",
      " Comment: If the ERI Flag for Hispanic is True (1), the employee is classified as “Hispanic” \n",
      " Comment: If more than 1 non-Hispanic ERI Flag is true, return “Two or More” \n",
      " DATAFRAME \n",
      "      lname          fname       rno_cd  eri_afr_amer    eri_asian   eri_hawaiian    eri_hispanic    eri_nat_amer    eri_white   rno_defined\n",
      "0    MOST           JEFF        E       0               0           0               0               0               1           White\n",
      "1    CRUISE         TOM         E       0               0           0               1               0               0           White\n",
      "2    DEPP           JOHNNY              0               0           0               0               0               1           Unknown\n",
      "3    DICAP          LEO                 0               0           0               0               0               1           Unknown\n",
      "4    BRANDO         MARLON      E       0               0           0               0               0               0           White\n",
      "5    HANKS          TOM         0                       0           0               0               0               1           Unknown\n",
      "6    DENIRO         ROBERT      E       0               1           0               0               0               1           White\n",
      "7    PACINO         AL          E       0               0           0               0               0               1           White\n",
      "8    WILLIAMS       ROBIN       E       0               0           1               0               0               0           White\n",
      "9    EASTWOOD       CLINT       E       0               0           0               0               0               1           White\n",
      " \n",
      "\n",
      "209\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from stackapi import StackAPI\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "api_key = 'OCUzFs8rOUeGlf2IabA7eA(('\n",
    "stack_api = StackAPI('stackoverflow', key=api_key)\n",
    "all_questions = []\n",
    "\n",
    "page_number = 1\n",
    "while True and page_number <= 2:\n",
    "    \n",
    "    # filter !)riR7Z77yfk*ain7nkhb obtain on page https://api.stackexchange.com/docs/questions#order=desc&sort=activity&filter=!)ro7JqS6jrm9vfa3KOAU&site=stackoverflow&run=true\n",
    "    questions = stack_api.fetch('questions', page=page_number, sort='votes', min=50, tagged='python', filter='!)ro7JqS6jrm9vfa3KOAU')\n",
    "\n",
    "    if not questions['items']:\n",
    "        break\n",
    "\n",
    "    all_questions.extend(questions['items'])\n",
    "    print(page_number)\n",
    "    page_number += 1\n",
    "\n",
    "questions_with_5_tags = [q for q in all_questions if len(q['tags']) >= 5]\n",
    "\n",
    "filtered_questions = [q for q in questions_with_5_tags if q.get('view_count', 0) > 20 and q.get('answer_count', 0) >= 1]\n",
    "\n",
    "question_data = []\n",
    "for item in filtered_questions:\n",
    "    soup = BeautifulSoup(item['body'], 'html.parser')\n",
    "    body_text = soup.get_text(separator=' ')\n",
    "    print(body_text)\n",
    "    \n",
    "    question_data.append({\n",
    "        'title': item['title'],\n",
    "        'body': body_text,\n",
    "        'tags': item['tags'],\n",
    "        'score': item['score']\n",
    "    })\n",
    "\n",
    "print(len(question_data))\n",
    "\n",
    "df = pd.DataFrame(question_data)\n",
    "df.to_csv('dataset.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-12T18:32:58.509055Z",
     "start_time": "2023-12-12T18:32:52.256050Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "304d685b88dee771"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
