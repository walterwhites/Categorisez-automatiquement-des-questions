title,body,tags,score,tags_transformed,title_lemmatized,body_lemmatized
How to use nodemon in npm scripts to build and start scripts?,"""scripts"": {
  ""build"": ""babel src -d lib"",
  ""start"": ""node --use_strict ./lib/index.js"",
  ""watch"": ""nodemon lib/index.js --exec npm run build""
}

Using the command npm run watch results in the following wrong command being run: [nodemon] starting ""npm lib/index.js run build""
How would I write a nodemon command that, on reload, transpiles the code using babel and reloads the code?
",<javascript><node.js><npm><nodemon><babeljs>,14,"javascript,node.js,npm,nodemon,babeljs",['how to use nodemon in npm scripts to build and start scripts'],['scripts build babel src d lib start node usestrict libindexjs watch nodemon libindexjs exec npm run build using the command npm run watch results in the following wrong command being run nodemon starting npm libindexjs run build how would i write a nodemon command that on reload transpiles the code using babel and reloads the code']
Why do I get this error? void* is not a pointer to object type.,"void *stackAddr[NUM_THREADS];

stackAddr[i] = malloc(STACKSIZE);

The compiler (g++ 4.4.3) complains where the malloc is called...
warning: pointer of type ‘void *’ used in arithmetic
error: ‘void*’ is not a pointer-to-object type

If you are interested in seeing the whole code, here it goes...
#include <pthread.h>
#include <stdio.h>
#include <stdlib.h>
#include <math.h>
#define NUM_THREADS 4

void *stackAddr[NUM_THREADS];
pthread_t thread[NUM_THREADS];
pthread_attr_t attr;

void *BusyWork(void *t)
{
   int i;
   long tid;
   double result=0.0;
   tid = (long)t;

   printf(""Thread %ld starting...\n"",tid);
   for ( i = 0; i < 1000; i++)
   {
      result = result + sin(i*tid) * tan(i*tid);
   }
   printf(""Thread %ld done. Result = %e\n"", tid, result);
   pthread_exit((void*) t);
}

void pthread_create_with_stack( pthread_t * pthread, void *(*start_routine) (void *), int tid )
{
    const size_t STACKSIZE = 0xC00000; //12582912
    void *stackAddr;
    int rc;
    size_t i;
    pthread_t thread;
    pid_t pid;

    stackAddr[tid] = malloc(STACKSIZE); // Error here!
    pthread_attr_setstack(&attr, stackAddr[tid], STACKSIZE);

    rc = pthread_create( pthread, &attr, start_routine, (void*)tid );
}

int main (int argc, char *argv[])
{
   int rc;
   long t;
   void *status;

   /* Initialize and set thread detached attribute */
   pthread_attr_init(&attr);
   pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_JOINABLE);

   for(t=0; t<NUM_THREADS; t++) 
   {
      printf(""Main: creating thread %ld\n"", t);
      rc = pthread_create_with_stack(&thread[t], BusyWork, t); 
      if (rc) 
      {
         printf(""ERROR; return code from pthread_create() is %d\n"", rc);
         exit(-1);
      }
   }

   /* Free attribute and wait for the other threads */
   pthread_attr_destroy(&attr);
   for(t=0; t<NUM_THREADS; t++) 
   {
      rc = pthread_join(thread[t], &status);
      if (rc) 
      {
         printf(""ERROR; return code from pthread_join() is %d\n"", rc);
         exit(-1);
      }
      printf(""Main: completed join with thread %ld having a status""   
            ""of %ld\n"",t,(long)status);
    }

    printf(""Main: program completed. Exiting.\n"");
    pthread_exit(NULL);
}

",<c++><c><linux><gcc><g++>,5,"c++,c,linux,gcc,g++","['why do i get this error', 'void is not a pointer to object type']","['void stackaddrnumthreads stackaddri mallocstacksize the compiler g 443 complains where the malloc is called warning pointer of type void used in arithmetic error void is not a pointertoobject type if you are interested in seeing the whole code here it goes include pthreadh include stdioh include stdlibh include mathh define numthreads 4 void stackaddrnumthreads pthreadt threadnumthreads pthreadattrt attr void busyworkvoid t int i long tid double result00 tid longt printfthread ld startingntid for i 0 i 1000 i result result sinitid tanitid printfthread ld done', 'result en tid result pthreadexitvoid t void pthreadcreatewithstack pthreadt pthread void startroutine void int tid const sizet stacksize 0xc00000 12582912 void stackaddr int rc sizet i pthreadt thread pidt pid stackaddrtid mallocstacksize error here', 'pthreadattrsetstackattr stackaddrtid stacksize rc pthreadcreate pthread attr startroutine voidtid int main int argc char argv int rc long t void status initialize and set thread detached attribute pthreadattrinitattr pthreadattrsetdetachstateattr pthreadcreatejoinable fort0 tnumthreads t printfmain creating thread ldn t rc pthreadcreatewithstackthreadt busywork t if rc printferror return code from pthreadcreate is dn rc exit1 free attribute and wait for the other threads pthreadattrdestroyattr fort0 tnumthreads t rc pthreadjointhreadt status if rc printferror return code from pthreadjoin is dn rc exit1 printfmain completed join with thread ld having a status of ldntlongstatus printfmain program completed', 'exitingn pthreadexitnull ']"
Altering a column: null to not null,"I have a table that has several nullable integer columns.  This is undesirable for several reasons, so I am looking to update all nulls to 0 and then set these columns to NOT NULL. Aside from changing nulls to 0, data must be preserved.
I am looking for the specific SQL syntax to alter a column (call it ColumnA) to ""not null"".  Assume the data has been updated to not contain nulls.
Using SQL server 2000.
",<sql-server><t-sql><null><alter-table><alter-column>,1363,"sql-server,t-sql,null,alter-table,alter-column",['altering a column null to not null'],"['i have a table that has several nullable integer columns', 'this is undesirable for several reasons so i am looking to update all nulls to 0 and then set these columns to not null', 'aside from changing nulls to 0 data must be preserved', 'i am looking for the specific sql syntax to alter a column call it columna to not null', 'assume the data has been updated to not contain nulls', 'using sql server 2000']"
"After setting a breakpoint in Qt, gdb says: ""Error accessing memory address""","I wrote a very simple Qt program here:
int main(int argc, char* argv[])
{
    QApplication app(argc, argv);

    QTableView table(&frame);
    table.resize(100, 100);
    table.show();

    return app.exec();
}

And when I try to set a breakpoint where the table gets clicked, I get this error from gdb:
(gdb) symbol-file /usr/lib/libQtGui.so.4.4.3.debug 
Load new symbol table from ""/usr/lib/libQtGui.so.4.4.3.debug""? (y or n) y
Reading symbols from /usr/lib/libQtGui.so.4.4.3.debug...done.
(gdb) br 'QAbstractItemView::clicked(QModelIndex const&)'
Breakpoint 1 at 0x5fc660: file .moc/release-shared/moc_qabstractitemview.cpp, line 313.
(gdb) run
Starting program: ./qt-test
Warning:
Cannot insert breakpoint 1.
Error accessing memory address 0x5fc660: Input/output error.

Does anyone know why the breakpoint can't be inserted?
",<debugging><qt><qt4><gdb><breakpoints>,8,"debugging,qt,qt4,gdb,breakpoints",['after setting a breakpoint in qt gdb says error accessing memory address'],"['i wrote a very simple qt program here int mainint argc char argv qapplication appargc argv qtableview tableframe tableresize100 100 tableshow return appexec and when i try to set a breakpoint where the table gets clicked i get this error from gdb gdb symbolfile usrliblibqtguiso443debug load new symbol table from usrliblibqtguiso443debug', 'y or n y reading symbols from usrliblibqtguiso443debugdone', 'gdb br qabstractitemviewclickedqmodelindex const breakpoint 1 at 0x5fc660 file mocreleasesharedmocqabstractitemviewcpp line 313', 'gdb run starting program qttest warning cannot insert breakpoint 1 error accessing memory address 0x5fc660 inputoutput error', 'does anyone know why the breakpoint cant be inserted']"
Why does FetchContent prefer subdirectory-subsumption vs installation of dependencies?,"Consider two software projects, proj_a and proj_b, with the latter depending on the former; and with both using CMake.
When reading about modern CMake, one gets the message that the ""appropriate"" way to express dependencies is via target dependencies; and one should arrange it so that dependent projects are represented as (imported) targets you can depend on. More specifically, in our example, proj_b will idiomatically have:
find_package(proj_a)

# etc etc.

target_link_library(bar proj_a::foo)

and proj_a will need to have been installed, utilizing the CMake installation-and-export-related commands, someplace where proj_b's CMake invocation will search for proj_a-config.cmake.
I like this approach and encourage others to adapt to it. It offers flexibility in the choice of your own version of proj_a vs the system version; and also allows for non-CMake proj_a's via a Findproj_a.cmake script (which again, can be system-level or part of proj_b).
So far so good, right? However, there are people who want to ""take matters into their own hands"" in terms of dependencies - and CMake officially condones this, with commands such as ExternalProject and more recently, FetchContent: This allows proj_b's configuration stage to actually download a (built, or in our case source-form) version of proj_a.
The puzzling part to me is that, after proj_a is downloaded, say to an external/proj_a directory, CMake's default behavior will be to
add_subdirectory(external/proj_a)

that is, to use proj_a as a subproject of proj_b and build them together. This, while the idiomatic use above allows the maintainer of proj_a to ""do their own thing"" in my CMakeFile, and only keep things neat and tidy for others via what I export/install.
My questions:

Why does it make sense to add_subdirectory(), rather than to build, install, and perform the equivalent of find_package() to meet the dependency? Or rather, why should the former, rather than the latter, be the default?
Should I really have to write my project-level CMakeLists.txt to be compatible with being add_subdirectory()'ed?

Note: Just to give some concrete examples of how this use constrains proj_a:

Must use unique option names which can't possibly clash with super-project names. So no more WITH_TESTS, BUILD_STATIC_LIB - it has to be: WITH_PROJ_A_TESTS and BUILD_PROJ_A_STATIC_LIB.
You have to account for the parent project having searched for other dependencies already, and perhaps differently than how you would like to search for them.

",<installation><cmake><build><build-dependencies><fetchcontent>,8,"installation,cmake,build,build-dependencies,fetchcontent",['why does fetchcontent prefer subdirectorysubsumption vs installation of dependencies'],"['consider two software projects proja and projb with the latter depending on the former and with both using cmake', 'when reading about modern cmake one gets the message that the appropriate way to express dependencies is via target dependencies and one should arrange it so that dependent projects are represented as imported targets you can depend on', 'more specifically in our example projb will idiomatically have findpackageproja etc etc', 'targetlinklibrarybar projafoo and proja will need to have been installed utilizing the cmake installationandexportrelated commands someplace where projbs cmake invocation will search for projaconfigcmake', 'i like this approach and encourage others to adapt to it', 'it offers flexibility in the choice of your own version of proja vs the system version and also allows for noncmake projas via a findprojacmake script which again can be systemlevel or part of projb', 'so far so good right', 'however there are people who want to take matters into their own hands in terms of dependencies and cmake officially condones this with commands such as externalproject and more recently fetchcontent this allows projbs configuration stage to actually download a built or in our case sourceform version of proja', 'the puzzling part to me is that after proja is downloaded say to an externalproja directory cmakes default behavior will be to addsubdirectoryexternalproja that is to use proja as a subproject of projb and build them together', 'this while the idiomatic use above allows the maintainer of proja to do their own thing in my cmakefile and only keep things neat and tidy for others via what i exportinstall', 'my questions why does it make sense to addsubdirectory rather than to build install and perform the equivalent of findpackage to meet the dependency', 'or rather why should the former rather than the latter be the default', 'should i really have to write my projectlevel cmakeliststxt to be compatible with being addsubdirectoryed', 'note just to give some concrete examples of how this use constrains proja must use unique option names which cant possibly clash with superproject names', 'so no more withtests buildstaticlib it has to be withprojatests and buildprojastaticlib', 'you have to account for the parent project having searched for other dependencies already and perhaps differently than how you would like to search for them']"
Vuetify data table is not showing data,"Vuetify data table is not showing data, it shows that there are 1 row out of 1 displayed, but the table body is empty. My component code:
<template>
  <v-data-table
    :headers=""headers""
    :items=""desserts""
  >
  </v-data-table>
</template>

<script>
export default {
  name: 'Users',
  data () {
    return {
      headers: [
        {
          text: 'Dessert (100g serving)',
          align: 'left',
          sortable: false,
          value: 'name'
        },
        { text: 'Fat (g)', value: 'fat' },
      ],
      desserts: [
        {
          name: 'Frozen Yogurt',
          fat: 6.0,
        },
      ]
    }
  }
}
</script>

<style scoped  lang=""stylus"">
</style>

Result:

Any idea how to fix this?
",<javascript><vue.js><vuejs2><vue-component><vuetify.js>,14,"javascript,vue.js,vuejs2,vue-component,vuetify.js",['vuetify data table is not showing data'],"['vuetify data table is not showing data it shows that there are 1 row out of 1 displayed but the table body is empty', 'my component code template vdatatable headersheaders itemsdesserts vdatatable template script export default name users data return headers text dessert 100g serving align left sortable false value name text fat g value fat desserts name frozen yogurt fat 60 script style scoped langstylus style result any idea how to fix this']"
Open-source java XSLT 2.0 implementation?,"I'm currently looking into using XSLT 2.0, but I cannot find any open-source java implementations (Saxon-B seems to fit the bill, but isn't schema-aware).
Am I missing something?
",<java><xml><open-source><xslt-2.0><xslt>,21,"java,xml,open-source,xslt-2.0,xslt",['opensource java xslt 20 implementation'],"['im currently looking into using xslt 20 but i cannot find any opensource java implementations saxonb seems to fit the bill but isnt schemaaware', 'am i missing something']"
Android Studio shortcut for autocomplete Toast(Kotlin),"I have a problem with the newest version of Android Studio(> 3) to use the autocomplete for Toast with Kotlin.
In older versions with Java, it was like typing ""Toast"", then pushing ""Tab"" button on keyboard to autocomplete this.
Now, in the versions of Android Studio > 3 and Kotlin it is not working.
Anyone know how to achive this?
",<android><android-studio><kotlin><android-studio-3.0><android-studio-3.1>,9,"android,android-studio,kotlin,android-studio-3.0,android-studio-3.1",['android studio shortcut for autocomplete toastkotlin'],"['i have a problem with the newest version of android studio 3 to use the autocomplete for toast with kotlin', 'in older versions with java it was like typing toast then pushing tab button on keyboard to autocomplete this', 'now in the versions of android studio 3 and kotlin it is not working', 'anyone know how to achive this']"
Azure Build Pipeline with There are no accounts registered with Xcode. Add your developer account to Xcode,"I am doing DevOps on my react-native projects. I want to build the project and want automation on iOS app deployment. But when I try to build it gives following error:

Check dependencies Code Signing Error: There are no accounts
  registered with Xcode. Add your developer account to Xcode Code
  Signing Error: No profiles for 'ios.kapiling' were found:  Xcode
  couldn't find any iOS App Development provisioning profiles matching
  'ios.kapiling'. Code Signing Error: Code signing is required for
  product type 'Application' in SDK 'iOS 11.4'

Here is my YAML script:
steps:
- task: Xcode@5
  displayName: Xcode
  inputs:
    actions: '-allowProvisioningUpdates archive '
    configuration: Release
    sdk: iphoneos11.4
    xcWorkspacePath: 'ios/community_app.xcworkspace'
    scheme: 'community_app'
    xcodeVersion: 10
    signingOption: auto
    teamId: XXXXXXXXXX

",<ios><xcode><react-native><azure-devops><azure-pipelines>,6,"ios,xcode,react-native,azure-devops,azure-pipelines","['azure build pipeline with there are no accounts registered with xcode', 'add your developer account to xcode']","['i am doing devops on my reactnative projects', 'i want to build the project and want automation on ios app deployment', 'but when i try to build it gives following error check dependencies code signing error there are no accounts registered with xcode', 'add your developer account to xcode code signing error no profiles for ioskapiling were found xcode couldnt find any ios app development provisioning profiles matching ioskapiling', 'code signing error code signing is required for product type application in sdk ios 114 here is my yaml script steps task xcode5 displayname xcode inputs actions allowprovisioningupdates archive configuration release sdk iphoneos114 xcworkspacepath ioscommunityappxcworkspace scheme communityapp xcodeversion 10 signingoption auto teamid xxxxxxxxxx']"
J2ME AES Decryption Error(org.bouncycastle.crypto.InvalidCipherTextException: pad block corrupted),"I am doing encryption and decryption using AES Algorithm with bouncy castle
My encryption and decryption works ok but it gives me error when my plain text size is bigger
even sometimes it is giving non decrypted data
public static boolean setEncryptionKey(String keyText)
{
    byte[] keyBytes = keyText.getBytes();

    key = new KeyParameter(keyBytes);
    engine = new AESFastEngine();
    cipher = new PaddedBufferedBlockCipher(engine);

    return true;
}

Encryption:
public static String encryptString(String plainText)
{

        byte[] plainArray = plainText.getBytes();

        cipher.init(true, key);
        byte[] cipherBytes = new byte[cipher.getOutputSize(plainArray.length)];
        int cipherLength = cipher.processBytes(plainArray, 0, plainArray.length, cipherBytes, 0);
        cipher.doFinal(cipherBytes, cipherLength);
        String cipherString = new String(cipherBytes);
        return cipherString;
    }

Decryption:
public static String decryptString(String encryptedText)
{

        byte[] cipherBytes = encryptedText.getBytes();
        cipher.init(false, key);
        byte[] decryptedBytes = new byte[cipher.getOutputSize(cipherBytes.length)];
        int decryptedLength = cipher.processBytes(cipherBytes, 0, cipherBytes.length, decryptedBytes, 0);
        cipher.doFinal(decryptedBytes, decryptedLength);
        String decryptedString = new String(decryptedBytes);

        int index = decryptedString.indexOf(""\u0000"");
        if (index >= 0)
        {
            decryptedString = decryptedString.substring(0, index);
        }
        return decryptedString;
    }

This decryption is giving me following error
org.bouncycastle.crypto.InvalidCipherTextException: pad block corrupted
        at org.bouncycastle.crypto.paddings.PKCS7Padding.padCount(+30)
        at org.bouncycastle.crypto.paddings.PaddedBufferedBlockCipher.doFinal(+190)
        at com.NewCrypto.decryptString(NewCrypto.java:103)
        at com.New_Midlet.startApp(New_Midlet.java:23)
        at javax.microedition.midlet.MIDletProxy.startApp(MIDletProxy.java:44)
        at com.sun.midp.midlet.Scheduler.schedule(Scheduler.java:375)
        at com.sun.midp.main.Main.runLocalClass(Main.java:477)
        at com.sun.midp.main.Main.main(+80)

what could be the problem ?
",<java-me><aes><encryption><bouncycastle><midlet>,5,"java-me,aes,encryption,bouncycastle,midlet",['j2me aes decryption errororgbouncycastlecryptoinvalidciphertextexception pad block corrupted'],['i am doing encryption and decryption using aes algorithm with bouncy castle my encryption and decryption works ok but it gives me error when my plain text size is bigger even sometimes it is giving non decrypted data public static boolean setencryptionkeystring keytext byte keybytes keytextgetbytes key new keyparameterkeybytes engine new aesfastengine cipher new paddedbufferedblockcipherengine return true encryption public static string encryptstringstring plaintext byte plainarray plaintextgetbytes cipherinittrue key byte cipherbytes new byteciphergetoutputsizeplainarraylength int cipherlength cipherprocessbytesplainarray 0 plainarraylength cipherbytes 0 cipherdofinalcipherbytes cipherlength string cipherstring new stringcipherbytes return cipherstring decryption public static string decryptstringstring encryptedtext byte cipherbytes encryptedtextgetbytes cipherinitfalse key byte decryptedbytes new byteciphergetoutputsizecipherbyteslength int decryptedlength cipherprocessbytescipherbytes 0 cipherbyteslength decryptedbytes 0 cipherdofinaldecryptedbytes decryptedlength string decryptedstring new stringdecryptedbytes int index decryptedstringindexofu0000 if index 0 decryptedstring decryptedstringsubstring0 index return decryptedstring this decryption is giving me following error orgbouncycastlecryptoinvalidciphertextexception pad block corrupted at orgbouncycastlecryptopaddingspkcs7paddingpadcount30 at orgbouncycastlecryptopaddingspaddedbufferedblockcipherdofinal190 at comnewcryptodecryptstringnewcryptojava103 at comnewmidletstartappnewmidletjava23 at javaxmicroeditionmidletmidletproxystartappmidletproxyjava44 at comsunmidpmidletschedulerscheduleschedulerjava375 at comsunmidpmainmainrunlocalclassmainjava477 at comsunmidpmainmainmain80 what could be the problem ']
Problems while traversing and extracting the nodes of a tree?,"I have the following trees (tree_1, tree_2, tree_3) stored in a dictionary (dict_1, dict_2, dict_3). How can I recursively traverse all the paths of the tree, collecting all the nodes from the root to the last node of each branch?
In other words, I would like to generate a list of all the possible sequences of nodes for all the branches of the trees (dicts). For example some possible branches for dict_1 (tree_1)are:
[[""FunctionDef"", ""try"", ""ExceptHandler"", ""Expr"", ""Call"", ""Attribute"",""Load""],
[""FunctionDef"", ""try"", ""ExceptHandler"", ""Expr"", ""Call"", ""Attribute"",""save_dictionary""],
[""FunctionDef"", ""try"", ""ExceptHandler"", ""Expr"", ""Call"", ""Attribute"",""Name"", ""self""],
..., 
[""FunctionDef"", ""arguments"", ""arg"", ""self""]]

So far, from a previous question I tried to:
def foo(nested_dict, c = []):
   for i in ['left', 'op', 'right', 'func', 'value', 'args', 'ctx',
             'body', 'comparators', 'ops', 'test', 'orelse', 'targets', 'slice', 'n', 'id', '_type']:
      if i in nested_dict:
        if isinstance(nested_dict[i], list):
            for b in nested_dict[i]:
                yield from foo(b, c+[nested_dict['_type']])
        elif isinstance(nested_dict[i], dict): #simple check here
            yield from foo(nested_dict[i], c+[nested_dict['_type']])
        else:
            yield c+[nested_dict[i]]

and
def foo_2(nested_dict, c = []):
  targets = {'left', 'op', 'right', 'func', 'value', 'args', 'ctx', 'body',
             'comparators', 'ops', 'test', 'orelse', 'targets', 'slice', 'n',
             'id', 'slice', 'annotation', 'arg', 'elts', 's', '_type'}
  for a, b in nested_dict.items():
     if a in targets:
        if isinstance(b, dict):
           yield from foo_2(b, c+[a])
        elif isinstance(b, list):
           for i in b:
              yield from foo_2(i, c+[a])
        else:
            yield c+[b]

However, both of them don't work because I am getting the wrong sequences. I tried to modify the targets because I thought that this issue was related to the fact that a target can not be reached out. Nevertheless, I am getting either incomplete or incorrect paths, and in general it is still not working, any idea of how to generate one list per path given a tree?
Here's a minimal example, given this tree:
{'_type': 'Expr',
 'col_offset': 0,
 'lineno': 1,
 'value': {'_type': 'Call',
  'args': [{'_type': 'BinOp',
    'col_offset': 6,
    'left': {'_type': 'Num', 'col_offset': 6, 'lineno': 1, 'n': 1},
    'lineno': 1,
    'op': {'_type': 'Add'},
    'right': {'_type': 'Num', 'col_offset': 8, 'lineno': 1, 'n': 2}}],
  'col_offset': 0,
  'func': {'_type': 'Name',
   'col_offset': 0,
   'ctx': {'_type': 'Load'},
   'id': 'print',
   'lineno': 1},
  'keywords': [],
  'lineno': 1}}

The output should be:
[[""Expr"", ""Call"", ""Name"", ""print""],
[""Expr"", ""Call"", ""Name"", ""Load""],
[""Expr"", ""Call"", ""Binop"", ""Num"", ""1""],
[""Expr"", ""Call"", ""Binop"", ""add""],
[""Expr"", ""Call"", ""Binop"", ""Num"", ""2""]]

",<python><python-3.x><dictionary><recursion><data-structures>,5,"python,python-3.x,dictionary,recursion,data-structures",['problems while traversing and extracting the nodes of a tree'],"['i have the following trees tree1 tree2 tree3 stored in a dictionary dict1 dict2 dict3', 'how can i recursively traverse all the paths of the tree collecting all the nodes from the root to the last node of each branch', 'in other words i would like to generate a list of all the possible sequences of nodes for all the branches of the trees dicts', 'for example some possible branches for dict1 tree1are functiondef try excepthandler expr call attributeload functiondef try excepthandler expr call attributesavedictionary functiondef try excepthandler expr call attributename self functiondef arguments arg self so far from a previous question i tried to def foonesteddict c for i in left op right func value args ctx body comparators ops test orelse targets slice n id type if i in nesteddict if isinstancenesteddicti list for b in nesteddicti yield from foob cnesteddicttype elif isinstancenesteddicti dict simple check here yield from foonesteddicti cnesteddicttype else yield cnesteddicti and def foo2nesteddict c targets left op right func value args ctx body comparators ops test orelse targets slice n id slice annotation arg elts s type for a b in nesteddictitems if a in targets if isinstanceb dict yield from foo2b ca elif isinstanceb list for i in b yield from foo2i ca else yield cb however both of them dont work because i am getting the wrong sequences', 'i tried to modify the targets because i thought that this issue was related to the fact that a target can not be reached out', 'nevertheless i am getting either incomplete or incorrect paths and in general it is still not working any idea of how to generate one list per path given a tree', 'heres a minimal example given this tree type expr coloffset 0 lineno 1 value type call args type binop coloffset 6 left type num coloffset 6 lineno 1 n 1 lineno 1 op type add right type num coloffset 8 lineno 1 n 2 coloffset 0 func type name coloffset 0 ctx type load id print lineno 1 keywords lineno 1 the output should be expr call name print expr call name load expr call binop num 1 expr call binop add expr call binop num 2']"
OpenCV shape matching between two similar shapes,"I'm trying to match a slightly irregular shape to a database of shapes. For example, here the contour I'm trying to match:

For more information, this is an outline of an HDMI connector, represented as a contour. It is slightly rough as this was taken with a phone while holding the HDMI.
This is my database of connectors:
HDMI: 
DVI: 
5PinDIN: 
DB25: 
These are a lot clearer as these are contours gathered from connector images from the internet.
For what I have tried:
cv2.matchShapes()
Since these are all just contours, I tried directly comparing them using the matchShapes() method, and it failed to produce good results. The similarities between the irregular contour, and my database was:
HDMI: 0.90
DB25: 0.84
5 Pin DIN: 0.5
DVI: 0.21
Since contours are more similar the closer to 0 the match result is, the algorithm completely failed. I tried the other methods of matching by changing the third parameter and was still unsuccessful.
ORB:
Being similar to SIFT, I tried keypoint matching. Averaging the distance between the different matches in my database (after finding the top 15% of matches):
mean([m.distance for m in matches])

The distances came up as:
Five Pin DIN: 7.6
DB25: 11.7
DVI: 12.1
HDMI: 19.6
As this classified a circle as the shape most like my contour, this has failed as well.
Here are the matching key points from ORB of the actual HDMI slot vs my example HDMI slot for more information:

Are there any ideas/other algorithms I should try? Or is a CNN my only choice (which I would rather avoid as I don't have the appropriate amount of data).
",<python><opencv><image-processing><contour><image-recognition>,11,"python,opencv,image-processing,contour,image-recognition",['opencv shape matching between two similar shapes'],"['im trying to match a slightly irregular shape to a database of shapes', 'for example here the contour im trying to match for more information this is an outline of an hdmi connector represented as a contour', 'it is slightly rough as this was taken with a phone while holding the hdmi', 'this is my database of connectors hdmi dvi 5pindin db25 these are a lot clearer as these are contours gathered from connector images from the internet', 'for what i have tried cv2matchshapes since these are all just contours i tried directly comparing them using the matchshapes method and it failed to produce good results', 'the similarities between the irregular contour and my database was hdmi 090 db25 084 5 pin din 05 dvi 021 since contours are more similar the closer to 0 the match result is the algorithm completely failed', 'i tried the other methods of matching by changing the third parameter and was still unsuccessful', 'orb being similar to sift i tried keypoint matching', 'averaging the distance between the different matches in my database after finding the top 15 of matches meanmdistance for m in matches the distances came up as five pin din 76 db25 117 dvi 121 hdmi 196 as this classified a circle as the shape most like my contour this has failed as well', 'here are the matching key points from orb of the actual hdmi slot vs my example hdmi slot for more information are there any ideasother algorithms i should try', 'or is a cnn my only choice which i would rather avoid as i dont have the appropriate amount of data']"
"one to one chat app with node.js, socket.io and redis","I currently have a chat application(one to one) in node.js and socket.io. as the users in my website are increasing, i want to introduce redis in my chat app. 
Here is a small example of my current app:
// all requires and connections
io.sockets.on('connection', function(socket) {

socket.on('message', function(msg) {
// code to get receiverssocket 
io.sockets.sockets[receiverssocket].emit('message',
{""source"": msg.sendersusername,""msg"": msg.msg});

});

});

Now, i am trying to find examples of how to do this with redis, but i cannot find an example of one to one chats with redis. i can only find examples in which messages are sent to all the users. Here is one of the examples i looked at
http://garydengblog.wordpress.com/2013/06/28/simple-chat-application-using-redis-socket-io-and-node-js/
One way of i thought of doing this was to create channels for each user receiving messages, but that would result in thousands of channels. Any help on how i can do this?
Edit: added some code
io.sockets.on('connection', function (client) {

sub.on(""message"", function (channel, message) {
console.log(""message received on server from publish "");
client.send(message);
});
client.on(""message"", function (msg) {
console.log(msg);
if(msg.type == ""chat""){
    pub.publish(""chatting."" + msg.tousername,msg.message);
}
else if(msg.type == ""setUsername""){
  sub.subscribe(""chatting."" + msg.user);
  sub.subscribe(""chatting.all"" );
  pub.publish(""chatting.all"",""A new user in connected:"" + msg.user);
  store.sadd(""onlineUsers"",msg.user);
}
});
client.on('disconnect', function () {
sub.quit();
pub.publish(""chatting.all"",""User is disconnected :"" + client.id);
});

});

",<node.js><sockets><redis><socket.io><node-redis>,7,"node.js,sockets,redis,socket.io,node-redis",['one to one chat app with nodejs socketio and redis'],"['i currently have a chat applicationone to one in nodejs and socketio', 'as the users in my website are increasing i want to introduce redis in my chat app', 'here is a small example of my current app all requires and connections iosocketsonconnection functionsocket socketonmessage functionmsg code to get receiverssocket iosocketssocketsreceiverssocketemitmessage source msgsendersusernamemsg msgmsg now i am trying to find examples of how to do this with redis but i cannot find an example of one to one chats with redis', 'i can only find examples in which messages are sent to all the users', 'here is one of the examples i looked at one way of i thought of doing this was to create channels for each user receiving messages but that would result in thousands of channels', 'any help on how i can do this', 'edit added some code iosocketsonconnection function client subonmessage function channel message consolelogmessage received on server from publish clientsendmessage clientonmessage function msg consolelogmsg ifmsgtype chat pubpublishchatting', ' msgtousernamemsgmessage else ifmsgtype setusername subsubscribechatting', ' msguser subsubscribechattingall pubpublishchattingalla new user in connected msguser storesaddonlineusersmsguser clientondisconnect function subquit pubpublishchattingalluser is disconnected clientid ']"
How do I apply OrderBy on an IQueryable using a string column name within a generic extension method?,"public static IQueryable<TResult> ApplySortFilter<T, TResult>(this IQueryable<T> query, string columnName)
  where T : EntityObject
{
  var param = Expression.Parameter(typeof(T), ""o"");
  var body = Expression.PropertyOrField(param,columnName);

  var sortExpression = Expression.Lambda(body, param);
  return query.OrderBy(sortExpression);
}

Because the type for OrderBy is not inferred from sortExpression I need to specify it something like this at run time:
var sortExpression = Expression.Lambda<T, TSortColumn>(body, param);

Or
return query.OrderBy<T, TSortColumn>(sortExpression);

I don't think this is possible however as TSortColumn can only be determined during runtime.
Is there a way around this?
",<c#><.net><linq><entity-framework><expression-trees>,91,"c#,.net,linq,entity-framework,expression-trees",['how do i apply orderby on an iqueryable using a string column name within a generic extension method'],"['public static iqueryabletresult applysortfiltert tresultthis iqueryablet query string columnname where t entityobject var param expressionparametertypeoft o var body expressionpropertyorfieldparamcolumnname var sortexpression expressionlambdabody param return queryorderbysortexpression because the type for orderby is not inferred from sortexpression i need to specify it something like this at run time var sortexpression expressionlambdat tsortcolumnbody param or return queryorderbyt tsortcolumnsortexpression i dont think this is possible however as tsortcolumn can only be determined during runtime', 'is there a way around this']"
Is there a way to automatically generate a list of columns that need indexing?,"The beauty of ORM lulled me into a soporific sleep. I've got an existing Django app with a lack of database indexes. Is there a way to automatically generate a list of columns that need indexing?
I was thinking maybe some middleware that logs which columns are involved in WHERE clauses? but is there anything built into MySQL that might help?
",<python><mysql><database><django><django-models>,5,"python,mysql,database,django,django-models",['is there a way to automatically generate a list of columns that need indexing'],"['the beauty of orm lulled me into a soporific sleep', 'ive got an existing django app with a lack of database indexes', 'is there a way to automatically generate a list of columns that need indexing', 'i was thinking maybe some middleware that logs which columns are involved in where clauses', 'but is there anything built into mysql that might help']"
Self-referencing inside class definition,"How do I reference class object inside class definition? Could you advice me how you would do it? Or more specifically how do you pass class object inside decorator of class method? 
Here is a simple example, I'm trying to pass second method I'm declaring to decorator of first one.
def decorate(w):
    def _wrap(f):
        def _call(*args, **kwargs):
            return w(f(*args, **kwargs))
        def _call
    return _wrap

class A():

    @dec(A.w)
    def f():
        return 2

    def w(f):
        return fr + 5 

As expected exception is raised
NameError: name 'A' is not defined

As a result of my investigation i learned that globals() doesn't contain A key while i'm inside decorate or _wrap functions, but defined inside _call. So I could probably find passed method by string name (e.g @dec('A.w')), but in that case it is impossible to cache method search inside _wrap closure.
So how do you fix that? :) 
",<python><class><decorator><python-decorators><class-members>,6,"python,class,decorator,python-decorators,class-members",['selfreferencing inside class definition'],"['how do i reference class object inside class definition', 'could you advice me how you would do it', 'or more specifically how do you pass class object inside decorator of class method', 'here is a simple example im trying to pass second method im declaring to decorator of first one', 'def decoratew def wrapf def callargs kwargs return wfargs kwargs def call return wrap class a decaw def f return 2 def wf return fr 5 as expected exception is raised nameerror name a is not defined as a result of my investigation i learned that globals doesnt contain a key while im inside decorate or wrap functions but defined inside call', 'so i could probably find passed method by string name eg decaw but in that case it is impossible to cache method search inside wrap closure', 'so how do you fix that', '']"
realloc(): invalid next size when reallocating to make space for strcat on char *,"I am getting invalid memory error on following code:
printf("" %s\n"",""FINE 5"");
printf(""%s LENGTH IS: %d\n"",""FINE 6"",strlen("": ""));
buffer = (char *)realloc(buffer, strlen(buffer)* sizeof(char) + (strlen("": "")+1)* sizeof(char));
printf("" %s\n"",""FINE 7"");
strcat(buffer, "": \0"");

Output:

FINE 5  FINE 6 LENGTH IS: 2
* glibc detected * ./auto: realloc(): invalid next size: 0x08cd72e0 ***
  ======= Backtrace: ========= /lib/tls/i686/cmov/libc.so.6(+0x6b591)[0x6dd591]

The point to note here is Fine 7 is never printed. and invalid next size error on every run is at the same location.
Found this relavent
",<c><string><malloc><realloc><strcat>,17,"c,string,malloc,realloc,strcat",['realloc invalid next size when reallocating to make space for strcat on char '],"['i am getting invalid memory error on following code printf snfine 5 printfs length is dnfine 6strlen buffer char reallocbuffer strlenbuffer sizeofchar strlen 1 sizeofchar printf snfine 7 strcatbuffer 0 output fine 5 fine 6 length is 2 glibc detected auto realloc invalid next size 0x08cd72e0 backtrace libtlsi686cmovlibcso60x6b5910x6dd591 the point to note here is fine 7 is never printed', 'and invalid next size error on every run is at the same location', 'found this relavent']"
Open tab by clicking on a stacked barchart,"I'm building a stacked barchart containing retweets using R, ggplot and plotly. If a part of a barchart is clicked on, I want a new browser tab to open and show the tweet from this specific date with the indicated amount of retweets. However, when I click on one of the bars in the example below, a different link is opened, indicating that the url´s are not properly connected with the bars. How do I solve this?
I have never worked or even seen JavaScript before, so chances are high the answer is in there. The plot is eventually meant to appear in a Shiny application.
library(rtweet)
library(ggplot2)
library(plotly)

# Get tweets
tweets <- get_timeline(""BBC"", n = 10)

# Create dataframe
data <- data.frame(""retweet_count"" = tweets$retweet_count,
                   ""week"" =  c(1,1,1,2,2,3,4,5,5,6),
                   ""url""  =  tweets$status_url)

# Create ggplot
ggplot(data = data,
           aes(x = week,
           y = retweet_count,
           label = url)) + 
  geom_bar(stat = 'sum', 
           fill = ""darkblue"")

# Convert to plotly
p <- ggplotly(
  p,
  tooltip = c(""y"", 'label'))

# Add URL data to plot
p$x$data[[1]]$customdata <- data$url

# JS function to make a tab open when clicking on a specific bar
onRender(
  p,
  ""
    function(el,x){
    el.on('plotly_click', function(d) {
    var websitelink = d.points[0].customdata;
    window.open(websitelink);
    });
    }
    "")

",<javascript><r><ggplot2><plotly><r-plotly>,6,"javascript,r,ggplot2,plotly,r-plotly",['open tab by clicking on a stacked barchart'],"['im building a stacked barchart containing retweets using r ggplot and plotly', 'if a part of a barchart is clicked on i want a new browser tab to open and show the tweet from this specific date with the indicated amount of retweets', 'however when i click on one of the bars in the example below a different link is opened indicating that the urls are not properly connected with the bars', 'how do i solve this', 'i have never worked or even seen javascript before so chances are high the answer is in there', 'the plot is eventually meant to appear in a shiny application', 'libraryrtweet libraryggplot2 libraryplotly get tweets tweets gettimelinebbc n 10 create dataframe data dataframeretweetcount tweetsretweetcount week c1112234556 url tweetsstatusurl create ggplot ggplotdata data aesx week y retweetcount label url geombarstat sum fill darkblue convert to plotly p ggplotly p tooltip cy label add url data to plot pxdata1customdata dataurl js function to make a tab open when clicking on a specific bar onrender p functionelx elonplotlyclick functiond var websitelink dpoints0customdata windowopenwebsitelink ']"
How to get Access to External Storage in Android 10 (Android Q)?,"I just migrated my sourcecode to Androidx, since I did that my share function to share a sound is no longer working. the Logcat says:
Failed to save file: /storage/emulated/0/appfolder/testsound.mp3 (Permission denied)

This is the part where it saves the sound:
            final String fileName = soundObject.getItemName() + "".mp3"";
            File storage = Environment.getExternalStorageDirectory();
            File directory = new File(storage.getAbsolutePath() + ""/appfolder/"");
            directory.mkdirs();
            final File file = new File(directory, fileName);
            InputStream in = view.getContext().getResources().openRawResource(soundObject.getItemID());

            try{
                Log.i(LOG_TAG, ""Saving sound "" + soundObject.getItemName());
                OutputStream out = new FileOutputStream(file);
                byte[] buffer = new byte[1024];

                int len;
                while ((len = in.read(buffer, 0, buffer.length)) != -1){
                    out.write(buffer, 0 , len);
                }
                in.close();
                out.close();

            } catch (IOException e){

                Log.e(LOG_TAG, ""Failed to save file: "" + e.getMessage());
            }

And this is the code where it shares the sound:
try{
                            if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.LOLLIPOP_MR1){


                                if (ActivityCompat.checkSelfPermission(view.getContext(), Manifest.permission.WRITE_EXTERNAL_STORAGE) != PackageManager.PERMISSION_GRANTED){
                                    ActivityCompat.requestPermissions((Activity) view.getContext(), new String[]{Manifest.permission.WRITE_EXTERNAL_STORAGE}, 1);

                                }else {
                                    final String AUTHORITY = view.getContext().getPackageName() + "".fileprovider"";
                                    Uri contentUri = FileProvider.getUriForFile(view.getContext(), AUTHORITY, file);
                                    final Intent intent = new Intent(Intent.ACTION_SEND);
                                    intent.putExtra(Intent.EXTRA_STREAM, contentUri);
                                    intent.setType(""audio/mp3"");
                                    view.getContext().startActivity(Intent.createChooser(intent, ""Share sound via...""));
                                }


                            }
                            else {
                                final Intent intent = new Intent(Intent.ACTION_SEND);
                                Uri fileUri = Uri.parse(file.getAbsolutePath());
                                intent.putExtra(Intent.EXTRA_STREAM, fileUri);
                                intent.setType(""audio/mp3"");
                                view.getContext().startActivity(Intent.createChooser(intent, ""Share sound via...""));
                            }

                        } catch (Exception e){
                            Log.e(LOG_TAG, ""Failed to share sound: "" + e.getMessage());
                        }
                    }

What do I have to change and how can I archieve that everyone no matter which Android Version he is using (minSdkVersion 16) can download and share the sound?
Sadly I'm getting many bad reviews atm because no one can share (Not even Android 9 and below eventhough they used to be able to)
Thank you
",<java><android><permissions><share><manifest>,11,"java,android,permissions,share,manifest",['how to get access to external storage in android 10 android q'],"['i just migrated my sourcecode to androidx since i did that my share function to share a sound is no longer working', 'the logcat says failed to save file storageemulated0appfoldertestsoundmp3 permission denied this is the part where it saves the sound final string filename soundobjectgetitemname mp3 file storage environmentgetexternalstoragedirectory file directory new filestoragegetabsolutepath appfolder directorymkdirs final file file new filedirectory filename inputstream in viewgetcontextgetresourcesopenrawresourcesoundobjectgetitemid try logilogtag saving sound soundobjectgetitemname outputstream out new fileoutputstreamfile byte buffer new byte1024 int len while len inreadbuffer 0 bufferlength 1 outwritebuffer 0 len inclose outclose catch ioexception e logelogtag failed to save file egetmessage and this is the code where it shares the sound try if buildversionsdkint buildversioncodeslollipopmr1 if activitycompatcheckselfpermissionviewgetcontext manifestpermissionwriteexternalstorage packagemanagerpermissiongranted activitycompatrequestpermissionsactivity viewgetcontext new stringmanifestpermissionwriteexternalstorage 1 else final string authority viewgetcontextgetpackagename fileprovider uri contenturi fileprovidergeturiforfileviewgetcontext authority file final intent intent new intentintentactionsend intentputextraintentextrastream contenturi intentsettypeaudiomp3 viewgetcontextstartactivityintentcreatechooserintent share sound via else final intent intent new intentintentactionsend uri fileuri uriparsefilegetabsolutepath intentputextraintentextrastream fileuri intentsettypeaudiomp3 viewgetcontextstartactivityintentcreatechooserintent share sound via catch exception e logelogtag failed to share sound egetmessage what do i have to change and how can i archieve that everyone no matter which android version he is using minsdkversion 16 can download and share the sound', 'sadly im getting many bad reviews atm because no one can share not even android 9 and below eventhough they used to be able to thank you']"
Generating cryptographically secure authentication tokens,"Background:
This is really a general best-practices question, but some background about the specific situation might be helpful:
We are developing a ""connected"" application for the iPhone.  It will communicate with the backend application via REST services.  In order to not have to prompt the user for a username and password every time they launch the application, we will expose a ""Login"" service that validates their username and password on initial launch and returns an authentication token that can be used for future web service requests for real data.  The token may have an expiration time after which we'll ask them to re-authenticate with their username/password.
The Question:
What are the best practices for generating this sort of token to be used for authentication?
For example, we could...

Hash (SHA-256, etc) a random string and store it in the database for the given user along with an expiration date.  Do a simple lookup of the token on subsequent requests to make sure it matches.
Encrypte the user id and some additional information (timestamp, etc) with a secret key.  Decrypt the token on subsequent requests to make sure it was issued by us.

This feels like it must be a solved problem.
",<c#><iphone><wcf><web-services><security>,60,"c#,iphone,wcf,web-services,security",['generating cryptographically secure authentication tokens'],"['background this is really a general bestpractices question but some background about the specific situation might be helpful we are developing a connected application for the iphone', 'it will communicate with the backend application via rest services', 'in order to not have to prompt the user for a username and password every time they launch the application we will expose a login service that validates their username and password on initial launch and returns an authentication token that can be used for future web service requests for real data', 'the token may have an expiration time after which well ask them to reauthenticate with their usernamepassword', 'the question what are the best practices for generating this sort of token to be used for authentication', 'for example we could hash sha256 etc a random string and store it in the database for the given user along with an expiration date', 'do a simple lookup of the token on subsequent requests to make sure it matches', 'encrypte the user id and some additional information timestamp etc with a secret key', 'decrypt the token on subsequent requests to make sure it was issued by us', 'this feels like it must be a solved problem']"
Authenticating With Facebook using Passport Not Working,"I'm trying to do Facebook authentication with my application. But so far, my attempts are unsuccessful. I'm completely new to Node.
When a user clicks that fb login button, the request need to be taken to /auth/facebook route where they will be passed to the Passport Strategy. There they will be sent to Facebook for authentication. But it never happens. The Facebook authentication windows never get showed. It seems like redirection not working. I did a few hours of searching but didn't get a solution.

Following is the parts of the code which I think important to this context
I had put my  App ID and App Secret in config/auth.js
module.exports = {

    'facebookAuth' : {
        'clientID'      : 'my-AppID-here', 
        'clientSecret'  : 'my-App-secret-here', 
        'callbackURL'   : 'http://localhost:8080/auth/facebook/callback'
    }
};

The strategy to authenticate with Facebook and handle the callback goes in config/passport.js
    var LocalStrategy    = require('passport-local').Strategy;
    var FacebookStrategy = require('passport-facebook').Strategy;

    // load up the user model and auth variables
    var User       = require('../app/models/user');
    var configAuth = require('./auth');

    module.exports = function(passport) {

        passport.serializeUser(function(user, done) {
            done(null, user.id);
        });

        passport.deserializeUser(function(id, done) {
            User.findById(id, function(err, user) {
                done(err, user);
            });
        });    

        // Facebook Strategy
        passport.use(new FacebookStrategy({

            // pull app id and secret from our auth.js file
            clientID        : configAuth.facebookAuth.clientID,
            clientSecret    : configAuth.facebookAuth.clientSecret,
            callbackURL     : configAuth.facebookAuth.callbackURL

        },

        // facebook will send back the token and profile
        function(token, refreshToken, profile, done) {

            process.nextTick(function() {

                // find the user in the database based on their facebook id
                User.findOne({ 'facebook.id' : profile.id }, function(err, user) {

                    if (err)
                        return done(err);

                    // if the user is found, then log them in
                    if (user) {
                        return done(null, user); 
                    } else {
                        // if there is no user found with that facebook id, create them
                        var newUser            = new User();

                        // set all of the facebook information in our user model
                        newUser.facebook.id    = profile.id; // set the users facebook id                   
                        newUser.facebook.token = token; // we will save the token that facebook provides to the user                    
                        newUser.facebook.name  = profile.name.givenName + ' ' + profile.name.familyName; // look at the passport user profile to see how names are returned
                        newUser.facebook.email = profile.emails[0].value; // facebook can return multiple emails so we'll take the first

                        // save our user to the database
                        newUser.save(function(err) {
                            if (err)
                                throw err;

                            // if successful, return the new user
                            return done(null, newUser);
                        });
                    }

                });
            });

        }));

    };

The relevant routes from app/routes.js
    module.exports = function(app, passport) {

        // route for facebook authentication and login
        app.get('/auth/facebook', passport.authenticate('facebook', { scope : 'email' }));

        // handle the callback after facebook has authenticated the user
        app.get('/auth/facebook/callback',
            passport.authenticate('facebook', {
                successRedirect : '/profile',
                failureRedirect : '/'
            }));

        // route for logging out
        app.get('/logout', function(req, res) {
            req.logout();
            res.redirect('/');
        });

    };

The the Login Button code in view
<a href=""/auth/facebook"" class=""btn btn-primary""><span class=""fa fa-facebook""></span> Facebook</a>

",<node.js><facebook><authentication><express><passport.js>,7,"node.js,facebook,authentication,express,passport.js",['authenticating with facebook using passport not working'],"['im trying to do facebook authentication with my application', 'but so far my attempts are unsuccessful', 'im completely new to node', 'when a user clicks that fb login button the request need to be taken to authfacebook route where they will be passed to the passport strategy', 'there they will be sent to facebook for authentication', 'but it never happens', 'the facebook authentication windows never get showed', 'it seems like redirection not working', 'i did a few hours of searching but didnt get a solution', 'following is the parts of the code which i think important to this context i had put my app id and app secret in configauthjs moduleexports facebookauth clientid myappidhere clientsecret myappsecrethere callbackurl the strategy to authenticate with facebook and handle the callback goes in configpassportjs var localstrategy requirepassportlocalstrategy var facebookstrategy requirepassportfacebookstrategy load up the user model and auth variables var user requireappmodelsuser var configauth requireauth moduleexports functionpassport passportserializeuserfunctionuser done donenull userid passportdeserializeuserfunctionid done userfindbyidid functionerr user doneerr user facebook strategy passportusenew facebookstrategy pull app id and secret from our authjs file clientid configauthfacebookauthclientid clientsecret configauthfacebookauthclientsecret callbackurl configauthfacebookauthcallbackurl facebook will send back the token and profile functiontoken refreshtoken profile done processnexttickfunction find the user in the database based on their facebook id userfindone facebookid profileid functionerr user if err return doneerr if the user is found then log them in if user return donenull user else if there is no user found with that facebook id create them var newuser new user set all of the facebook information in our user model newuserfacebookid profileid set the users facebook id newuserfacebooktoken token we will save the token that facebook provides to the user newuserfacebookname profilenamegivenname profilenamefamilyname look at the passport user profile to see how names are returned newuserfacebookemail profileemails0value facebook can return multiple emails so well take the first save our user to the database newusersavefunctionerr if err throw err if successful return the new user return donenull newuser the relevant routes from approutesjs moduleexports functionapp passport route for facebook authentication and login appgetauthfacebook passportauthenticatefacebook scope email handle the callback after facebook has authenticated the user appgetauthfacebookcallback passportauthenticatefacebook successredirect profile failureredirect route for logging out appgetlogout functionreq res reqlogout resredirect the the login button code in view a hrefauthfacebook classbtn btnprimaryspan classfa fafacebookspan facebooka']"
"Where does the T, U, V convention for generic type params come from?","Java, C#, and TypeScript (aka. the Sun/Hejlsberg family of languages) use T, U, V, etc. to represent generic type parameters. Ostensibly that's because T stands for ""Type"", and U and V follow T in the alphabet.
On the other hand, Scala uses A, B, C and so on, and OCaml and Haskell use a, b, and c.
Where do these conventions come from? Is it because the functional languages are closer to math proofs, where α, β, and γ are used by convention?

Similar, but doesn't answer my question: Where does the C# generics naming convention come from?.
",<java><c#><scala><generics><programming-languages>,7,"java,c#,scala,generics,programming-languages",['where does the t u v convention for generic type params come from'],"['java c and typescript aka', 'the sunhejlsberg family of languages use t u v etc', 'to represent generic type parameters', 'ostensibly thats because t stands for type and u and v follow t in the alphabet', 'on the other hand scala uses a b c and so on and ocaml and haskell use a b and c where do these conventions come from', 'is it because the functional languages are closer to math proofs where and are used by convention', 'similar but doesnt answer my question where does the c generics naming convention come from']"
ruby/ruby on rails memory leak detection,"I wrote a small web app using ruby on rails, its main purpose is to upload, store, and display results from xml(files can be up to several MB) files.  After running for about 2 months I noticed that the mongrel process was using about 4GB of memory.  I did some research on debugging ruby memory leaks and could not find much. So I have two questions.

Are there any good tools that can be used to find memory leaks in Ruby/rails?
What type of coding patterns cause memory leaks in ruby?

",<ruby-on-rails><ruby><memory><memory-leaks><coding-style>,46,"ruby-on-rails,ruby,memory,memory-leaks,coding-style",['rubyruby on rails memory leak detection'],"['i wrote a small web app using ruby on rails its main purpose is to upload store and display results from xmlfiles can be up to several mb files', 'after running for about 2 months i noticed that the mongrel process was using about 4gb of memory', 'i did some research on debugging ruby memory leaks and could not find much', 'so i have two questions', 'are there any good tools that can be used to find memory leaks in rubyrails', 'what type of coding patterns cause memory leaks in ruby']"
Showing two different fibonacci functions are equivalent,"I'm trying to learn exactly what it means to prove a program correct. I'm starting from scratch and getting hung up on the first steps/the introduction to the topic.
In this paper on total functional programming, two definitions of the fibonacci function are given. The traditional one:
fib 0 = 0
fib 1 = 1
fib n = fib (n-1) + fib (n-2)
--fib (n+2) = fib (n+1) + fib (n+2) --The definition as given in the paper 
                                    --It seems incorrect to me. Typo?

and a tail recursive version I had never seen before:
fib' n = f n 0 1
f 0 a b = a
f n a b = f (n-1) b (a+b)

The paper then claimed that it is ""straightforward"" to prove by induction that both functions return the same result for all positive Integers n. This is the first time I've thought of analysing programs like this. It's quite interesting to think that you can prove that two programs are equivilent, so I immediately tried to do this proof by induction myself. Either my maths skills are rusty or the task is not actually all that straightforward.
I proved for n = 1
fib' 1 = f 1 0 1
       = f 0 1 1
       = 1
fib 1  = 1 (By definition)
therefore
fib' n = fib n for n = 1

I made the n = k assumption
fib' k  = fib k
f k 0 1 = fib k

I start trying to prove that if the assumption holds true, then the functions are also equivilant for n = k + 1 (and hence they are all equivalent for all n >= 1 QED)
fib' (k+1)  = fib (k+1)
f (k+1) 0 1 = fib k + fib (k-1)

I've tried various manipulations, substituting the assumption in at the right time and so on, but I just can't get LHS to equal RHS and therefore prove that the functions/programs are equivalent. What am I missing? The paper mentions that the task is equivalent to proving
f n (fib p) (fib (p+1)) = fib (p+n)

by induction for arbitrary p. But I don't see how that's true at all. How did the authors arrive at this equation? That's a valid transformation on the equation only if p = 0. I don't see how that means it works for arbitrary p. To prove it for arbitrary p requires you to go through another layer of induction. Surely the correct formula to prove would be
fib' (n+p)  = fib (n+p)
f (n+p) 0 1 = fib (n+p)

So far that hasn't helped either. Can anyone show me how the induction would be done? Or link to a page that shows the proof (I did search, couldn't find anything).
",<haskell><functional-programming><fibonacci><correctness><induction>,16,"haskell,functional-programming,fibonacci,correctness,induction",['showing two different fibonacci functions are equivalent'],"['im trying to learn exactly what it means to prove a program correct', 'im starting from scratch and getting hung up on the first stepsthe introduction to the topic', 'in this paper on total functional programming two definitions of the fibonacci function are given', 'the traditional one fib 0 0 fib 1 1 fib n fib n1 fib n2 fib n2 fib n1 fib n2 the definition as given in the paper it seems incorrect to me', 'typo', 'and a tail recursive version i had never seen before fib n f n 0 1 f 0 a b a f n a b f n1 b ab the paper then claimed that it is straightforward to prove by induction that both functions return the same result for all positive integers n this is the first time ive thought of analysing programs like this', 'its quite interesting to think that you can prove that two programs are equivilent so i immediately tried to do this proof by induction myself', 'either my maths skills are rusty or the task is not actually all that straightforward', 'i proved for n 1 fib 1 f 1 0 1 f 0 1 1 1 fib 1 1 by definition therefore fib n fib n for n 1 i made the n k assumption fib k fib k f k 0 1 fib k i start trying to prove that if the assumption holds true then the functions are also equivilant for n k 1 and hence they are all equivalent for all n 1 qed fib k1 fib k1 f k1 0 1 fib k fib k1 ive tried various manipulations substituting the assumption in at the right time and so on but i just cant get lhs to equal rhs and therefore prove that the functionsprograms are equivalent', 'what am i missing', 'the paper mentions that the task is equivalent to proving f n fib p fib p1 fib pn by induction for arbitrary p but i dont see how thats true at all', 'how did the authors arrive at this equation', 'thats a valid transformation on the equation only if p 0 i dont see how that means it works for arbitrary p to prove it for arbitrary p requires you to go through another layer of induction', 'surely the correct formula to prove would be fib np fib np f np 0 1 fib np so far that hasnt helped either', 'can anyone show me how the induction would be done', 'or link to a page that shows the proof i did search couldnt find anything']"
ActiveRecord appends 'AND (1=0)' to end of queries,"I've been playing around in the rails console trying to get things to work, and I notice that one of my queries keeps returning nil when it shouldn't.  Upon looking at the generated SQL query I notice that it has AND (1=0) appended to it each time.  This is kind of annoying, and I'm not sure why it's doing this.
Note: Using the actable gem.
Steps to reproduce:
(After connecting to tables in rails console)
2.1.2 :xxxx > @parent = Parent.take
Parent Load (38.1ms)  SELECT  `parents`.* FROM `parents`  LIMIT 1
 => #<Parent id: 37, ...>

2.1.2 :xxxx > @child = Child.where(id: @parent.actable_id)
SQL (0.7ms)  SELECT `childs`.`id` AS t0_r0, `childs`.`attribute` AS t0_r1, FROM `childs`
...
LEFT OUTER JOIN `parents` ON `parents`.`actable_id` = `childs`.`id` AND `parents`.`actable_type` = 'child type' WHERE `childs`.`id` = 20 AND (1=0)
 => #<ActiveRecord::Relation []>

Why is this happening? How do I make it stop?
",<mysql><ruby-on-rails><activerecord><ruby-on-rails-4><rails-console>,32,"mysql,ruby-on-rails,activerecord,ruby-on-rails-4,rails-console",['activerecord appends and 10 to end of queries'],"['ive been playing around in the rails console trying to get things to work and i notice that one of my queries keeps returning nil when it shouldnt', 'upon looking at the generated sql query i notice that it has and 10 appended to it each time', 'this is kind of annoying and im not sure why its doing this', 'note using the actable gem', 'steps to reproduce after connecting to tables in rails console 212 xxxx parent parenttake parent load 381ms select parents', ' from parents limit 1 parent id 37 212 xxxx child childwhereid parentactableid sql 07ms select childsid as t0r0 childsattribute as t0r1 from childs left outer join parents on parentsactableid childsid and parentsactabletype child type where childsid 20 and 10 activerecordrelation why is this happening', 'how do i make it stop']"
Dates with no time or timezone component in Java/MySQL,"I need to be able to store a date (year/month/day) with no time component. It's an abstract concept of a date, such as a birthday - I need to represent a date in the year and not a particular instant in time.
I am using Java to parse the date from some input text, and need to store in a MySQL database. No matter what timezone the database, application, or any client is in, they should all see the same year/month/day.
My application will run on a machine with a different system timezone from the database server, and I don't have control over either. Does anyone have an elegant solution for ensuring I store the date correctly?
I can think of these solutions, neither of which seems very nice:

Query my MySQL connection for its timezone and parse the input date in that timezone
Process the date entirely as a string yyyy-MM-dd

",<java><sql><date><timezone><java-time>,9,"java,sql,date,timezone,java-time",['dates with no time or timezone component in javamysql'],"['i need to be able to store a date yearmonthday with no time component', 'its an abstract concept of a date such as a birthday i need to represent a date in the year and not a particular instant in time', 'i am using java to parse the date from some input text and need to store in a mysql database', 'no matter what timezone the database application or any client is in they should all see the same yearmonthday', 'my application will run on a machine with a different system timezone from the database server and i dont have control over either', 'does anyone have an elegant solution for ensuring i store the date correctly', 'i can think of these solutions neither of which seems very nice query my mysql connection for its timezone and parse the input date in that timezone process the date entirely as a string yyyymmdd']"
Using adaboost within R's caret package,"I've been using the ada R package for a while, and more recently, caret. According to the documentation, caret's train() function should have an option that uses ada.  But, caret is puking at me when I use the same syntax that sits within my ada() call.
Here's a demonstration, using the wine sample data set.
library(doSNOW)
registerDoSNOW(makeCluster(2, type = ""SOCK""))
library(caret)
library(ada)

wine = read.csv(""http://www.nd.edu/~mclark19/learn/data/goodwine.csv"")


set.seed(1234) #so that the indices will be the same when re-run
trainIndices = createDataPartition(wine$good, p = 0.8, list = F)
wanted = !colnames(wine) %in% c(""free.sulfur.dioxide"", ""density"", ""quality"",
                            ""color"", ""white"")

wine_train = wine[trainIndices, wanted]
wine_test = wine[-trainIndices, wanted]
cv_opts = trainControl(method=""cv"", number=10)


 ###now, the example that works using ada() 

 results_ada <- ada(good ~ ., data=wine_train, control=rpart.control
 (maxdepth=30, cp=0.010000, minsplit=20, xval=10), iter=500)

##this works, and gives me a confusion matrix.

results_ada
     ada(good ~ ., data = wine_train, control = rpart.control(maxdepth = 30, 
     cp = 0.01, minsplit = 20, xval = 10), iter = 500)
     Loss: exponential Method: discrete   Iteration: 500 
      Final Confusion Matrix for Data:
      Final Prediction
      etc. etc. etc. etc.

##Now, the calls that don't work. 

results_ada = train(good~., data=wine_train, method=""ada"",
control=rpart.control(maxdepth=30, cp=0.010000, minsplit=20, 
xval=10), iter=500)
   Error in train.default(x, y, weights = w, ...) : 
   final tuning parameters could not be determined
   In addition: Warning messages:
   1: In nominalTrainWorkflow(dat = trainData, info = trainInfo, method = method,  :
    There were missing values in resampled performance measures.
   2: In train.default(x, y, weights = w, ...) :
    missing values found in aggregated results

 ###this doesn't work, either

results_ada = train(good~., data=wine_train, method=""ada"", trControl=cv_opts,
maxdepth=10, nu=0.1, iter=50)

  Error in train.default(x, y, weights = w, ...) : 
  final tuning parameters could not be determined
  In addition: Warning messages:
  1: In nominalTrainWorkflow(dat = trainData, info = trainInfo, method = method,  :
    There were missing values in resampled performance measures.
  2: In train.default(x, y, weights = w, ...) :
   missing values found in aggregated results

I'm guessing it's that train() wants additional input, but the warning thrown doesn't give me any hints on what's missing. Additionally, I could be missing a dependency, but there's no hint on what should be there....
",<r><machine-learning><data-mining><classification><adaboost>,12,"r,machine-learning,data-mining,classification,adaboost",['using adaboost within rs caret package'],"['ive been using the ada r package for a while and more recently caret', 'according to the documentation carets train function should have an option that uses ada', 'but caret is puking at me when i use the same syntax that sits within my ada call', 'heres a demonstration using the wine sample data set', 'librarydosnow registerdosnowmakecluster2 type sock librarycaret libraryada wine readcsv setseed1234 so that the indices will be the same when rerun trainindices createdatapartitionwinegood p 08 list f wanted colnameswine in cfreesulfurdioxide density quality color white winetrain winetrainindices wanted winetest winetrainindices wanted cvopts traincontrolmethodcv number10 now the example that works using ada resultsada adagood datawinetrain controlrpartcontrol maxdepth30 cp0010000 minsplit20 xval10 iter500 this works and gives me a confusion matrix', 'resultsada adagood data winetrain control rpartcontrolmaxdepth 30 cp 001 minsplit 20 xval 10 iter 500 loss exponential method discrete iteration 500 final confusion matrix for data final prediction etc', 'etc', 'etc', 'etc', 'now the calls that dont work', 'resultsada traingood datawinetrain methodada controlrpartcontrolmaxdepth30 cp0010000 minsplit20 xval10 iter500 error in traindefaultx y weights w final tuning parameters could not be determined in addition warning messages 1 in nominaltrainworkflowdat traindata info traininfo method method there were missing values in resampled performance measures', '2 in traindefaultx y weights w missing values found in aggregated results this doesnt work either resultsada traingood datawinetrain methodada trcontrolcvopts maxdepth10 nu01 iter50 error in traindefaultx y weights w final tuning parameters could not be determined in addition warning messages 1 in nominaltrainworkflowdat traindata info traininfo method method there were missing values in resampled performance measures', '2 in traindefaultx y weights w missing values found in aggregated results im guessing its that train wants additional input but the warning thrown doesnt give me any hints on whats missing', 'additionally i could be missing a dependency but theres no hint on what should be there']"
How to convert multiple parquet files into TFrecord files using SPARK?,"I would like to produce stratified TFrecord files from a large DataFrame based on a certain condition, for which I use write.partitionBy(). I'm also using the tensorflow-connector in SPARK, but this apparently does not work together with a write.partitionBy() operation. Therefore, I have not found another way than to try to work in two steps:

Repartion the dataframe according to my condition, using partitionBy() and write the resulting partitions to parquet files.
Read those parquet files to convert them into TFrecord files with the tensorflow-connector plugin.

It is the second step that I'm unable to do efficiently. My idea was to read in the individual parquet files on the executors and immediately write them into TFrecord files. But this needs access to the SQLContext which can only be done in the Driver (discussed here) so not in parallel. I would like to do something like this:
# List all parquet files to be converted
import glob, os
files = glob.glob('/path/*.parquet'))

sc = SparkSession.builder.getOrCreate()
sc.parallelize(files, 2).foreach(lambda parquetFile: convert_parquet_to_tfrecord(parquetFile))

Could I construct the function convert_parquet_to_tfrecord that would be able to do this on the executors?
I've also tried just using the wildcard when reading all the parquet files:
SQLContext(sc).read.parquet('/path/*.parquet')

This indeed reads all parquet files, but unfortunately not into individual partitions. It appears that the original structure gets lost, so it doesn't help me if I want the exact contents of the individual parquet files converted into TFrecord files. 
Any other suggestions?
",<apache-spark><pyspark><apache-spark-sql><parquet><tfrecord>,5,"apache-spark,pyspark,apache-spark-sql,parquet,tfrecord",['how to convert multiple parquet files into tfrecord files using spark'],"['i would like to produce stratified tfrecord files from a large dataframe based on a certain condition for which i use writepartitionby', 'im also using the tensorflowconnector in spark but this apparently does not work together with a writepartitionby operation', 'therefore i have not found another way than to try to work in two steps repartion the dataframe according to my condition using partitionby and write the resulting partitions to parquet files', 'read those parquet files to convert them into tfrecord files with the tensorflowconnector plugin', 'it is the second step that im unable to do efficiently', 'my idea was to read in the individual parquet files on the executors and immediately write them into tfrecord files', 'but this needs access to the sqlcontext which can only be done in the driver discussed here so not in parallel', 'i would like to do something like this list all parquet files to be converted import glob os files globglobpathparquet sc sparksessionbuildergetorcreate scparallelizefiles 2foreachlambda parquetfile convertparquettotfrecordparquetfile could i construct the function convertparquettotfrecord that would be able to do this on the executors', 'ive also tried just using the wildcard when reading all the parquet files sqlcontextscreadparquetpathparquet this indeed reads all parquet files but unfortunately not into individual partitions', 'it appears that the original structure gets lost so it doesnt help me if i want the exact contents of the individual parquet files converted into tfrecord files', 'any other suggestions']"
Sax - ExpatParser$ParseException,"I'm making an Android application that reads an XML Internet. This application uses SAX to parse XML. This is my code for the part of parsing:
public LectorSAX(String url){
    try{
        SAXParserFactory spf=SAXParserFactory.newInstance();
        SAXParser sp = spf.newSAXParser();
        DefaultHandler lxmlr=new LibraryXMLReader() ;
        sp.parse(url, lxmlr);

        nodo=((LibraryXMLReader)lxmlr).getNodoActual();

    }catch(ParserConfigurationException e){ 
        System.err.println(""Error de parseo en LectorSAX.java: ""+e);
    }catch(SAXException e){
        System.err.println(""Error de sax LectorSAX.java: "" + e);
    } catch (IOException e){
        System.err.println(""Error de  io LectorSAX.java: "" + e);
    }
}

The problem is that SAXException occurs. The exception message is as follows:

org.apache.harmony.xml.ExpatParser$ParseException: At line 4, column
  42: not well-formed (invalid token)

However, if I put the same code in a normal Java SE application, this exception does not occur and everything works fine.
Why the same code works fine in a Java SE application, not an Android?. On the other hand, How to solve the problem?.
Thanks for the help.
Greetings.
",<java><android><xml-parsing><sax><saxparser>,5,"java,android,xml-parsing,sax,saxparser",['sax expatparserparseexception'],"['im making an android application that reads an xml internet', 'this application uses sax to parse xml', 'this is my code for the part of parsing public lectorsaxstring url try saxparserfactory spfsaxparserfactorynewinstance saxparser sp spfnewsaxparser defaulthandler lxmlrnew libraryxmlreader spparseurl lxmlr nodolibraryxmlreaderlxmlrgetnodoactual catchparserconfigurationexception e systemerrprintlnerror de parseo en lectorsaxjava e catchsaxexception e systemerrprintlnerror de sax lectorsaxjava e catch ioexception e systemerrprintlnerror de io lectorsaxjava e the problem is that saxexception occurs', 'the exception message is as follows orgapacheharmonyxmlexpatparserparseexception at line 4 column 42 not wellformed invalid token however if i put the same code in a normal java se application this exception does not occur and everything works fine', 'why the same code works fine in a java se application not an android', 'on the other hand how to solve the problem', 'thanks for the help', 'greeting']"
How to execute Travis CI 'before_deploy' step only once for multi-deploy configuration?,"In my project I has configured Travis CI build process which releases new versions of artifact to Github releases. My .travis.yml file:
language: java
jdk: oraclejdk8

branches:
  only:
    - master

before_install: mvn package

before_deploy:
  - export TRAVIS_TAG=""1.$TRAVIS_BUILD_NUMBER""
  - echo ""$TRAVIS_TAG"" ""$TRAVIS_COMMIT""
  - git config --local user.name ""$USER_NAME""
  - git config --local user.email ""$USER_EMAIL""
  - git tag ""$TRAVIS_TAG"" ""$TRAVIS_COMMIT""
  
deploy:
  provider: releases
  tag_name: $TRAVIS_TAG
  target_commitish: $TRAVIS_COMMIT
  name: $TRAVIS_TAG
  overwrite: true
  skip_cleanup: true
  api_key: $GITHUB_TOKEN
  file_glob: true
  file:
    - target/my-artifact-$TRAVIS_TAG.jar
  on:
    branch: master

notifications:
  email:
    on_success: never
    on_failure: always

I wanted to add ability to deploy artifact to Heroku and for that I added second item to deploy step, this one:
provider: heroku
api_key: $HEROKU_API_KEY
on:
  branch: master

With these changes the final version of Travis CI config:
language: java
jdk: oraclejdk8

branches:
  only:
    - master

before_install: mvn package

before_deploy:
  - export TRAVIS_TAG=""1.$TRAVIS_BUILD_NUMBER""
  - echo ""$TRAVIS_TAG"" ""$TRAVIS_COMMIT""
  - git config --local user.name ""$USER_NAME""
  - git config --local user.email ""$USER_EMAIL""
  - git tag ""$TRAVIS_TAG"" ""$TRAVIS_COMMIT""
  
deploy:
  - provider: releases
    tag_name: $TRAVIS_TAG
    target_commitish: $TRAVIS_COMMIT
    name: $TRAVIS_TAG
    overwrite: true
    skip_cleanup: true
    api_key: $GITHUB_TOKEN
    file_glob: true
    file:
      - target/my-artifact-$TRAVIS_TAG.jar
    on:
      branch: master
  - provider: heroku
    api_key: $HEROKU_API_KEY
    on:
      branch: master

notifications:
  email:
    on_success: never
    on_failure: always

But builds with such configuration are failing with message

fatal: tag already exists
The command ""git tag ""$TRAVIS_TAG"" ""$TRAVIS_COMMIT"""" failed and exited with 128 during
Your build has been stopped.

As result - I see that new version of artifact was released to Github releases, but deployment to Heroku was failed. I investigated the issue and it looks like Travis CI pipeline try to execute step before_deploy before each deploy, and when it try to execute it for deployment to Heroku it fail due to Git tag with such name was already created in before_deploy step for deploy to Github releases.
How can I fix the issue and configure Travis CI to execute before_deploy step only once?
",<github><continuous-integration><travis-ci><continuous-deployment><continuous-delivery>,5,"github,continuous-integration,travis-ci,continuous-deployment,continuous-delivery",['how to execute travis ci beforedeploy step only once for multideploy configuration'],"['in my project i has configured travis ci build process which releases new versions of artifact to github releases', 'my travisyml file language java jdk oraclejdk8 branches only master beforeinstall mvn package beforedeploy export travistag1travisbuildnumber echo travistag traviscommit git config local username username git config local useremail useremail git tag travistag traviscommit deploy provider releases tagname travistag targetcommitish traviscommit name travistag overwrite true skipcleanup true apikey githubtoken fileglob true file targetmyartifacttravistagjar on branch master notifications email onsuccess never onfailure always i wanted to add ability to deploy artifact to heroku and for that i added second item to deploy step this one provider heroku apikey herokuapikey on branch master with these changes the final version of travis ci config language java jdk oraclejdk8 branches only master beforeinstall mvn package beforedeploy export travistag1travisbuildnumber echo travistag traviscommit git config local username username git config local useremail useremail git tag travistag traviscommit deploy provider releases tagname travistag targetcommitish traviscommit name travistag overwrite true skipcleanup true apikey githubtoken fileglob true file targetmyartifacttravistagjar on branch master provider heroku apikey herokuapikey on branch master notifications email onsuccess never onfailure always but builds with such configuration are failing with message fatal tag already exists the command git tag travistag traviscommit failed and exited with 128 during your build has been stopped', 'as result i see that new version of artifact was released to github releases but deployment to heroku was failed', 'i investigated the issue and it looks like travis ci pipeline try to execute step beforedeploy before each deploy and when it try to execute it for deployment to heroku it fail due to git tag with such name was already created in beforedeploy step for deploy to github releases', 'how can i fix the issue and configure travis ci to execute beforedeploy step only once']"
Python Scikit-learn Perceptron Output Probabilities,"I'm using scikit-learn's Perceptron algorithm to do binary classification. When using some of the other algorithms in the library (RandomForestClassifer, LogisticRegression, etc.), I can use model.predict_proba() to have the algorithm output the probability of getting a positive (1) for each example. Is there a way to get a similar output for the Perceptron algorithm? 
The closest I've been able to come is model.decision_function(), which outputs a confidence score for the example based on the signed distance to the hyperplane, but I'm not sure how to convert these confidence scores to the probability figures I want. 
model.predict() is also only returning binary values. 
",<python><scikit-learn><neural-network><classification><perceptron>,5,"python,scikit-learn,neural-network,classification,perceptron",['python scikitlearn perceptron output probabilities'],"['im using scikitlearns perceptron algorithm to do binary classification', 'when using some of the other algorithms in the library randomforestclassifer logisticregression etc', ' i can use modelpredictproba to have the algorithm output the probability of getting a positive 1 for each example', 'is there a way to get a similar output for the perceptron algorithm', 'the closest ive been able to come is modeldecisionfunction which outputs a confidence score for the example based on the signed distance to the hyperplane but im not sure how to convert these confidence scores to the probability figures i want', 'modelpredict is also only returning binary values']"
How can I serve robots.txt on an SPA using React with Firebase hosting?,"I have an SPA built using create-react-app and wish to have a robots.txt like this:
http://example.com/robots.txt

I see on this page that:

You need to make sure your server is configured to catch any URL after it's configured to serve from a directory.

But for firebase hosting, I'm not sure what to do.
",<reactjs><firebase><single-page-application><robots.txt><create-react-app>,17,"reactjs,firebase,single-page-application,robots.txt,create-react-app",['how can i serve robotstxt on an spa using react with firebase hosting'],"['i have an spa built using createreactapp and wish to have a robotstxt like this i see on this page that you need to make sure your server is configured to catch any url after its configured to serve from a directory', 'but for firebase hosting im not sure what to do']"
Bootstrap-3: Input Group-Addon STRETCHES with jQuery Validation messages,"I'm using Twitter Bootstrap 3 with jQuery Validate plugin, but for some reason when the validation error message pops up it STRETCHES my Input Group-Addon box and the icon.
NORMAL [NO VALIDATION]

WITH VALIDATION

Here's my Fiddle in case you want to solve the problem: My Fiddle

I've tried multiple solutions on the web such as 
GitHub Issue of Input Addon and Input Addon issue on Stack
  Overflow
But I can't seem to fix the problem, no matter what I try. 

Please let me know what do I have to do to prevent the INPUT GROUP-ADDON from stretching when the validation errors appear. Thank you!
My main code is provided below:
jQuery
$('.login-form').validate ({
        // validation rules for registration form
    errorClass: ""error-class"",
    validClass: ""valid-class"",  
    onError : function(){
        $('.input-group.error-class').find('.help-block.form-error').each(function() {
          $(this).closest('.form-group').addClass('error-class').append($(this));
        });
    },

        rules: {
            username: {
                required: true,
                minlength: 3,
                maxlength: 40
            },

          password: {
                required: true,
                minlength: 7,
                maxlength: 20
            }
            },

        messages: {
            username: {
                required: ""Please enter your username or email address"",
                minlength: ""Usernames can't be shorter than three characters"",
                maxlength: ""Usernames or emails must be shorter than forty characters.""
            },
                       password: {
                required: ""Please enter your password"",
                minlength: ""Passwords can't be shorter than seven characters"",
                maxlength: ""Passwords must be shorter than forty characters.""
            },

                highlight: function(element, errorClass) {
        $(element).removeClass(errorClass);
    }    
        },

  submitHandler: function() {  
            $('#noenter').show();   

        }  
    });

HTML
<!-- Modal -->
<div class=""modal fade"" id=""myModal"" tabindex=""-1"" role=""dialog"" aria-labelledby=""myModalLabel"">
  <form class=""login-form"" action=""login"" method=""post"" action=""../PHP/ValidateForm.php"">
    <div class=""modal-dialog"" role=""document"">
      <div class=""modal-content"">
        <div class=""modal-header"">
          <button type=""button"" class=""close"" data-dismiss=""modal"" aria-label=""Close""><span aria-hidden=""true"">&times;</span></button>
          <h4 class=""modal-title"" style=""color:red;"" id=""myModalLabel"">TITLE</h4>
        </div>
        <div class=""modal-body"">
          <!-- Text input-->
          <div class=""form-group"">

            <div class=""input-group"">
              <span class=""input-group-addon""><i class=""fa fa-2x fa-user""></i></span>
              <input required id=""username"" name=""username"" placeholder=""Username or Email"" class=""inputfield form-control"" type=""text"">


            </div>
          </div>

          <!-- Text input-->
          <div class=""form-group"">

            <div class=""input-group"">
              <span class=""input-group-addon""><i class=""fa fa-2x fa-lock""></i></span>
              <input required id=""password"" name=""password"" placeholder=""Password"" class=""form-control"" type=""password"">


            </div>
          </div>
          <div class=""error"">

          </div>
          <input title=""Log In"" name=""submit"" value=""Log In"" type=""submit"" class=""loginbtn btn btn-lg btn-block"">
        </div>

        <p class=""text-muted""><strong>Need an account? <a href=""#"">Join </a></strong>

        </p>


      </div>
    </div>
  </form>
</div>

CSS
.form-control {
  color: #000 !important;
}

form label.error-class {
  font: 15px Tahoma, sans-serif;
  color: #ED7476;
  margin-left: 5px;
  position: relative;
}

form input.error-class,
form input.error-class:hover,
form input.error:focus,
form select.error-class,
form textarea.error-class {
  background: #FFEDED;
}

.error-class {
  color: red;
  z-index: 0;
  position: relative;
  display: inline-block;
}

.valid-class {
  color: black;
}

",<jquery><css><twitter-bootstrap-3><jquery-plugins><jquery-validate>,5,"jquery,css,twitter-bootstrap-3,jquery-plugins,jquery-validate",['bootstrap3 input groupaddon stretches with jquery validation messages'],"['im using twitter bootstrap 3 with jquery validate plugin but for some reason when the validation error message pops up it stretches my input groupaddon box and the icon', 'normal no validation with validation heres my fiddle in case you want to solve the problem my fiddle ive tried multiple solutions on the web such as github issue of input addon and input addon issue on stack overflow but i cant seem to fix the problem no matter what i try', 'please let me know what do i have to do to prevent the input groupaddon from stretching when the validation errors appear', 'thank you', 'my main code is provided below jquery loginformvalidate validation rules for registration form errorclass errorclass validclass validclass onerror function inputgrouperrorclassfindhelpblockformerroreachfunction thisclosestformgroupaddclasserrorclassappendthis rules username required true minlength 3 maxlength 40 password required true minlength 7 maxlength 20 messages username required please enter your username or email address minlength usernames cant be shorter than three characters maxlength usernames or emails must be shorter than forty characters', ' password required please enter your password minlength passwords cant be shorter than seven characters maxlength passwords must be shorter than forty characters', ' highlight functionelement errorclass elementremoveclasserrorclass submithandler function noentershow html modal div classmodal fade idmymodal tabindex1 roledialog arialabelledbymymodallabel form classloginform actionlogin methodpost actionphpvalidateformphp div classmodaldialog roledocument div classmodalcontent div classmodalheader button typebutton classclose datadismissmodal arialabelclosespan ariahiddentruetimesspanbutton h4 classmodaltitle stylecolorred idmymodallabeltitleh4 div div classmodalbody text input div classformgroup div classinputgroup span classinputgroupaddoni classfa fa2x fauserispan input required idusername nameusername placeholderusername or email classinputfield formcontrol typetext div div text input div classformgroup div classinputgroup span classinputgroupaddoni classfa fa2x falockispan input required idpassword namepassword placeholderpassword classformcontrol typepassword div div div classerror div input titlelog in namesubmit valuelog in typesubmit classloginbtn btn btnlg btnblock div p classtextmutedstrongneed an account', 'a hrefjoin astrong p div div form div css formcontrol color 000 important form labelerrorclass font 15px tahoma sansserif color ed7476 marginleft 5px position relative form inputerrorclass form inputerrorclasshover form inputerrorfocus form selecterrorclass form textareaerrorclass background ffeded errorclass color red zindex 0 position relative display inlineblock validclass color black ']"
Rails 5.0.0.beta1 - Generating an URL from non sanitized request parameters is insecure,"We are upgrading from Rails 4.2.5 to 5.0.0.beta1
When testing we expected to see index views rendered with paginated links as before.
But we now get an ArgumentError error page, for example:
ArgumentError in Transactions#index 
/app/views/kaminari/_paginator.html.erb where line #10 raised:


<%= paginator.render do -%>

Generating an URL from non sanitized request parameters is insecure!

Application Trace | Framework Trace | Full Trace

app/views/kaminari/_paginator.html.erb:10:in block in _app_views_kaminari__paginator_html_erb___4026289994022119719_69904100316060' app/views/kaminari/_paginator.html.erb:9:in_app_views_kaminari__paginator_html_erb___4026289994022119719_69904100316060'
app/views/transactions/index.html.erb:2:in `_app_views_transactions_index_html_erb__422882858554400818_60602560'

An issue has been raised with kaminari
On further investigation here is the new Rails 5.0.0.beta1 code that now throws the error:

Adding this to config/application.rb 'fixes' it, but not a great idea:
config.action_controller.permit_all_parameters = true

Instead adding this does not fix the issue, not sure why:
config.action_controller.always_permitted_parameters =  [:current_page, :page, :total_pages, :per_page, :remote, :paginator]

",<ruby-on-rails><upgrade><kaminari><sanitize><ruby-on-rails-5>,18,"ruby-on-rails,upgrade,kaminari,sanitize,ruby-on-rails-5",['rails 500beta1 generating an url from non sanitized request parameters is insecure'],"['we are upgrading from rails 425 to 500beta1 when testing we expected to see index views rendered with paginated links as before', 'but we now get an argumenterror error page for example argumenterror in transactionsindex appviewskaminaripaginatorhtmlerb where line 10 raised paginatorrender do generating an url from non sanitized request parameters is insecure', 'application trace framework trace full trace appviewskaminaripaginatorhtmlerb10in block in appviewskaminaripaginatorhtmlerb402628999402211971969904100316060 appviewskaminaripaginatorhtmlerb9inappviewskaminaripaginatorhtmlerb402628999402211971969904100316060 appviewstransactionsindexhtmlerb2in appviewstransactionsindexhtmlerb42288285855440081860602560 an issue has been raised with kaminari on further investigation here is the new rails 500beta1 code that now throws the error adding this to configapplicationrb fixes it but not a great idea configactioncontrollerpermitallparameters true instead adding this does not fix the issue not sure why configactioncontrolleralwayspermittedparameters currentpage page totalpages perpage remote paginator']"
Laravel 5.5 Redis problem - Call to undefined method Illuminate\Support\Facades\Redis::connect(),"I moved my Laravel 5.5 application to another server - I use exactly the same code there (did a git clone) with exactly the same composer.json and composer.lock files (even the NGINX configuration is the same).
When I run my application I get the following error:
Symfony \ Component \ Debug \ Exception \ FatalThrowableError (E_ERROR)
Call to undefined method Illuminate\Support\Facades\Redis::connect()

Here is the code:
namespace App\Http\Controllers;
use Illuminate\Http\Request;
...
public function somefunction() {
    $redis = new \Redis();
    $redis->connect(env('REDIS_HOST')); <-------------
...

The composer package predis/predis is installed and I have no php-redis on my system.
On both systems (debian) redis is installed and runs on 127.0.0.1. Both systems use the same configuration in .env and in config/*:
REDIS_HOST=127.0.0.1
REDIS_PASSWORD=null
REDIS_PORT=6379

The only thing, which is different is, that on one system (old one) I'm runnning php7.0 and on the new system I run php7.3 - I switched to php7.0 on the new system to check if that's the error, but I still get the exception.
Once again - on my other server everything is running fine with exactly the same code, which frustrates me - I can't figure out why this is happening.
",<laravel><redis><laravel-5.5><predis><phpredis>,5,"laravel,redis,laravel-5.5,predis,phpredis",['laravel 55 redis problem call to undefined method illuminatesupportfacadesredisconnect'],"['i moved my laravel 55 application to another server i use exactly the same code there did a git clone with exactly the same composerjson and composerlock files even the nginx configuration is the same', 'when i run my application i get the following error symfony component debug exception fatalthrowableerror eerror call to undefined method illuminatesupportfacadesredisconnect here is the code namespace apphttpcontrollers use illuminatehttprequest public function somefunction redis new redis redisconnectenvredishost the composer package predispredis is installed and i have no phpredis on my system', 'on both systems debian redis is installed and runs on 127001 both systems use the same configuration in env and in config redishost127001 redispasswordnull redisport6379 the only thing which is different is that on one system old one im runnning php70 and on the new system i run php73 i switched to php70 on the new system to check if thats the error but i still get the exception', 'once again on my other server everything is running fine with exactly the same code which frustrates me i cant figure out why this is happening']"
Why does Unix block size increase with bigger memory size?,"I am profiling binary data which has 

increasing Unix block size (one got from stat > Blocks) when the number of events are increased as in the following figure
but the byte distance between events stay constant
I have noticed some changes in other fields of the file which may explain the increasing Unix block size


The unix block size is a dynamic measure. 
I am interested in why it is increasing with bigger memory units in some systems.
I have had an idea that it should be constant. 
I used different environments to provide the stat output:

Debian Linux 8.1 with its default stat
OSX 10.8.5 with Xcode 6 and its default stat

Greybeard's comment may have the answer to the blocks behaviour:

The stat (1) command used to be a thin CLI to the stat (2) system
  call, which used to transfer relevant parts of a file's inode. Pretty
  early on, the meaning of the st_blksize member of the C struct
  returned by stat (2) was changed to ""preferred"" blocksize for
  efficient file system I/O, which carries well to file systems with
  mixed block sizes or non-block oriented allocation.

How can you measure the block size in case (1) and (2) separately?
Why can the Unix block size increase with bigger memory size?
",<algorithm><unix><memory><time-complexity><space-complexity>,7,"algorithm,unix,memory,time-complexity,space-complexity",['why does unix block size increase with bigger memory size'],"['i am profiling binary data which has increasing unix block size one got from stat blocks when the number of events are increased as in the following figure but the byte distance between events stay constant i have noticed some changes in other fields of the file which may explain the increasing unix block size the unix block size is a dynamic measure', 'i am interested in why it is increasing with bigger memory units in some systems', 'i have had an idea that it should be constant', 'i used different environments to provide the stat output debian linux 81 with its default stat osx 1085 with xcode 6 and its default stat greybeards comment may have the answer to the blocks behaviour the stat 1 command used to be a thin cli to the stat 2 system call which used to transfer relevant parts of a files inode', 'pretty early on the meaning of the stblksize member of the c struct returned by stat 2 was changed to preferred blocksize for efficient file system io which carries well to file systems with mixed block sizes or nonblock oriented allocation', 'how can you measure the block size in case 1 and 2 separately', 'why can the unix block size increase with bigger memory size']"
Java 8 Date API vs Calendar / Date / DateFormat,"There is this new-n-cool Date API in Java 8, the java.time package. I understand that it is better designed, less ambiguous and more thread-safe than the old classes. Still, I am not sure how to go about using it:

Should I use it exclusively instead of the old classes?
Should I replace existing usages of old classes whereever I spot them because the new stuff is so much better?
Should I refrain from using java.util.Calendar, java.util.Date, java.sql.Date and java.text.DateFormat in favor of the new API all together OR are there use cases where the old classes are still preferable?
Has the Joda Time API become obsolete thanks to the new Date API similarly to the substitution of Guava FluentIterable by Java 8 stream API?

I know these are a lot of questions, but they feel somewhat related to each other. If somebody can answer the whole bunch, that would be awesome, but good partial answers are also appreciated.
",<date><calendar><java-8><jodatime><java-time>,22,"date,calendar,java-8,jodatime,java-time",['java 8 date api vs calendar date dateformat'],"['there is this newncool date api in java 8 the javatime package', 'i understand that it is better designed less ambiguous and more threadsafe than the old classes', 'still i am not sure how to go about using it should i use it exclusively instead of the old classes', 'should i replace existing usages of old classes whereever i spot them because the new stuff is so much better', 'should i refrain from using javautilcalendar javautildate javasqldate and javatextdateformat in favor of the new api all together or are there use cases where the old classes are still preferable', 'has the joda time api become obsolete thanks to the new date api similarly to the substitution of guava fluentiterable by java 8 stream api', 'i know these are a lot of questions but they feel somewhat related to each other', 'if somebody can answer the whole bunch that would be awesome but good partial answers are also appreciated']"
When will Dijkstra's algorithm and Prim's algorithm produce different outputs?,"I know the difference between Prim's and Dijkstra's algorithm. The former produces a MST while latter gives shortest path from source to all node.  Mathematically, these aren't the same, so we wouldn't always expect the two algorithms to produce the same results.
However, while trying different examples I am getting the same result. The pseudocode for Prim's algorithm and Dijkstra's algorithm also look very similar. Can someone please give me an example where Prim's produces a MST which will not be obtained while solving with Dijkstra's or vice-versa.
Also, according to my knowledge. Both of these algorithm uses following approach. Please correct me if I am wrong:

Find shortest i-j where i from set which has already been included and j
       from set which hasn't been included yet and then add j to the set.

",<algorithm><graph><graph-algorithm><dijkstra><prims-algorithm>,5,"algorithm,graph,graph-algorithm,dijkstra,prims-algorithm",['when will dijkstras algorithm and prims algorithm produce different outputs'],"['i know the difference between prims and dijkstras algorithm', 'the former produces a mst while latter gives shortest path from source to all node', 'mathematically these arent the same so we wouldnt always expect the two algorithms to produce the same results', 'however while trying different examples i am getting the same result', 'the pseudocode for prims algorithm and dijkstras algorithm also look very similar', 'can someone please give me an example where prims produces a mst which will not be obtained while solving with dijkstras or viceversa', 'also according to my knowledge', 'both of these algorithm uses following approach', 'please correct me if i am wrong find shortest ij where i from set which has already been included and j from set which hasnt been included yet and then add j to the set']"
Pandas Panel fancy indexing: How to return (index of) all DataFrames in Panel based on Boolean of multiple columns in each df,"I've got a Pandas Panel with many DataFrames with the same rows/column labels.  I want to make a new panel with DataFrames that fulfill certain criteria based on a couple columns.
This is easy with dataframes and rows:  Say I have a df, zHe_compare.  I can get the suitable rows with:
zHe_compare[(zHe_compare['zHe_calc'] > 100) & (zHe_compare['zHe_med'] > 100) | ((zHe_obs_lo_2s <=zHe_compare['zHe_calc']) & (zHe_compare['zHe_calc'] <= zHe_obs_hi_2s))]

but how do I do (pseudocode, simplified boolean):
good_results_panel = results_panel[ all_dataframes[ sum ('zHe_calc' < 'zHe_obs') > min_num ] ]

I know the the inner boolean part, but how do I specify this for each dataframe in a panel?  Because I need multiple columns from each df, I haven't met success using the panel.minor_xs slicing techniques.
thanks!
",<python><indexing><panel><dataframe><pandas>,7,"python,indexing,panel,dataframe,pandas",['pandas panel fancy indexing how to return index of all dataframes in panel based on boolean of multiple columns in each df'],"['ive got a pandas panel with many dataframes with the same rowscolumn labels', 'i want to make a new panel with dataframes that fulfill certain criteria based on a couple columns', 'this is easy with dataframes and rows say i have a df zhecompare', 'i can get the suitable rows with zhecomparezhecomparezhecalc 100 zhecomparezhemed 100 zheobslo2s zhecomparezhecalc zhecomparezhecalc zheobshi2s but how do i do pseudocode simplified boolean goodresultspanel resultspanel alldataframes sum zhecalc zheobs minnum i know the the inner boolean part but how do i specify this for each dataframe in a panel', 'because i need multiple columns from each df i havent met success using the panelminorxs slicing techniques', 'thanks']"
How to make a texture always face the camera ..?,"Update 5
Created another fiddle to show what is expected would look like. An invisible skydome and a cubecamera are added and environment map is used; in my case, none of these technique should be used for the reasons already mentioned. 


var MatcapTransformer = function(uvs, face) {
  for (var i = uvs.length; i-- > 0;) {
    uvs[i].x = face.vertexNormals[i].x * 0.5 + 0.5;
    uvs[i].y = face.vertexNormals[i].y * 0.5 + 0.5;
  }
};

var TransformUv = function(geometry, xformer) {
  // The first argument is also used as an array in the recursive calls 
  // as there's no method overloading in javascript; and so is the callback. 
  var a = arguments[0],
    callback = arguments[1];

  var faceIterator = function(uvFaces, index) {
    xformer(uvFaces[index], geometry.faces[index]);
  };

  var layerIterator = function(uvLayers, index) {
    TransformUv(uvLayers[index], faceIterator);
  };

  for (var i = a.length; i-- > 0;) {
    callback(a, i);
  }

  if (!(i < 0)) {
    TransformUv(geometry.faceVertexUvs, layerIterator);
  }
};

var SetResizeHandler = function(renderer, camera) {
  var callback = function() {
    renderer.setSize(window.innerWidth, window.innerHeight);
    camera.aspect = window.innerWidth / window.innerHeight;
    camera.updateProjectionMatrix();
  };

  // bind the resize event
  window.addEventListener('resize', callback, false);

  // return .stop() the function to stop watching window resize
  return {
    stop: function() {
      window.removeEventListener('resize', callback);
    }
  };
};

(function() {
  var fov = 45;
  var aspect = window.innerWidth / window.innerHeight;
  var loader = new THREE.TextureLoader();

  var texture = loader.load('https://i.postimg.cc/mTsN30vx/canyon-s.jpg');
  texture.wrapS = THREE.RepeatWrapping;
  texture.wrapT = THREE.RepeatWrapping;
  texture.center.set(1 / 2, 1 / 2);

  var cubeCam = new THREE.CubeCamera(.1, 200, 4096);
  cubeCam.renderTarget.texture.wrapS = THREE.RepeatWrapping;
  cubeCam.renderTarget.texture.wrapT = THREE.RepeatWrapping;
  cubeCam.renderTarget.texture.center.set(1 / 2, 1 / 2);

  var geoSky = new THREE.SphereGeometry(2, 16, 16);
  var matSky = new THREE.MeshBasicMaterial({
    'map': texture,
    'side': THREE.BackSide
  });
  var meshSky = new THREE.Mesh(geoSky, matSky);
  meshSky.visible = false;

  var geometry = new THREE.IcosahedronGeometry(1, 1);
  var material = new THREE.MeshBasicMaterial({
    'envMap': cubeCam.renderTarget.texture
  });
  var mesh = new THREE.Mesh(geometry, material);

  var geoWireframe = new THREE.WireframeGeometry(geometry);
  var matWireframe = new THREE.LineBasicMaterial({
    'color': 'red',
    'linewidth': 2
  });
  mesh.add(new THREE.LineSegments(geoWireframe, matWireframe));

  var camera = new THREE.PerspectiveCamera(fov, aspect);
  camera.position.setZ(20);

  var scene = new THREE.Scene();
  scene.add(mesh);
  scene.add(meshSky);

  {
    var mirror = new THREE.CubeCamera(.1, 2000, 4096);
    var geoPlane = new THREE.PlaneGeometry(16, 16);
    var matPlane = new THREE.MeshBasicMaterial({
      'envMap': mirror.renderTarget.texture
    });

    var plane = new THREE.Mesh(geoPlane, matPlane);
    plane.add(mirror);
    plane.position.setZ(-4);
    plane.lookAt(mesh.position);
    scene.add(plane);
  }

  var renderer = new THREE.WebGLRenderer();

  var container = document.getElementById('container1');
  container.appendChild(renderer.domElement);

  SetResizeHandler(renderer, camera);
  renderer.setSize(window.innerWidth, window.innerHeight);

  var controls = new THREE.TrackballControls(camera, container);

  var fixTextureWhenRotateAroundAllAxis = function() {
    mesh.rotation.y += 0.01;
    mesh.rotation.x += 0.01;
    mesh.rotation.z += 0.01;

    cubeCam.update(renderer, scene);
  };

  renderer.setAnimationLoop(function() {
    // controls.update();

    plane.visible = false;

    {
      meshSky.visible = true;
      mesh.visible = false;

      fixTextureWhenRotateAroundAllAxis();

      mesh.visible = true;

      meshSky.visible = false;
    }

    mirror.update(renderer, scene);
    plane.visible = true;

    renderer.render(scene, camera);
  });
})();
body {
  background-color: #000;
  margin: 0px;
  overflow: hidden;
}
<script src=""https://threejs.org/build/three.min.js""></script>
<script src=""https://threejs.org/examples/js/controls/TrackballControls.js""></script>

<div id='container1'></div>




Update 4
Important: Please note there is a reflective plane in back of the target mesh which is for observing if the texture binds to the mesh surface correctly, it has nothing to do with what I'm trying to solve. 

Update 3
Created a new fiddle to show what is NOT the expected behaviour

Code 



var MatcapTransformer=function(uvs, face) {
	for(var i=uvs.length; i-->0;) {
		uvs[i].x=face.vertexNormals[i].x*0.5+0.5;
		uvs[i].y=face.vertexNormals[i].y*0.5+0.5;
	}
};

var TransformUv=function(geometry, xformer) {
	// The first argument is also used as an array in the recursive calls 
	// as there's no method overloading in javascript; and so is the callback. 
	var a=arguments[0], callback=arguments[1];

	var faceIterator=function(uvFaces, index) {
		xformer(uvFaces[index], geometry.faces[index]);
	};

	var layerIterator=function(uvLayers, index) {
		TransformUv(uvLayers[index], faceIterator);
	};

	for(var i=a.length; i-->0;) {
		callback(a, i);
	}

	if(!(i<0)) {
		TransformUv(geometry.faceVertexUvs, layerIterator);
	}
};

var SetResizeHandler=function(renderer, camera) {
	var callback=function() {
		renderer.setSize(window.innerWidth, window.innerHeight);
		camera.aspect=window.innerWidth/window.innerHeight;
		camera.updateProjectionMatrix();
	};

	// bind the resize event
	window.addEventListener('resize', callback, false);

	// return .stop() the function to stop watching window resize
	return {
		stop: function() {
			window.removeEventListener('resize', callback);
		}
	};
};

	var getVertexShader=function() {
		return `
void main() {
	gl_Position=projectionMatrix*modelViewMatrix*vec4(position, 1.0);
}
`;
	};

	var getFragmentShader=function(size) {
		return `
uniform sampler2D texture1;
const vec2 size=vec2(`+size.x+`, `+size.y+`);

void main() {
	gl_FragColor=texture2D(texture1, gl_FragCoord.xy/size.xy);
}
`;
	};


(function() {
	var fov=45;
	var aspect=window.innerWidth/window.innerHeight;
	var loader=new THREE.TextureLoader();

	var texture=loader.load('https://i.postimg.cc/mTsN30vx/canyon-s.jpg');
	texture.wrapS=THREE.RepeatWrapping;
	texture.wrapT=THREE.RepeatWrapping;
	texture.center.set(1/2, 1/2);

	var geometry=new THREE.SphereGeometry(1, 16, 16);
	// var geometry=new THREE.BoxGeometry(2, 2, 2);

	// var material=new THREE.MeshBasicMaterial({ 'map': texture });
	var material=new THREE.ShaderMaterial({
		'uniforms': { 'texture1': { 'type': 't', 'value': texture } }
		, 'vertexShader': getVertexShader()
		, 'fragmentShader': getFragmentShader({ 'x': 512, 'y': 256 })
	});

	var mesh=new THREE.Mesh(geometry, material);
	var geoWireframe=new THREE.WireframeGeometry(geometry);
	var matWireframe=new THREE.LineBasicMaterial({ 'color': 'red', 'linewidth': 2 });
	mesh.add(new THREE.LineSegments(geoWireframe, matWireframe));

	var camera=new THREE.PerspectiveCamera(fov, aspect);
	camera.position.setZ(20);

	var scene=new THREE.Scene();
	scene.add(mesh);
  
	{
		var mirror=new THREE.CubeCamera(.1, 2000, 4096);
		var geoPlane=new THREE.PlaneGeometry(16, 16);
		var matPlane=new THREE.MeshBasicMaterial({
			'envMap': mirror.renderTarget.texture
		});

		var plane=new THREE.Mesh(geoPlane, matPlane);
		plane.add(mirror);
		plane.position.setZ(-4);
		plane.lookAt(mesh.position);
		scene.add(plane);
	}

	var renderer=new THREE.WebGLRenderer();

	var container=document.getElementById('container1');
	container.appendChild(renderer.domElement);

	SetResizeHandler(renderer, camera);
	renderer.setSize(window.innerWidth, window.innerHeight);

	var fixTextureWhenRotateAroundYAxis=function() {
		mesh.rotation.y+=0.01;
		texture.offset.set(mesh.rotation.y/(2*Math.PI), 0);
	};

	var fixTextureWhenRotateAroundZAxis=function() {
		mesh.rotation.z+=0.01;
		texture.rotation=-mesh.rotation.z
		TransformUv(geometry, MatcapTransformer);
	};

	var fixTextureWhenRotateAroundAllAxis=function() {
		mesh.rotation.y+=0.01;
		mesh.rotation.x+=0.01;
		mesh.rotation.z+=0.01;
	};
  
	var controls=new THREE.TrackballControls(camera, container);

	renderer.setAnimationLoop(function() {
			fixTextureWhenRotateAroundAllAxis();

			controls.update();
			plane.visible=false;
			mirror.update(renderer, scene);
			plane.visible=true;   

		renderer.render(scene, camera);
	});
})();
body {
	background-color: #000;
	margin: 0px;
	overflow: hidden;
}
<script src=""https://threejs.org/build/three.min.js""></script>
<script src=""https://threejs.org/examples/js/controls/TrackballControls.js""></script>

<div id='container1'></div>



Maybe I should rephrase my question, but I lack the knowledge to describe accurately about what I'm trying to solve, please help .. (Panoramic-Transform-With-Texture-Looking-At-Direction-Locked-Onto-The-Camera maybe .. ?)

Update 2 
(Has deprecated as code snippet is applied. )

Update
OK .. I've added 3 methods: 

TransformUv accepts a geometry, and a transformer method which handles uv-transform. The callback accepts an uvs array for each face and the corresponding Face3 of geometry.faces[] as its parameters. 
MatcapTransformer is the uv-transform handler callback to do the matcap transform. 
and 
fixTextureWhenRotateAroundZAxis works like what it named. 

So far none of the fixTexture.. methods can work alltogether, also, fixTextureWhenRotateAroundXAxis is not figured out. The problem remains unsolved, I wish what's just added could help you to help me out. 

I'm trying to make the texture of a mesh always face an active perspective camera, no matter what are the relative positions. 
For constructing a real case of my scene and the interaction would be quite complex, I built a minimal example to demonstrate my intention. 

Code


var MatcapTransformer=function(uvs, face) {
	for(var i=uvs.length; i-->0;) {
		uvs[i].x=face.vertexNormals[i].x*0.5+0.5;
		uvs[i].y=face.vertexNormals[i].y*0.5+0.5;
	}
};

var TransformUv=function(geometry, xformer) {
	// The first argument is also used as an array in the recursive calls 
	// as there's no method overloading in javascript; and so is the callback. 
	var a=arguments[0], callback=arguments[1];

	var faceIterator=function(uvFaces, index) {
		xformer(uvFaces[index], geometry.faces[index]);
	};

	var layerIterator=function(uvLayers, index) {
		TransformUv(uvLayers[index], faceIterator);
	};

	for(var i=a.length; i-->0;) {
		callback(a, i);
	}

	if(!(i<0)) {
		TransformUv(geometry.faceVertexUvs, layerIterator);
	}
};

var SetResizeHandler=function(renderer, camera) {
	var callback=function() {
		renderer.setSize(window.innerWidth, window.innerHeight);
		camera.aspect=window.innerWidth/window.innerHeight;
		camera.updateProjectionMatrix();
	};

	// bind the resize event
	window.addEventListener('resize', callback, false);

	// return .stop() the function to stop watching window resize
	return {
		stop: function() {
			window.removeEventListener('resize', callback);
		}
	};
};

(function() {
	var fov=45;
	var aspect=window.innerWidth/window.innerHeight;
	var loader=new THREE.TextureLoader();

	var texture=loader.load('https://i.postimg.cc/mTsN30vx/canyon-s.jpg');
	texture.wrapS=THREE.RepeatWrapping;
	texture.wrapT=THREE.RepeatWrapping;
	texture.center.set(1/2, 1/2);

	var geometry=new THREE.SphereGeometry(1, 16, 16);
	var material=new THREE.MeshBasicMaterial({ 'map': texture });
	var mesh=new THREE.Mesh(geometry, material);

	var geoWireframe=new THREE.WireframeGeometry(geometry);
	var matWireframe=new THREE.LineBasicMaterial({ 'color': 'red', 'linewidth': 2 });
	mesh.add(new THREE.LineSegments(geoWireframe, matWireframe));

	var camera=new THREE.PerspectiveCamera(fov, aspect);
	camera.position.setZ(20);

	var scene=new THREE.Scene();
	scene.add(mesh);
  
	{
		var mirror=new THREE.CubeCamera(.1, 2000, 4096);
		var geoPlane=new THREE.PlaneGeometry(16, 16);
		var matPlane=new THREE.MeshBasicMaterial({
			'envMap': mirror.renderTarget.texture
		});

		var plane=new THREE.Mesh(geoPlane, matPlane);
		plane.add(mirror);
		plane.position.setZ(-4);
		plane.lookAt(mesh.position);
		scene.add(plane);
	}

	var renderer=new THREE.WebGLRenderer();

	var container=document.getElementById('container1');
	container.appendChild(renderer.domElement);

	SetResizeHandler(renderer, camera);
	renderer.setSize(window.innerWidth, window.innerHeight);

	var fixTextureWhenRotateAroundYAxis=function() {
		mesh.rotation.y+=0.01;
		texture.offset.set(mesh.rotation.y/(2*Math.PI), 0);
	};

	var fixTextureWhenRotateAroundZAxis=function() {
		mesh.rotation.z+=0.01;
		texture.rotation=-mesh.rotation.z
		TransformUv(geometry, MatcapTransformer);
	};

	// This is wrong
	var fixTextureWhenRotateAroundAllAxis=function() {
		mesh.rotation.y+=0.01;
		mesh.rotation.x+=0.01;
		mesh.rotation.z+=0.01;

		// Dun know how to do it correctly .. 
		texture.offset.set(mesh.rotation.y/(2*Math.PI), 0);
	};
  
	var controls=new THREE.TrackballControls(camera, container);

	renderer.setAnimationLoop(function() {
		fixTextureWhenRotateAroundYAxis();

		// Uncomment the following line and comment out `fixTextureWhenRotateAroundYAxis` to see the demo
		// fixTextureWhenRotateAroundZAxis();

		// fixTextureWhenRotateAroundAllAxis();
    
		// controls.update();
		plane.visible=false;
		mirror.update(renderer, scene);
		plane.visible=true; 
		renderer.render(scene, camera);
	});
})();
body {
	background-color: #000;
	margin: 0px;
	overflow: hidden;
}
<script src=""https://threejs.org/build/three.min.js""></script>
<script src=""https://threejs.org/examples/js/controls/TrackballControls.js""></script>

<div id='container1'></div>




Please note that although the mesh itself rotates in this demonstration, my real intention is making the camera move like orbiting around the mesh. 
I've added the wireframe to make the movement more clear. As you can see
 I use fixTextureWhenRotateAroundYAxis to do it correctly, but it's only for the y-axis. The mesh.rotation.y in my real code is calculated something like 
var ve=camera.position.clone();
ve.sub(mesh.position);
var rotY=Math.atan2(ve.x, ve.z);
var offsetX=rotY/(2*Math.PI);

However, I lack the knowledge of how to do fixTextureWhenRotateAroundAllAxis correctly. There are some restrictions of solving this: 

CubeCamera/CubeMap cannot be used as the client machines might have performance issues
Do not simply make the mesh lookAt the camera as they are eventually of any kind of geometry, not only the spheres; tricks like lookAt and restore .quaternion in a frame would be ok. 

Please don't get me wrong that I'm asking an XY problem as I don't have the right to expose proprietary code or I wouldn't have to pay the effort to build a minimal example :)
",<javascript><three.js><geometry><texture-mapping><uv-mapping>,10,"javascript,three.js,geometry,texture-mapping,uv-mapping",['how to make a texture always face the camera '],"['update 5 created another fiddle to show what is expected would look like', 'an invisible skydome and a cubecamera are added and environment map is used in my case none of these technique should be used for the reasons already mentioned', 'var matcaptransformer functionuvs face for var i uvslength i 0 uvsix facevertexnormalsix 05 05 uvsiy facevertexnormalsiy 05 05 var transformuv functiongeometry xformer the first argument is also used as an array in the recursive calls as theres no method overloading in javascript and so is the callback', 'var a arguments0 callback arguments1 var faceiterator functionuvfaces index xformeruvfacesindex geometryfacesindex var layeriterator functionuvlayers index transformuvuvlayersindex faceiterator for var i alength i 0 callbacka i if ', 'i 0 transformuvgeometryfacevertexuvs layeriterator var setresizehandler functionrenderer camera var callback function renderersetsizewindowinnerwidth windowinnerheight cameraaspect windowinnerwidth windowinnerheight cameraupdateprojectionmatrix bind the resize event windowaddeventlistenerresize callback false return stop the function to stop watching window resize return stop function windowremoveeventlistenerresize callback function var fov 45 var aspect windowinnerwidth windowinnerheight var loader new threetextureloader var texture loaderload texturewraps threerepeatwrapping texturewrapt threerepeatwrapping texturecenterset1 2 1 2 var cubecam new threecubecamera1 200 4096 cubecamrendertargettexturewraps threerepeatwrapping cubecamrendertargettexturewrapt threerepeatwrapping cubecamrendertargettexturecenterset1 2 1 2 var geosky new threespheregeometry2 16 16 var matsky new threemeshbasicmaterial map texture side threebackside var meshsky new threemeshgeosky matsky meshskyvisible false var geometry new threeicosahedrongeometry1 1 var material new threemeshbasicmaterial envmap cubecamrendertargettexture var mesh new threemeshgeometry material var geowireframe new threewireframegeometrygeometry var matwireframe new threelinebasicmaterial color red linewidth 2 meshaddnew threelinesegmentsgeowireframe matwireframe var camera new threeperspectivecamerafov aspect camerapositionsetz20 var scene new threescene sceneaddmesh sceneaddmeshsky var mirror new threecubecamera1 2000 4096 var geoplane new threeplanegeometry16 16 var matplane new threemeshbasicmaterial envmap mirrorrendertargettexture var plane new threemeshgeoplane matplane planeaddmirror planepositionsetz4 planelookatmeshposition sceneaddplane var renderer new threewebglrenderer var container documentgetelementbyidcontainer1 containerappendchildrendererdomelement setresizehandlerrenderer camera renderersetsizewindowinnerwidth windowinnerheight var controls new threetrackballcontrolscamera container var fixtexturewhenrotatearoundallaxis function meshrotationy 001 meshrotationx 001 meshrotationz 001 cubecamupdaterenderer scene renderersetanimationloopfunction controlsupdate planevisible false meshskyvisible true meshvisible false fixtexturewhenrotatearoundallaxis meshvisible true meshskyvisible false mirrorupdaterenderer scene planevisible true rendererrenderscene camera body backgroundcolor 000 margin 0px overflow hidden script src script src div idcontainer1div update 4 important please note there is a reflective plane in back of the target mesh which is for observing if the texture binds to the mesh surface correctly it has nothing to do with what im trying to solve', 'update 3 created a new fiddle to show what is not the expected behaviour code var matcaptransformerfunctionuvs face forvar iuvslength i0 uvsixfacevertexnormalsix0505 uvsiyfacevertexnormalsiy0505 var transformuvfunctiongeometry xformer the first argument is also used as an array in the recursive calls as theres no method overloading in javascript and so is the callback', 'var aarguments0 callbackarguments1 var faceiteratorfunctionuvfaces index xformeruvfacesindex geometryfacesindex var layeriteratorfunctionuvlayers index transformuvuvlayersindex faceiterator forvar ialength i0 callbacka i if', 'i0 transformuvgeometryfacevertexuvs layeriterator var setresizehandlerfunctionrenderer camera var callbackfunction renderersetsizewindowinnerwidth windowinnerheight cameraaspectwindowinnerwidthwindowinnerheight cameraupdateprojectionmatrix bind the resize event windowaddeventlistenerresize callback false return stop the function to stop watching window resize return stop function windowremoveeventlistenerresize callback var getvertexshaderfunction return void main glpositionprojectionmatrixmodelviewmatrixvec4position 10 var getfragmentshaderfunctionsize return uniform sampler2d texture1 const vec2 sizevec2sizex sizey void main glfragcolortexture2dtexture1 glfragcoordxysizexy function var fov45 var aspectwindowinnerwidthwindowinnerheight var loadernew threetextureloader var textureloaderload texturewrapsthreerepeatwrapping texturewraptthreerepeatwrapping texturecenterset12 12 var geometrynew threespheregeometry1 16 16 var geometrynew threeboxgeometry2 2 2 var materialnew threemeshbasicmaterial map texture var materialnew threeshadermaterial uniforms texture1 type t value texture vertexshader getvertexshader fragmentshader getfragmentshader x 512 y 256 var meshnew threemeshgeometry material var geowireframenew threewireframegeometrygeometry var matwireframenew threelinebasicmaterial color red linewidth 2 meshaddnew threelinesegmentsgeowireframe matwireframe var cameranew threeperspectivecamerafov aspect camerapositionsetz20 var scenenew threescene sceneaddmesh var mirrornew threecubecamera1 2000 4096 var geoplanenew threeplanegeometry16 16 var matplanenew threemeshbasicmaterial envmap mirrorrendertargettexture var planenew threemeshgeoplane matplane planeaddmirror planepositionsetz4 planelookatmeshposition sceneaddplane var renderernew threewebglrenderer var containerdocumentgetelementbyidcontainer1 containerappendchildrendererdomelement setresizehandlerrenderer camera renderersetsizewindowinnerwidth windowinnerheight var fixtexturewhenrotatearoundyaxisfunction meshrotationy001 textureoffsetsetmeshrotationy2mathpi 0 var fixtexturewhenrotatearoundzaxisfunction meshrotationz001 texturerotationmeshrotationz transformuvgeometry matcaptransformer var fixtexturewhenrotatearoundallaxisfunction meshrotationy001 meshrotationx001 meshrotationz001 var controlsnew threetrackballcontrolscamera container renderersetanimationloopfunction fixtexturewhenrotatearoundallaxis controlsupdate planevisiblefalse mirrorupdaterenderer scene planevisibletrue rendererrenderscene camera body backgroundcolor 000 margin 0px overflow hidden script src script src div idcontainer1div maybe i should rephrase my question but i lack the knowledge to describe accurately about what im trying to solve please help panoramictransformwithtexturelookingatdirectionlockedontothecamera maybe ', '', 'update 2 has deprecated as code snippet is applied ', 'update ok ive added 3 methods transformuv accepts a geometry and a transformer method which handles uvtransform', 'the callback accepts an uvs array for each face and the corresponding face3 of geometryfaces as its parameters', 'matcaptransformer is the uvtransform handler callback to do the matcap transform', 'and fixtexturewhenrotatearoundzaxis works like what it named', 'so far none of the fixtexture methods can work alltogether also fixtexturewhenrotatearoundxaxis is not figured out', 'the problem remains unsolved i wish whats just added could help you to help me out', 'im trying to make the texture of a mesh always face an active perspective camera no matter what are the relative positions', 'for constructing a real case of my scene and the interaction would be quite complex i built a minimal example to demonstrate my intention', 'code var matcaptransformerfunctionuvs face forvar iuvslength i0 uvsixfacevertexnormalsix0505 uvsiyfacevertexnormalsiy0505 var transformuvfunctiongeometry xformer the first argument is also used as an array in the recursive calls as theres no method overloading in javascript and so is the callback', 'var aarguments0 callbackarguments1 var faceiteratorfunctionuvfaces index xformeruvfacesindex geometryfacesindex var layeriteratorfunctionuvlayers index transformuvuvlayersindex faceiterator forvar ialength i0 callbacka i if', 'i0 transformuvgeometryfacevertexuvs layeriterator var setresizehandlerfunctionrenderer camera var callbackfunction renderersetsizewindowinnerwidth windowinnerheight cameraaspectwindowinnerwidthwindowinnerheight cameraupdateprojectionmatrix bind the resize event windowaddeventlistenerresize callback false return stop the function to stop watching window resize return stop function windowremoveeventlistenerresize callback function var fov45 var aspectwindowinnerwidthwindowinnerheight var loadernew threetextureloader var textureloaderload texturewrapsthreerepeatwrapping texturewraptthreerepeatwrapping texturecenterset12 12 var geometrynew threespheregeometry1 16 16 var materialnew threemeshbasicmaterial map texture var meshnew threemeshgeometry material var geowireframenew threewireframegeometrygeometry var matwireframenew threelinebasicmaterial color red linewidth 2 meshaddnew threelinesegmentsgeowireframe matwireframe var cameranew threeperspectivecamerafov aspect camerapositionsetz20 var scenenew threescene sceneaddmesh var mirrornew threecubecamera1 2000 4096 var geoplanenew threeplanegeometry16 16 var matplanenew threemeshbasicmaterial envmap mirrorrendertargettexture var planenew threemeshgeoplane matplane planeaddmirror planepositionsetz4 planelookatmeshposition sceneaddplane var renderernew threewebglrenderer var containerdocumentgetelementbyidcontainer1 containerappendchildrendererdomelement setresizehandlerrenderer camera renderersetsizewindowinnerwidth windowinnerheight var fixtexturewhenrotatearoundyaxisfunction meshrotationy001 textureoffsetsetmeshrotationy2mathpi 0 var fixtexturewhenrotatearoundzaxisfunction meshrotationz001 texturerotationmeshrotationz transformuvgeometry matcaptransformer this is wrong var fixtexturewhenrotatearoundallaxisfunction meshrotationy001 meshrotationx001 meshrotationz001 dun know how to do it correctly textureoffsetsetmeshrotationy2mathpi 0 var controlsnew threetrackballcontrolscamera container renderersetanimationloopfunction fixtexturewhenrotatearoundyaxis uncomment the following line and comment out fixtexturewhenrotatearoundyaxis to see the demo fixtexturewhenrotatearoundzaxis fixtexturewhenrotatearoundallaxis controlsupdate planevisiblefalse mirrorupdaterenderer scene planevisibletrue rendererrenderscene camera body backgroundcolor 000 margin 0px overflow hidden script src script src div idcontainer1div please note that although the mesh itself rotates in this demonstration my real intention is making the camera move like orbiting around the mesh', 'ive added the wireframe to make the movement more clear', 'as you can see i use fixtexturewhenrotatearoundyaxis to do it correctly but its only for the yaxis', 'the meshrotationy in my real code is calculated something like var vecamerapositionclone vesubmeshposition var rotymathatan2vex vez var offsetxroty2mathpi however i lack the knowledge of how to do fixtexturewhenrotatearoundallaxis correctly', 'there are some restrictions of solving this cubecameracubemap cannot be used as the client machines might have performance issues do not simply make the mesh lookat the camera as they are eventually of any kind of geometry not only the spheres tricks like lookat and restore quaternion in a frame would be ok please dont get me wrong that im asking an xy problem as i dont have the right to expose proprietary code or i wouldnt have to pay the effort to build a minimal example ']"
xclip does not terminate when tracing it,"I have made the following observations:
$ xclip text.txt

The execution terminates instantly, it copies the content of text.txt to the default selection XA_PRIMARY which means you can paste it through your middle mouse button or xclip -o.
When I want to see what xclip is doing, it does not terminate anymore:
$ xclip -verbose text.txt
Connected to X server.
Using UTF8_STRING.
Reading text.txt...
Waiting for selection requests, Control-C to quit
  Waiting for selection request number 1

It does not terminate until I select something in my X11 system, for instance this very output I have pasted here. I would understand this, if the behavior is limited to verbose. After all you want to sit around and see what happens.
I can reproduce the same behavior with strace, but only if the fork option is provided
$ strace -f xclip text.txt

or when shelling out from Ruby with a system execution command that should return the output, which is in fact nothing.
$ ruby -e ""`xclip text.txt`""

The hints that strace gave, is that it is polling on a file descriptor to wait for an event. This event is satisfied if I select something. Is this behavior explainable? I have gotten evidence, that this is not reproducable on any system. Could this be related to the ticket #9 Not closing stdout when setting clipboard from stdin?
I am running xclip version 0.12 on Ubuntu 13.04.
",<linux><unix><ubuntu><x11><xclip>,8,"linux,unix,ubuntu,x11,xclip",['xclip does not terminate when tracing it'],"['i have made the following observations xclip texttxt the execution terminates instantly it copies the content of texttxt to the default selection xaprimary which means you can paste it through your middle mouse button or xclip o when i want to see what xclip is doing it does not terminate anymore xclip verbose texttxt connected to x server', 'using utf8string', 'reading texttxt waiting for selection requests controlc to quit waiting for selection request number 1 it does not terminate until i select something in my x11 system for instance this very output i have pasted here', 'i would understand this if the behavior is limited to verbose', 'after all you want to sit around and see what happens', 'i can reproduce the same behavior with strace but only if the fork option is provided strace f xclip texttxt or when shelling out from ruby with a system execution command that should return the output which is in fact nothing', ' ruby e xclip texttxt the hints that strace gave is that it is polling on a file descriptor to wait for an event', 'this event is satisfied if i select something', 'is this behavior explainable', 'i have gotten evidence that this is not reproducable on any system', 'could this be related to the ticket 9 not closing stdout when setting clipboard from stdin', 'i am running xclip version 012 on ubuntu 1304']"
Using useBuildCache in gradle and kapt,"I would like to use the new kotlin gradle plugin capability and cache my build results, for more information please read this.
Another way of boosting the build is to cache kapt tasks, but it's not enabled by default 

because Gradle does not yet have a way to map inputs and outputs for
  annotation processors

The only kapt dependency that I have is dagger 2, from your experience is it safe to cache it ?
",<android><gradle><kotlin><android-gradle-plugin><dagger-2>,7,"android,gradle,kotlin,android-gradle-plugin,dagger-2",['using usebuildcache in gradle and kapt'],"['i would like to use the new kotlin gradle plugin capability and cache my build results for more information please read this', 'another way of boosting the build is to cache kapt tasks but its not enabled by default because gradle does not yet have a way to map inputs and outputs for annotation processors the only kapt dependency that i have is dagger 2 from your experience is it safe to cache it ']"
How to disable ripple effect on password toggle button of TextInputLayout,"I use TextInputLayout to show password toggle button. It is working but the ripple effect is behind the background of the EditText (I use drawable background for the EditText). How can I disable the ripple effect of the password button or bring the ripple in front of the EditText background? Here the recorded video that demonstrated the problem https://i.stack.imgur.com/g1TSE.jpg. 
<com.google.android.material.textfield.TextInputLayout
                android:layout_width=""match_parent""
                android:layout_height=""wrap_content""
                android:layout_marginTop=""25dp""
                app:hintEnabled=""false""
                app:passwordToggleEnabled=""true"">

                <com.google.android.material.textfield.TextInputEditText
                    android:layout_width=""match_parent""
                    android:layout_height=""wrap_content""
                    android:background=""@drawable/bg_edit""
                    android:hint=""••••••""
                    android:inputType=""textPassword""
                    android:padding=""18dp"" />
            </com.google.android.material.textfield.TextInputLayout>

",<android><xml><material-design><android-textinputlayout><material-components-android>,5,"android,xml,material-design,android-textinputlayout,material-components-android",['how to disable ripple effect on password toggle button of textinputlayout'],"['i use textinputlayout to show password toggle button', 'it is working but the ripple effect is behind the background of the edittext i use drawable background for the edittext', 'how can i disable the ripple effect of the password button or bring the ripple in front of the edittext background', 'here the recorded video that demonstrated the problem comgoogleandroidmaterialtextfieldtextinputlayout androidlayoutwidthmatchparent androidlayoutheightwrapcontent androidlayoutmargintop25dp apphintenabledfalse apppasswordtoggleenabledtrue comgoogleandroidmaterialtextfieldtextinputedittext androidlayoutwidthmatchparent androidlayoutheightwrapcontent androidbackgrounddrawablebgedit androidhint androidinputtypetextpassword androidpadding18dp comgoogleandroidmaterialtextfieldtextinputlayout']"
Only iOS 7 crash [NSNull intValue]: unrecognized selector sent to instance,"I want to get data from JSON service. Only iOS 7 version crash when get data from JSON value. 
It returns from JSON service below that:
{
    voteAverageRating = 0;
    voteCount = 0;
}

My code
int voteCount = [listDic objectForKey:@""voteCount""] intValue] ;

_LB_voteNumber.text = [NSString stringWithFormat:@""(%i)"",voteCount];

Its work for iOS 5,5.1,6.0,6.1 but it crash only iOS7 version. It gave this error:

0x00098117    _mh_execute_header [NSNull intValue]: unrecognized selector
  sent to instance

Then i changed my code below that;
NSString *voteCount = [listDic objectForKey:@""voteCount""] ;

_LB_voteNumber.text = [NSString stringWithFormat:@""(%@)"",voteCount];

When runs this code. It crashed again only iOS 7 version. It gave this error:

0x00098117    _mh_execute_header [NSNull length]: unrecognized selector
  sent to instance

How can i solve this problem ? 
",<iphone><ios><objective-c><json><ios7>,10,"iphone,ios,objective-c,json,ios7",['only ios 7 crash nsnull intvalue unrecognized selector sent to instance'],"['i want to get data from json service', 'only ios 7 version crash when get data from json value', 'it returns from json service below that voteaveragerating 0 votecount 0 my code int votecount listdic objectforkeyvotecount intvalue lbvotenumbertext nsstring stringwithformativotecount its work for ios 5516061 but it crash only ios7 version', 'it gave this error 0x00098117 mhexecuteheader nsnull intvalue unrecognized selector sent to instance then i changed my code below that nsstring votecount listdic objectforkeyvotecount lbvotenumbertext nsstring stringwithformatvotecount when runs this code', 'it crashed again only ios 7 version', 'it gave this error 0x00098117 mhexecuteheader nsnull length unrecognized selector sent to instance how can i solve this problem ']"
Can PostgreSQL JOIN on jsonb array objects?,"I am considering switching to PostgreSQL, because of the JSON support. However, I am wondering, if the following would be possible with a single query:
Let's say there are two tables:
Table 1) organisations:
  ID (INT)  |  members (JSONB)                                        |
------------+---------------------------------------------------------|
     1      | [{ id: 23, role: ""admin"" }, { id: 24, role: ""default"" }]|
     2      | [{ id: 23, role: ""user"" }]

Table 2) users:
  ID (INT)  | name TEXT | email TEXT    |
------------+-----------+---------------|
     23     | Max       | max@gmail.com |
     24     | Joe       | joe@gmail.com |

Now I want to get a result like this (all i have is the ID of the organisation [1]):
  ID (INT)  |  members (JSONB)                                       |
------------+--------------------------------------------------------|
     1      | [{ id: 23, name: ""Max"", email: ""max@gmail.com"", role: 
                ""admin"" },
               { id: 24, name: ""Joe"", email: ""joe@gmail.com "", role: 
                ""default"" }]
(1 row)

I know this is not what JSONB is intended for and that there is a better solution for storing this data in SQL, but I am just curious if it would be possible.
Thanks!
",<sql><arrays><json><postgresql><lateral-join>,17,"sql,arrays,json,postgresql,lateral-join",['can postgresql join on jsonb array objects'],"['i am considering switching to postgresql because of the json support', 'however i am wondering if the following would be possible with a single query lets say there are two tables table 1 organisations id int members jsonb 1 id 23 role admin id 24 role default 2 id 23 role user table 2 users id int name text email text 23 max maxgmailcom 24 joe joegmailcom now i want to get a result like this all i have is the id of the organisation 1 id int members jsonb 1 id 23 name max email maxgmailcom role admin id 24 name joe email joegmailcom role default 1 row i know this is not what jsonb is intended for and that there is a better solution for storing this data in sql but i am just curious if it would be possible', 'thanks']"
"Python, OpenCV: classify gender using ORB features and KNN","Task: Classify images of human faces as female or male. Training images with labels are available, obtain the test image from webcam.
Using: Python 2.7, OpenCV 2.4.4
I am using ORB to extract features from a grayscale image which I hope to use for training a K-Nearest Neighbor classifier. Each training image is of a different person so the number of keypoints and descriptors for each image are obviously different. My problem is that I'm not able to understand the OpenCV docs for KNN and ORB. I've seen other SO questions about ORB, KNN and FLANN but they didn't help much. 
What exactly is the nature of the descriptor given by ORB? How is it different than descriptors obtained by BRIEF, SURF, SIFT, etc.? 
It seems that the feature descriptors should be of the same size for each training sample in  KNN. How do I make sure that the descriptors are of the same size for each image? More generally, in what format should features be presented to KNN for training with given data and labels? Should the data be an int or float? Can it be char? 
The training data can be found here. 
I am also using the haarcascade_frontalface_alt.xml from opencv samples
Right now the KNN model is given just 10 images for training to see if my program passes without errors which, it does not. 
Here is my code: 
import cv2
from numpy import float32 as np.float32

def chooseCascade():
    # TODO: Option for diferent cascades
    # HAAR Classifier for frontal face
    _cascade = cv2.CascadeClassifier('haarcascade_frontalface_alt.xml')
    return _cascade

def cropToObj(cascade,imageFile):
    # Load as 1-channel grayscale image
    image = cv2.imread(imageFile,0)

    # Crop to the object of interest in the image
    objRegion = cascade.detectMultiScale(image) # TODO: What if multiple ojbects in image?

    x1 = objRegion[0,0]
    y1 = objRegion[0,1]
    x1PlusWidth = objRegion[0,0]+objRegion[0,2]
    y1PlusHeight = objRegion[0,1]+objRegion[0,3]

    _objImage = image[y1:y1PlusHeight,x1:x1PlusWidth]

    return _objImage

def recognizer(fileNames):
    # ORB contructor
    orb = cv2.ORB(nfeatures=100)

    keyPoints = []
    descriptors = [] 

    # A cascade for face detection
    haarFaceCascade = chooseCascade()

    # Start processing images
    for imageFile in fileNames:
        # Find faces using the HAAR cascade
        faceImage = cropToObj(haarFaceCascade,imageFile)

        # Extract keypoints and description 
        faceKeyPoints, faceDescriptors = orb.detectAndCompute(faceImage, mask = None)

        #print faceDescriptors.shape
        descRow = faceDescriptors.shape[0]
        descCol = faceDescriptors.shape[1]

        flatFaceDescriptors = faceDescriptors.reshape(descRow*descCol).astype(np.float32)

        keyPoints.append(faceKeyPoints)
        descriptors.append(flatFaceDescriptors)

    print descriptors

    # KNN model and training on descriptors
    responses = []
    for name in fileNames:
        if name.startswith('BF'):
            responses.append(0) # Female
        else:
            responses.append(1) # Male

    knn = cv2.KNearest()
    knnTrainSuccess = knn.train(descriptors,
                                responses,
                                isRegression = False) # isRegression = false, implies classification

    # Obtain test face image from cam
    capture = cv2.VideoCapture(0)
    closeCamera = -1
    while(closeCamera < 0):
        _retval, _camImage = capture.retrieve()      

        # Find face in camera image
        testFaceImage = haarFaceCascade.detectMultiScale(_camImage) # TODO: What if multiple faces?

        # Keyponts and descriptors of test face image
        testFaceKP, testFaceDesc = orb.detectAndCompute(testFaceImage, mask = None)
        testDescRow = testFaceDesc.shape[0]
        flatTestFaceDesc = testFaceDesc.reshape(1,testDescRow*testDescCol).astype(np.float32) 

        # Args in knn.find_nearest: testData, neighborhood
        returnedValue, result, neighborResponse, distance = knn.find_nearest(flatTestFaceDesc,3) 

        print returnedValue, result, neighborResponse, distance


        # Display results
        # TODO: Overlay classification text
        cv2.imshow(""testImage"", _camImage)

        closeCamera = cv2.waitKey(1)
    cv2.destroyAllWindows()


if __name__ == '__main__':
    fileNames = ['BF09NES_gray.jpg', 
                 'BF11NES_gray.jpg', 
                 'BF13NES_gray.jpg', 
                 'BF14NES_gray.jpg', 
                 'BF18NES_gray.jpg', 
                 'BM25NES_gray.jpg', 
                 'BM26NES_gray.jpg', 
                 'BM29NES_gray.jpg', 
                 'BM31NES_gray.jpg', 
                 'BM34NES_gray.jpg']

    recognizer(fileNames)

Currently I am getting an error at the line with knn.train() where descriptors is not detected as a numpy array. 
Also, is this approach completely wrong? Am I supposed to use some other way for gender classification? I wasn't satisfied with the fisherface and eigenface example in the opencv facerec demo so please don't direct me to those. 
Any other help is much appreciated. Thanks. 
--- EDIT ---
I've tried a few things and come up with an answer. 
I am still hoping that someone in SO community can help me by suggesting an idea so that I don't have to hardcode things into my solution. I also suspect that knn.match_nearest() isn't doing what I need it to do. 
And as expected, the recognizer is not at all accurate and very prone to giving misclassification due to rotation, lighting, etc. Any suggestions on improving this approach would be really appreciated.
The database I am using for training is: Karolinska Directed Emotional Faces
",<python><opencv><image-processing><classification><image-recognition>,5,"python,opencv,image-processing,classification,image-recognition",['python opencv classify gender using orb features and knn'],"['task classify images of human faces as female or male', 'training images with labels are available obtain the test image from webcam', 'using python 27 opencv 244 i am using orb to extract features from a grayscale image which i hope to use for training a knearest neighbor classifier', 'each training image is of a different person so the number of keypoints and descriptors for each image are obviously different', 'my problem is that im not able to understand the opencv docs for knn and orb', 'ive seen other so questions about orb knn and flann but they didnt help much', 'what exactly is the nature of the descriptor given by orb', 'how is it different than descriptors obtained by brief surf sift etc', 'it seems that the feature descriptors should be of the same size for each training sample in knn', 'how do i make sure that the descriptors are of the same size for each image', 'more generally in what format should features be presented to knn for training with given data and labels', 'should the data be an int or float', 'can it be char', 'the training data can be found here', 'i am also using the haarcascadefrontalfacealtxml from opencv samples right now the knn model is given just 10 images for training to see if my program passes without errors which it does not', 'here is my code import cv2 from numpy import float32 as npfloat32 def choosecascade todo option for diferent cascades haar classifier for frontal face cascade cv2cascadeclassifierhaarcascadefrontalfacealtxml return cascade def croptoobjcascadeimagefile load as 1channel grayscale image image cv2imreadimagefile0 crop to the object of interest in the image objregion cascadedetectmultiscaleimage todo what if multiple ojbects in image', 'x1 objregion00 y1 objregion01 x1pluswidth objregion00objregion02 y1plusheight objregion01objregion03 objimage imagey1y1plusheightx1x1pluswidth return objimage def recognizerfilenames orb contructor orb cv2orbnfeatures100 keypoints descriptors a cascade for face detection haarfacecascade choosecascade start processing images for imagefile in filenames find faces using the haar cascade faceimage croptoobjhaarfacecascadeimagefile extract keypoints and description facekeypoints facedescriptors orbdetectandcomputefaceimage mask none print facedescriptorsshape descrow facedescriptorsshape0 desccol facedescriptorsshape1 flatfacedescriptors facedescriptorsreshapedescrowdesccolastypenpfloat32 keypointsappendfacekeypoints descriptorsappendflatfacedescriptors print descriptors knn model and training on descriptors responses for name in filenames if namestartswithbf responsesappend0 female else responsesappend1 male knn cv2knearest knntrainsuccess knntraindescriptors responses isregression false isregression false implies classification obtain test face image from cam capture cv2videocapture0 closecamera 1 whileclosecamera 0 retval camimage captureretrieve find face in camera image testfaceimage haarfacecascadedetectmultiscalecamimage todo what if multiple faces', ' keyponts and descriptors of test face image testfacekp testfacedesc orbdetectandcomputetestfaceimage mask none testdescrow testfacedescshape0 flattestfacedesc testfacedescreshape1testdescrowtestdesccolastypenpfloat32 args in knnfindnearest testdata neighborhood returnedvalue result neighborresponse distance knnfindnearestflattestfacedesc3 print returnedvalue result neighborresponse distance display results todo overlay classification text cv2imshowtestimage camimage closecamera cv2waitkey1 cv2destroyallwindows if name main filenames bf09nesgrayjpg bf11nesgrayjpg bf13nesgrayjpg bf14nesgrayjpg bf18nesgrayjpg bm25nesgrayjpg bm26nesgrayjpg bm29nesgrayjpg bm31nesgrayjpg bm34nesgrayjpg recognizerfilenames currently i am getting an error at the line with knntrain where descriptors is not detected as a numpy array', 'also is this approach completely wrong', 'am i supposed to use some other way for gender classification', 'i wasnt satisfied with the fisherface and eigenface example in the opencv facerec demo so please dont direct me to those', 'any other help is much appreciated', 'thanks', ' edit ive tried a few things and come up with an answer', 'i am still hoping that someone in so community can help me by suggesting an idea so that i dont have to hardcode things into my solution', 'i also suspect that knnmatchnearest isnt doing what i need it to do', 'and as expected the recognizer is not at all accurate and very prone to giving misclassification due to rotation lighting etc', 'any suggestions on improving this approach would be really appreciated', 'the database i am using for training is karolinska directed emotional faces']"
Is it possible to implement liftM2 in Scala?,"In Haskell, liftM2 can be defined as:
liftM2 :: (Monad m) => (a1 -> a2 -> r) -> m a1 -> m a2 -> m r
liftM2 f m1 m2 = do
  x1 <- m1
  x2 <- m2
  return $ f x1 x2

I'd like to translate this to Scala.  My first attempt was the following:
def liftM2[T1, T2, R, M[_]](f: (T1, T2) => R)(ma: M[T1], mb: M[T2]) : M[R] = for {
  a <- ma
  b <- mb
} yield f(a, b)

This fails in what I guess is the most obvious way possible: ""value flatMap is not a member of type parameter M[T1]"".  Right, I haven't indicated that M[_] is some kind of monad.  So the next thing I tried was to define some structural type like:
type Monad[A] = {
  def flatMap[B](f: (A) => Monad[B]): Monad[B]
}

... and to have M[A] <: Monad[A].  But that doesn't work, because Scala doesn't have recursive structural types.
So the next few things I tried involved gyrations similar to M[A] <: FilterMonadic[A, _].  Those all failed, probably because I wasn't able to figure out the right implicit-fu for CanBuildFrom.
The most closely-related question I could find here on StackOverflow was this one, touching both on recursive structural types and how to mimic Haskell's typeclasses in Scala.  But that approach requires defining an implicit conversion from each type you care about to the trait defining the typeclass, which seems terribly circular in this case...
Is there any good way to do what I'm trying to do?
",<scala><haskell><monads><typeclass><lifting>,28,"scala,haskell,monads,typeclass,lifting",['is it possible to implement liftm2 in scala'],"['in haskell liftm2 can be defined as liftm2 monad m a1 a2 r m a1 m a2 m r liftm2 f m1 m2 do x1 m1 x2 m2 return f x1 x2 id like to translate this to scala', 'my first attempt was the following def liftm2t1 t2 r mf t1 t2 rma mt1 mb mt2 mr for a ma b mb yield fa b this fails in what i guess is the most obvious way possible value flatmap is not a member of type parameter mt1', 'right i havent indicated that m is some kind of monad', 'so the next thing i tried was to define some structural type like type monada def flatmapbf a monadb monadb and to have ma monada', 'but that doesnt work because scala doesnt have recursive structural types', 'so the next few things i tried involved gyrations similar to ma filtermonadica ', 'those all failed probably because i wasnt able to figure out the right implicitfu for canbuildfrom', 'the most closelyrelated question i could find here on stackoverflow was this one touching both on recursive structural types and how to mimic haskells typeclasses in scala', 'but that approach requires defining an implicit conversion from each type you care about to the trait defining the typeclass which seems terribly circular in this case is there any good way to do what im trying to do']"
error: index.js: Cannot find module 'babel-plugin-r' React Native,"What I have Done to cause the Error:
I have a freshly installed Bare React Native Project . I wanted to use Drawer Navigation and had to install React Native Reanimated 2.3.0-alpha.2 .
what I have already tried to resolve the error

I have installed fresh bare react native project
Cleared Metro Cache
Tried to use Reanimated 2.0.0
I have Followed all the steps from https://www.reanimated2.com/docs/next/installation.

Error
BUNDLE  ./index.js
error: index.js: Cannot find module 'babel-plugin-r'
Require stack:

D:\Work\React Native\React Native with Node\healthapp\node_modules@babel\core\lib\config\files\plugins.js
D:\Work\React Native\React Native with Node\healthapp\node_modules@babel\core\lib\config\files\index.js
D:\Work\React Native\React Native with Node\healthapp\node_modules@babel\core\lib\index.js
D:\Work\React Native\React Native with Node\healthapp\node_modules\metro-transform-worker\src\index.js
D:\Work\React Native\React Native with Node\healthapp\node_modules\metro\src\DeltaBundler\Worker.js
D:\Work\React Native\React Native with Node\healthapp\node_modules\metro\node_modules\jest-worker\build\workers\processChild.js

",<android><react-native><react-navigation><navigation-drawer><react-native-reanimated-v2>,5,"android,react-native,react-navigation,navigation-drawer,react-native-reanimated-v2",['error indexjs cannot find module babelpluginr react native'],"['what i have done to cause the error i have a freshly installed bare react native project ', 'i wanted to use drawer navigation and had to install react native reanimated 230alpha2 ', 'what i have already tried to resolve the error i have installed fresh bare react native project cleared metro cache tried to use reanimated 200 i have followed all the steps from error bundle indexjs error indexjs cannot find module babelpluginr require stack dworkreact nativereact native with nodehealthappnodemodulesbabelcorelibconfigfilespluginsjs dworkreact nativereact native with nodehealthappnodemodulesbabelcorelibconfigfilesindexjs dworkreact nativereact native with nodehealthappnodemodulesbabelcorelibindexjs dworkreact nativereact native with nodehealthappnodemodulesmetrotransformworkersrcindexjs dworkreact nativereact native with nodehealthappnodemodulesmetrosrcdeltabundlerworkerjs dworkreact nativereact native with nodehealthappnodemodulesmetronodemodulesjestworkerbuildworkersprocesschildjs']"
"Error ""java.net.SocketException: Too many open files"" at deployment phase in jboss-portal-2.7.2","When start the jboss-portal-2.7.2 at some point in the log message:
2013-01-30 20:32:02,541 ERROR [org.apache.tomcat.util.net.JIoEndpoint] Socket accept failed
java.net.SocketException: Too many open files
        at java.net.PlainSocketImpl.socketAccept(Native Method)
        at java.net.PlainSocketImpl.accept(PlainSocketImpl.java:408)
        at java.net.ServerSocket.implAccept(ServerSocket.java:462)
        at java.net.ServerSocket.accept(ServerSocket.java:430)
        at org.apache.tomcat.util.net.DefaultServerSocketFactory.acceptSocket(DefaultServerSocketFactory.java:61)
        at org.apache.tomcat.util.net.JIoEndpoint$Acceptor.run(JIoEndpoint.java:309)
        at java.lang.Thread.run(Thread.java:662)

In the deploy folder a total of 20. war modules. Any solutions?
",<java><file-io><jboss><socketexception><jboss-portal>,6,"java,file-io,jboss,socketexception,jboss-portal",['error javanetsocketexception too many open files at deployment phase in jbossportal272'],"['when start the jbossportal272 at some point in the log message 20130130 203202541 error orgapachetomcatutilnetjioendpoint socket accept failed javanetsocketexception too many open files at javanetplainsocketimplsocketacceptnative method at javanetplainsocketimplacceptplainsocketimpljava408 at javanetserversocketimplacceptserversocketjava462 at javanetserversocketacceptserversocketjava430 at orgapachetomcatutilnetdefaultserversocketfactoryacceptsocketdefaultserversocketfactoryjava61 at orgapachetomcatutilnetjioendpointacceptorrunjioendpointjava309 at javalangthreadrunthreadjava662 in the deploy folder a total of 20 war modules', 'any solutions']"
On Windows is there a **light-weight** IDE that can be used both with C and Perl?,"When I asked this previously I should have mentioned that it's particularly a light-weight IDE that I'm after, so I’m having to ask again as a different question.
Something that is not just a text editor, is light-weight and versatile, that would suit Strawberry Perl, the GCC that comes with MinGW, GDB and Subversion. Something that when I want to use it is straight-away available, and is also fast to shut down preserving all my work. It doesn't matter if it's not a free or open-source program, what does matter is that it’s stable and is comfortable to use.
Maybe trying to have one IDE to use for both C and Perl is the wrong way to go about it - resulting in a solution that's not going to handle either one language or the other as well as a dedicated IDE would?
",<windows><perl><svn><ide><gnu-toolchain>,8,"windows,perl,svn,ide,gnu-toolchain",['on windows is there a lightweight ide that can be used both with c and perl'],"['when i asked this previously i should have mentioned that its particularly a lightweight ide that im after so im having to ask again as a different question', 'something that is not just a text editor is lightweight and versatile that would suit strawberry perl the gcc that comes with mingw gdb and subversion', 'something that when i want to use it is straightaway available and is also fast to shut down preserving all my work', 'it doesnt matter if its not a free or opensource program what does matter is that its stable and is comfortable to use', 'maybe trying to have one ide to use for both c and perl is the wrong way to go about it resulting in a solution thats not going to handle either one language or the other as well as a dedicated ide would']"
Migrating Java TreeMap code to Scala?,"I am migrating my Java code base to pure Scala and I am stuck on this one piece of code. I have an implementation of an IntervalMap i.e. a data structures that let's you efficiently map ranges [from,to] to values where the set, delete and get operations are all O(log n) (slightly different from an IntervalTree or a SegmentTree).
This code uses Java's java.util.TreeMaps and while migrating to Scala, I ran into 2 big issues:

Scala has no mutable.TreeMap - I decided to go around it by using mutable.TreeSet (oddly Scala has mutable.TreeSet but no mutable.TreeMap) for storing the keys and storing the values in an auxiliary mutable.Map. This is an unpleasant hack but is there any better way?
Next problem is Scala's mutable.TreeSet has no equivalent of java.util.TreeSet's ceilingKey, floorEntry, pollFirst, pollLast which are all O(log n) operations in Java.

So, how can I best migrate my code to Scala? What are the best practices in these situations? I really do not want to write my own tree implementations. Is there a more idiomatic Scala way of writing IntervalMaps that I am not aware of? Or is there some reputable library out there? Or does Scala just plain suck here with its gimped TreeSet and non-existent TreeMaps. Ofcourse I can just use Java's TreeMap in Scala but that is ugly and I lose all the nice Scala collection features and I might as well use Java then.
Here is my current Java code: https://gist.github.com/pathikrit/5574521
",<java><scala><scala-collections><treemap><treeset>,19,"java,scala,scala-collections,treemap,treeset",['migrating java treemap code to scala'],"['i am migrating my java code base to pure scala and i am stuck on this one piece of code', 'i have an implementation of an intervalmap ie', 'a data structures that lets you efficiently map ranges fromto to values where the set delete and get operations are all olog n slightly different from an intervaltree or a segmenttree', 'this code uses javas javautiltreemaps and while migrating to scala i ran into 2 big issues scala has no mutabletreemap i decided to go around it by using mutabletreeset oddly scala has mutabletreeset but no mutabletreemap for storing the keys and storing the values in an auxiliary mutablemap', 'this is an unpleasant hack but is there any better way', 'next problem is scalas mutabletreeset has no equivalent of javautiltreesets ceilingkey floorentry pollfirst polllast which are all olog n operations in java', 'so how can i best migrate my code to scala', 'what are the best practices in these situations', 'i really do not want to write my own tree implementations', 'is there a more idiomatic scala way of writing intervalmaps that i am not aware of', 'or is there some reputable library out there', 'or does scala just plain suck here with its gimped treeset and nonexistent treemaps', 'ofcourse i can just use javas treemap in scala but that is ugly and i lose all the nice scala collection features and i might as well use java then', 'here is my current java code']"
Avoiding false positives with clang's ThreadSanitizer and TBB,"Has anyone tried clang's ThreadSanitizer with Intel Threading Building Blocks (TBB)?
My experience so far was that you will get a lot of warnings, even for relatively simple examples. Unfortunately, many of them seem to be false positives.
In this answer to another ThreadSanitizer question, suppression files are recommended. Could that help? Is there a suppression file for TBB or any other technique?
(Side note: With Helgrind, it looks similar. Many false positives.)
",<c++><clang><race-condition><tbb><thread-sanitizer>,13,"c++,clang,race-condition,tbb,thread-sanitizer",['avoiding false positives with clangs threadsanitizer and tbb'],"['has anyone tried clangs threadsanitizer with intel threading building blocks tbb', 'my experience so far was that you will get a lot of warnings even for relatively simple examples', 'unfortunately many of them seem to be false positives', 'in this answer to another threadsanitizer question suppression files are recommended', 'could that help', 'is there a suppression file for tbb or any other technique', 'side note with helgrind it looks similar', 'many false positives']"
Different results when R script is automated,"The following command executes ghostscript on a pdf file. (the pdf_file variable contains the path to that pdf) 
bbox <- system(paste( ""C:/gs/gs8.64/bin/gswin32c.exe -sDEVICE=bbox -dNOPAUSE -dBATCH -f"", pdf_file, ""2>&1"" ), intern=TRUE)

After execution bbox includes the following character string.
GPL Ghostscript 8.64 (2009-02-03)
Copyright (C) 2009 Artifex Software, Inc.  All rights reserved.
This software comes with NO WARRANTY: see the file PUBLIC for details.
Processing pages 1 through 1.
Page 1
%%BoundingBox: 36 2544 248 2825
%%HiResBoundingBox: 36.395015 2544.659922 247.070032 2824.685914
Error: /undefinedfilename in (2>&1)
Operand stack:

Execution stack:
   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push
Dictionary stack:
   --dict:1147/1684(ro)(G)--   --dict:1/20(G)--   --dict:69/200(L)--
Current allocation mode is local
Last OS error: No such file or directory
GPL Ghostscript 8.64: Unrecoverable error, exit code 1

This string is then manipulated in order for the BoundingBox dimensions (36 2544 248 2825) to be isolated and used for cropping the pdf file. So far everything works ok.
However, when I schedule this script in Task Manager (using Rscript.exe or Rcmd.exe BATCH), or when the script is inside an R chunk and I press knit HTML, bbox gets the following character string which lacks the BoundingBox information, and makes it unusable: 
GPL Ghostscript 8.64 (2009-02-03)
Copyright (C) 2009 Artifex Software, Inc.  All rights reserved.
This software comes with NO WARRANTY: see the file PUBLIC for details.
Processing pages 1 through 1.
Page 1
Error: /undefinedfilename in (2>&1)
Operand stack:

Execution stack:
   %interp_exit   .runexec2   --nostringval--   --nostringval--   --nostringval--   2   %stopped_push   --nostringval--   --nostringval--   --nostringval--   false   1   %stopped_push
Dictionary stack:
   --dict:1147/1684(ro)(G)--   --dict:1/20(G)--   --dict:69/200(L)--
Current allocation mode is local
Last OS error: No such file or directory

How can I get over this problem and have the script run automated?
(The script comes from the accepted answer to that question)
",<windows><r><redirect><automation><ghostscript>,7,"windows,r,redirect,automation,ghostscript",['different results when r script is automated'],"['the following command executes ghostscript on a pdf file', 'the pdffile variable contains the path to that pdf bbox systempaste cgsgs864bingswin32cexe sdevicebbox dnopause dbatch f pdffile 21 interntrue after execution bbox includes the following character string', 'gpl ghostscript 864 20090203 copyright c 2009 artifex software inc all rights reserved', 'this software comes with no warranty see the file public for details', 'processing pages 1 through 1 page 1 boundingbox 36 2544 248 2825 hiresboundingbox 36395015 2544659922 247070032 2824685914 error undefinedfilename in 21 operand stack execution stack interpexit runexec2 nostringval nostringval nostringval 2 stoppedpush nostringval nostringval nostringval false 1 stoppedpush dictionary stack dict11471684rog dict120g dict69200l current allocation mode is local last os error no such file or directory gpl ghostscript 864 unrecoverable error exit code 1 this string is then manipulated in order for the boundingbox dimensions 36 2544 248 2825 to be isolated and used for cropping the pdf file', 'so far everything works ok however when i schedule this script in task manager using rscriptexe or rcmdexe batch or when the script is inside an r chunk and i press knit html bbox gets the following character string which lacks the boundingbox information and makes it unusable gpl ghostscript 864 20090203 copyright c 2009 artifex software inc all rights reserved', 'this software comes with no warranty see the file public for details', 'processing pages 1 through 1 page 1 error undefinedfilename in 21 operand stack execution stack interpexit runexec2 nostringval nostringval nostringval 2 stoppedpush nostringval nostringval nostringval false 1 stoppedpush dictionary stack dict11471684rog dict120g dict69200l current allocation mode is local last os error no such file or directory how can i get over this problem and have the script run automated', 'the script comes from the accepted answer to that question']"
How to plot time series in python,"I have been trying to plot a time series graph from a CSV file. I have managed to read the file and converted the data from string to date using strptime and stored in a list. When I tried plotting a test plot in matplotlib with the list containing the date information it plotted the date as a series of dots; that is, for a date 2012-may-31 19:00, I got a plot with a dot at 2012, 05, 19, 31, 00 on y-axis for the value of x=1 and so on. I understand that this is not the correct way of passing date information for plotting. Can someone tell me how to pass this information correctly.
",<python><matplotlib><datetime><plot><time-series>,70,"python,matplotlib,datetime,plot,time-series",['how to plot time series in python'],"['i have been trying to plot a time series graph from a csv file', 'i have managed to read the file and converted the data from string to date using strptime and stored in a list', 'when i tried plotting a test plot in matplotlib with the list containing the date information it plotted the date as a series of dots that is for a date 2012may31 1900 i got a plot with a dot at 2012 05 19 31 00 on yaxis for the value of x1 and so on', 'i understand that this is not the correct way of passing date information for plotting', 'can someone tell me how to pass this information correctly']"
Compiling NASM on Mac OSX,"Writing a compiler in school, last milestone is generating assembly code. Trying to learn NASM. Starting at the beginning, http://www.cs.lmu.edu/~ray/notes/nasmexamples/, trying to compile a Hello World.
; ----------------------------------------------------------------------------
; helloworld.asm
;
; This is a Win32 console program that writes ""Hello, World"" on one line and
; then exits.  It needs to be linked with a C library.
; ----------------------------------------------------------------------------

    global  _main
    extern  _printf

    section .text
_main:
    push    message
    call    _printf
    add     esp, 4
    ret
message:
    db      'Hello, World', 10, 0

To assemble, link and run this program under Windows:
nasm -fwin32 helloworld.asm
gcc helloworld.obj
a

Under Linux, you'll need to remove the leading underscores from function names, and execute
nasm -felf helloworld.asm
gcc helloworld.o
./a.out

But I'm on OSX. Found this little resource: http://salahuddin66.blogspot.com/2009/08/nasm-in-mac-os-x.html. In Mac OS X we should use format macho...
nasm -f macho -o hello.o hello.asm

...and for the linker (we need to specify the entry point)...
ld -e main -o hello hello.o

But when I do this...
Undefined symbols:
    ""printf"", referenced from:
        _main in hello.o
ld: symbol(s) not found for inferred architecture i386

Sorry, I know it's a lot to read. And I doubt there are many NASM coders around these parts, but worth a try right? I'd appreciate any help I can get.
",<macos><gcc><compiler-construction><linker><nasm>,5,"macos,gcc,compiler-construction,linker,nasm",['compiling nasm on mac osx'],"['writing a compiler in school last milestone is generating assembly code', 'trying to learn nasm', 'starting at the beginning trying to compile a hello world', ' helloworldasm this is a win32 console program that writes hello world on one line and then exits', 'it needs to be linked with a c library', ' global main extern printf section text main push message call printf add esp 4 ret message db hello world 10 0 to assemble link and run this program under windows nasm fwin32 helloworldasm gcc helloworldobj a under linux youll need to remove the leading underscores from function names and execute nasm felf helloworldasm gcc helloworldo aout but im on osx', 'found this little resource in mac os x we should use format macho nasm f macho o helloo helloasm and for the linker we need to specify the entry point ld e main o hello helloo but when i do this undefined symbols printf referenced from main in helloo ld symbols not found for inferred architecture i386 sorry i know its a lot to read', 'and i doubt there are many nasm coders around these parts but worth a try right', 'id appreciate any help i can get']"
Dagger Hilt: Scope dependencies for parent-/child-fragments,"I am trying to find a solution in how to define Hilt in a certain fragment related scenario. I have the following setup:

Activity

Parent Fragment 1

Child Fragment 1
Child Fragment 2
...
Child Fragment n-1


Parent Fragment 2

Child Fragment 1
Child Fragment 2
...
Child Fragment n-1





Parent Fragment 1 is using the dependency A. The instance of that dependency is something I want to share only between that parent fragment and all of its child fragments. The parent fragment 2 + its child fragments should use a different instance than the parent fragment 1 + children. Generally his structure should have only two instances of any given dependency - one for the first flow and one for the second.
I can see that a custom scope might work here but I am uncertain about how to use that in regards to Hilt.
",<android><android-fragments><dagger-2><dagger><dagger-hilt>,7,"android,android-fragments,dagger-2,dagger,dagger-hilt",['dagger hilt scope dependencies for parentchildfragments'],"['i am trying to find a solution in how to define hilt in a certain fragment related scenario', 'i have the following setup activity parent fragment 1 child fragment 1 child fragment 2 child fragment n1 parent fragment 2 child fragment 1 child fragment 2 child fragment n1 parent fragment 1 is using the dependency a the instance of that dependency is something i want to share only between that parent fragment and all of its child fragments', 'the parent fragment 2 its child fragments should use a different instance than the parent fragment 1 children', 'generally his structure should have only two instances of any given dependency one for the first flow and one for the second', 'i can see that a custom scope might work here but i am uncertain about how to use that in regards to hilt']"
"How can I send ""audience"" field in oauth2/token call made by Swagger-ui?","I am using Swagger-UI with Swashbuckle v5.6 to document an Auth0 (OAuth2) secured .NET Web API. 
I've been trying to configure Swagger to obtain a token in the UI from Auth0 service. So far I've managed to do that, but the problem is that I need to send in the POST /token request's body the ""audience"" field, and I am struggling to find out how to do that from SwaggerConfig.cs.
So far my SwaggerConfig.cs looks like this : 
public class SwaggerConfig
{
    public static void Register()
    {
        var thisAssembly = typeof(SwaggerConfig).Assembly;
        string appName = ""myApi"";
        var audience = System.Configuration.ConfigurationManager.AppSettings[""AuthAudience""];
        string tokenUrl = ""somethingsomething/oauth/token"";

        GlobalConfiguration.Configuration
            .EnableSwagger(c =>
                {
                    c.SingleApiVersion(""v1"", ""myApi"");
                    c.IncludeXmlComments(string.Format(@""{0}\bin\myApi.XML"", System.AppDomain.CurrentDomain.BaseDirectory));
                    c.DescribeAllEnumsAsStrings();

                    c.OAuth2(""oauth2"")
                        .Description(""client credentials grant flow"")
                        .Flow(""password"")
                        .TokenUrl(tokenUrl)
                        .Scopes(scopes =>
                        {
                            scopes.Add(""myapi"", ""openid profile email address phone"");
                        });

                    c.OperationFilter<AssignOperationFilters>();
                    c.DocumentFilter<SecurityRequirementsDocumentFilter>();
                })
            .EnableSwaggerUi(c =>
            {
                var clientId =  System.Configuration.ConfigurationManager.AppSettings[""Auth0ApiClientId""];
                var clientSecret = System.Configuration.ConfigurationManager.AppSettings[""Auth0ApiClientSecret""];

                var additionalParams = new Dictionary<string, string>{ {""audience"", audience } };

                c.EnableOAuth2Support(clientId,
                                    clientSecret,
                                    appName,
                                    ""tmdq"",
                                    additionalQueryStringParams: additionalParams);

            });
    }
}

",<c#><oauth-2.0><swagger><swagger-ui><swagger-2.0>,6,"c#,oauth-2.0,swagger,swagger-ui,swagger-2.0",['how can i send audience field in oauth2token call made by swaggerui'],"['i am using swaggerui with swashbuckle v56 to document an auth0 oauth2 secured net web api', 'ive been trying to configure swagger to obtain a token in the ui from auth0 service', 'so far ive managed to do that but the problem is that i need to send in the post token requests body the audience field and i am struggling to find out how to do that from swaggerconfigcs', 'so far my swaggerconfigcs looks like this public class swaggerconfig public static void register var thisassembly typeofswaggerconfigassembly string appname myapi var audience systemconfigurationconfigurationmanagerappsettingsauthaudience string tokenurl somethingsomethingoauthtoken globalconfigurationconfiguration enableswaggerc csingleapiversionv1 myapi cincludexmlcommentsstringformat0binmyapixml systemappdomaincurrentdomainbasedirectory cdescribeallenumsasstrings coauth2oauth2 descriptionclient credentials grant flow flowpassword tokenurltokenurl scopesscopes scopesaddmyapi openid profile email address phone coperationfilterassignoperationfilters cdocumentfiltersecurityrequirementsdocumentfilter enableswaggeruic var clientid systemconfigurationconfigurationmanagerappsettingsauth0apiclientid var clientsecret systemconfigurationconfigurationmanagerappsettingsauth0apiclientsecret var additionalparams new dictionarystring string audience audience cenableoauth2supportclientid clientsecret appname tmdq additionalquerystringparams additionalparams ']"
Why can't I get the argument count of a template function at compile-time?,"#include <cstddef>

template<typename... Types>
constexpr std::size_t getArgCount(Types&&...) noexcept
{
    return sizeof...(Types);
}

struct A
{
    int n;

    void f()
    {
        static_assert(getArgCount(n) > 0); // not ok, why?
    }
};

int main()
{
    int n;
    static_assert(getArgCount(n) > 0); // ok
}

Why can't I get the argument count of a template function at compile-time?
error message:
1>test.cpp
1>test.cpp(17,45): error C2131:  expression did not evaluate to a constant
1>test.cpp(17,42): message :  failure was caused by a read of a variable outside its lifetime
1>test.cpp(17,42): message :  see usage of 'this'

",<c++><c++11><language-lawyer><constexpr><static-assert>,12,"c++,c++11,language-lawyer,constexpr,static-assert",['why cant i get the argument count of a template function at compiletime'],"['include cstddef templatetypename types constexpr stdsizet getargcounttypes noexcept return sizeoftypes struct a int n void f staticassertgetargcountn 0 not ok why ', ' int main int n staticassertgetargcountn 0 ok why cant i get the argument count of a template function at compiletime', 'error message 1testcpp 1testcpp1745 error c2131 expression did not evaluate to a constant 1testcpp1742 message failure was caused by a read of a variable outside its lifetime 1testcpp1742 message see usage of this']"
How do I organise throwing business-logic exceptions in NestJs services?,"I have a few doubts regarding this github issue discussion: https://github.com/nestjs/nest/issues/310
I want to throw business-domain exceptions from my service's methods as shekohex suggested. I wonder where exactly should I keep them? I believe many of them will be quite similiar across domains (like EntityNotFoundException, ActionForbiddenException etc.) so it would make sense to keep them on the application level (some kind of shared module). On the other hand that makes particular domain less independent (for example, what if I need to extract few of them into another application some time in the future?). What is more, some of the exceptions can be domain-specific and I'd have to keep them inside appropriate domain module's structure.
Let's assume I do keep some of them in the shared module and the rest in the individual domain catalogues. How do I map them to the proper HttpExceptions? If I make global exception filter I also make my domain controllers even more dependent on the application-layer. How do I map domain-specific exceptions? Do I create another module-level exception filter?
Is creating global- or module-level filters a way to go? Decorating every endpoint with UseFilters seems pretty cumbersome.
Thanks in advance for your input!
",<javascript><node.js><typescript><architecture><nestjs>,10,"javascript,node.js,typescript,architecture,nestjs",['how do i organise throwing businesslogic exceptions in nestjs services'],"['i have a few doubts regarding this github issue discussion i want to throw businessdomain exceptions from my services methods as shekohex suggested', 'i wonder where exactly should i keep them', 'i believe many of them will be quite similiar across domains like entitynotfoundexception actionforbiddenexception etc', 'so it would make sense to keep them on the application level some kind of shared module', 'on the other hand that makes particular domain less independent for example what if i need to extract few of them into another application some time in the future', 'what is more some of the exceptions can be domainspecific and id have to keep them inside appropriate domain modules structure', 'lets assume i do keep some of them in the shared module and the rest in the individual domain catalogues', 'how do i map them to the proper httpexceptions', 'if i make global exception filter i also make my domain controllers even more dependent on the applicationlayer', 'how do i map domainspecific exceptions', 'do i create another modulelevel exception filter', 'is creating global or modulelevel filters a way to go', 'decorating every endpoint with usefilters seems pretty cumbersome', 'thanks in advance for your input']"
"Scaling solutions for MySQL (Replication, Clustering)","At the startup I'm working at we are now considering scaling solutions for our database. Things get somewhat confusing (for me at least) with MySQL, which has the MySQL cluster, replication and MySQL cluster replication (from ver. 5.1.6), which is an asynchronous version of the MySQL cluster. The MySQL manual explains some of the differences in its cluster FAQ, but it is hard to ascertain from it when to use one or the other.
I would appreciate any advice from people who are familiar with the differences between those solutions and what are the pros and cons, and when do you recommend to use each.
",<mysql><replication><scaling><cluster-computing><database-cluster>,86,"mysql,replication,scaling,cluster-computing,database-cluster",['scaling solutions for mysql replication clustering'],"['at the startup im working at we are now considering scaling solutions for our database', 'things get somewhat confusing for me at least with mysql which has the mysql cluster replication and mysql cluster replication from ver', '516 which is an asynchronous version of the mysql cluster', 'the mysql manual explains some of the differences in its cluster faq but it is hard to ascertain from it when to use one or the other', 'i would appreciate any advice from people who are familiar with the differences between those solutions and what are the pros and cons and when do you recommend to use each']"
How can i configure gmail in Android emulator?,"I want to send email from emulator. How can i configure the emulator ?
",<android><email><configuration><gmail><emulation>,11,"android,email,configuration,gmail,emulation",['how can i configure gmail in android emulator'],"['i want to send email from emulator', 'how can i configure the emulator ']"
What is the recommended toolchain for formatting XML DocBook?,"I've seen Best tools for working with DocBook XML documents, but my question is slightly different.  Which is the currently recommended formatting toolchain - as opposed to editing tool - for XML DocBook?
In Eric Raymond's 'The Art of Unix Programming' from 2003 (an excellent book!), the suggestion is XML-FO (XML Formatting Objects), but I've since seen suggestions here that indicated that XML-FO is no longer under development (though I can no longer find that question on StackOverflow, so maybe it was erroneous).
Assume I'm primarily interested in Unix/Linux (including MacOS X), but I wouldn't automatically ignore Windows-only solutions.
Is Apache's FOP the best way to go?  Are there any alternatives?
",<xml><apache><pdf><apache-fop><docbook>,24,"xml,apache,pdf,apache-fop,docbook",['what is the recommended toolchain for formatting xml docbook'],"['ive seen best tools for working with docbook xml documents but my question is slightly different', 'which is the currently recommended formatting toolchain as opposed to editing tool for xml docbook', 'in eric raymonds the art of unix programming from 2003 an excellent book', ' the suggestion is xmlfo xml formatting objects but ive since seen suggestions here that indicated that xmlfo is no longer under development though i can no longer find that question on stackoverflow so maybe it was erroneous', 'assume im primarily interested in unixlinux including macos x but i wouldnt automatically ignore windowsonly solutions', 'is apaches fop the best way to go', 'are there any alternatives']"
Android: Extending user's contact book. Performance ContentProvider vs Sqlite vs List in memory,"Me and my Android team have a problem. We have an app that present the user's contact book, with extended information.
Current setup
Our app reads the Contacts Provider of the Android OS. Sends this information to our Server that calculates a couple of necessary fields for us. This information is later fetched by our app and we save this information in an SQLite database. What we end up with in our database is two tables. One with all Numbers and all the extra information that the server calculated for us. The other table is one with all Contacts (one contact can have multiple numbers). This Contacts table was created only for performance; we can have a Cursor selecting all rows in this Contacts table in our CursorAdapter when presenting the contact book for the user.
Hence, when presenting the contact book to the user, we only need to read from our own SQLite database and only one table (e.g. no JOINs). 
The main problem
There is a lot of syncing going on. Since, data is duplicated, we need to check for adds/changes/removes and need to sync all the f-ing time. Moreover, when we now are about to change a particular thing in our presentation layer, we need to change our Contacts table to include this particular information.
Priority for us
1st: Performance when presenting the contact book to the user. 
2nd: Code maintainability.
Hence, do not comment ""Do not duplicate data--it's the root of all problems"". It is more important to us that the user does not have performance issues than if we as developers have to spend some extra time writing good synchronization algorithms.
Solutions?
I don't know why, but I've always thought that a CursorAdapter (reading all rows from one table) is performing much better than an ArrayAdapter with a List of objects (held in memory). Anyone know if this is true? Because one solution which will help us at least half the way is to, on start up, join the Contacts Provider (native contact book) and our extended information, save this in a List in memory and present this with an ArrayAdapter. 
Creating your own Content Providers? I know little about creating your own content provider. Anyone tried to create a content provider that extend the information of the native contact book and join these. Maybe with the implementation of this interface: ContactsContract.DataColumnsWithJoins? Anyone tried anything similar? How's the performance when presenting this information in a CursorAdapter?
Please ask for any more information I might have forgot and I will update the question!
Thanks a lot in advance for all helpful tips and solutions!
",<android><performance><sqlite><android-contentprovider><android-cursoradapter>,13,"android,performance,sqlite,android-contentprovider,android-cursoradapter","['android extending users contact book', 'performance contentprovider vs sqlite vs list in memory']","['me and my android team have a problem', 'we have an app that present the users contact book with extended information', 'current setup our app reads the contacts provider of the android os', 'sends this information to our server that calculates a couple of necessary fields for us', 'this information is later fetched by our app and we save this information in an sqlite database', 'what we end up with in our database is two tables', 'one with all numbers and all the extra information that the server calculated for us', 'the other table is one with all contacts one contact can have multiple numbers', 'this contacts table was created only for performance we can have a cursor selecting all rows in this contacts table in our cursoradapter when presenting the contact book for the user', 'hence when presenting the contact book to the user we only need to read from our own sqlite database and only one table eg', 'no joins', 'the main problem there is a lot of syncing going on', 'since data is duplicated we need to check for addschangesremoves and need to sync all the fing time', 'moreover when we now are about to change a particular thing in our presentation layer we need to change our contacts table to include this particular information', 'priority for us 1st performance when presenting the contact book to the user', '2nd code maintainability', 'hence do not comment do not duplicate dataits the root of all problems', 'it is more important to us that the user does not have performance issues than if we as developers have to spend some extra time writing good synchronization algorithms', 'solution', 'i dont know why but ive always thought that a cursoradapter reading all rows from one table is performing much better than an arrayadapter with a list of objects held in memory', 'anyone know if this is true', 'because one solution which will help us at least half the way is to on start up join the contacts provider native contact book and our extended information save this in a list in memory and present this with an arrayadapter', 'creating your own content providers', 'i know little about creating your own content provider', 'anyone tried to create a content provider that extend the information of the native contact book and join these', 'maybe with the implementation of this interface contactscontractdatacolumnswithjoins', 'anyone tried anything similar', 'hows the performance when presenting this information in a cursoradapter', 'please ask for any more information i might have forgot and i will update the question', 'thanks a lot in advance for all helpful tips and solutions']"
Translating WP with __() and sprintf(),"I'm trying to translate WP theme. I have this code:
$translation = __( get_color(), 'textdomain' );

It works, I get color dynamically from get_color() function, and it translates well. But when I use ""Theme Check"" plugin I get error for this code.
I need to use this instead:
$translation = sprintf( __( '%s', 'textdomain' ), get_color() );

But in that case my placeholder %s doesn't translates, and I get original color name (not translated).
What I'm doing wrong? Thank you.
",<php><wordpress><internationalization><gettext><translate>,5,"php,wordpress,internationalization,gettext,translate",['translating wp with and sprintf'],"['im trying to translate wp theme', 'i have this code translation getcolor textdomain it works i get color dynamically from getcolor function and it translates well', 'but when i use theme check plugin i get error for this code', 'i need to use this instead translation sprintf s textdomain getcolor but in that case my placeholder s doesnt translates and i get original color name not translated', 'what im doing wrong', 'thank you']"
Looking for a .NET BuildServer SaaS,"I've a question regarding Build Servers for .NET Projects. Currently I'm using TeamBuild in conjunction w/ TFS 2010 to do automated builds in the .NET world. Some older projects are built using plain old MSBuild scripts.
To get rid of the administrative effort I'm currently moving my sources to github. Github offers, as many other sites service hooks to trigger build servers for doing automated builds such as CI or nightly builds.
Sure I could use TeamCity OnPremise and dynamically create Build Agents in Windows Azure using VMRole and Virtual Disks, but I think this hybrid solution is a little bit moronic. 
So what are your thoughts about the following architectural idea?
Let's say you're using github as source control platform. When commiting sources to your repository an Azure WebRole hosting a WCF Service will be triggered. 
The WebRole itself will just use the Azure API to fire up a new instance of a custom Azure VMRole. 
The Azure VMRole itself will use some kind of buildscript such as Rake or MSBuild to have as few developer tools installed on the build agent as needed. After building the entire project the artifacts will be published to Azure BlobStorage and the WebRole hosting the WCF service will be called again, but right now the Azure WebRole is going to terminate the BuildAgent. 
While using such a setup you could minimize the costs for the build agent and build nearly any kind of project as far as you're able to install the required element for the build by using PowerShell.
So in bottom line: what are your thoughts on this architecture? Other Ideas? Is there an existing service offering such a solution?
Thorsten
",<build><azure><continuous-integration><saas><azure-vm-role>,10,"build,azure,continuous-integration,saas,azure-vm-role",['looking for a net buildserver saas'],"['ive a question regarding build servers for net projects', 'currently im using teambuild in conjunction w tfs 2010 to do automated builds in the net world', 'some older projects are built using plain old msbuild scripts', 'to get rid of the administrative effort im currently moving my sources to github', 'github offers as many other sites service hooks to trigger build servers for doing automated builds such as ci or nightly builds', 'sure i could use teamcity onpremise and dynamically create build agents in windows azure using vmrole and virtual disks but i think this hybrid solution is a little bit moronic', 'so what are your thoughts about the following architectural idea', 'lets say youre using github as source control platform', 'when commiting sources to your repository an azure webrole hosting a wcf service will be triggered', 'the webrole itself will just use the azure api to fire up a new instance of a custom azure vmrole', 'the azure vmrole itself will use some kind of buildscript such as rake or msbuild to have as few developer tools installed on the build agent as needed', 'after building the entire project the artifacts will be published to azure blobstorage and the webrole hosting the wcf service will be called again but right now the azure webrole is going to terminate the buildagent', 'while using such a setup you could minimize the costs for the build agent and build nearly any kind of project as far as youre able to install the required element for the build by using powershell', 'so in bottom line what are your thoughts on this architecture', 'other ideas', 'is there an existing service offering such a solution', 'thorsten']"
How do I use properly CASE..WHEN in MySQL,"Here is a demo query, notice it is very simple, Fetches only where base_price is 0,
And still, it chooses the condition 3:
SELECT
   CASE course_enrollment_settings.base_price
    WHEN course_enrollment_settings.base_price = 0      THEN 1
    WHEN course_enrollment_settings.base_price<101      THEN 2
    WHEN course_enrollment_settings.base_price>100 AND   
                      course_enrollment_settings.base_price<201 THEN 3
        ELSE 6
   END AS 'calc_base_price',
   course_enrollment_settings.base_price
FROM
    course_enrollment_settings
WHERE course_enrollment_settings.base_price = 0

base_price is decimal(8,0)
When run this on my DB, I get:

3 0
  3 0
  3 0
  3 0
  3 0

",<mysql><sql><conditional-statements><switch-statement><case>,84,"mysql,sql,conditional-statements,switch-statement,case",['how do i use properly casewhen in mysql'],['here is a demo query notice it is very simple fetches only where baseprice is 0 and still it chooses the condition 3 select case courseenrollmentsettingsbaseprice when courseenrollmentsettingsbaseprice 0 then 1 when courseenrollmentsettingsbaseprice101 then 2 when courseenrollmentsettingsbaseprice100 and courseenrollmentsettingsbaseprice201 then 3 else 6 end as calcbaseprice courseenrollmentsettingsbaseprice from courseenrollmentsettings where courseenrollmentsettingsbaseprice 0 baseprice is decimal80 when run this on my db i get 3 0 3 0 3 0 3 0 3 0']
How to get attribute value for an assembly in Cecil,"Is there a way to get str1 in code ?
[MyAttribute(""str1"")]
class X {}

The instance of Mono.Cecil.CustomAttribute.Fields is empty.
",<c#><.net><mono><metadata><mono.cecil>,13,"c#,.net,mono,metadata,mono.cecil",['how to get attribute value for an assembly in cecil'],"['is there a way to get str1 in code ', 'myattributestr1 class x the instance of monocecilcustomattributefields is empty']"
Run Junit test class inside one-jar with junit outside the jar,"So I have packed my classes and their dependancies (apache commons cli) inside a jar file using one-jar (which was easy enough to do, see section Command-Line Approach). Now I am curious if I can run the java test class inside the jar using a Junit jar outside the class. So the path to the test class inside sw.jar is :
sw.jar\main\sw.jar\uoa\di\ys11\hw2\TestSmithWaterman.class

(the main\ is a one-jar thing). I have tried variations of :
java -jar -cp lib/junit.jar org.junit.runner.JUnitCore  uoa.di.ys11.hw2.TestSmithWaterman

with no luck - so what would the command line be ? Or do I need to modify the one-jar manifest somehow ?
EDIT : the /boot-manifest.mf:
Manifest-Version: 1.0
Main-Class: com.simontuffs.onejar.Boot
One-Jar-Main-Class: uoa.di.ys11.hw2.Hw2

while the /META-INF/MANIFEST.MF:
Manifest-Version: 1.0
Created-By: 1.7.0_09 (Oracle Corporation)
Main-Class: com.simontuffs.onejar.Boot
One-Jar-Main-Class: uoa.di.ys11.hw2.Hw2

",<java><command-line><jar><junit><executable-jar>,9,"java,command-line,jar,junit,executable-jar",['run junit test class inside onejar with junit outside the jar'],"['so i have packed my classes and their dependancies apache commons cli inside a jar file using onejar which was easy enough to do see section commandline approach', 'now i am curious if i can run the java test class inside the jar using a junit jar outside the class', 'so the path to the test class inside swjar is swjarmainswjaruoadiys11hw2testsmithwatermanclass the main is a onejar thing', 'i have tried variations of java jar cp libjunitjar orgjunitrunnerjunitcore uoadiys11hw2testsmithwaterman with no luck so what would the command line be ', 'or do i need to modify the onejar manifest somehow ', 'edit the bootmanifestmf manifestversion 10 mainclass comsimontuffsonejarboot onejarmainclass uoadiys11hw2hw2 while the metainfmanifestmf manifestversion 10 createdby 17009 oracle corporation mainclass comsimontuffsonejarboot onejarmainclass uoadiys11hw2hw2']"
Only show command in context menu on specific filename (+extension),"So basically I only want to display the Command when I right click on a file named ""example.cs"". Since I am using Visual Studio 2019 I can't go with the old BeforeQueryStatus way. Instead using the ProvideUIContextRule Attribute on my Package class. Which currently looks something like this:
    [ProvideUIContextRule(_uiContextSupportedFiles,
    name: ""Supported Files"",
    expression: ""CSharp"",
    termNames: new[] { ""CSharp"" },
    termValues: new[] { ""HierSingleSelectionName:.cs$"" })]

Which totally looks fine for the extension of the file itself. So is there any way to restrict it to example.cs?
By the way I am using this Guide.
",<visual-studio><contextmenu><visual-studio-extensions><vsix><visual-studio-2019>,5,"visual-studio,contextmenu,visual-studio-extensions,vsix,visual-studio-2019",['only show command in context menu on specific filename extension'],"['so basically i only want to display the command when i right click on a file named examplecs', 'since i am using visual studio 2019 i cant go with the old beforequerystatus way', 'instead using the provideuicontextrule attribute on my package class', 'which currently looks something like this provideuicontextruleuicontextsupportedfiles name supported files expression csharp termnames new csharp termvalues new hiersingleselectionnamecs which totally looks fine for the extension of the file itself', 'so is there any way to restrict it to examplecs', 'by the way i am using this guide']"
Iterate between each input to validate value,"I have this code which validate the input's value if empty and shows the message error with a twitter bootstrap popover:
$(document).on(""ready"", login_events());

function login_events(){

    $(""#userId, #password"").on(""change"", validateEmpty);
    $(""#loginButton"").on(""click"", validateAll);

}

function validateEmpty(){

    input = $(this);
    input.popover({animation: true, placement: 'right', trigger: 'manual', title: 'Field is Empty', content: input.attr(""data-empty-message"")});
    isValid = true;

    if(input.val() === """"){
        input.popover('show');
        isValid =  false;
    }
    else{
        input.popover('hide');
    }

    return isValid;

}

This works perfectly when the change event is done but I want to do another function which will iterate between each input in the form, validate if it's empty (validateEmpty()) and preventDefault if any are empty.
As you can see I have the click event setup for the #loginButton to run the validateAll function which I have something like this but cannot figure out a right way to do it:
function validateAll(event){

    $(""#loginForm input"").each(validateEmpty);

}

",<jquery><forms><validation><each><preventdefault>,5,"jquery,forms,validation,each,preventdefault",['iterate between each input to validate value'],"['i have this code which validate the inputs value if empty and shows the message error with a twitter bootstrap popover documentonready loginevents function loginevents userid passwordonchange validateempty loginbuttononclick validateall function validateempty input this inputpopoveranimation true placement right trigger manual title field is empty content inputattrdataemptymessage isvalid true ifinputval inputpopovershow isvalid false else inputpopoverhide return isvalid this works perfectly when the change event is done but i want to do another function which will iterate between each input in the form validate if its empty validateempty and preventdefault if any are empty', 'as you can see i have the click event setup for the loginbutton to run the validateall function which i have something like this but cannot figure out a right way to do it function validateallevent loginform inputeachvalidateempty ']"
javascript scroll effect is not working in angularjs controller,"HTML :
<div class=""scroller-size"">
    <div class=""scroller scroller-left"" style=""padding-top: 25px;""><i class=""glyphicon glyphicon-chevron-left""></i></div>
    <div class=""scroller scroller-right"" style=""padding-top: 25px;""><i class=""glyphicon glyphicon-chevron-right""></i></div>
    <div class=""wrapper"" style=""height:73px;"">
        <ul class=""nav nav-tabs list"" id=""myTab"">
                <li ng-repeat=""pf in printlist""><img style=""image-rendering: -webkit-optimize-contrast; image-rendering: optimizeQuality;"" class=""img-responsive pull-right"" ng-src=""{{pf.imagePath}}"" ng-click=""pf.selectFile = !pf.selectFile ;showCustom($event,pf)""></li>
        </ul>
    </div>
</div>

Javascript:
var hidWidth;
var scrollBarWidths = 20;

var widthOfList = function () {
    var itemsWidth = 0;
    $('.list li').each(function () {
        var itemWidth = $(this).outerWidth();
        itemsWidth += itemWidth;
    });
    return itemsWidth;
};

var widthOfHidden = function () {
    return (($('.wrapper').outerWidth()) - widthOfList() - getLeftPosi()) - scrollBarWidths;
};

var getLeftPosi = function () {
    return $('.list').position().left;
};

var reAdjust = function () {
    if (($('.wrapper').outerWidth()) < widthOfList()) {
        $('.scroller-right').show();
    } else {
        $('.scroller-right').hide();
    }

    if (getLeftPosi() < 0) {
        $('.scroller-left').show();
    } else {
        $('.item').animate({left: ""-="" + getLeftPosi() + ""px""}, 'slow');
        $('.scroller-left').hide();
    }
}

reAdjust();

$(window).on('resize', function (e) {
    reAdjust();
});

$(window).on('load', function (e) {
    reAdjust();
});

$('.scroller-right').click(function () {

    $('.scroller-left').fadeIn('slow');
    $('.scroller-right').fadeOut('slow');

    $('.list').animate({left: ""+="" + widthOfHidden() + ""px""}, 'slow', function () {

    });
});

$('.scroller-left').click(function () {

    $('.scroller-right').fadeIn('slow');
    $('.scroller-left').fadeOut('slow');

    $('.list').animate({left: ""-="" + getLeftPosi() + ""px""}, 'slow', function () {

    });
});

CSS:
.wrapper {
  width: 100%;
  white-space: nowrap;
  overflow-y: hidden;
  overflow-x: scroll;
  -webkit-overflow-scrolling: touch;
  padding: 1rem;
  background-color: white;
  // Toggle this depending upon whether you want to see the scrollbar
  &::-webkit-scrollbar {
    display: none;
  }
}

.internal {
  display: inline;
}
.list {
  position:absolute;
  left:0px;
  top:0px;
  min-width:3000px;
  margin-left:12px;
  margin-top:0px;
}
.list li{
  display:table-cell;
  position:relative;
  text-align:center;
  cursor:grab;
  cursor:-webkit-grab;
  color:#efefef;
  vertical-align:middle;
}
.scroller {
  text-align:center;
  cursor:pointer;
  display:none;
  padding:7px;
  padding-top:11px;
  white-space: no-wrap;
  vertical-align:middle;
  background-color:#fff;
}
.scroller-right{
  float:right;
}
.scroller-left {
  float:left;
}
.scroller-size {
  height: auto;
  margin-top: 1%;
}
.nav-tabs {
  border-bottom: 0px solid transparent !important;
}

I used this code in angularjs controller it's working fine. but i need when i click the left or right arrow it showing start and end files my intention is it must show the file depends on the screen for example like for 5s 3 files ,for 6s 4 files.I tried to change the JavaScript stucking badly to fix the scroll issue.anyone can help me to fix this issue

",<javascript><jquery><html><css><angularjs>,5,"javascript,jquery,html,css,angularjs",['javascript scroll effect is not working in angularjs controller'],"['html div classscrollersize div classscroller scrollerleft stylepaddingtop 25pxi classglyphicon glyphiconchevronleftidiv div classscroller scrollerright stylepaddingtop 25pxi classglyphicon glyphiconchevronrightidiv div classwrapper styleheight73px ul classnav navtabs list idmytab li ngrepeatpf in printlistimg styleimagerendering webkitoptimizecontrast imagerendering optimizequality classimgresponsive pullright ngsrcpfimagepath ngclickpfselectfile pfselectfile showcustomeventpfli ul div div javascript var hidwidth var scrollbarwidths 20 var widthoflist function var itemswidth 0 list lieachfunction var itemwidth thisouterwidth itemswidth itemwidth return itemswidth var widthofhidden function return wrapperouterwidth widthoflist getleftposi scrollbarwidths var getleftposi function return listpositionleft var readjust function if wrapperouterwidth widthoflist scrollerrightshow else scrollerrighthide if getleftposi 0 scrollerleftshow else itemanimateleft getleftposi px slow scrollerlefthide readjust windowonresize function e readjust windowonload function e readjust scrollerrightclickfunction scrollerleftfadeinslow scrollerrightfadeoutslow listanimateleft widthofhidden px slow function scrollerleftclickfunction scrollerrightfadeinslow scrollerleftfadeoutslow listanimateleft getleftposi px slow function css wrapper width 100 whitespace nowrap overflowy hidden overflowx scroll webkitoverflowscrolling touch padding 1rem backgroundcolor white toggle this depending upon whether you want to see the scrollbar webkitscrollbar display none internal display inline list positionabsolute left0px top0px minwidth3000px marginleft12px margintop0px list li displaytablecell positionrelative textaligncenter cursorgrab cursorwebkitgrab colorefefef verticalalignmiddle scroller textaligncenter cursorpointer displaynone padding7px paddingtop11px whitespace nowrap verticalalignmiddle backgroundcolorfff scrollerright floatright scrollerleft floatleft scrollersize height auto margintop 1 navtabs borderbottom 0px solid transparent important i used this code in angularjs controller its working fine', 'but i need when i click the left or right arrow it showing start and end files my intention is it must show the file depends on the screen for example like for 5s 3 files for 6s 4 filesi tried to change the javascript stucking badly to fix the scroll issueanyone can help me to fix this issue']"
AngularJS and Webpack Integration,"I am looking for some help with using webpack for a large AngularJS application. We are using folder structure based on feature (each feature/page has a module and they have controllers, directives). I have successfully configured webpack to get it working with Grunt, which produces one single bundle. I want to create chunks as its going to be a large app, we would like to load modules (page/feature) artifacts asynchronously. 
I am going through some of the webpack example to use 'code splitting' using require([deps],fn ) syntax. However I couldn't get the chunks lazy-loaded. First of all, I don't know where exactly, I would need to import these chunks before AngularJS would route the user to next page. I am struggling to find a clear separation of responsibility. 
Did someone point me to an example AngularJS application where webpack is used to load controllers/directives/filters asynchronously after each route? 
Few of the links I am following: 
Should I use Browserify or Webpack for lazy loading of dependancies in angular 1.x
https://github.com/petehunt/webpack-howto#9-async-loading
http://dontkry.com/posts/code/single-page-modules-with-webpack.html
",<javascript><java><angularjs><lazy-loading><webpack>,9,"javascript,java,angularjs,lazy-loading,webpack",['angularjs and webpack integration'],"['i am looking for some help with using webpack for a large angularjs application', 'we are using folder structure based on feature each featurepage has a module and they have controllers directives', 'i have successfully configured webpack to get it working with grunt which produces one single bundle', 'i want to create chunks as its going to be a large app we would like to load modules pagefeature artifacts asynchronously', 'i am going through some of the webpack example to use code splitting using requiredepsfn syntax', 'however i couldnt get the chunks lazyloaded', 'first of all i dont know where exactly i would need to import these chunks before angularjs would route the user to next page', 'i am struggling to find a clear separation of responsibility', 'did someone point me to an example angularjs application where webpack is used to load controllersdirectivesfilters asynchronously after each route', 'few of the links i am following should i use browserify or webpack for lazy loading of dependancies in angular 1x']"
Chrome - Automatically open devtools on network and perserve log,"I am using playwright for test automation.
Every test run creates a new instance of chromium.
When I pass --auto-open-devtools-for-tabs it opens devtools as expected.
But, I need to go one step further and have checkbox Perserve Log enabled.
Tests are fast and I need to see requests before redirect.
",<python><google-chrome><webautomation><playwright><playwright-python>,5,"python,google-chrome,webautomation,playwright,playwright-python",['chrome automatically open devtools on network and perserve log'],"['i am using playwright for test automation', 'every test run creates a new instance of chromium', 'when i pass autoopendevtoolsfortabs it opens devtools as expected', 'but i need to go one step further and have checkbox perserve log enabled', 'tests are fast and i need to see requests before redirect']"
SwiftUI: ScrollView that drags bottom sheet with it,"I'm trying to create a SwiftUI Scrollview that drags its container like this: https://drive.google.com/file/d/1O92DgsVI1OjM1HEUXUwVywB8gcdShOP-/view?usp=sharing
Many Apple apps use this (Apple Maps, Music, Wallet, etc) but I haven't found an easy way to do it wit SwiftUI. What do you think is the best way to implement this simply?
I've looked at most libraries here https://github.com/search?q=swiftui+drawer but none of them implements their drawer with a ScrollView in it that can drag the view.
I also tried implementing a custom UIScrollView as UIViewRepresentable and I tried to tweak the scrollViewWillBeginDragging() but I could not make it work.
",<ios><swiftui><swiftui-list><swiftui-scrollview><draggesture>,5,"ios,swiftui,swiftui-list,swiftui-scrollview,draggesture",['swiftui scrollview that drags bottom sheet with it'],"['im trying to create a swiftui scrollview that drags its container like this many apple apps use this apple maps music wallet etc but i havent found an easy way to do it wit swiftui', 'what do you think is the best way to implement this simply', 'ive looked at most libraries here but none of them implements their drawer with a scrollview in it that can drag the view', 'i also tried implementing a custom uiscrollview as uiviewrepresentable and i tried to tweak the scrollviewwillbegindragging but i could not make it work']"
custom validation message in vee-validate,"I am using Laravel - 5.8 with Vue.js. My question is about how to show a custom error message for a rule in the Vee-Validate library. My custom message for the ""required"" rule is not showing, and instead it reads: ""The first_name field is required."" The expected message is ""Please enter first name.""
Below code is in app.js
import { ValidationProvider } from 'vee-validate/dist/vee-validate.full';

This is my HTML component code.
<template>    
    <div>
        <form role=""form"">
            <ValidationProvider name=""first_name"" :rules=""required"">
                <div slot-scope=""{ errors }"">
                    <input v-model=""profileForm.first_name"" class=""form-control"">
                    <p>{{ errors[0] }}</p>
                </div>
            </ValidationProvider>
                  
            <button type=""button"" @click=""validateBeforeSubmit()"">Update Profile</button>
        </form>
    </div>
</template>

Below is my JS script code
<script>
    import { localize } from 'vee-validate/dist/vee-validate.full';
    import en from ""vee-validate/dist/locale/en.json"";

    export default {
        data() {
            return {
                profileForm: {
                    first_name: ''
                },
                customMessages: {
                    en: {
                        custom: {
                            'first_name': {
                                required: 'Please enter first name'
                            }
                        }
                    }
                },
            }
        },
        created() {
            localize(""en"", this.customMessages);
        },
        methods: {
            validateBeforeSubmit() {
                this.$validator.validateAll();
            }
        }
    }
</script>

Am I missing anything?
",<laravel><vue.js><vue-component><laravel-5.8><vee-validate>,9,"laravel,vue.js,vue-component,laravel-5.8,vee-validate",['custom validation message in veevalidate'],"['i am using laravel 58 with vuejs', 'my question is about how to show a custom error message for a rule in the veevalidate library', 'my custom message for the required rule is not showing and instead it reads the firstname field is required', 'the expected message is please enter first name', 'below code is in appjs import validationprovider from veevalidatedistveevalidatefull this is my html component code', 'template div form roleform validationprovider namefirstname rulesrequired div slotscope errors input vmodelprofileformfirstname classformcontrol p errors0 p div validationprovider button typebutton clickvalidatebeforesubmitupdate profilebutton form div template below is my js script code script import localize from veevalidatedistveevalidatefull import en from veevalidatedistlocaleenjson export default data return profileform firstname custommessages en custom firstname required please enter first name created localizeen thiscustommessages methods validatebeforesubmit thisvalidatorvalidateall script am i missing anything']"
Performance impact of using CDI,"I am writing a Java EE 6 web application and I am noticing a significant performance impact when using an injected object versus creating and using the object directly. The overhead appears to be of the order of 50 - 60ms per method call.
For example, using non-injected 150 method calls take approx 500ms whereas using the injected object 150 method calls take 12,000 - 13,000ms. An order of magnitude difference and then some.
Is this usual?
I am running on JBoss AS 7.1.1 final which uses Weld to handle CDI.
The injected object is defined as a singleton bean (via the javax.ejb.Singleton annotation). Could this be causing part of the problem? Or is it just the Weld proxy causing the slow down?
",<java><java-ee-6><jboss7.x><cdi><jboss-weld>,10,"java,java-ee-6,jboss7.x,cdi,jboss-weld",['performance impact of using cdi'],"['i am writing a java ee 6 web application and i am noticing a significant performance impact when using an injected object versus creating and using the object directly', 'the overhead appears to be of the order of 50 60ms per method call', 'for example using noninjected 150 method calls take approx 500ms whereas using the injected object 150 method calls take 12000 13000ms', 'an order of magnitude difference and then some', 'is this usual', 'i am running on jboss as 711 final which uses weld to handle cdi', 'the injected object is defined as a singleton bean via the javaxejbsingleton annotation', 'could this be causing part of the problem', 'or is it just the weld proxy causing the slow down']"
Laravel 5 - how to run a Controller method from an Artisan Command?,"I need some code from my Controller to run every ten minutes. Easy enough with Scheduler and Commands. But. I've created a Command, registered it with Laravel Scheduler (in Kernel.php) and now I am unable to instantiate the Controller. I know it's a wrong way to approach this problem, but I just needed a quick test. Is there a way, mind you a hacky way, to accomplish this? Thank you.
Update #1:
The Command:
<?php

namespace App\Console\Commands;

use Illuminate\Console\Command;
use App\Http\Controllers\StatsController;


class UpdateProfiles extends Command
{
    /**
     * The name and signature of the console command.
     *
     * @var string
     */
    protected $signature = 'update-profiles';

    /**
     * The console command description.
     *
     * @var string
     */
    protected $description = 'Updates profiles in database.';

    /**
     * Create a new command instance.
     *
     * @return void
     */
    public function __construct()
    {
        parent::__construct();
    }

    /**
     * Execute the console command.
     *
     * @return mixed
     */
    public function handle()
    {
        StatsController::updateStats('<theProfileName>');
    }
}

updateStats() method in StatsController.php
public static function updateStats($theProfileName) { 
   // the body
}

This returns a FatalErrorException:
[Symfony\Component\Debug\Exception\FatalErrorException] 
syntax error, unexpected 'if' (T_IF)

Update #2:
Turns out that I've had an typo in the updateStats() method, but the answer by @alexey-mezenin works like a charm! It is also enough to import the Controller into the Command:
use App\Http\Controllers\StatsController;

And then initialize it as you'd do normally:
public function handle() {
   $statControl        = new StatsController;
   $statControl->updateStats('<theProfileName>');
}

",<php><laravel><controller><command><laravel-artisan>,7,"php,laravel,controller,command,laravel-artisan",['laravel 5 how to run a controller method from an artisan command'],"['i need some code from my controller to run every ten minutes', 'easy enough with scheduler and commands', 'ive created a command registered it with laravel scheduler in kernelphp and now i am unable to instantiate the controller', 'i know its a wrong way to approach this problem but i just needed a quick test', 'is there a way mind you a hacky way to accomplish this', 'thank you', 'update 1 the command php namespace appconsolecommands use illuminateconsolecommand use apphttpcontrollersstatscontroller class updateprofiles extends command the name and signature of the console command', ' var string protected signature updateprofiles the console command description', ' var string protected description updates profiles in database', ' create a new command instance', ' return void public function construct parentconstruct execute the console command', ' return mixed public function handle statscontrollerupdatestatstheprofilename updatestats method in statscontrollerphp public static function updatestatstheprofilename the body this returns a fatalerrorexception symfonycomponentdebugexceptionfatalerrorexception syntax error unexpected if tif update 2 turns out that ive had an typo in the updatestats method but the answer by alexeymezenin works like a charm', 'it is also enough to import the controller into the command use apphttpcontrollersstatscontroller and then initialize it as youd do normally public function handle statcontrol new statscontroller statcontrolupdatestatstheprofilename ']"
How do I limit PHP apps to their own directories and their own php.ini?,"I am running multiple PHP apps on my Mac, running OS X 10.5.6, Apache 2, PHP 5.  I have subdomains setup for each project, a host file entries for each subdomain, and Virtual Directory blocks in the Apache config.  So  
project1.localhost goes to /Library/WebServer/Documents/Project1
project2.localhost goes to /Library/WebServer/Documents/Project2
etc...
However, this method doesn't really ""isolate"" the web apps.  For example, if I include a script like so:
<?php
include(""/includes/include.php"");
?>

It references the script from the base directory of my computer.  So it accesses
C:/includes/include.php
Is there a way for me to make it reference
C:/Library/WebServer/Documents/Project2/includes/include.php
Basically, make it so that its not aware of anything outside of its own directory.  Also, is there a way to use php.ini's on a per subdomain basis as well?
",<php><apache><include><subdomain><server-side-includes>,6,"php,apache,include,subdomain,server-side-includes",['how do i limit php apps to their own directories and their own phpini'],"['i am running multiple php apps on my mac running os x 1056 apache 2 php 5 i have subdomains setup for each project a host file entries for each subdomain and virtual directory blocks in the apache config', 'so project1localhost goes to librarywebserverdocumentsproject1 project2localhost goes to librarywebserverdocumentsproject2 etc however this method doesnt really isolate the web apps', 'for example if i include a script like so php includeincludesincludephp it references the script from the base directory of my computer', 'so it accesses cincludesincludephp is there a way for me to make it reference clibrarywebserverdocumentsproject2includesincludephp basically make it so that its not aware of anything outside of its own directory', 'also is there a way to use phpinis on a per subdomain basis as well']"
How to expose C++ structs for computations to Qml,"I have the following problem.
I am developing a model in C++ and a View in Qml, connecting them via Controllers. In my model I perform multiple calculations. I also offer users of my application the possibility, to write custom event handlers, written in qml.
Now I came across a point, where I decided to use Fixed point notation and I have written a corresponding C++ class. Now I want offer the FixedPoint class - including all its operators - to developers, who decide to extend my application in Qml. So far, I offered all data as QProperties, which is required by coding guidelines. But I am open for other solutions to discuss them in my team.
Clearly, a fixed point is no identity and algorithms rely on the possibility of copying it, which is not allowed when inheriting from QObject.
So the question arrives: How can I expose a c++ class / struct to QML, which is NOT an identity?  
An example in code:
struct FixedPoint
{
    FixedPoint(FixedPoint&);
    FixedPoint& operator=(FixedPoint&);
    ...
    int mantissa;
    int exponent;
}

I want to use it in Qml as an property (value) of a QQuickItem written in C++:
MyQmlObject{
    value{ mantissa: 134; exponent: 3 }
}

The property value is then used throughout computations in javascript and is copied several times a long the way. So I cannot make value a property of type FixedPoint* I think. Am I right?
",<c++><qt><qml><qobject><qquickitem>,14,"c++,qt,qml,qobject,qquickitem",['how to expose c structs for computations to qml'],"['i have the following problem', 'i am developing a model in c and a view in qml connecting them via controllers', 'in my model i perform multiple calculations', 'i also offer users of my application the possibility to write custom event handlers written in qml', 'now i came across a point where i decided to use fixed point notation and i have written a corresponding c class', 'now i want offer the fixedpoint class including all its operators to developers who decide to extend my application in qml', 'so far i offered all data as qproperties which is required by coding guidelines', 'but i am open for other solutions to discuss them in my team', 'clearly a fixed point is no identity and algorithms rely on the possibility of copying it which is not allowed when inheriting from qobject', 'so the question arrives how can i expose a c class struct to qml which is not an identity', 'an example in code struct fixedpoint fixedpointfixedpoint fixedpoint operatorfixedpoint int mantissa int exponent i want to use it in qml as an property value of a qquickitem written in c myqmlobject value mantissa 134 exponent 3 the property value is then used throughout computations in javascript and is copied several times a long the way', 'so i cannot make value a property of type fixedpoint i think', 'am i right']"
Shell Vs Process.start for executing external application,"I can open the windows calculator from my application in following ways:

Using Shell() 
Shell(""C:\WINDOWS\system32\calc.exe"") 

Using Process.start()
Process.start(""C:\WINDOWS\system32\calc.exe"")  

Open notepad application 
Shell(""C:\WINDOWS\system32\notepad.exe"", AppWinStyle.NormalFocus)  
Process.start(""C:\WINDOWS\system32\notepad.exe"", AppWinStyle.NormalFocus)


Can anyone tell me that what is the difference between these two calls? which one is the best practice?
",<.net><vb.net><windows><shell><process>,5,".net,vb.net,windows,shell,process",['shell vs processstart for executing external application'],"['i can open the windows calculator from my application in following ways using shell shellcwindowssystem32calcexe using processstart processstartcwindowssystem32calcexe open notepad application shellcwindowssystem32notepadexe appwinstylenormalfocus processstartcwindowssystem32notepadexe appwinstylenormalfocus can anyone tell me that what is the difference between these two calls', 'which one is the best practice']"
localStorage html5 feature not working in WebView on Samsung Android device,"I have a html5 application that I wrap with a WebView. To store and retrieve user input values between pages, I use the localStorage html5 feature. 
It works fine on my Nexus 4 (Android 4.4.4), but it does not work on Samsung Galaxy Tab 2 (Android 4.3.x) (= nothing happens, but also no error in logcat).
Or, to be more clear: on Samsung, it does not work if the html pages are loaded from within the app's asset folder. It does work though if I put the pages on a server, as below in the outcommented line.
However, on Nexus 4, loading from file:///android_asset/ and also if I load the pages on a desktop browser (Chrome, Firefox) from file:// path, it is also working.
Update 1: I just had another user who reported the issue with a LG device, so it does not seem to be Samsung specific.
Update 2: Storing and loading the value from localStorage works fine on all devices on the same page, however, not between different pages. In my example, I can store and retrieve the value on 01_home.html, but when I go to another page in the android_asset folder, I cannot read it anymore (on LG, Samsung devices). Works fine on Nexus 4 though.
Below are the settings of the web view.
    webView = (WebView)this.findViewById(R.id.webView);
    webViewClient = new MyWebViewClient(this);
    webViewClient.setSm(sm);
    webView.setWebViewClient(webViewClient);
    WebSettings webSettings = webView.getSettings();
    webSettings.setJavaScriptEnabled(true);
    webSettings.setDomStorageEnabled(true);
    webView.getSettings().setJavaScriptEnabled(true);
    webView.getSettings().setDomStorageEnabled(true);
    webView.getSettings().setPluginState(WebSettings.PluginState.ON);
    webView.getSettings().setAppCacheEnabled(false);
    webView.getSettings().setCacheMode(WebSettings.LOAD_NO_CACHE);
    webView.getSettings().setUseWideViewPort(true);
    webView.getSettings().setLoadWithOverviewMode(true);
    webView.getSettings().setBuiltInZoomControls(false);
    webView.getSettings().setSupportZoom(false);
    webView.getSettings().setDefaultZoom(WebSettings.ZoomDensity.FAR);

    webView.loadUrl(""file:///android_asset/01_home.html""); // does NOT work!
    // webView.loadUrl(""http://192.168.178.33/01_home.html""); // does work!

Local storage code in the pages:
// storing
var data = document.getElementById('data').value;
window.localStorage.setItem((1), data);

// reading
document.getElementById('data').value = window.localStorage.getItem(1);

",<android><html><webview><local-storage><samsung-mobile>,9,"android,html,webview,local-storage,samsung-mobile",['localstorage html5 feature not working in webview on samsung android device'],"['i have a html5 application that i wrap with a webview', 'to store and retrieve user input values between pages i use the localstorage html5 feature', 'it works fine on my nexus 4 android 444 but it does not work on samsung galaxy tab 2 android 43x nothing happens but also no error in logcat', 'or to be more clear on samsung it does not work if the html pages are loaded from within the apps asset folder', 'it does work though if i put the pages on a server as below in the outcommented line', 'however on nexus 4 loading from fileandroidasset and also if i load the pages on a desktop browser chrome firefox from file path it is also working', 'update 1 i just had another user who reported the issue with a lg device so it does not seem to be samsung specific', 'update 2 storing and loading the value from localstorage works fine on all devices on the same page however not between different pages', 'in my example i can store and retrieve the value on 01homehtml but when i go to another page in the androidasset folder i cannot read it anymore on lg samsung devices', 'works fine on nexus 4 though', 'below are the settings of the web view', 'webview webviewthisfindviewbyidridwebview webviewclient new mywebviewclientthis webviewclientsetsmsm webviewsetwebviewclientwebviewclient websettings websettings webviewgetsettings websettingssetjavascriptenabledtrue websettingssetdomstorageenabledtrue webviewgetsettingssetjavascriptenabledtrue webviewgetsettingssetdomstorageenabledtrue webviewgetsettingssetpluginstatewebsettingspluginstateon webviewgetsettingssetappcacheenabledfalse webviewgetsettingssetcachemodewebsettingsloadnocache webviewgetsettingssetusewideviewporttrue webviewgetsettingssetloadwithoverviewmodetrue webviewgetsettingssetbuiltinzoomcontrolsfalse webviewgetsettingssetsupportzoomfalse webviewgetsettingssetdefaultzoomwebsettingszoomdensityfar webviewloadurlfileandroidasset01homehtml does not work', ' webviewloadurl does work', 'local storage code in the pages storing var data documentgetelementbyiddatavalue windowlocalstoragesetitem1 data reading documentgetelementbyiddatavalue windowlocalstoragegetitem1']"
"AVPlayer ""freezes"" the app at the start of buffering an audio stream","I am using a subclass of AVQueuePlayer and when I add new AVPlayerItem with a streaming URL the app freezes for about a second or two. By freezing I mean that it doesn't respond to touches on the UI. Also, if I have a song playing already and then add another one to the queue, AVQueuePlayer automatically starts preloading the song while it is still streaming the first one. This makes the app not respond to touches on the UI for two seconds just like when adding the first song but the song is still playing. So that means AVQueuePlayer is doing something in main thread that is causing the apparent ""freeze"".
I am using insertItem:afterItem: to add my AVPlayerItem. I tested and made sure that this was the method that was causing the delay. Maybe it could be something that AVPlayerItem does when it gets activated by AVQueuePlayer at the moment of adding it to the queue.
Must point out that I am using the Dropbox API v1 beta to get the streaming URL by using this method call:
[[self restClient] loadStreamableURLForFile:metadata.path];

Then when I receive the stream URL I send it to AVQueuePlayer as follows:
[self.player insertItem:[AVPlayerItem playerItemWithURL:url] afterItem:nil];

So my question is: How do I avoid this?
Should I do the preloading of an audio stream on my own without the help of AVPlayer? If so, how do I do this?
Thanks.
",<ios><audio-streaming><dropbox><avplayer><avqueueplayer>,62,"ios,audio-streaming,dropbox,avplayer,avqueueplayer",['avplayer freezes the app at the start of buffering an audio stream'],"['i am using a subclass of avqueueplayer and when i add new avplayeritem with a streaming url the app freezes for about a second or two', 'by freezing i mean that it doesnt respond to touches on the ui', 'also if i have a song playing already and then add another one to the queue avqueueplayer automatically starts preloading the song while it is still streaming the first one', 'this makes the app not respond to touches on the ui for two seconds just like when adding the first song but the song is still playing', 'so that means avqueueplayer is doing something in main thread that is causing the apparent freeze', 'i am using insertitemafteritem to add my avplayeritem', 'i tested and made sure that this was the method that was causing the delay', 'maybe it could be something that avplayeritem does when it gets activated by avqueueplayer at the moment of adding it to the queue', 'must point out that i am using the dropbox api v1 beta to get the streaming url by using this method call self restclient loadstreamableurlforfilemetadatapath then when i receive the stream url i send it to avqueueplayer as follows selfplayer insertitemavplayeritem playeritemwithurlurl afteritemnil so my question is how do i avoid this', 'should i do the preloading of an audio stream on my own without the help of avplayer', 'if so how do i do this', 'thanks']"
"Run Custom Tool for Entity Framework, what does it do?","In Visual Studio, when working with Entity Framework and applying Run Custom Tool for .tt and .Context.tt files,  What is it and what does it do?
Why it's solving database sync-problems (Sometimes)? and why i should run it for (.tt) before run it for (.Context.tt)?
",<c#><asp.net><visual-studio><entity-framework><entity-framework-5>,11,"c#,asp.net,visual-studio,entity-framework,entity-framework-5",['run custom tool for entity framework what does it do'],"['in visual studio when working with entity framework and applying run custom tool for tt and contexttt files what is it and what does it do', 'why its solving database syncproblems sometimes', 'and why i should run it for tt before run it for contexttt']"
.Net standard version for .Net core 2.2,"Googled a bit but couldn't find the .Net standard version for .Net core 2.2. Only version I got is,

Any hint please?
",<asp.net-core><.net-core><.net-standard><asp.net-core-2.2><.net-core-2.2>,11,"asp.net-core,.net-core,.net-standard,asp.net-core-2.2,.net-core-2.2",['net standard version for net core 22'],['googled a bit but couldnt find the net standard version for net core 22 only version i got is any hint please']
Calling System.Diagnostics.Trace from a Dynamics CRM 2011 Plugin,"Wondering if any of you have any ideas about the following issue I’m running into.
Here is some super simple plug-in code.
namespace Demo.DebugTraceBlog
{
    public class TraceAndDebugDemo : IPlugin
    {
        public void Execute(IServiceProvider serviceProvider)
        {
            Trace.WriteLine(""Started Plugin"");    
            Trace.WriteLine(""Plugin Working"");    
            Trace.WriteLine(""Ending Plugin"");                
        }
    }
}

I’m using DebugView (http://goo.gl/YRfus) to view the Trace messages being written. When I execute this code as a plug-in running in the sandbox I get the results I expect: three lines appear in DebugView and if I attach VS to the Sandbox worker process I see three lines written to the Output window. Now when I change the isolation mode to none, and let it run in the W3WP.EXE process I do not get any output to DebugView and when I attach to W3WP.EXE I can set a breakpoint to validate it is running but I do not get any output to the Output window.
Any idea of why this is occurring and how I can go about overriding the cause and force the non-sandbox execution to work as expected. I can take some guesses about it having to do with running inside of the CRM IIS processes and that CRM is suppressing the Trace writing – I specifically used Trace instead of Debug in attempt to avoid the issue, but no luck.
I know I can use the ITracingService but that does not meet my current requirement.
",<c#><asp.net><iis-7><dynamics-crm-2011><system.diagnostics>,7,"c#,asp.net,iis-7,dynamics-crm-2011,system.diagnostics",['calling systemdiagnosticstrace from a dynamics crm 2011 plugin'],"['wondering if any of you have any ideas about the following issue im running into', 'here is some super simple plugin code', 'namespace demodebugtraceblog public class traceanddebugdemo iplugin public void executeiserviceprovider serviceprovider tracewritelinestarted plugin tracewritelineplugin working tracewritelineending plugin im using debugview to view the trace messages being written', 'when i execute this code as a plugin running in the sandbox i get the results i expect three lines appear in debugview and if i attach vs to the sandbox worker process i see three lines written to the output window', 'now when i change the isolation mode to none and let it run in the w3wpexe process i do not get any output to debugview and when i attach to w3wpexe i can set a breakpoint to validate it is running but i do not get any output to the output window', 'any idea of why this is occurring and how i can go about overriding the cause and force the nonsandbox execution to work as expected', 'i can take some guesses about it having to do with running inside of the crm iis processes and that crm is suppressing the trace writing i specifically used trace instead of debug in attempt to avoid the issue but no luck', 'i know i can use the itracingservice but that does not meet my current requirement']"
Why would you append a shard ID to a generated ID?,"I'm reading this:
https://instagram-engineering.com/sharding-ids-at-instagram-1cf5a71e5a5c
In in the last section ""Solution"", where they are generating a globally unique ID based on the DB's autoincrement feature + milliseconds since epoch + shard ID.
Why do we need to append shard ID to it?
Specifically, it says 

Next, we take the shard ID for this particular piece of data we’re
  trying to insert. Let’s say we’re sharding by user ID, and there are
  2000 logical shards; if our user ID is 31341, then the shard ID is
  31341 % 2000 -> 1341. We fill the next 13 bits with this value

THis doesn't make sense: if you are already modding user ID by number of shards (31341 % 2000), that means 1) You already have user ID! 2) You already know the shard it belongs to with the mod function!
What am I misunderstanding here?
",<database><facebook><instagram><sharding><id-generation>,6,"database,facebook,instagram,sharding,id-generation",['why would you append a shard id to a generated id'],"['im reading this in in the last section solution where they are generating a globally unique id based on the dbs autoincrement feature milliseconds since epoch shard id', 'why do we need to append shard id to it', 'specifically it says next we take the shard id for this particular piece of data were trying to insert', 'lets say were sharding by user id and there are 2000 logical shards if our user id is 31341 then the shard id is 31341 2000 1341 we fill the next 13 bits with this value this doesnt make sense if you are already modding user id by number of shards 31341 2000 that means 1 you already have user id', '2 you already know the shard it belongs to with the mod function', 'what am i misunderstanding here']"
URL Encoding with Underscores in a Directory Name?,"We've run into an odd argument where I work, and I may be wrong on this, so this is why I am asking.
Our software outputs a directory to an Apache server that replaces an underscore with a %5F in the name of the directory.  
For instance if the name of the directory was listed as a string in our software it would be: ""andy_test"", but then when the software outputs the directory to the Apache server, it would become ""andy%5Ftest"".  Unfortunately, when you access the url on the server it ends up becoming ""andy%255Ftest"".  
Somehow this seems wrong to me, once again the progression is:

andy_test <- (as a string in the software)
andy%5Ftest <- (listed as a directory on the server)
andy%255Ftest <- (must be used when calling the same directory as a URL on the server from a web browser.)

I'm assuming that ""%5"" is encoding for underscore, and that ""%25"" is encoding for ""%"".
Now it would seem to me that the way that the directory name should be listed on the server would be just plain andy_test and if you were using an encoded URI then maybe you would end up with the ""andy%5Ftest"" to access the directory on the apache server.  
I asked the guys on the backend about it, and they said that they were just: ""encoding anything that was not a letter or a number.
So I guess I'm a bit confused on this.  Can you tell me who is right, and direct me to some information on why?
",<apache><encoding><url-rewriting><directory><apache2>,9,"apache,encoding,url-rewriting,directory,apache2",['url encoding with underscores in a directory name'],"['weve run into an odd argument where i work and i may be wrong on this so this is why i am asking', 'our software outputs a directory to an apache server that replaces an underscore with a 5f in the name of the directory', 'for instance if the name of the directory was listed as a string in our software it would be andytest but then when the software outputs the directory to the apache server it would become andy5ftest', 'unfortunately when you access the url on the server it ends up becoming andy255ftest', 'somehow this seems wrong to me once again the progression is andytest as a string in the software andy5ftest listed as a directory on the server andy255ftest must be used when calling the same directory as a url on the server from a web browser', 'im assuming that 5 is encoding for underscore and that 25 is encoding for ', 'now it would seem to me that the way that the directory name should be listed on the server would be just plain andytest and if you were using an encoded uri then maybe you would end up with the andy5ftest to access the directory on the apache server', 'i asked the guys on the backend about it and they said that they were just encoding anything that was not a letter or a number', 'so i guess im a bit confused on this', 'can you tell me who is right and direct me to some information on why']"
How to fix side bar and header using CSS for JS & jQuery Scroller,"I have this layout and I want to make the left sidebar, right sidebar and the header fixed. 

This is my css :
    #container {
        padding-left: 200px;      /* LC fullwidth */
        padding-right: 190px;     /* RC fullwidth + CC padding */
    }

    #container .column {
        position: relative;
        float: left;
    }

    #center {
        padding: 10px 20px;       /* CC padding */
        width: 100%;
        overflow-x:hidden;
    }

    #left {
        width: 180px;             /* LC width */
        padding: 0 10px;          /* LC padding */
        right: 240px;             /* LC fullwidth + CC padding */
        margin-left: -100%;
    }

    #right {
        width: 130px;             /* RC width */
        padding: 0 10px;          /* RC padding */
        margin-right: -100%;
    }

    #footer {
        clear: both;
    }

& the code is here
After this step, I want to add nanScrollerJS to the right side bar.
I'm not familiar with CSS
",<javascript><html><css><layout><scroller>,5,"javascript,html,css,layout,scroller",['how to fix side bar and header using css for js jquery scroller'],"['i have this layout and i want to make the left sidebar right sidebar and the header fixed', 'this is my css container paddingleft 200px lc fullwidth paddingright 190px rc fullwidth cc padding container column position relative float left center padding 10px 20px cc padding width 100 overflowxhidden left width 180px lc width padding 0 10px lc padding right 240px lc fullwidth cc padding marginleft 100 right width 130px rc width padding 0 10px rc padding marginright 100 footer clear both the code is here after this step i want to add nanscrollerjs to the right side bar', 'im not familiar with css']"
What are the viable database abstraction layers for Python,"I'm starting to get involved in an open source project Gramps which is exploring switching their backend from BSDDB to a relational database. Either SQLite or MySQL we haven't fully decided and may even try to do both in some limited capacity. I'm a professional developer but I'm new to python so I'm not that familiar with the current selection of tools/libraries. I've been tasked with researching DB Abstraction Layers. There is currently a wiki discussion going on to compare them. An object relational mapper might be nice but isn't absolutely necessary. though I know that is usually synonymous with a DB Abstraction Layer. If an ORM is included ad hock queries have to be available without to much wrestling.
Right now the list includes:
CouchDB
I haven't yet looked into this.
DB-API
this seems to be a standard python api and each db creates their own module that uses it. Even BSDDB seems to have one written but I haven't fully explored it. are the modules interchangeable?
SQLAlchemy
This seems to be the most popular right now? but I have very limited exposure to the python world.
SQLObject 
I haven't yet looked into this.
So what are peoples views and suggestions on database abstraction layers for python?
",<python><sql><mysql><database><sqlite>,20,"python,sql,mysql,database,sqlite",['what are the viable database abstraction layers for python'],"['im starting to get involved in an open source project gramps which is exploring switching their backend from bsddb to a relational database', 'either sqlite or mysql we havent fully decided and may even try to do both in some limited capacity', 'im a professional developer but im new to python so im not that familiar with the current selection of toolslibraries', 'ive been tasked with researching db abstraction layers', 'there is currently a wiki discussion going on to compare them', 'an object relational mapper might be nice but isnt absolutely necessary', 'though i know that is usually synonymous with a db abstraction layer', 'if an orm is included ad hock queries have to be available without to much wrestling', 'right now the list includes couchdb i havent yet looked into this', 'dbapi this seems to be a standard python api and each db creates their own module that uses it', 'even bsddb seems to have one written but i havent fully explored it', 'are the modules interchangeable', 'sqlalchemy this seems to be the most popular right now', 'but i have very limited exposure to the python world', 'sqlobject i havent yet looked into this', 'so what are peoples views and suggestions on database abstraction layers for python']"
How does spacy lemmatizer works?,"For lemmatization spacy has a lists of words:  adjectives, adverbs, verbs... and also lists for exceptions: adverbs_irreg... for the regular ones there is a set of rules
Let's take as example the word ""wider""
As it is an adjective the rule for lemmatization should be take from this list:
ADJECTIVE_RULES = [
    [""er"", """"],
    [""est"", """"],
    [""er"", ""e""],
    [""est"", ""e""]
] 

As I understand the process will be like this:
1) Get the POS tag of the word to know whether it is a noun, a verb...
2) If the word is in the list of irregular cases is replaced directly if not one of the rules is applied.
Now, how is decided to use ""er"" -> ""e"" instead of ""er""-> """" to get ""wide"" and not ""wid""? 
Here it can be tested.
",<python><nlp><wordnet><spacy><lemmatization>,15,"python,nlp,wordnet,spacy,lemmatization",['how does spacy lemmatizer works'],"['for lemmatization spacy has a lists of words adjectives adverbs verbs and also lists for exceptions adverbsirreg for the regular ones there is a set of rules lets take as example the word wider as it is an adjective the rule for lemmatization should be take from this list adjectiverules er est er e est e as i understand the process will be like this 1 get the pos tag of the word to know whether it is a noun a verb 2 if the word is in the list of irregular cases is replaced directly if not one of the rules is applied', 'now how is decided to use er e instead of er to get wide and not wid', 'here it can be tested']"
"Can a Controller have database queries (MySQL)? If yes, when?","I am reading lots of tutorials on MVC, so my question, can a perfect PHP MVC framework have database queries in Controller? As I understand, the most comfortable way is to put all database queries in Model, right? And if I have POST or smth, I just pass that POST to Model and it makes all inserts and etc. ?
Or I am missing something? And if Controller can have a database queries, in which situation would it be?
",<php><mysql><oop><model-view-controller><frameworks>,5,"php,mysql,oop,model-view-controller,frameworks","['can a controller have database queries mysql', 'if yes when']","['i am reading lots of tutorials on mvc so my question can a perfect php mvc framework have database queries in controller', 'as i understand the most comfortable way is to put all database queries in model right', 'and if i have post or smth i just pass that post to model and it makes all inserts and etc', '', 'or i am missing something', 'and if controller can have a database queries in which situation would it be']"
"Signalr deserializes my objects incorrectly in IIS 7.5 and Edge/IE, foreverFrame broken?","So I have a simple Signalr/Knockout project that uses the mapping plugin to bind  a simple object (item with an array of more items) to viewModels I defined in JS: 
var someObjectMapping = {
    'MyItemArray': {
        create: function (options) {
            return new MyItemViewModel(options.data);
        }
    }
}

var myItemMapping = {
    'ItemChildren': {
        create: function (options) {
            return new ItemChildViewModel(options.data);
        }
    }
}

var SomeObjectViewModel = function (data) {
    ko.mapping.fromJS(data, someObjectMapping, this);
}

var MyItemViewModel = function (data) {
    ko.mapping.fromJS(data, myItemMapping, this);
}

var ItemChildViewModel = function (data) {
    ko.mapping.fromJS(data, null, this);
}

I use SignalR's default settings to connect to my hub like so:
    var myHubProxy = $.connection.myHub;

    myHubProxy.client.processSomeObject = function(someObject) {
        console.log('SomeObject received');
        var viewModel = new SomeObjectViewModel(someObject);
        ko.applyBindings(viewModel);
    }

    $.connection.hub.start().done(function() {
        console.log('Now connected, connection ID=' + $.connection.hub.id);
        myHubProxy.server.getSomeObject();
    });

When my object comes back, knockout applies the binding and the mapping gets processed. Then the object and its child arrays are naturally rendered on the page:
<h2 data-bind=""text: MyItem""></h2>
<ul data-bind=""foreach: MyItemArray"">
    <li>
        <span data-bind=""text: Name""></span>
        <ul data-bind=""foreach: ItemChildren"">
            <li data-bind=""text: Name""></li>
        </ul>
    </li>
</ul>

Now for the kicker: This works in on my local machine (Win 10, IIS Express), in all browsers (Chrome/Firefox/Safari/IE), no problem. When I publish this to IIS 7.5 however, it works in all browsers except for Internet Explorer 8-10 and Microsoft Edge. Same code.
When I drill through F12 I notice that, from IIS, the create function in the first mapping gets an array:

When instead, on first break, I should have the first item in my array like it does on my local machine:

Drilling up the callstack reveals that the parent object in knockout.mapping's createCallback function is not being interpreted as an array as it should:

However, on my local machine, it works as expected:

Strangely, one of two things can workaround the issue: First, if I serialize the object I get back from SignalR and then deseralize it before binding it my knockout model, everything works from all browsers from IIS 7.5:
  myHubProxy.client.processSomeObject = function(someObject) {
        console.log('SomeObject received');
        var jsonStr = JSON.stringify(someObject);
        var viewModel = new SomeObjectViewModel(JSON.parse(jsonStr));
        ko.applyBindings(viewModel);
    }

But this can affect performance.
OR if I force SignalR's transport to longPolling, again everything works in all browsers from IIS 7.5:
    $.connection.hub.start({ transport: ""longPolling"" }).done(function () {
        console.log('Now connected, connection ID=' + $.connection.hub.id);
        myHubProxy.server.getSomeObject();
    });

But then I wouldn't have the advantages WebSockets provides over polling.
IIS 7.5 doesn't support WebSockets
I can also hardcode my json and bind it with knockout, which works as expected in all browsers.
It took me forever to discover what was going on, and I've been struggling to figure this one out. It's strange that this works from IIS 7.5 in all the other browsers but IE/Edge when they're running the same simple script. It also works with in all browsers IIS 10 (non-Express), which isn't an option for the server I'm publishing to.
Edit: Uffe has pointed out that IIS 7.5 doesn't support WebSockets. After enabling logging, I saw that, for IIS 7.5, Signalr will instead fallback to foreverFrame for IE and serverSentEvents (which isn't supported in IE) for other browsers. 
I also tested forcing foreverFrame, which reproduced the issue on my machine with IIS 10 Express: 
    $.connection.hub.start({ transport: 'foreverFrame'}).done(function () {
        console.log('Now connected, connection ID=' + $.connection.hub.id);
        myHubProxy.server.getSomeObject();
    });

So another workaround would be to skip foreverFrame from the transport altogether when publishing to IIS 7.5 like so:
    $.connection.hub.start({ transport: ['serverSentEvents','longPolling']}).done(function () {
        console.log('Now connected, connection ID=' + $.connection.hub.id);
        myHubProxy.server.getSomeObject();
    });

Here's a sample project which reproduces the issue: 
https://onedrive.live.com/redir?resid=D4E23CA0ED671323!1466815&authkey=!AEAEBajrZx3y8e4&ithint=folder%2csln
",<asp.net><iis><knockout.js><signalr><knockout-mapping-plugin>,6,"asp.net,iis,knockout.js,signalr,knockout-mapping-plugin",['signalr deserializes my objects incorrectly in iis 75 and edgeie foreverframe broken'],"['so i have a simple signalrknockout project that uses the mapping plugin to bind a simple object item with an array of more items to viewmodels i defined in js var someobjectmapping myitemarray create function options return new myitemviewmodeloptionsdata var myitemmapping itemchildren create function options return new itemchildviewmodeloptionsdata var someobjectviewmodel function data komappingfromjsdata someobjectmapping this var myitemviewmodel function data komappingfromjsdata myitemmapping this var itemchildviewmodel function data komappingfromjsdata null this i use signalrs default settings to connect to my hub like so var myhubproxy connectionmyhub myhubproxyclientprocesssomeobject functionsomeobject consolelogsomeobject received var viewmodel new someobjectviewmodelsomeobject koapplybindingsviewmodel connectionhubstartdonefunction consolelognow connected connection id connectionhubid myhubproxyservergetsomeobject when my object comes back knockout applies the binding and the mapping gets processed', 'then the object and its child arrays are naturally rendered on the page h2 databindtext myitemh2 ul databindforeach myitemarray li span databindtext namespan ul databindforeach itemchildren li databindtext nameli ul li ul now for the kicker this works in on my local machine win 10 iis express in all browsers chromefirefoxsafariie no problem', 'when i publish this to iis 75 however it works in all browsers except for internet explorer 810 and microsoft edge', 'same code', 'when i drill through f12 i notice that from iis the create function in the first mapping gets an array when instead on first break i should have the first item in my array like it does on my local machine drilling up the callstack reveals that the parent object in knockoutmappings createcallback function is not being interpreted as an array as it should however on my local machine it works as expected strangely one of two things can workaround the issue first if i serialize the object i get back from signalr and then deseralize it before binding it my knockout model everything works from all browsers from iis 75 myhubproxyclientprocesssomeobject functionsomeobject consolelogsomeobject received var jsonstr jsonstringifysomeobject var viewmodel new someobjectviewmodeljsonparsejsonstr koapplybindingsviewmodel but this can affect performance', 'or if i force signalrs transport to longpolling again everything works in all browsers from iis 75 connectionhubstart transport longpolling donefunction consolelognow connected connection id connectionhubid myhubproxyservergetsomeobject but then i wouldnt have the advantages websockets provides over polling', 'iis 75 doesnt support websockets i can also hardcode my json and bind it with knockout which works as expected in all browsers', 'it took me forever to discover what was going on and ive been struggling to figure this one out', 'its strange that this works from iis 75 in all the other browsers but ieedge when theyre running the same simple script', 'it also works with in all browsers iis 10 nonexpress which isnt an option for the server im publishing to', 'edit uffe has pointed out that iis 75 doesnt support websockets', 'after enabling logging i saw that for iis 75 signalr will instead fallback to foreverframe for ie and serversentevents which isnt supported in ie for other browsers', 'i also tested forcing foreverframe which reproduced the issue on my machine with iis 10 express connectionhubstart transport foreverframedonefunction consolelognow connected connection id connectionhubid myhubproxyservergetsomeobject so another workaround would be to skip foreverframe from the transport altogether when publishing to iis 75 like so connectionhubstart transport serversenteventslongpollingdonefunction consolelognow connected connection id connectionhubid myhubproxyservergetsomeobject heres a sample project which reproduces the issue']"
How to change Bootstrap navbar collapse breakpoint,"Currently when the browser width drops below 768px, the navbar changes to collapsed mode. I want to change this width to 1000px so when the browser is below 1000px the navbar changes to collapsed mode. I want to do this without using LESS, I am using stylus not LESS. 
My issue is the same as in this question: Bootstrap 3 Navbar Collapse
But all the answers in that questions explain how to do it by changing LESS variable. I haven't been dealing with LESS, I am using stylus so I want to know how this can be done using stylus or another method. 
Thanks! 
",<css><twitter-bootstrap><responsive-design><navbar><bootstrap-5>,237,"css,twitter-bootstrap,responsive-design,navbar,bootstrap-5",['how to change bootstrap navbar collapse breakpoint'],"['currently when the browser width drops below 768px the navbar changes to collapsed mode', 'i want to change this width to 1000px so when the browser is below 1000px the navbar changes to collapsed mode', 'i want to do this without using less i am using stylus not less', 'my issue is the same as in this question bootstrap 3 navbar collapse but all the answers in that questions explain how to do it by changing less variable', 'i havent been dealing with less i am using stylus so i want to know how this can be done using stylus or another method', 'thanks']"
Signing AWS HTTP requests with Apache HttpComponents Client,"I'm trying to make HTTP requests to an AWS Elasticsearch domain protected by an IAM access policy. I need to sign these requests for them to be authorized by AWS.
I'm using Jest, which in turn use Apache HttpComponents Client.
This seems to be a common use case, but I can't find what should I do so Jest can sign all requests.
",<java><amazon-web-services><elasticsearch><apache-httpcomponents><elasticsearch-jest>,14,"java,amazon-web-services,elasticsearch,apache-httpcomponents,elasticsearch-jest",['signing aws http requests with apache httpcomponents client'],"['im trying to make http requests to an aws elasticsearch domain protected by an iam access policy', 'i need to sign these requests for them to be authorized by aws', 'im using jest which in turn use apache httpcomponents client', 'this seems to be a common use case but i cant find what should i do so jest can sign all requests']"
How to set request args with Flask test_client?,"I have to test out a certain view that gets certain information from request.args.
I can't mock this since a lot of stuff in the view uses the request object.
The only alternative I can think of is to manually set request.args.
I can do that with the test_request_context(), e.g:
with self.app.test_request_context() as req:
    req.request.args = {'code': 'mocked access token'}
    MyView()

Now the request inside this view will have the arguments that I've set.
However I need to call my view, not just initialize it, so I use this:
with self.app.test_client() as c:
    resp = c.get('/myview')

But I don't know how to manipulate the request arguments in this manner.
I have tried this:
with self.app.test_client() as c:
    with self.app.test_request_context() as req:
        req.request.args = {'code': 'mocked access token'}
        resp = c.get('/myview')

but this does not set request.args.
",<python><unit-testing><testing><flask><flask-testing>,35,"python,unit-testing,testing,flask,flask-testing",['how to set request args with flask testclient'],"['i have to test out a certain view that gets certain information from requestargs', 'i cant mock this since a lot of stuff in the view uses the request object', 'the only alternative i can think of is to manually set requestargs', 'i can do that with the testrequestcontext eg with selfapptestrequestcontext as req reqrequestargs code mocked access token myview now the request inside this view will have the arguments that ive set', 'however i need to call my view not just initialize it so i use this with selfapptestclient as c resp cgetmyview but i dont know how to manipulate the request arguments in this manner', 'i have tried this with selfapptestclient as c with selfapptestrequestcontext as req reqrequestargs code mocked access token resp cgetmyview but this does not set requestargs']"
How to implement animated vector drawables using the design support library 23.2?,"I've seen  the android developers blog that the new design support library 23.2 supports animated vector. When i searched i came across this link to implement animated vector drawable. Is it the same way to implement animated vector drawables in design support library 23.2? Can someone help me out with the new implementation?
",<android><animation><android-studio><androiddesignsupport><android-vectordrawable>,6,"android,animation,android-studio,androiddesignsupport,android-vectordrawable",['how to implement animated vector drawables using the design support library 232'],"['ive seen the android developers blog that the new design support library 232 supports animated vector', 'when i searched i came across this link to implement animated vector drawable', 'is it the same way to implement animated vector drawables in design support library 232', 'can someone help me out with the new implementation']"
Best practice to export core data entities,"I need to export a few entities with its relationships in order to import it in other iOS device. For example:
A.relationship1 <------>> B.relationship1 (one to many)
B.relationship2 <-------> C.relationship1 (one to one)

Is there a way to serialize/deserialize (or other methods) to export/import ""easily"" a fragment of the core data model (objects and its relationships fetched by a fetched results controller? By serializing all the data pack (NSData or something), deserializing and inserting it to the context (importing).
Please point me in the right direction.
Thanks in advance.
",<ios><objective-c><core-data><export><entity>,7,"ios,objective-c,core-data,export,entity",['best practice to export core data entities'],"['i need to export a few entities with its relationships in order to import it in other ios device', 'for example arelationship1 brelationship1 one to many brelationship2 crelationship1 one to one is there a way to serializedeserialize or other methods to exportimport easily a fragment of the core data model objects and its relationships fetched by a fetched results controller', 'by serializing all the data pack nsdata or something deserializing and inserting it to the context importing', 'please point me in the right direction', 'thanks in advance']"
Native JavaScript sort performing slower than implemented mergesort and quicksort,"I've implemented a mergesort and a quicksort to compare them with the native JavaScript sort. For the quicksort I've tried to use this algorithm: view algorithm on youtube. Both algorithms use as less memory as possible, for the merge sort an auxiliary array is passed for each recursive call (to avoid overheads) , and for the quicksort, positions of the starting and ending positions. I'm using sorts to manage large amounts of data in a NodeJs app.
Below you have the mergesort, quicksort and native JavaScript sort and you can test the performance 
The question is: Why is the native JavaScript performing slower ? 
In my case: 
Chrome - merge sort: measure: 1997.920ms; quicksort: measure: 1755.740ms; native : measure: 4988.105ms
Node: merge sort: measure: 2233.413ms; quicksort: measure: 1876.055ms; native: measure: 6317.118ms
Merge Sort


var length = 10000000; //  ten millions;
var arr = [];
for (let i = length; i > 0; i--) {
  // random array
  arr.push(parseInt(Math.random() * 1000000000));
}
var mergeSort = function(array) {
  function merge(arr, aux, lo, mid, hi) {
    for (var k = lo; k <= hi; k++) {
      aux[k] = arr[k];
    }

    var i = lo;
    var j = mid + 1;
    for (var k = lo; k <= hi; k++) {
      if (i > mid) {
        arr[k] = aux[j++];
      } else if (j > hi) {
        arr[k] = aux[i++];
      } else if (aux[i] < aux[j]) {
        arr[k] = aux[i++];
      } else {
        arr[k] = aux[j++];
      }
    }
  }

  function sort(array, aux, lo, hi) {
    if (hi <= lo) return;
    var mid = Math.floor(lo + (hi - lo) / 2);
    sort(array, aux, lo, mid);
    sort(array, aux, mid + 1, hi);

    merge(array, aux, lo, mid, hi);
  }

  function merge_sort(array) {
    var aux = array.slice(0);
    sort(array, aux, 0, array.length - 1);
    return array;
  }

  return merge_sort(array);
}


console.time('measure');
mergeSort(arr);
console.timeEnd('measure');
console.log(arr[0], arr[1]);



Quicksort


var length = 10000000; //  ten millions;
var arr = [];
for (let i = length; i > 0; i--) {
  // random array
  arr.push(parseInt(Math.random() * 1000000000));
}

function quickSort(arr, leftPos, rightPos, arrLength) {
  let initialLeftPos = leftPos;
  let initialRightPos = rightPos;
  let direction = true;
  let pivot = rightPos;
  while ((leftPos - rightPos) < 0) {
    if (direction) {
      if (arr[pivot] < arr[leftPos]) {
        quickSort.swap(arr, pivot, leftPos);
        pivot = leftPos;
        rightPos--;
        direction = !direction;
      } else
        leftPos++;
    } else {
      if (arr[pivot] <= arr[rightPos]) {
        rightPos--;
      } else {
        quickSort.swap(arr, pivot, rightPos);
        leftPos++;
        pivot = rightPos;
        direction = !direction;
      }
    }
  }
  if (pivot - 1 > initialLeftPos) {
    quickSort(arr, initialLeftPos, pivot - 1, arrLength);
  }
  if (pivot + 1 < initialRightPos) {
    quickSort(arr, pivot + 1, initialRightPos, arrLength);
  }
}
quickSort.swap = (arr, el1, el2) => {
  let swapedElem = arr[el1];
  arr[el1] = arr[el2];
  arr[el2] = swapedElem;
}
arrLength = arr.length;
console.time('measure');
quickSort(arr, 0, arrLength - 1, arrLength);
console.log(arr[0], arr[1]);
console.timeEnd('measure');



Native Javascript Sort


var length = 10000000; //  ten millions;
var arr = [];
for (let i = length; i > 0; i--) {
  // random array
  arr.push(parseInt(Math.random() * 100000000));
}

console.time('measure');
arr.sort(function compareNumbers(a, b) {
  return a - b;
});
console.timeEnd('measure');

console.log(arr[0], arr[1]);



",<javascript><node.js><algorithm><performance><sorting>,23,"javascript,node.js,algorithm,performance,sorting",['native javascript sort performing slower than implemented mergesort and quicksort'],"['ive implemented a mergesort and a quicksort to compare them with the native javascript sort', 'for the quicksort ive tried to use this algorithm view algorithm on youtube', 'both algorithms use as less memory as possible for the merge sort an auxiliary array is passed for each recursive call to avoid overheads and for the quicksort positions of the starting and ending positions', 'im using sorts to manage large amounts of data in a nodejs app', 'below you have the mergesort quicksort and native javascript sort and you can test the performance the question is why is the native javascript performing slower ', 'in my case chrome merge sort measure 1997920ms quicksort measure 1755740ms native measure 4988105ms node merge sort measure 2233413ms quicksort measure 1876055ms native measure 6317118ms merge sort var length 10000000 ten millions var arr for let i length i 0 i random array arrpushparseintmathrandom 1000000000 var mergesort functionarray function mergearr aux lo mid hi for var k lo k hi k auxk arrk var i lo var j mid 1 for var k lo k hi k if i mid arrk auxj else if j hi arrk auxi else if auxi auxj arrk auxi else arrk auxj function sortarray aux lo hi if hi lo return var mid mathfloorlo hi lo 2 sortarray aux lo mid sortarray aux mid 1 hi mergearray aux lo mid hi function mergesortarray var aux arrayslice0 sortarray aux 0 arraylength 1 return array return mergesortarray consoletimemeasure mergesortarr consoletimeendmeasure consolelogarr0 arr1 quicksort var length 10000000 ten millions var arr for let i length i 0 i random array arrpushparseintmathrandom 1000000000 function quicksortarr leftpos rightpos arrlength let initialleftpos leftpos let initialrightpos rightpos let direction true let pivot rightpos while leftpos rightpos 0 if direction if arrpivot arrleftpos quicksortswaparr pivot leftpos pivot leftpos rightpos direction direction else leftpos else if arrpivot arrrightpos rightpos else quicksortswaparr pivot rightpos leftpos pivot rightpos direction direction if pivot 1 initialleftpos quicksortarr initialleftpos pivot 1 arrlength if pivot 1 initialrightpos quicksortarr pivot 1 initialrightpos arrlength quicksortswap arr el1 el2 let swapedelem arrel1 arrel1 arrel2 arrel2 swapedelem arrlength arrlength consoletimemeasure quicksortarr 0 arrlength 1 arrlength consolelogarr0 arr1 consoletimeendmeasure native javascript sort var length 10000000 ten millions var arr for let i length i 0 i random array arrpushparseintmathrandom 100000000 consoletimemeasure arrsortfunction comparenumbersa b return a b consoletimeendmeasure consolelogarr0 arr1']"
I don't want my Excel Add-In to return an array (instead I need a UDF to change other cells),"I've created an Excel Add-In, and one of the functions of this Add-In, lets say New_Years currently takes in 2 years and outputs every New Years day between those 2 years as an array in Excel.  So New_Years(2000,2002) would return Jan 1st 2000, Jan 1st 2001, and Jan 1st 2002 in the last cell.
The problem is that I have to know there are going to be 3 dates in that time, select 3 cells, enter my formula in the top cell, and then hit Ctrl + Shift + Enter to fill out the array.
I use XLW version 5 to convert my C++ code to an .xll file.  I would really like it if there was some way I could just fill in one square with my formula, and Excel would fill in the squares below as needed with the appropriate dates.  Anyone know if this is possible?  Or impossible?
Many thanks!
",<c++><arrays><excel><add-in><excel-addins>,6,"c++,arrays,excel,add-in,excel-addins",['i dont want my excel addin to return an array instead i need a udf to change other cells'],"['ive created an excel addin and one of the functions of this addin lets say newyears currently takes in 2 years and outputs every new years day between those 2 years as an array in excel', 'so newyears20002002 would return jan 1st 2000 jan 1st 2001 and jan 1st 2002 in the last cell', 'the problem is that i have to know there are going to be 3 dates in that time select 3 cells enter my formula in the top cell and then hit ctrl shift enter to fill out the array', 'i use xlw version 5 to convert my c code to an xll file', 'i would really like it if there was some way i could just fill in one square with my formula and excel would fill in the squares below as needed with the appropriate dates', 'anyone know if this is possible', 'or impossible', 'many thanks']"
Running PowerShell from .NET Core,"Is there a way to run PowerShell scripts from .net-core ? 
I'm trying to run a PowerShell script in a new .net core 'website\api'.
From what I can tell in order to run PowerShell on .net we need to add the
System.Management.Automation namespace.
This isn't possible for .net core ( or I haven't found the appropriate way to add it).
There are a couple of NuGet packages which are also aimed at adding this DLL to project but those aren't compatible with .net core either.
Is there a way to do this on .net core ? 
Here are some links I've tried but none of them are .net core specific:
http://www.powershellmagazine.com/2014/03/18/writing-a-powershell-module-in-c-part-1-the-basics/
Referencing system.management.automation.dll in Visual Studio
https://www.nuget.org/packages/System.Management.Automation/
",<c#><.net><powershell><asp.net-core><.net-core>,41,"c#,.net,powershell,asp.net-core,.net-core",['running powershell from net core'],"['is there a way to run powershell scripts from netcore ', 'im trying to run a powershell script in a new net core websiteapi', 'from what i can tell in order to run powershell on net we need to add the systemmanagementautomation namespace', 'this isnt possible for net core or i havent found the appropriate way to add it', 'there are a couple of nuget packages which are also aimed at adding this dll to project but those arent compatible with net core either', 'is there a way to do this on net core ', 'here are some links ive tried but none of them are net core specific referencing systemmanagementautomationdll in visual studio']"
How to handle RESTful update of remote server with SyncAdapter,"I've watched the Google I/O REST talk and read the slides: http://www.google.com/events/io/2010/sessions/developing-RESTful-android-apps.html
I'm still a bit unclear on how to nicely handle, say, an update error thrown by the remote server. I have implemented my own ContentProvider and SyncAdapter. Consider this scenario:
Update a user's Contact Details via REST call:

Request an update using a ContentResolver. 
My ContentProvider immediately updates the app's local Sqlite database and requests a Sync (as per recommendations in the Google I/O talk).
My SyncAdapter.onPerformSync() is called and does a REST call to update the remote data.
Remote server responds with ""ERROR: Invalid Phone Number"" (for instance).

My question is, what is the best way for the SyncAdapter to signal to my ContentProvider that this change needs to be backed out of the app's local database, and to also signal to my Activity that the update request failed (and pass the error messages returned from the Server)?
My activity needs to display a progress spinner while waiting for the result, and know whether the request succeeded or failed.

For updating the local app database with content from the Server, the SyncAdapter pattern makes complete sense to me, and I have that working fine. But for updates from the app to the server, I can't seem to find a nice way to handle the above scenario.

And another thing... ;)
Say I call ContentResolver.notifyChange(uri, null, true); from within my ContentProvider's update() method. true along with android:supportsUploading=""true"" will cause my SyncAdapter's onPerformSync() to be called. Great, but inside onPerformSync(), how do I tell what URI I should sync? I don't want to simply refresh my entire DB every time I get a Sync request. But you can't even pass a Bundle into the notifyChangeCall() to be passed on to onPerformSync().
All the examples I've seen of onPerformSync() have been so simple, and not using a custom ContentProvider, any real world examples out there? And the docs are a bit of a bird's nest. Virgil Dobjanschi, Sir, you've left me up the creek without a paddle.
",<android><rest><synchronization><android-contentprovider><android-syncadapter>,21,"android,rest,synchronization,android-contentprovider,android-syncadapter",['how to handle restful update of remote server with syncadapter'],"['ive watched the google io rest talk and read the slides im still a bit unclear on how to nicely handle say an update error thrown by the remote server', 'i have implemented my own contentprovider and syncadapter', 'consider this scenario update a users contact details via rest call request an update using a contentresolver', 'my contentprovider immediately updates the apps local sqlite database and requests a sync as per recommendations in the google io talk', 'my syncadapteronperformsync is called and does a rest call to update the remote data', 'remote server responds with error invalid phone number for instance', 'my question is what is the best way for the syncadapter to signal to my contentprovider that this change needs to be backed out of the apps local database and to also signal to my activity that the update request failed and pass the error messages returned from the server', 'my activity needs to display a progress spinner while waiting for the result and know whether the request succeeded or failed', 'for updating the local app database with content from the server the syncadapter pattern makes complete sense to me and i have that working fine', 'but for updates from the app to the server i cant seem to find a nice way to handle the above scenario', 'and another thing say i call contentresolvernotifychangeuri null true from within my contentproviders update method', 'true along with androidsupportsuploadingtrue will cause my syncadapters onperformsync to be called', 'great but inside onperformsync how do i tell what uri i should sync', 'i dont want to simply refresh my entire db every time i get a sync request', 'but you cant even pass a bundle into the notifychangecall to be passed on to onperformsync', 'all the examples ive seen of onperformsync have been so simple and not using a custom contentprovider any real world examples out there', 'and the docs are a bit of a birds nest', 'virgil dobjanschi sir youve left me up the creek without a paddle']"
Does the last element in a loop deserve a separate treatment?,"When reviewing, I sometimes encounter this kind of loop:
i = begin
while ( i != end ) {    
   // ... do stuff
   if ( i == end-1 (the one-but-last element) ) {
      ... do other stuff
   }
   increment i
}

Then I ask the question: would you write this?
i = begin
mid = ( end - begin ) / 2 // (the middle element)
while ( i != end ) {    
   // ... do stuff
   if ( i > mid ) {
      ... do other stuff
   }
   increment i
}

In my opinion, this beats the intention of writing a loop: you loop because there is something common to be done for each of the elements.  Using this construct, for some of the elements you do something different.  So, I conclude, you need a separate loop for those elements:
i = begin
mid = ( end - begin ) / 2 //(the middle element)
while ( i != mid ) {    
   // ... do stuff
   increment i
}

while ( i != end ) {
   // ... do stuff
   // ... do other stuff
   increment i
}

Now I even saw a question on SO on how to write the if-clause in a nice way...  And I got sad: something isn't right here.
Am I wrong?  If so, what's so good about cluttering the loop body with special cases, which you are aware of upfront, at coding time?
",<language-agnostic><loops><for-loop><while-loop><control-structure>,20,"language-agnostic,loops,for-loop,while-loop,control-structure",['does the last element in a loop deserve a separate treatment'],"['when reviewing i sometimes encounter this kind of loop i begin while i end do stuff if i end1 the onebutlast element do other stuff increment i then i ask the question would you write this', 'i begin mid end begin 2 the middle element while i end do stuff if i mid do other stuff increment i in my opinion this beats the intention of writing a loop you loop because there is something common to be done for each of the elements', 'using this construct for some of the elements you do something different', 'so i conclude you need a separate loop for those elements i begin mid end begin 2 the middle element while i mid do stuff increment i while i end do stuff do other stuff increment i now i even saw a question on so on how to write the ifclause in a nice way and i got sad something isnt right here', 'am i wrong', 'if so whats so good about cluttering the loop body with special cases which you are aware of upfront at coding time']"
Firebase observeSingleEvent stays in memory,"My app uses firebase's observeSingleEventOfType quite a fair bit and I came to realise that my app's memory increase over time. I have commented out all my code except a test button that calls the following function. 
func loadPostsTest() {
    FIRDatabase.database().reference().child(""posts"").observeSingleEventOfType(.Value, withBlock: { (snapshot: FIRDataSnapshot) in
        print(snapshot.value)
    })
}

When the program starts, I hit the test button at a fast speed approximately 2,3 times a second and observed the memory graph as shown below. The memory goes up and doesn't come back down after the request. This issue is effecting my app quite a fair bit in the long run as my app's memory would grow from 70mb to 150+mb because of that. Any reason for this?
Note, the short five second rest was me stopping to ensure that all ""snapshots"" are printed out. 
Note 2... When I stop pressing the button, the memory remains at the same level as shown in the ""short rest section"". Just incase you think that it grows by itself indefinitely

-------UPDATE----------
To further confirm the problem, I have create a brand new project with nothing in it but firebase import, a button in the story board with the following code and simulated on my 6s (Simulating on simulator does not appear to have this problem). Image below proves that there is something fishy going on here with firebase as my memory went from 11.1mb to 17.3mb with 303 requests within a minute or so.

import UIKit
import Firebase

class ViewController: UIViewController {

var count: Int = 0

override func viewDidLoad() {
    super.viewDidLoad()
    // Do any additional setup after loading the view, typically from a nib.
}

@IBAction func testBtnPressed(sender: AnyObject) {
    FIRDatabase.database().reference().child(""posts"").observeSingleEventOfType(.Value, withBlock: {[weak self] (snapshot: FIRDataSnapshot) in
        print(self?.count)
        self?.count += 1
    })
}

",<ios><swift><xcode><firebase><firebase-realtime-database>,26,"ios,swift,xcode,firebase,firebase-realtime-database",['firebase observesingleevent stays in memory'],"['my app uses firebases observesingleeventoftype quite a fair bit and i came to realise that my apps memory increase over time', 'i have commented out all my code except a test button that calls the following function', 'func loadpoststest firdatabasedatabasereferencechildpostsobservesingleeventoftypevalue withblock snapshot firdatasnapshot in printsnapshotvalue when the program starts i hit the test button at a fast speed approximately 23 times a second and observed the memory graph as shown below', 'the memory goes up and doesnt come back down after the request', 'this issue is effecting my app quite a fair bit in the long run as my apps memory would grow from 70mb to 150mb because of that', 'any reason for this', 'note the short five second rest was me stopping to ensure that all snapshots are printed out', 'note 2 when i stop pressing the button the memory remains at the same level as shown in the short rest section', 'just incase you think that it grows by itself indefinitely update to further confirm the problem i have create a brand new project with nothing in it but firebase import a button in the story board with the following code and simulated on my 6s simulating on simulator does not appear to have this problem', 'image below proves that there is something fishy going on here with firebase as my memory went from 111mb to 173mb with 303 requests within a minute or so', 'import uikit import firebase class viewcontroller uiviewcontroller var count int 0 override func viewdidload superviewdidload do any additional setup after loading the view typically from a nib ', 'ibaction func testbtnpressedsender anyobject firdatabasedatabasereferencechildpostsobservesingleeventoftypevalue withblock weak self snapshot firdatasnapshot in printselfcount selfcount 1 ']"
Syntax Error: Support for the experimental syntax 'jsx' isn't currently enabled in react js,"i am trying run my react application using npm start commamnd and installed both @babel/preset-react and @babel/plugin-syntax-jsx. but i am running this react application getting following error.
Support for the experimental syntax 'jsx' isn't currently enabled (7:9):
   6 | const PostCodeLookup = props => {
>  7 |  return <PostcodeLookup {...props} />
     |         ^
   8 |
   9 | };
  

Add @babel/preset-react (https://git.io/JfeDR) to the 'presets' section of your Babel config to enable transformation.
If you want to leave it as-is, add @babel/plugin-syntax-jsx (https://git.io/vb4yA) to the 'plugins' section to enable parsing.
",<reactjs><plugins><babeljs><jsx><preset>,5,"reactjs,plugins,babeljs,jsx,preset",['syntax error support for the experimental syntax jsx isnt currently enabled in react js'],"['i am trying run my react application using npm start commamnd and installed both babelpresetreact and babelpluginsyntaxjsx', 'but i am running this react application getting following error', 'support for the experimental syntax jsx isnt currently enabled 79 6 const postcodelookup props 7 return postcodelookup props 8 9 add babelpresetreact to the presets section of your babel config to enable transformation', 'if you want to leave it asis add babelpluginsyntaxjsx to the plugins section to enable parsing']"
Set priority to GUI thread in Qt,"Is it possible to set priority to the main GUI thread so it has higher priority comparing to the other threads (QThread)?
My aim is to not to freeze up the GUI while the other threads are doing some intensive computation which may occupy CPU to 100% load. It would be great if someone can share a way to make sure GUI will not freeze during this period while the other computation threads can still try to maximize the CPU usage.
I thought about managing other threads, so I don't start too many computation threads at the same time.
",<c++><multithreading><qt><user-interface><qthread>,14,"c++,multithreading,qt,user-interface,qthread",['set priority to gui thread in qt'],"['is it possible to set priority to the main gui thread so it has higher priority comparing to the other threads qthread', 'my aim is to not to freeze up the gui while the other threads are doing some intensive computation which may occupy cpu to 100 load', 'it would be great if someone can share a way to make sure gui will not freeze during this period while the other computation threads can still try to maximize the cpu usage', 'i thought about managing other threads so i dont start too many computation threads at the same time']"
Handling atexit for multiple app objects with Flask dev server reloader,"This is yet another flask dev server reloader question. There are a million questions asking why it loads everything twice, and this is not one of them. I understand that it loads everything twice, my question involves dealing with this reality and I haven't found an answer that I think addresses what I'm trying to do.
My question is, how can I cleanup all app objects at exit? 
My current approach is shown below. In this example I run my cleanup code using an atexit function. 
from flask import Flask

app = Flask(__name__)
print(""start_app_id: "", '{}'.format(id(app)))

import atexit
@atexit.register
def shutdown():
    print(""AtExit_app_id: "", '{}'.format(id(app)))
    #do some cleanup on the app object here

if __name__ == ""__main__"":
    import os
    if os.environ.get('WERKZEUG_RUN_MAIN') == ""true"":
        print(""reloaded_main_app_id: "", '{}'.format(id(app)))
    else:
        print(""first_main_app_id: "", '{}'.format(id(app)))

    app.run(host='0.0.0.0', debug=True)

The output of this code is as follows:
start_app_id:  140521561348864
first_main_app_id:  140521561348864
 * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)
 * Restarting with stat
start_app_id:  140105598483312
reloaded_main_app_id:  140105598483312
 * Debugger is active!
 * Debugger pin code: xxx-xxx-xxx
^CAtExit_app_id:  140521561348864

Note that when first loaded, an app object with ID '864 is created. During the automatic reloading, a new app object with ID '312 is created. Then when I hit Ctrl-C (last line), the atexit routine is called and the original '864 app object is the one that is accessible using the app variable -- not the newer '312 app object.
I want to be able to do cleanup on all app objects floating around when the server closes or is Ctrl-C'd (in this case both '864 and '312). Any recs on how to do this?
Or alternately, if I could just run the cleanup on the newer '312 object created after reloading I could also make that work -- however my current approach only lets me cleanup the original app object.
Thanks.
UPDATE1: I found a link that suggested using try/finally instead of the atexit hook to accomplish what I set out to do above. Switching to this results in exactly the same behavior as atexit and therefore doesn't help with my issue:
from flask import Flask

app = Flask(__name__)
print(""start_app_id: "", '{}'.format(id(app)))

if __name__ == ""__main__"":
    import os
    if os.environ.get('WERKZEUG_RUN_MAIN') == ""true"":
        print(""reloaded_main_app_id: "", '{}'.format(id(app)))
    else:
        print(""first_main_app_id: "", '{}'.format(id(app)))

    try:
        app.run(host='0.0.0.0', debug=True)
    finally:
        print(""Finally_app_id: "", '{}'.format(id(app)))
        #do app cleanup code here

",<python-3.x><flask><resource-cleanup><atexit><devserver>,5,"python-3.x,flask,resource-cleanup,atexit,devserver",['handling atexit for multiple app objects with flask dev server reloader'],"['this is yet another flask dev server reloader question', 'there are a million questions asking why it loads everything twice and this is not one of them', 'i understand that it loads everything twice my question involves dealing with this reality and i havent found an answer that i think addresses what im trying to do', 'my question is how can i cleanup all app objects at exit', 'my current approach is shown below', 'in this example i run my cleanup code using an atexit function', 'from flask import flask app flaskname printstartappid formatidapp import atexit atexitregister def shutdown printatexitappid formatidapp do some cleanup on the app object here if name main import os if osenvirongetwerkzeugrunmain true printreloadedmainappid formatidapp else printfirstmainappid formatidapp apprunhost0000 debugtrue the output of this code is as follows startappid 140521561348864 firstmainappid 140521561348864 running on press ctrlc to quit restarting with stat startappid 140105598483312 reloadedmainappid 140105598483312 debugger is active', ' debugger pin code xxxxxxxxx catexitappid 140521561348864 note that when first loaded an app object with id 864 is created', 'during the automatic reloading a new app object with id 312 is created', 'then when i hit ctrlc last line the atexit routine is called and the original 864 app object is the one that is accessible using the app variable not the newer 312 app object', 'i want to be able to do cleanup on all app objects floating around when the server closes or is ctrlcd in this case both 864 and 312', 'any recs on how to do this', 'or alternately if i could just run the cleanup on the newer 312 object created after reloading i could also make that work however my current approach only lets me cleanup the original app object', 'thanks', 'update1 i found a link that suggested using tryfinally instead of the atexit hook to accomplish what i set out to do above', 'switching to this results in exactly the same behavior as atexit and therefore doesnt help with my issue from flask import flask app flaskname printstartappid formatidapp if name main import os if osenvirongetwerkzeugrunmain true printreloadedmainappid formatidapp else printfirstmainappid formatidapp try apprunhost0000 debugtrue finally printfinallyappid formatidapp do app cleanup code here']"
Global Keyboard intercept input,"I currently am able capture keyboard inputs while the program is not in focus using this solution.
Using global keyboard hook (WH_KEYBOARD_LL) in WPF / C#
I however want to know whether it is possible to stop other applications from using the input if it matches certain criteria, I would like to use it to capture bar-codes into my program while it runs in the background, but if you are working in notepad, the bar-code should preferably not be typed there as well.
I've added the following but the characters are still added to notepad as well.
if (nCode >= 0)
{
   if (wParam == (IntPtr)InterceptKeys.WM_KEYDOWN)
   {
      int vkCode = Marshal.ReadInt32(lParam);
      RawKeyEventArgs rk = new RawKeyEventArgs(vkCode, false);                    

      if (KeyDown != null)
         KeyDown(this, rk);
      if (rk.isHandled)
      {
         return (IntPtr)0;
      }
   }
}

return InterceptKeys.CallNextHookEx(hookId, nCode, wParam, lParam);

Is the return supposed to be something different?
",<c#><wpf><keyboard><hook><barcode-scanner>,5,"c#,wpf,keyboard,hook,barcode-scanner",['global keyboard intercept input'],"['i currently am able capture keyboard inputs while the program is not in focus using this solution', 'using global keyboard hook whkeyboardll in wpf c i however want to know whether it is possible to stop other applications from using the input if it matches certain criteria i would like to use it to capture barcodes into my program while it runs in the background but if you are working in notepad the barcode should preferably not be typed there as well', 'ive added the following but the characters are still added to notepad as well', 'if ncode 0 if wparam intptrinterceptkeyswmkeydown int vkcode marshalreadint32lparam rawkeyeventargs rk new rawkeyeventargsvkcode false if keydown null keydownthis rk if rkishandled return intptr0 return interceptkeyscallnexthookexhookid ncode wparam lparam is the return supposed to be something different']"
ASP.NET - best queue system for a new application,"My organization is getting ready to implement a new system, which is a asp.net application.  The application will have a large queue of offline work that is initiated by the website.  This queue will hold different types of activity, ideally in XML messages.  Think of things like email notifications, scheduled tasks, etc.
In the past, the organization would likely have used MSMQ to accomplish this task.  However, they consider MSMQ to be old school (and I partly agree with them), so we are going to do an architectural review to determine the ""best"" solution.
In my mind, there are a few potential choices:
 1. Stick with a new implementation on the latest version of MSMQ - not ideal, but a known product.
 2. Use Windows Workflow Foundation, which I've heard from a few other developers that have used this for this type of thing.
 3. Develop a custom database solution.
Am I missing any obvious solutions?  This ideally will be a Microsoft product, but really just needs to work in a Microsoft centric shop.
I'm concerned about the following:
 1. Ease of implementation and maintenance
 2. A solution which will be around for awhile
 3. Able to handle a good volume of rows, with medium sized XML data in them
 4. Absolutely reliable queue system, with quick updating (multiple utility processes will likely be grabbing records out of the queue to process them).
",<.net><workflow-foundation><queue><msmq><message-queue>,9,".net,workflow-foundation,queue,msmq,message-queue",['aspnet best queue system for a new application'],"['my organization is getting ready to implement a new system which is a aspnet application', 'the application will have a large queue of offline work that is initiated by the website', 'this queue will hold different types of activity ideally in xml messages', 'think of things like email notifications scheduled tasks etc', 'in the past the organization would likely have used msmq to accomplish this task', 'however they consider msmq to be old school and i partly agree with them so we are going to do an architectural review to determine the best solution', 'in my mind there are a few potential choices 1 stick with a new implementation on the latest version of msmq not ideal but a known product', '2 use windows workflow foundation which ive heard from a few other developers that have used this for this type of thing', '3 develop a custom database solution', 'am i missing any obvious solutions', 'this ideally will be a microsoft product but really just needs to work in a microsoft centric shop', 'im concerned about the following 1 ease of implementation and maintenance 2 a solution which will be around for awhile 3 able to handle a good volume of rows with medium sized xml data in them 4 absolutely reliable queue system with quick updating multiple utility processes will likely be grabbing records out of the queue to process them']"
Javascript: Cast Math.sqrt to int?,"I've searched through google (maybe I didn't look hard enough) but I could not find how to turn Math.sqrt into an int.
I want to use Math.sqrt for a for loop and I guess I need it as an int but I can't seem to figure out how to cast the result to an int.  So how do I do it?
I tried something similar to Java:
(int) Math.sqrt(num);

But it didn't work.
Thanks in advance :)
",<javascript><math><type-conversion><int><casting>,12,"javascript,math,type-conversion,int,casting",['javascript cast mathsqrt to int'],"['ive searched through google maybe i didnt look hard enough but i could not find how to turn mathsqrt into an int', 'i want to use mathsqrt for a for loop and i guess i need it as an int but i cant seem to figure out how to cast the result to an int', 'so how do i do it', 'i tried something similar to java int mathsqrtnum but it didnt work', 'thanks in advance ']"
How to backup Anaconda added packages?,"I have Anaconda for Python 2, It came packed with a lot of useful packages. During my work, I have added several packages to it using conda install command. Now I have to format my system, and I want to backup/pack all the added libraries, either as full packages or even by knowing the installation command of each one.
I searched StackOverflow, I found one unanswered question with a similar problem, the question suggested conda list -e >file_list.txt to create a file contains all the installed packages, but this is not sufficient for me, I want Anaconda to determine which package is added by me, and by which command, or to pack the added packages in full. 
Thanks for help.
",<python><backup><anaconda><conda><install.packages>,8,"python,backup,anaconda,conda,install.packages",['how to backup anaconda added packages'],"['i have anaconda for python 2 it came packed with a lot of useful packages', 'during my work i have added several packages to it using conda install command', 'now i have to format my system and i want to backuppack all the added libraries either as full packages or even by knowing the installation command of each one', 'i searched stackoverflow i found one unanswered question with a similar problem the question suggested conda list e filelisttxt to create a file contains all the installed packages but this is not sufficient for me i want anaconda to determine which package is added by me and by which command or to pack the added packages in full', 'thanks for help']"
mscorlib not found when building Xamarin.Android project with CakeBuild,"I'm in the process of integrating a Xamarin Android project into our CI pipeline. We already use CakeBuild for other .NET projects and so I wanted to use it here, as well.
The problem is that I always get the following error message when trying to build with Cake:

C:\Program Files (x86)\MSBuild\Xamarin\Android\Xamarin.Android.Common.targets(406,2): error : Could not load assembly
   'mscorlib, Version=0.0.0.0, Culture=neutral, PublicKeyToken='. Perhaps it doesn't exist in the Mono for Android profile? [C:\[myproject].csproj]

Building works in Visual Studio 2015 and using the Visual Studio Developer Command Prompt. Because of this, I was thinking it had something to do with the environment variables that are set in VS and via the VS command prompt. So what I did was make a small batch file:
call ""%vs140comntools%vsvars32.bat""
Powershell.exe ./build.ps1 -Target Build

But I'm getting the exact same error. In my projects, there is no explicit reference to mscorlib.
The Cake build task looks like this:
Task(""Build"")
.IsDependentOn(""Restore-NuGet-Packages"")
.Does(() =>
{
    var settings = new MSBuildSettings()
    {
        ArgumentCustomization = args =>
        {
            args = args.Append(""/t:PackageForAndroid"");
            args = args.Append(""/p:TargetFrameworkRootPath=\""C:\\Program Files (x86)\\Reference Assemblies\\Microsoft\\Framework\"""");
            return args;
        },
        Verbosity = Verbosity.Normal
    };
    settings.SetConfiguration(configuration);
    MSBuild(""../myproject.csproj"", settings);    
});

I had to add the TargetFrameworkRootPath because it won't find the reference assemblies if I do not set it explicitly.
I'm wondering what else to do to replicate the build environment of VS / VS command prompt.
",<c#><android><xamarin><msbuild><cakebuild>,5,"c#,android,xamarin,msbuild,cakebuild",['mscorlib not found when building xamarinandroid project with cakebuild'],"['im in the process of integrating a xamarin android project into our ci pipeline', 'we already use cakebuild for other net projects and so i wanted to use it here as well', 'the problem is that i always get the following error message when trying to build with cake cprogram files x86msbuildxamarinandroidxamarinandroidcommontargets4062 error could not load assembly mscorlib version0000 cultureneutral publickeytoken', 'perhaps it doesnt exist in the mono for android profile', 'cmyprojectcsproj building works in visual studio 2015 and using the visual studio developer command prompt', 'because of this i was thinking it had something to do with the environment variables that are set in vs and via the vs command prompt', 'so what i did was make a small batch file call vs140comntoolsvsvars32bat powershellexe buildps1 target build but im getting the exact same error', 'in my projects there is no explicit reference to mscorlib', 'the cake build task looks like this taskbuild isdependentonrestorenugetpackages does var settings new msbuildsettings argumentcustomization args args argsappendtpackageforandroid args argsappendptargetframeworkrootpathcprogram files x86reference assembliesmicrosoftframework return args verbosity verbositynormal settingssetconfigurationconfiguration msbuildmyprojectcsproj settings i had to add the targetframeworkrootpath because it wont find the reference assemblies if i do not set it explicitly', 'im wondering what else to do to replicate the build environment of vs vs command prompt']"
overly patches which represent the significants points over contour map,"I am trying to add hatching (like dots, hashes, .. ) over contour map. Such hatching could represent the only the statistically significant contours, or contours with certain criteria. Like the following image on nature article (second and third plot) http://www.nature.com/articles/srep16853/figures/3. 
The following code show plot of precipitation from NOAA data available for download at. 
import numpy as np
import sys 
import netCDF4 as nc
import matplotlib.pyplot as plt
import matplotlib.mlab as m 
import mpl_toolkits.basemap as bm
import os
sys.path.insert(0, '../');import py4met as sm;reload(sm)

#- Reading data for a timeslice, latitude, and longitude:
diri_output=""./""
diri=""./""
tmp_file = nc.Dataset(diri+""precip.mon.mean.nc"",""r"")
print(tmp_file.variables)
p_pre   = tmp_file.variables['precip']
lat     = tmp_file.variables['lat'][:]
lon     = tmp_file.variables['lon'][:]
time    = tmp_file.variables['time']
tmp_file.close


lat1=np.min(lat)
lat2=np.max(lat)
lon1=np.min(lon)
lon2=np.max(lon)

[lonall, latall] = np.meshgrid(lon[:], lat[:])
plt.figure(num=None, figsize=(8+4, 6+4), dpi=80, facecolor='w', edgecolor='k')    
mapproj = bm.Basemap(projection='cyl',llcrnrlat=lat1, llcrnrlon=lon1,urcrnrlat=lat2, urcrnrlon=lon2,resolution='l')
mapproj.drawcoastlines()
mapproj.drawmapboundary(fill_color='white')
mapproj.drawcountries()
x, y = mapproj(lonall, latall)
plt.contourf(x,y,p_pre[240,:,:],cmap=plt.cm.GnBu)
plt.colorbar(orientation='horizontal',pad=0.05,shrink=0.6)
plt.title(""title"")
xx,yy=np.where(p_pre[240,:,:] >= 20)
sig=np.copy(p_pre[0,:,:])
sig[:,:]=1
sig[xx,yy]=0
#plt.contourf(x,y,sig,hatches=['.'])
plt.show()  

I want to hatch all contours above 20 mm, so I used the above command  

plt.contourf(x,y,sig,hatches=['.'])

but it didn’t work (it make dotes everywhere on the map and not only contours with specific criteria), thus I commented it. 
Any ideas.
",<python><matplotlib><statistics><contour><anova>,5,"python,matplotlib,statistics,contour,anova",['overly patches which represent the significants points over contour map'],"['i am trying to add hatching like dots hashes over contour map', 'such hatching could represent the only the statistically significant contours or contours with certain criteria', 'like the following image on nature article second and third plot the following code show plot of precipitation from noaa data available for download at', 'import numpy as np import sys import netcdf4 as nc import matplotlibpyplot as plt import matplotlibmlab as m import mpltoolkitsbasemap as bm import os syspathinsert0 import py4met as smreloadsm reading data for a timeslice latitude and longitude dirioutput diri tmpfile ncdatasetdiriprecipmonmeanncr printtmpfilevariables ppre tmpfilevariablesprecip lat tmpfilevariableslat lon tmpfilevariableslon time tmpfilevariablestime tmpfileclose lat1npminlat lat2npmaxlat lon1npminlon lon2npmaxlon lonall latall npmeshgridlon lat pltfigurenumnone figsize84 64 dpi80 facecolorw edgecolork mapproj bmbasemapprojectioncylllcrnrlatlat1 llcrnrlonlon1urcrnrlatlat2 urcrnrlonlon2resolutionl mapprojdrawcoastlines mapprojdrawmapboundaryfillcolorwhite mapprojdrawcountries x y mapprojlonall latall pltcontourfxyppre240cmappltcmgnbu pltcolorbarorientationhorizontalpad005shrink06 plttitletitle xxyynpwhereppre240 20 signpcopyppre0 sig1 sigxxyy0 pltcontourfxysighatches', 'pltshow i want to hatch all contours above 20 mm so i used the above command pltcontourfxysighatches', 'but it didnt work it make dotes everywhere on the map and not only contours with specific criteria thus i commented it', 'any ideas']"
Best approach for dealing with time measures?,"My goal is to write a framework for measuring method execution or transaction time and for processing the measurements, i.e. storing, analysis etc. Transaction may include calls to external systems, with synchronously or asynchronously waiting for the results.
There already have been some questions around that topic, like 

""How do I time a method's execution"" 
""Measure execution time for a Java method"" 
""System.currentTimeMillis vs System.nanoTime""

And all the answers boil down to three approaches for taking the time

System.currentTimeMillis()
System.nanoTime()
Instant.now() and Duration(since Java 8)

I know, all of these have some implications
System.currentTimeMillis()
The result of this method depends on the platform. On Linux you get 1ms resolution, of Windows you get 10ms (single core) ~15ms (multi core). So it's ok for measuring large running operations or multiple executions of short running ops.
System.nanoTime()
You get a high resolution time measure, with nano second precision (but not necessarily nano second accuracy) and you get an overflow after 292 years (I could live with that).
Instant.now() and Duration
Since Java 8 there is the new time API. An instant has a second and a nano second field, so it uses on top of the Object reference two long values (same for Duration). You also get nano second precision, depending on the underlying clock (see ""Java 8 Instant.now() with nanosecond resolution?""). The instantiaion is done by invoking Instant.now() which maps down to System.currentTimeMillis() for the normal System clock.
Given the facts, it becomes apparent, that best precision is only achievable with System.nanoTime(), but my question targets more towards a best-practice for dealing with the measures in general, which not only includes the measure taking but also the measure handling.

Instant and Duration provide best API support (calculating, comparing, etc) but have os-dependend precision in standard case, and more overhead for memory and creating a measure (Object construction, deeper callstack)
System.nanoTime() and System.currentTimeMillis() have different levels of precision but only have basic ""api"" support (math operations on long), but are faster to get and smaller to keep in memory.

So what would be the best approach? Are there any implications I didn't think of? Are there any alternatives?
",<java><performance><time><java-8><timing>,11,"java,performance,time,java-8,timing",['best approach for dealing with time measures'],"['my goal is to write a framework for measuring method execution or transaction time and for processing the measurements ie', 'storing analysis etc', 'transaction may include calls to external systems with synchronously or asynchronously waiting for the results', 'there already have been some questions around that topic like how do i time a methods execution measure execution time for a java method systemcurrenttimemillis vs systemnanotime and all the answers boil down to three approaches for taking the time systemcurrenttimemillis systemnanotime instantnow and durationsince java 8 i know all of these have some implications systemcurrenttimemillis the result of this method depends on the platform', 'on linux you get 1ms resolution of windows you get 10ms single core 15ms multi core', 'so its ok for measuring large running operations or multiple executions of short running ops', 'systemnanotime you get a high resolution time measure with nano second precision but not necessarily nano second accuracy and you get an overflow after 292 years i could live with that', 'instantnow and duration since java 8 there is the new time api', 'an instant has a second and a nano second field so it uses on top of the object reference two long values same for duration', 'you also get nano second precision depending on the underlying clock see java 8 instantnow with nanosecond resolution', 'the instantiaion is done by invoking instantnow which maps down to systemcurrenttimemillis for the normal system clock', 'given the facts it becomes apparent that best precision is only achievable with systemnanotime but my question targets more towards a bestpractice for dealing with the measures in general which not only includes the measure taking but also the measure handling', 'instant and duration provide best api support calculating comparing etc but have osdependend precision in standard case and more overhead for memory and creating a measure object construction deeper callstack systemnanotime and systemcurrenttimemillis have different levels of precision but only have basic api support math operations on long but are faster to get and smaller to keep in memory', 'so what would be the best approach', 'are there any implications i didnt think of', 'are there any alternatives']"
Cocoa-Touch – Delegate confusion,"I just started a new project running Xcode 4.2.1 and iOS5 SDK. The project is setup with ARC. I'm trying to set the AppDelegate to be the delegate for UITabBarController by doing [tabBarController setDelegate:self]; if I do that I get a warning message saying: 
warning: Semantic Issue: Sending 'AppDelegate *const __strong' to parameter of incompatible type 'id<UITabBarControllerDelegate>'

Alright fair enough, I set my AppDelegate to conform to the UITabBarControllerDelegate by doing 
@interface AppDelegate : UIResponder <UIApplicationDelegate, UITabBarControllerDelegate>

Great, the warning goes away.
I now get another error. In a view controller I want to get a hold of the AppDelegate so I do this: AppDelegate *appDelegate = [[UIApplication sharedApplication] delegate]; but this will render a warning saying:
warning: Semantic Issue: Initializing 'AppDelegate *__strong' with an expression of incompatible type 'id<UIApplicationDelegate>'

But if I remove that my AppDelegate conforms to the UITabControllerDelegate protocol my second warning disappears.
Very strange behaviour, what gives Cocoa experts?
",<objective-c><cocoa-touch><delegates><automatic-ref-counting><uiapplicationdelegate>,27,"objective-c,cocoa-touch,delegates,automatic-ref-counting,uiapplicationdelegate",['cocoatouch delegate confusion'],"['i just started a new project running xcode 421 and ios5 sdk', 'the project is setup with arc', 'im trying to set the appdelegate to be the delegate for uitabbarcontroller by doing tabbarcontroller setdelegateself if i do that i get a warning message saying warning semantic issue sending appdelegate const strong to parameter of incompatible type iduitabbarcontrollerdelegate alright fair enough i set my appdelegate to conform to the uitabbarcontrollerdelegate by doing interface appdelegate uiresponder uiapplicationdelegate uitabbarcontrollerdelegate great the warning goes away', 'i now get another error', 'in a view controller i want to get a hold of the appdelegate so i do this appdelegate appdelegate uiapplication sharedapplication delegate but this will render a warning saying warning semantic issue initializing appdelegate strong with an expression of incompatible type iduiapplicationdelegate but if i remove that my appdelegate conforms to the uitabcontrollerdelegate protocol my second warning disappears', 'very strange behaviour what gives cocoa experts']"
Is it possible to make querySelectorAll live like getElementsByTagName?,"getElementsByTagName() has 2 great features: it is fast and it is live. But what if I want to get p strong. Of course I could refine a selection using getElementsByTagName() again but wouldn't I lose the live effect for the new p tags?
Is there a way to turn querySelectorAll into a live selector?
Or... is there a way to use getElementsByTagName() and getElementsByClassName() to create a function that works in a similar way (at least with descendants) as querySelectorAll but being live?
",<javascript><dom><css-selectors><getelementsbytagname><selectors-api>,16,"javascript,dom,css-selectors,getelementsbytagname,selectors-api",['is it possible to make queryselectorall live like getelementsbytagname'],"['getelementsbytagname has 2 great features it is fast and it is live', 'but what if i want to get p strong', 'of course i could refine a selection using getelementsbytagname again but wouldnt i lose the live effect for the new p tags', 'is there a way to turn queryselectorall into a live selector', 'or is there a way to use getelementsbytagname and getelementsbyclassname to create a function that works in a similar way at least with descendants as queryselectorall but being live']"
Air iOS SharedObject deleted after updating,"I'm using SharedObjects in my game to store the progress of the player in the game (level scores, unlocked levels, etc.).
Everything is working fine, but the problem is when I submitted an update of the game (with the same certificates and the same names of the .swf and .ipa files) when the game is updated the old SharedObject is deleted and this is very big problem for the game and for me.
Both versions of the game are made with Flash CS 6 and Air SDK 3.5. 
Any idea why the SharedObject is deleted, how can I prevent that?
",<ios><actionscript-3><flash><air><shared-objects>,5,"ios,actionscript-3,flash,air,shared-objects",['air ios sharedobject deleted after updating'],"['im using sharedobjects in my game to store the progress of the player in the game level scores unlocked levels etc', 'everything is working fine but the problem is when i submitted an update of the game with the same certificates and the same names of the swf and ipa files when the game is updated the old sharedobject is deleted and this is very big problem for the game and for me', 'both versions of the game are made with flash cs 6 and air sdk 35 any idea why the sharedobject is deleted how can i prevent that']"
What does #/ means in url?,"I am working on ROR web apps. My webpage url looks like below-
http://dev.ibiza.jp:3000/facebook/report?advertiser_id=2102#/dashboard

Here I understood that advertiser_id is 2102 but I couldn't understand what #/dashboard is pointing to?
",<html><ruby-on-rails><angularjs><web><fragment-identifier>,19,"html,ruby-on-rails,angularjs,web,fragment-identifier",['what does means in url'],"['i am working on ror web apps', 'my webpage url looks like below here i understood that advertiserid is 2102 but i couldnt understand what dashboard is pointing to']"
How to use forever-monitor with Electron-Angular project?,"I am using Angular 2 with Electron and want to keep running a process in background to show notifications. I am using forever-monitor for that, it works only in development mode, but when I package my app using electron-packager, this stops working. My code looks like that:
main.ts
exports.runBackgroundProcess = () =>  {

// Run a background process forever
var forever = require('forever-monitor');
var child = new(forever.Monitor)('src/assets/notification-process.js', 
{
  env: {ELECTRON_RUN_AS_NODE: 1},
  options: []
});

child.start();
}

I wrote a function in main.ts that will run background process when called from angular component. Code in notification-process.js is following:
notification-process.js
notifier = require('node-notifier')

notifierFun = (msg) =>  {
 notifier.notify({
 title: 'Notify Me',
 message: msg,
 wait: true
 });
}

var CronJob = require('cron').CronJob;

new CronJob('* * * * * *', function() {
  notifierFun(""Message from notification process"");
});

Finally I am calling the function from app.component.ts
let main_js  = this.electronService.remote.require(""./main.js"");
main_js.runBackgroundProcess();

",<node.js><angular><electron><node-modules><forever-monitor>,8,"node.js,angular,electron,node-modules,forever-monitor",['how to use forevermonitor with electronangular project'],"['i am using angular 2 with electron and want to keep running a process in background to show notifications', 'i am using forevermonitor for that it works only in development mode but when i package my app using electronpackager this stops working', 'my code looks like that maints exportsrunbackgroundprocess run a background process forever var forever requireforevermonitor var child newforevermonitorsrcassetsnotificationprocessjs env electronrunasnode 1 options childstart i wrote a function in maints that will run background process when called from angular component', 'code in notificationprocessjs is following notificationprocessjs notifier requirenodenotifier notifierfun msg notifiernotify title notify me message msg wait true var cronjob requirecroncronjob new cronjob function notifierfunmessage from notification process finally i am calling the function from appcomponentts let mainjs thiselectronserviceremoterequiremainjs mainjsrunbackgroundprocess']"
UI Testing Failure - Neither element nor any descendant has keyboard focus on secureTextField,"This is my case:
let passwordSecureTextField = app.secureTextFields[""password""]
passwordSecureTextField.tap()
passwordSecureTextField.typeText(""wrong_password"") //here is an error


UI Testing Failure - Neither element nor any descendant has keyboard focus. Element:

What is wrong? This is working nice for normal textFields, but problem arise only with secureTextFields. Any workarounds?
",<ios><xcode><swift><ios9><xcode-ui-testing>,170,"ios,xcode,swift,ios9,xcode-ui-testing",['ui testing failure neither element nor any descendant has keyboard focus on securetextfield'],"['this is my case let passwordsecuretextfield appsecuretextfieldspassword passwordsecuretextfieldtap passwordsecuretextfieldtypetextwrongpassword here is an error ui testing failure neither element nor any descendant has keyboard focus', 'element what is wrong', 'this is working nice for normal textfields but problem arise only with securetextfields', 'any workarounds']"
Asp.net Core MVC - obtaining dependency during app shutdown,"I'm developing a web app using ASP.net Core MVC 2.2, and in my Startup class I'm registering a dependency injection of type MyService, like so:
public void ConfigureServices(IServiceCollection services)
{
    //Inject dependency
    services.AddSingleton<MyService>();

    //...other stuff...
}

This works correctly. However, I need to retrieve the instance of MyService during application shutdown, in order to do some cleanup operations before the app terminates. 
So I tried doing this - first I injected IServiceProvider in my startup class, so it is available:
public Startup(IConfiguration configuration, IServiceProvider serviceProvider)
{
    ServiceProvider = serviceProvider;
    Configuration = configuration;
}

and then, in the Configure method, I configured a hook to the ApplicationStopping event, to intercept shutdown and call the OnShutdown method:
public void Configure(IApplicationBuilder app, IHostingEnvironment env, IApplicationLifetime applicationLifetime)
{
    //Register app termination event hook
    applicationLifetime.ApplicationStopping.Register(OnShutdown);

    //...do stuff...
}

finally, in my OnShutdown method I try obtaining my dependency and using it:
private void OnShutdown()
{
    var myService = ServiceProvider.GetService<MyService>();
    myService.DoSomething(); //NullReference exception, myService is null!
}

However, as you can see from the comment in the code, this doesn't work: the returned dependency is always null. What am I doing wrong here?
",<c#><asp.net-core><.net-core><asp.net-core-mvc><asp.net-core-2.2>,6,"c#,asp.net-core,.net-core,asp.net-core-mvc,asp.net-core-2.2",['aspnet core mvc obtaining dependency during app shutdown'],"['im developing a web app using aspnet core mvc 22 and in my startup class im registering a dependency injection of type myservice like so public void configureservicesiservicecollection services inject dependency servicesaddsingletonmyservice other stuff this works correctly', 'however i need to retrieve the instance of myservice during application shutdown in order to do some cleanup operations before the app terminates', 'so i tried doing this first i injected iserviceprovider in my startup class so it is available public startupiconfiguration configuration iserviceprovider serviceprovider serviceprovider serviceprovider configuration configuration and then in the configure method i configured a hook to the applicationstopping event to intercept shutdown and call the onshutdown method public void configureiapplicationbuilder app ihostingenvironment env iapplicationlifetime applicationlifetime register app termination event hook applicationlifetimeapplicationstoppingregisteronshutdown do stuff finally in my onshutdown method i try obtaining my dependency and using it private void onshutdown var myservice serviceprovidergetservicemyservice myservicedosomething nullreference exception myservice is null ', 'however as you can see from the comment in the code this doesnt work the returned dependency is always null', 'what am i doing wrong here']"
Scala: reflection and case classes,"The following code succeeds, but is there a better way of doing the same thing? Perhaps something specific to case classes? In the following code, for each field of type String in my simple case class, the code goes through my list of instances of that case class and finds the length of the longest string of that field.
case class CrmContractorRow(
                             id: Long,
                             bankCharges: String,
                             overTime: String,
                             name$id: Long,
                             mgmtFee: String,
                             contractDetails$id: Long,
                             email: String,
                             copyOfVisa: String)

object Go {
  def main(args: Array[String]) {
    val a = CrmContractorRow(1,""1"",""1"",4444,""1"",1,""1"",""1"")
    val b = CrmContractorRow(22,""22"",""22"",22,""55555"",22,""nine long"",""22"")
    val c = CrmContractorRow(333,""333"",""333"",333,""333"",333,""333"",""333"")
    val rows = List(a,b,c)

    c.getClass.getDeclaredFields.filter(p => p.getType == classOf[String]).foreach{f =>
      f.setAccessible(true)
      println(f.getName + "": "" + rows.map(row => f.get(row).asInstanceOf[String]).maxBy(_.length))
    }
  }
}

Result:
bankCharges: 3
overTime: 3
mgmtFee: 5
email: 9
copyOfVisa: 3

",<scala><reflection><shapeless><case-class><scala-reflect>,8,"scala,reflection,shapeless,case-class,scala-reflect",['scala reflection and case classes'],"['the following code succeeds but is there a better way of doing the same thing', 'perhaps something specific to case classes', 'in the following code for each field of type string in my simple case class the code goes through my list of instances of that case class and finds the length of the longest string of that field', 'case class crmcontractorrow id long bankcharges string overtime string nameid long mgmtfee string contractdetailsid long email string copyofvisa string object go def mainargs arraystring val a crmcontractorrow11144441111 val b crmcontractorrow222222225555522nine long22 val c crmcontractorrow333333333333333333333333 val rows listabc cgetclassgetdeclaredfieldsfilterp pgettype classofstringforeachf fsetaccessibletrue printlnfgetname rowsmaprow fgetrowasinstanceofstringmaxbylength result bankcharges 3 overtime 3 mgmtfee 5 email 9 copyofvisa 3']"
UIActionSheet from Popover with iOS8 GM,"Anyone is getting this message while trying to show UIActionSheet from popover?
Your application has presented a UIAlertController () of style UIAlertControllerStyleActionSheet. The modalPresentationStyle of a UIAlertController with this style is UIModalPresentationPopover. You must provide location information for this popover through the alert controller's popoverPresentationController. You must provide either a sourceView and sourceRect or a barButtonItem.  If this information is not known when you present the alert controller, you may provide it in the UIPopoverPresentationControllerDelegate method -prepareForPopoverPresentation.
Previously to the GM I used some workaround for converting the UIActionSheet to UIAlertController and this is working fine.
However it seems that Apple tried to solve the UIActionSheet issues and I didn't want to use my workaround - but it seems that I have no choice...
",<ios><ios8><uipopovercontroller><uiactionsheet><uialertcontroller>,47,"ios,ios8,uipopovercontroller,uiactionsheet,uialertcontroller",['uiactionsheet from popover with ios8 gm'],"['anyone is getting this message while trying to show uiactionsheet from popover', 'your application has presented a uialertcontroller of style uialertcontrollerstyleactionsheet', 'the modalpresentationstyle of a uialertcontroller with this style is uimodalpresentationpopover', 'you must provide location information for this popover through the alert controllers popoverpresentationcontroller', 'you must provide either a sourceview and sourcerect or a barbuttonitem', 'if this information is not known when you present the alert controller you may provide it in the uipopoverpresentationcontrollerdelegate method prepareforpopoverpresentation', 'previously to the gm i used some workaround for converting the uiactionsheet to uialertcontroller and this is working fine', 'however it seems that apple tried to solve the uiactionsheet issues and i didnt want to use my workaround but it seems that i have no choice']"
Uploading many files in Shiny,"I am developing an app that helps to organize and visualize many PDF documents by topic/theme. I can upload and read a single PDF but I have difficulty in reading multiple PDF documents.
For single PDF document:
ui.R
  ---
  fileInput('file1', 'Choose PDF File', accept=c('.pdf'))

 ---

server.R
   --------

   library(pdftools)

   -------


 mypdf<-reactive({

   inFile <- input$file1

   if (is.null(inFile)){
  return(NULL)
  }else{
  pdf_text(inFile$datapath)

   }

  })


To upload multiple PDF files, I have to use multiple = TRUE in the ui.R portion of the code, but how can I read in all the uploaded files?
",<r><pdf><shiny><visualization><text-mining>,5,"r,pdf,shiny,visualization,text-mining",['uploading many files in shiny'],"['i am developing an app that helps to organize and visualize many pdf documents by topictheme', 'i can upload and read a single pdf but i have difficulty in reading multiple pdf documents', 'for single pdf document uir fileinputfile1 choose pdf file acceptcpdf serverr librarypdftools mypdfreactive infile inputfile1 if isnullinfile returnnull else pdftextinfiledatapath to upload multiple pdf files i have to use multiple true in the uir portion of the code but how can i read in all the uploaded files']"
How can I make gitweb ignore whitespace changes?,"Is there a url parameter I can pass into gitweb (or anything else I can do) to tell it not to show me whitespace changes?
Backstory:
I have a file-generating process that creates hundreds of files that it then programatically checks into git.  Recently I made some minor changes to this process, which resulted in a bunch of whitespace being removed from every file that it generates, and some non-whitespace changes being made to just a few files that it generates.  I am trying to use gitweb to verify that my non-whitespace changes are in these files, but it's really hard to do because of all the whitespace changes I have to sift through before I see any of the real changes.  I know if I were doing a git diff from the command line I could just pass it the -w parameter, but I am really just trying to use gitweb for this.
",<git><diff><whitespace><git-commit><gitweb>,6,"git,diff,whitespace,git-commit,gitweb",['how can i make gitweb ignore whitespace changes'],"['is there a url parameter i can pass into gitweb or anything else i can do to tell it not to show me whitespace changes', 'backstory i have a filegenerating process that creates hundreds of files that it then programatically checks into git', 'recently i made some minor changes to this process which resulted in a bunch of whitespace being removed from every file that it generates and some nonwhitespace changes being made to just a few files that it generates', 'i am trying to use gitweb to verify that my nonwhitespace changes are in these files but its really hard to do because of all the whitespace changes i have to sift through before i see any of the real changes', 'i know if i were doing a git diff from the command line i could just pass it the w parameter but i am really just trying to use gitweb for this']"
ASP.NET Identity external authentication provider custom icon,"With SimpleMembership you can add an icon to the external authentication provider buttons like this:
SimpleMembership:
Dictionary<string, object> FacebooksocialData = new Dictionary<string, object>();
FacebooksocialData.Add(""Icon"", ""/content/images/gui/loginFacebook.png"");
OAuthWebSecurity.RegisterFacebookClient(
    appId: ""x"",
    appSecret: ""x"",
    displayName: ""Facebook"",
    extraData: FacebooksocialData);

And then display them like this in your view:
@foreach (AuthenticationClientData p in Model)
{
    <button class=""externalLoginService"" style=""cursor:pointer;color:transparent;border:none;background:url(@p.ExtraData[""Icon""]);width:94px;height:93px;margin-right:20px;"" type=""submit"" name=""provider"" value=""@p.AuthenticationClient.ProviderName"" title=""Log in with @p.DisplayName"">@p.DisplayName</button>
}

ASP.NET Identity(?):
app.UseFacebookAuthentication(
   appId: ""x"",
   appSecret: ""x"");

How to achieve the same thing using ASP.NET Identity (controller and view)?
",<asp.net><oauth-2.0><openid><simplemembership><asp.net-identity>,6,"asp.net,oauth-2.0,openid,simplemembership,asp.net-identity",['aspnet identity external authentication provider custom icon'],"['with simplemembership you can add an icon to the external authentication provider buttons like this simplemembership dictionarystring object facebooksocialdata new dictionarystring object facebooksocialdataaddicon contentimagesguiloginfacebookpng oauthwebsecurityregisterfacebookclient appid x appsecret x displayname facebook extradata facebooksocialdata and then display them like this in your view foreach authenticationclientdata p in model button classexternalloginservice stylecursorpointercolortransparentbordernonebackgroundurlpextradataiconwidth94pxheight93pxmarginright20px typesubmit nameprovider valuepauthenticationclientprovidername titlelog in with pdisplaynamepdisplaynamebutton aspnet identity', ' appusefacebookauthentication appid x appsecret x how to achieve the same thing using aspnet identity controller and view']"
NodeJS/express - security for public API endpoint,"I'm developing my web-site project based on NodeJs/Express, and for some UI parts I'm using Jquery ajax request to fetch secondary data. 
How can we handle some basic control on our Rest API end-points that are used for ajax calls by the browser?
I was thinking about some kind of token authorization , but it can be also used by other clients (scripts etc.) once it has been intercepted , so how can we protect our server from unwanted requests? What other controls should be used in this cases (recognize too many request from same client, clients black list,etc)? 
",<node.js><ajax><rest><api><express>,10,"node.js,ajax,rest,api,express",['nodejsexpress security for public api endpoint'],"['im developing my website project based on nodejsexpress and for some ui parts im using jquery ajax request to fetch secondary data', 'how can we handle some basic control on our rest api endpoints that are used for ajax calls by the browser', 'i was thinking about some kind of token authorization but it can be also used by other clients scripts etc', 'once it has been intercepted so how can we protect our server from unwanted requests', 'what other controls should be used in this cases recognize too many request from same client clients black listetc']"
Set Item Permissions,"Folders work:
I now know how to set the permissions of a folder in a library:
public void ChangeItemPermissions()
{
    _SharePoint.ClientContext _ClientContext = new _SharePoint.ClientContext(""https://sharepoint.oshirowanen.com/sites/oshirodev/"");
    _ClientContext.Credentials = new NetworkCredential(""user"", ""pass"", ""oshirowanen.com"");

    _SharePoint.Principal user = _ClientContext.Web.EnsureUser(@""oshirowanen\tom"");

    var _List = _ClientContext.Web.Lists.GetByTitle(""Library1"");
    var _Item = _List.LoadItemByUrl(""/sites/oshirodev/Library1/Folder1"");
    var roleDefinition = _ClientContext.Site.RootWeb.RoleDefinitions.GetByType(_SharePoint.RoleType.Reader);
    var roleBindings = new _SharePoint.RoleDefinitionBindingCollection(_ClientContext) { roleDefinition };
    _Item.BreakRoleInheritance(false,true);
    _Item.RoleAssignments.Add(user, roleBindings);

    _ClientContext.ExecuteQuery();
}


File attempt:
I've tried adding the file name to this line:
var _Item = _List.LoadItemByUrl(""/sites/oshirodev/Library1/Folder1/File1.docx"");
Notice the (/File1.docx) added to the end of the above line.

Error received:
But that just gives an error:
System.NullReferenceException was unhandled
  HResult=-2147467261
  Message=Object reference not set to an instance of an object.
  Source=ItemPermissions
  StackTrace:
       at ItemPermissions.Form1.ChangeItemPermissions() in c:\Users\Oshirowanen\Documents\Visual Studio 2013\Projects\ItemPermissions\ItemPermissions\Form1.cs:line 46
       at ItemPermissions.Form1.button1_Click(Object sender, EventArgs e) in c:\Users\Oshirowanen\Documents\Visual Studio 2013\Projects\ItemPermissions\ItemPermissions\Form1.cs:line 345
       at System.Windows.Forms.Control.OnClick(EventArgs e)
       at System.Windows.Forms.Button.OnClick(EventArgs e)
       at System.Windows.Forms.Button.OnMouseUp(MouseEventArgs mevent)
       at System.Windows.Forms.Control.WmMouseUp(Message& m, MouseButtons button, Int32 clicks)
       at System.Windows.Forms.Control.WndProc(Message& m)
       at System.Windows.Forms.ButtonBase.WndProc(Message& m)
       at System.Windows.Forms.Button.WndProc(Message& m)
       at System.Windows.Forms.Control.ControlNativeWindow.OnMessage(Message& m)
       at System.Windows.Forms.Control.ControlNativeWindow.WndProc(Message& m)
       at System.Windows.Forms.NativeWindow.DebuggableCallback(IntPtr hWnd, Int32 msg, IntPtr wparam, IntPtr lparam)
       at System.Windows.Forms.UnsafeNativeMethods.DispatchMessageW(MSG& msg)
       at System.Windows.Forms.Application.ComponentManager.System.Windows.Forms.UnsafeNativeMethods.IMsoComponentManager.FPushMessageLoop(IntPtr dwComponentID, Int32 reason, Int32 pvLoopData)
       at System.Windows.Forms.Application.ThreadContext.RunMessageLoopInner(Int32 reason, ApplicationContext context)
       at System.Windows.Forms.Application.ThreadContext.RunMessageLoop(Int32 reason, ApplicationContext context)
       at System.Windows.Forms.Application.Run(Form mainForm)
       at ItemPermissions.Program.Main() in c:\Users\Oshirowanen\Documents\Visual Studio 2013\Projects\ItemPermissions\ItemPermissions\Program.cs:line 18
       at System.AppDomain._nExecuteAssembly(RuntimeAssembly assembly, String[] args)
       at System.AppDomain.ExecuteAssembly(String assemblyFile, Evidence assemblySecurity, String[] args)
       at Microsoft.VisualStudio.HostingProcess.HostProc.RunUsersAssembly()
       at System.Threading.ThreadHelper.ThreadStart_Context(Object state)
       at System.Threading.ExecutionContext.RunInternal(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state, Boolean preserveSyncCtx)
       at System.Threading.ExecutionContext.Run(ExecutionContext executionContext, ContextCallback callback, Object state)
       at System.Threading.ThreadHelper.ThreadStart()
  InnerException: 


Relevant info:
This is a WinForm app running on a local machine, created with C#, using .NET 4.0.  SharePoint version is 2010.

The question:
How do I set the permissions for a specific file?  As I already know how to set permissions for a specific folder.
",<c#><.net><sharepoint><sharepoint-2010><csom>,13,"c#,.net,sharepoint,sharepoint-2010,csom",['set item permissions'],"['folders work i now know how to set the permissions of a folder in a library public void changeitempermissions sharepointclientcontext clientcontext new sharepointclientcontext clientcontextcredentials new networkcredentialuser pass oshirowanencom sharepointprincipal user clientcontextwebensureuseroshirowanentom var list clientcontextweblistsgetbytitlelibrary1 var item listloaditembyurlsitesoshirodevlibrary1folder1 var roledefinition clientcontextsiterootwebroledefinitionsgetbytypesharepointroletypereader var rolebindings new sharepointroledefinitionbindingcollectionclientcontext roledefinition itembreakroleinheritancefalsetrue itemroleassignmentsadduser rolebindings clientcontextexecutequery file attempt ive tried adding the file name to this line var item listloaditembyurlsitesoshirodevlibrary1folder1file1docx notice the file1docx added to the end of the above line', 'error received but that just gives an error systemnullreferenceexception was unhandled hresult2147467261 messageobject reference not set to an instance of an object', 'sourceitempermissions stacktrace at itempermissionsform1changeitempermissions in cusersoshirowanendocumentsvisual studio 2013projectsitempermissionsitempermissionsform1csline 46 at itempermissionsform1button1clickobject sender eventargs e in cusersoshirowanendocumentsvisual studio 2013projectsitempermissionsitempermissionsform1csline 345 at systemwindowsformscontrolonclickeventargs e at systemwindowsformsbuttononclickeventargs e at systemwindowsformsbuttononmouseupmouseeventargs mevent at systemwindowsformscontrolwmmouseupmessage m mousebuttons button int32 clicks at systemwindowsformscontrolwndprocmessage m at systemwindowsformsbuttonbasewndprocmessage m at systemwindowsformsbuttonwndprocmessage m at systemwindowsformscontrolcontrolnativewindowonmessagemessage m at systemwindowsformscontrolcontrolnativewindowwndprocmessage m at systemwindowsformsnativewindowdebuggablecallbackintptr hwnd int32 msg intptr wparam intptr lparam at systemwindowsformsunsafenativemethodsdispatchmessagewmsg msg at systemwindowsformsapplicationcomponentmanagersystemwindowsformsunsafenativemethodsimsocomponentmanagerfpushmessageloopintptr dwcomponentid int32 reason int32 pvloopdata at systemwindowsformsapplicationthreadcontextrunmessageloopinnerint32 reason applicationcontext context at systemwindowsformsapplicationthreadcontextrunmessageloopint32 reason applicationcontext context at systemwindowsformsapplicationrunform mainform at itempermissionsprogrammain in cusersoshirowanendocumentsvisual studio 2013projectsitempermissionsitempermissionsprogramcsline 18 at systemappdomainnexecuteassemblyruntimeassembly assembly string args at systemappdomainexecuteassemblystring assemblyfile evidence assemblysecurity string args at microsoftvisualstudiohostingprocesshostprocrunusersassembly at systemthreadingthreadhelperthreadstartcontextobject state at systemthreadingexecutioncontextruninternalexecutioncontext executioncontext contextcallback callback object state boolean preservesyncctx at systemthreadingexecutioncontextrunexecutioncontext executioncontext contextcallback callback object state boolean preservesyncctx at systemthreadingexecutioncontextrunexecutioncontext executioncontext contextcallback callback object state at systemthreadingthreadhelperthreadstart innerexception relevant info this is a winform app running on a local machine created with c using net 40 sharepoint version is 2010 the question how do i set the permissions for a specific file', 'as i already know how to set permissions for a specific folder']"
Checking of **kwargs in concrete implementation of abstract class method. Interface issue?,"I am trying to implement the Strategy design pattern to create an interface for an underlying algorithm to be implemented in a modular fashion.
Currently, as per code below, I have one top-level/parent abstract class (ParentAbstractStrategy) that defines the base interface for the strategy method.
I also have a one-level-down from this abstract class (ChildAbstractStrategy).
The reason I have two abstract classes is because of the attributes they need to hold; see the __init__ methods. 
ChildAbstractStrategy is a special case of ParentAbstractStrategy in that it stores an additional attribute: attr2.
Otherwise its interface is identical, as seen by identical strategy method signatures.
Sometimes, I want to be able to directly subclass ParentAbstractStrategy and implement the strategy method (see ConcreteStrategyA), but other times I want to be able to subclass ChildAbstractStrategy, because the extra attribute is required (see ConcreteStrategyB).
An additional complication is that in some subclasses of either abstract class I want to be able to handle additional arguments in the strategy method. This is why I have added **kwargs to all signatures of the strategy method, so that I can pass in whatever additional arguments I want to a subclass, on a case-by-case basis.
This creates the last problem: these extra arguments are not optional in the subclasses. E.g. in the strategy method of ConcreteStrategyB I want to be certain that the caller passed in a third argument.
I'm basically abusing **kwargs to provide what probably should be positional arguments (since I can't give them sane defaults and need their existence to be enforced).
This current solution of using **kwargs for ""method overloading"" in subclasses feels really messy, and I'm not sure if this means there is a problem with the class inheritance scheme or interface design, or both.
Is there a way that I can achieve these design goals in a cleaner fashion. It feels like I'm missing something big picture here and maybe the class/interface design is bad. Maybe creating two disjoint abstract classes with different signatures for the strategy method?
import abc


class ParentAbstractStrategy(metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def __init__(self, attr1):
        self.attr1 = attr1

    @abc.abstractmethod
    def strategy(self, arg1, arg2, **kwargs):
        raise NotImplementedError


class ChildAbstractStrategy(ParentAbstractStrategy, metaclass=abc.ABCMeta):
    @abc.abstractmethod
    def __init__(self, attr1, attr2):
        super().__init__(attr1)
        self.attr2 = attr2

    @abc.abstractmethod
    def strategy(self, arg1, arg2, **kwargs):
        raise NotImplementedError


class ConcreteStrategyA(ParentAbstractStrategy):
    def __init__(self, attr1):
        super().__init__(attr1)

    def strategy(self, arg1, arg2, **kwargs):
        print(arg1, arg2)


class ConcreteStrategyB(ChildAbstractStrategy):
    def __init__(self, attr1, attr2):
        super().__init__(attr1, attr2)

    def strategy(self, arg1, arg2, **kwargs):
        print(arg1, arg2)
        arg3 = kwargs.get(""arg3"", None)

        if arg3 is None:
            raise ValueError(""Missing arg3"")
        else:
            print(arg3)

Here's an interpreter session demonstrating how it's currently working:
>>> a = ConcreteStrategyA(1)
>>> a.attr1
1
>>> a.strategy(""a"", ""b"")
a b
>>> b = ConcreteStrategyB(1, 2)
>>> b.attr1
1
>>> b.attr2
2
>>> b.strategy(""a"", ""b"")
a b
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/space/strategy.py"", line 42, in strategy
    raise ValueError(""Missing arg3"")
ValueError: Missing arg3
>>> b.strategy(""a"", ""b"", arg3=""c"")
a b
c

",<python><python-3.x><abstract-class><strategy-pattern><keyword-argument>,10,"python,python-3.x,abstract-class,strategy-pattern,keyword-argument","['checking of kwargs in concrete implementation of abstract class method', 'interface issue']","['i am trying to implement the strategy design pattern to create an interface for an underlying algorithm to be implemented in a modular fashion', 'currently as per code below i have one toplevelparent abstract class parentabstractstrategy that defines the base interface for the strategy method', 'i also have a oneleveldown from this abstract class childabstractstrategy', 'the reason i have two abstract classes is because of the attributes they need to hold see the init methods', 'childabstractstrategy is a special case of parentabstractstrategy in that it stores an additional attribute attr2', 'otherwise its interface is identical as seen by identical strategy method signatures', 'sometimes i want to be able to directly subclass parentabstractstrategy and implement the strategy method see concretestrategya but other times i want to be able to subclass childabstractstrategy because the extra attribute is required see concretestrategyb', 'an additional complication is that in some subclasses of either abstract class i want to be able to handle additional arguments in the strategy method', 'this is why i have added kwargs to all signatures of the strategy method so that i can pass in whatever additional arguments i want to a subclass on a casebycase basis', 'this creates the last problem these extra arguments are not optional in the subclasses', 'eg', 'in the strategy method of concretestrategyb i want to be certain that the caller passed in a third argument', 'im basically abusing kwargs to provide what probably should be positional arguments since i cant give them sane defaults and need their existence to be enforced', 'this current solution of using kwargs for method overloading in subclasses feels really messy and im not sure if this means there is a problem with the class inheritance scheme or interface design or both', 'is there a way that i can achieve these design goals in a cleaner fashion', 'it feels like im missing something big picture here and maybe the classinterface design is bad', 'maybe creating two disjoint abstract classes with different signatures for the strategy method', 'import abc class parentabstractstrategymetaclassabcabcmeta abcabstractmethod def initself attr1 selfattr1 attr1 abcabstractmethod def strategyself arg1 arg2 kwargs raise notimplementederror class childabstractstrategyparentabstractstrategy metaclassabcabcmeta abcabstractmethod def initself attr1 attr2 superinitattr1 selfattr2 attr2 abcabstractmethod def strategyself arg1 arg2 kwargs raise notimplementederror class concretestrategyaparentabstractstrategy def initself attr1 superinitattr1 def strategyself arg1 arg2 kwargs printarg1 arg2 class concretestrategybchildabstractstrategy def initself attr1 attr2 superinitattr1 attr2 def strategyself arg1 arg2 kwargs printarg1 arg2 arg3 kwargsgetarg3 none if arg3 is none raise valueerrormissing arg3 else printarg3 heres an interpreter session demonstrating how its currently working a concretestrategya1 aattr1 1 astrategya b a b b concretestrategyb1 2 battr1 1 battr2 2 bstrategya b a b traceback most recent call last file stdin line 1 in module file homespacestrategypy line 42 in strategy raise valueerrormissing arg3 valueerror missing arg3 bstrategya b arg3c a b c']"
Are there any guarantees for unions that contain a wrapped type and the type itself?,"Can I put a T and a wrapped T in an union and inspect them as I like?
union Example {
    T value;
    struct Wrapped { 
       T wrapped;
    } wrapper;
};

// for simplicity T = int

Example ex;
ex.value = 12;
cout << ex.wrapper.wrapped; // ?

The C++11 standards only guarantee save inspection of the common initial sequence, but value isn't a struct. I guess the answer is no, since wrapped types aren't even guaranteed to be memory compatible to their unwrapped counterpart and accessing inactive members is only well-defined on common initial sequences.
",<c++><struct><types><language-lawyer><unions>,11,"c++,struct,types,language-lawyer,unions",['are there any guarantees for unions that contain a wrapped type and the type itself'],"['can i put a t and a wrapped t in an union and inspect them as i like', 'union example t value struct wrapped t wrapped wrapper for simplicity t int example ex exvalue 12 cout exwrapperwrapped ', 'the c11 standards only guarantee save inspection of the common initial sequence but value isnt a struct', 'i guess the answer is no since wrapped types arent even guaranteed to be memory compatible to their unwrapped counterpart and accessing inactive members is only welldefined on common initial sequences']"
Public free web services for testing soap client,"Are there any publicly available SOAP 1.2/WSDL 2.0 compliant free web services for testing a Python based soap client library (e.g. Zolera SOAP Infrastructure)? 
So far, it appears to me that Google Web API may be the only option.
Otherwise, how can one test a SOAP 1.2 compliant client library?
",<python><web-services><soap><soappy><zsi>,100,"python,web-services,soap,soappy,zsi",['public free web services for testing soap client'],"['are there any publicly available soap 12wsdl 20 compliant free web services for testing a python based soap client library eg', 'zolera soap infrastructure', 'so far it appears to me that google web api may be the only option', 'otherwise how can one test a soap 12 compliant client library']"
Angular - how to simulate HttpError response in service,"How can I simulate HTTP error response in Angular service? I often need to handle different HTTP error codes and sometimes I need implement solution, but backend is not ready. How can I mock errors from backend?
Example code
  public getData(): Observable<Response> {
    return this.httpClient.get<Response>(`${this.endpoint}`);
  }

",<angular><typescript><error-handling><mocking><http-error>,14,"angular,typescript,error-handling,mocking,http-error",['angular how to simulate httperror response in service'],"['how can i simulate http error response in angular service', 'i often need to handle different http error codes and sometimes i need implement solution but backend is not ready', 'how can i mock errors from backend', 'example code public getdata observableresponse return thishttpclientgetresponsethisendpoint ']"
IsPersistent not working - Cookie only valid for current session,"I have an ASP.NET MVC 5 application using ASP.NET Identity 2.1.0 for user authentication.
Everything worked fine in the past, but now I found out that persisting user sessions does not work anymore. I can not tell what change broke this, but it worked when I implemented Identity (converted the application from SimpleMembership) and this is my logic I have at the moment:
var result = await SignInManager.PasswordSignInAsync(model.UserName, model.Password, 
                                     model.RememberMe, shouldLockout: true);

SignInManager is my ApplicationSignInManager based on SignInManager<ApplicationUser, int> and model.RememberMe is true.  
And my setup:
app.CreatePerOwinContext<ApplicationSignInManager>(ApplicationSignInManager.Create);

app.UseCookieAuthentication(new CookieAuthenticationOptions
    {
        AuthenticationType = DefaultAuthenticationTypes.ApplicationCookie,
        LoginPath = new PathString(""/Account/Login""),
        Provider = new CookieAuthenticationProvider
            {
                OnValidateIdentity = ApplicationCookieIdentityValidator.OnValidateIdentity(
                    validateInterval: TimeSpan.FromMinutes(0),
                    regenerateIdentity: (manager, user) => user.GenerateUserIdentityAsync(manager))
            }
    });
app.UseTwoFactorSignInCookie(DefaultAuthenticationTypes.TwoFactorCookie, TimeSpan.FromMinutes(5));
app.UseTwoFactorRememberBrowserCookie(DefaultAuthenticationTypes.TwoFactorRememberBrowserCookie);
app.UseExternalSignInCookie(DefaultAuthenticationTypes.ExternalCookie);

Everything works fine, except persisting the user sessions. I checked the cookies returned by my server and the .AspNet.ApplicationCookie is allways returned as ""valid for current session"" instead of some date in the future. So when I close and reopen the browser I need to log in again...
Does anybody have an idea why this is not working (anymore)?
P.S.: I have overriden SignInAsync in my ApplicationSignInManager because I do some custom logic there, but I even checked with the debugger and for the following call:
await base.SignInAsync(user, isPersistent, rememberBrowser);

isPersistent is true, so it should create a persisten cookie.
",<c#><asp.net-mvc><asp.net-mvc-5><asp.net-identity><asp.net-identity-2>,8,"c#,asp.net-mvc,asp.net-mvc-5,asp.net-identity,asp.net-identity-2",['ispersistent not working cookie only valid for current session'],"['i have an aspnet mvc 5 application using aspnet identity 210 for user authentication', 'everything worked fine in the past but now i found out that persisting user sessions does not work anymore', 'i can not tell what change broke this but it worked when i implemented identity converted the application from simplemembership and this is my logic i have at the moment var result await signinmanagerpasswordsigninasyncmodelusername modelpassword modelrememberme shouldlockout true signinmanager is my applicationsigninmanager based on signinmanagerapplicationuser int and modelrememberme is true', 'and my setup appcreateperowincontextapplicationsigninmanagerapplicationsigninmanagercreate appusecookieauthenticationnew cookieauthenticationoptions authenticationtype defaultauthenticationtypesapplicationcookie loginpath new pathstringaccountlogin provider new cookieauthenticationprovider onvalidateidentity applicationcookieidentityvalidatoronvalidateidentity validateinterval timespanfromminutes0 regenerateidentity manager user usergenerateuseridentityasyncmanager appusetwofactorsignincookiedefaultauthenticationtypestwofactorcookie timespanfromminutes5 appusetwofactorrememberbrowsercookiedefaultauthenticationtypestwofactorrememberbrowsercookie appuseexternalsignincookiedefaultauthenticationtypesexternalcookie everything works fine except persisting the user sessions', 'i checked the cookies returned by my server and the aspnetapplicationcookie is allways returned as valid for current session instead of some date in the future', 'so when i close and reopen the browser i need to log in again does anybody have an idea why this is not working anymore', 'p', ' i have overriden signinasync in my applicationsigninmanager because i do some custom logic there but i even checked with the debugger and for the following call await basesigninasyncuser ispersistent rememberbrowser ispersistent is true so it should create a persisten cookie']"
Create Function in h2 from Oracle,"i have the following function in oracle that i have to translate into h2. Could anyone help me. I have no idea to do this:
create or replace function unpack_info (p_trackchar table.ordchar%type) 
 return varchar2 is
l_res varchar2(8);
begin
select decode(bitand(to_number(ascii(p_trackchar)),1),1,'1','0') ||
  decode(bitand(to_number(ascii(p_trackchar)),2),2,'1','0') ||
  decode(bitand(to_number(ascii(p_trackchar)),4),4,'1','0') ||
  decode(bitand(to_number(ascii(p_trackchar)),8),8,'1','0') ||
  decode(bitand(to_number(ascii(p_trackchar)),16),16,'1','0') ||
  decode(bitand(to_number(ascii(p_trackchar)),32),32,'1','0') ||
  decode(bitand(to_number(ascii(p_trackchar)),64),64,'1','0') into l_res
from dual;
return l_res;
end;

I have tried to do first some basics but the creation of this function will not work:
CREATE ALIAS HTS.TEST AS $$
String nextPrime(String value){
 return null;
}
$$;

I get this error:

Error: Syntax Fehler in SQL Befehl ""CREATE ALIAS HTS.TEST AS []$$
      String nextPrime(String value){
      return null""
      Syntax error in SQL statement ""CREATE ALIAS HTS.TEST AS []$$
      String nextPrime(String value){
      return null"" [42000-162]

Is this the right way to do the translation or what can i do?
I have created an alias (the test one) and could execute it. Now O have to create the alias for unpack:info. Could someone help me cause of the syntax etc. how does the function looks as an alias in h2?
",<java><database><oracle><function><h2>,5,"java,database,oracle,function,h2",['create function in h2 from oracle'],"['i have the following function in oracle that i have to translate into h2', 'could anyone help me', 'i have no idea to do this create or replace function unpackinfo ptrackchar tableordchartype return varchar2 is lres varchar28 begin select decodebitandtonumberasciiptrackchar1110 decodebitandtonumberasciiptrackchar2210 decodebitandtonumberasciiptrackchar4410 decodebitandtonumberasciiptrackchar8810 decodebitandtonumberasciiptrackchar161610 decodebitandtonumberasciiptrackchar323210 decodebitandtonumberasciiptrackchar646410 into lres from dual return lres end i have tried to do first some basics but the creation of this function will not work create alias htstest as string nextprimestring value return null i get this error error syntax fehler in sql befehl create alias htstest as string nextprimestring value return null syntax error in sql statement create alias htstest as string nextprimestring value return null 42000162 is this the right way to do the translation or what can i do', 'i have created an alias the test one and could execute it', 'now o have to create the alias for unpackinfo', 'could someone help me cause of the syntax etc', 'how does the function looks as an alias in h2']"
How do you mock an Apollo Server RESTDataSource for unit testing with Jest?,"I'm trying to test a data source in my Apollo Server that based on Apollo Server's RESTDataSource (https://www.apollographql.com/docs/apollo-server/data/data-sources/#rest-data-source).  I'm trying to test it using Jest.  The class has methods that pull in data from an external REST API, as well as from another module that calls a second API (so this RESTDataSource ultimately depends on two external APIs, one of which is called directly here, and one of which is called indirectly). 
I'm not an expert on testing, and I'm unclear how to mock the external APIs. GraphQL Tools has some tools that allow you to mock your server, but I'm not sure that's what I want.  Or should I use Jest's methods for mocking ES6 classes, forgetting that this is a GraphQL server?  If so, since I'm working with a class, do I just mock the methods using something like MyClass.myMethod as the mocked method?
Does anything change in how I do this if I'm using TypeScript (which I am), other than setting up Jest to work with TypeScript?
Obviously the correct route is to pick one of the options above, but I'm a bit 'not seeing the forest for the trees', that is, due to my inexperience with testing, I don't know which of these is the correct route to follow.
Thanks for any clues.
",<typescript><unit-testing><jestjs><apollo><apollo-server>,10,"typescript,unit-testing,jestjs,apollo,apollo-server",['how do you mock an apollo server restdatasource for unit testing with jest'],"['im trying to test a data source in my apollo server that based on apollo servers restdatasource im trying to test it using jest', 'the class has methods that pull in data from an external rest api as well as from another module that calls a second api so this restdatasource ultimately depends on two external apis one of which is called directly here and one of which is called indirectly', 'im not an expert on testing and im unclear how to mock the external apis', 'graphql tools has some tools that allow you to mock your server but im not sure thats what i want', 'or should i use jests methods for mocking es6 classes forgetting that this is a graphql server', 'if so since im working with a class do i just mock the methods using something like myclassmymethod as the mocked method', 'does anything change in how i do this if im using typescript which i am other than setting up jest to work with typescript', 'obviously the correct route is to pick one of the options above but im a bit not seeing the forest for the trees that is due to my inexperience with testing i dont know which of these is the correct route to follow', 'thanks for any clues']"
How to create and connect related resources using Spring Data REST repositories?,"I have a simple proof-of-concept demo using Spring Data REST / RestRepository architecture. My two entities are :
@Entity
@org.hibernate.annotations.Proxy(lazy=false)
@Table(name=""Address"")
public class Address implements Serializable {

    public Address() {}

    @Column(name=""ID"", nullable=false, unique=true) 
    @Id 
    @GeneratedValue(generator=""CUSTOMER_ADDRESSES_ADDRESS_ID_GENERATOR"")    
    @org.hibernate.annotations.GenericGenerator(name=""CUSTOMER_ADDRESSES_ADDRESS_ID_GENERATOR"", strategy=""native"")  
    private int ID;

    @RestResource(exported = false)
    @ManyToOne(targetEntity=domain.location.CityStateZip.class, fetch=FetchType.LAZY)   
    @org.hibernate.annotations.Cascade({org.hibernate.annotations.CascadeType.PERSIST}) 
    @JoinColumns({ @JoinColumn(name=""CityStateZipID"", referencedColumnName=""ID"", nullable=false) }) 
    private domain.location.CityStateZip cityStateZip;

    @Column(name=""StreetNo"", nullable=true) 
    private int streetNo;

    @Column(name=""StreetName"", nullable=false, length=40)   
    private String streetName;

    <setters and getters ommitted>  
}

and for CityStateZip:
@Entity
public class CityStateZip {

    public CityStateZip() {}

    @Column(name=""ID"", nullable=false, unique=true) 
    @Id 
    @GeneratedValue(generator=""CUSTOMER_ADDRESSES_CITYSTATEZIP_ID_GENERATOR"")   
    @org.hibernate.annotations.GenericGenerator(name=""CUSTOMER_ADDRESSES_CITYSTATEZIP_ID_GENERATOR"", strategy=""native"") 
    private int ID;

    @Column(name=""ZipCode"", nullable=false, length=10)  
    private String zipCode;

    @Column(name=""City"", nullable=false, length=24) 
    private String city;

    @Column(name=""StateProv"", nullable=false, length=2) 
    private String stateProv;

}

with repositories:
@RepositoryRestResource(collectionResourceRel = ""addr"", path = ""addr"") 
public interface AddressRepository extends JpaRepository<Address, Integer> {

     List<Address> findByStreetNoAndStreetNameStartingWithIgnoreCase(@Param(""stNumber"") Integer streetNo, @Param(""street"") String streetName);
     List<Address> findByStreetNameStartingWithIgnoreCase(@Param(""street"") String streetName);
     List<Address> findByStreetNo(@Param(""streetNo"") Integer strNo);
}

and:
// @RepositoryRestResource(collectionResourceRel = ""zip"", path = ""zip"", exported = false)
@RepositoryRestResource(collectionResourceRel = ""zip"", path = ""zip"")
public interface CityStateZipRepository extends JpaRepository<CityStateZip, Integer> {

    List<CityStateZip> findByZipCode(@Param(""zipCode"") String zipCode);
    List<CityStateZip> findByStateProv(@Param(""stateProv"") String stateProv);
    List<CityStateZip> findByCityAndStateProv(@Param(""city"") String city, @Param(""state"") String state);
}

and main() code of 
@Configuration
@EnableJpaRepositories
@Import(RepositoryRestMvcConfiguration.class)
@EnableAutoConfiguration
// @EnableTransactionManagement
@PropertySource(value = { ""file:/etc/domain.location/application.properties"" })
@ComponentScan
public class Application {

    public static void main(String[] args) {
        SpringApplication.run(Application.class, args);
    }
}

with this code, I can save a CSZ by POSTing this JSON to http://example.com:8080/zip:
{ ""zipCode"" : ""28899"" , ""city"" : ""Ada"", ""stateProv"" : ""NC"" }

but if I try to save an Address by POSTing the JSON to …/add:
{ ""streetNo"" : ""985"" ,  ""streetName"" : ""Bellingham"",   ""plus4Zip"" : 2212,  ""cityStateZip"" : { ""zipCode"" : ""28115"" , ""city"" : ""Mooresville"", ""stateProv"" : ""NC""  }    }

I get the error 
{
    ""cause"": {
        ""cause"": {
            ""cause"": null,
            ""message"": ""Template must not be null or empty!""
        },
        ""message"": ""Template must not be null or empty! (through reference chain: domain.location.Address[\""cityStateZip\""])""
    },
    ""message"": ""Could not read JSON: Template must not be null or empty! (through reference chain: domain.location.Address[\""cityStateZip\""]); nested exception is com.fasterxml.jackson.databind.JsonMappingException: Template must not be null or empty! (through reference chain: domain.location.Address[\""cityStateZip\""])""
}

Now if I change CityStateZipRepository to include export=false in the annotation, I can then  save the Address and CSZ to the database. But at that time, …/zip is no longer exposed on the interface, AND doing GET …/addr or …/addr/{id} causes this error:
{
    ""timestamp"": 1417728145384,
    ""status"": 500,
    ""error"": ""Internal Server Error"",
    ""exception"": ""org.springframework.http.converter.HttpMessageNotWritableException"",
    ""message"": ""Could not write JSON: No serializer found for class org.hibernate.proxy.pojo.javassist.JavassistLazyInitializer and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: org.springframework.hateoas.PagedResources[\""_embedded\""]->java.util.UnmodifiableMap[\""addr\""]->java.util.ArrayList[0]->org.springframework.hateoas.Resource[\""content\""]->domain.location.Address[\""cityStateZip\""]->domain.location.CityStateZip_$$_jvst4e0_0[\""handler\""]); nested exception is com.fasterxml.jackson.databind.JsonMappingException: No serializer found for class org.hibernate.proxy.pojo.javassist.JavassistLazyInitializer and no properties discovered to create BeanSerializer (to avoid exception, disable SerializationFeature.FAIL_ON_EMPTY_BEANS) ) (through reference chain: org.springframework.hateoas.PagedResources[\""_embedded\""]->java.util.UnmodifiableMap[\""addr\""]->java.util.ArrayList[0]->org.springframework.hateoas.Resource[\""content\""]->domain.location.Address[\""cityStateZip\""]->domain.location.CityStateZip_$$_jvst4e0_0[\""handler\""])"",
    ""path"": ""/addr""
}

Isa there a way to set up this model to be able to POST and GET from this database? Also, the JSON passed to Address will save a new instance of CityStateZip - what format will allow us to reference an existing CityStateZip element?
Thanks for any help you can provide - this has been driving us crazy for days now. 
",<java><json><spring><rest><spring-data-rest>,7,"java,json,spring,rest,spring-data-rest",['how to create and connect related resources using spring data rest repositories'],"['i have a simple proofofconcept demo using spring data rest restrepository architecture', 'my two entities are entity orghibernateannotationsproxylazyfalse tablenameaddress public class address implements serializable public address columnnameid nullablefalse uniquetrue id generatedvaluegeneratorcustomeraddressesaddressidgenerator orghibernateannotationsgenericgeneratornamecustomeraddressesaddressidgenerator strategynative private int id restresourceexported false manytoonetargetentitydomainlocationcitystatezipclass fetchfetchtypelazy orghibernateannotationscascadeorghibernateannotationscascadetypepersist joincolumns joincolumnnamecitystatezipid referencedcolumnnameid nullablefalse private domainlocationcitystatezip citystatezip columnnamestreetno nullabletrue private int streetno columnnamestreetname nullablefalse length40 private string streetname setters and getters ommitted and for citystatezip entity public class citystatezip public citystatezip columnnameid nullablefalse uniquetrue id generatedvaluegeneratorcustomeraddressescitystatezipidgenerator orghibernateannotationsgenericgeneratornamecustomeraddressescitystatezipidgenerator strategynative private int id columnnamezipcode nullablefalse length10 private string zipcode columnnamecity nullablefalse length24 private string city columnnamestateprov nullablefalse length2 private string stateprov with repositories repositoryrestresourcecollectionresourcerel addr path addr public interface addressrepository extends jparepositoryaddress integer listaddress findbystreetnoandstreetnamestartingwithignorecaseparamstnumber integer streetno paramstreet string streetname listaddress findbystreetnamestartingwithignorecaseparamstreet string streetname listaddress findbystreetnoparamstreetno integer strno and repositoryrestresourcecollectionresourcerel zip path zip exported false repositoryrestresourcecollectionresourcerel zip path zip public interface citystateziprepository extends jparepositorycitystatezip integer listcitystatezip findbyzipcodeparamzipcode string zipcode listcitystatezip findbystateprovparamstateprov string stateprov listcitystatezip findbycityandstateprovparamcity string city paramstate string state and main code of configuration enablejparepositories importrepositoryrestmvcconfigurationclass enableautoconfiguration enabletransactionmanagement propertysourcevalue fileetcdomainlocationapplicationproperties componentscan public class application public static void mainstring args springapplicationrunapplicationclass args with this code i can save a csz by posting this json to zipcode 28899 city ada stateprov nc but if i try to save an address by posting the json to add streetno 985 streetname bellingham plus4zip 2212 citystatezip zipcode 28115 city mooresville stateprov nc i get the error cause cause cause null message template must not be null or empty', ' message template must not be null or empty', 'through reference chain domainlocationaddresscitystatezip message could not read json template must not be null or empty', 'through reference chain domainlocationaddresscitystatezip nested exception is comfasterxmljacksondatabindjsonmappingexception template must not be null or empty', 'through reference chain domainlocationaddresscitystatezip now if i change citystateziprepository to include exportfalse in the annotation i can then save the address and csz to the database', 'but at that time zip is no longer exposed on the interface and doing get addr or addrid causes this error timestamp 1417728145384 status 500 error internal server error exception orgspringframeworkhttpconverterhttpmessagenotwritableexception message could not write json no serializer found for class orghibernateproxypojojavassistjavassistlazyinitializer and no properties discovered to create beanserializer to avoid exception disable serializationfeaturefailonemptybeans through reference chain orgspringframeworkhateoaspagedresourcesembeddedjavautilunmodifiablemapaddrjavautilarraylist0orgspringframeworkhateoasresourcecontentdomainlocationaddresscitystatezipdomainlocationcitystatezipjvst4e00handler nested exception is comfasterxmljacksondatabindjsonmappingexception no serializer found for class orghibernateproxypojojavassistjavassistlazyinitializer and no properties discovered to create beanserializer to avoid exception disable serializationfeaturefailonemptybeans through reference chain orgspringframeworkhateoaspagedresourcesembeddedjavautilunmodifiablemapaddrjavautilarraylist0orgspringframeworkhateoasresourcecontentdomainlocationaddresscitystatezipdomainlocationcitystatezipjvst4e00handler path addr isa there a way to set up this model to be able to post and get from this database', 'also the json passed to address will save a new instance of citystatezip what format will allow us to reference an existing citystatezip element', 'thanks for any help you can provide this has been driving us crazy for days now']"
Convert u8 array to base64 string in Rust,"I have an array of u8 in Rust. How would I go about converting these to a String representing them as base64?
",<arrays><string><rust><type-conversion><base64>,17,"arrays,string,rust,type-conversion,base64",['convert u8 array to base64 string in rust'],"['i have an array of u8 in rust', 'how would i go about converting these to a string representing them as base64']"
Multichannel blind deconvolution in the simplest formulation: how to solve?,"Recently I began to study deconvolution algorithms and met the following acquisition model:

where f is the original (latent) image, g is the input (observed) image, h is the point spread function (degradation kernel), n is a random additive noise and * is the convolution operator. 
If we know g and h, then we can recover f using Richardson-Lucy algorithm:

where , (W,H) is the size of rectangular support of h and multiplication and division are pointwise. Simple enough to code in C++, so I did just so. It turned out that  approximates to f while i is less then some m and then it starts rapidly decay. So the algorithm just needed to be stopped at this m - the most satisfactory iteration.
If the point spread function g is also unknown then the problem is said to be blind, and the modification of Richardson-Lucy algorithm can be applied:


For initial guess for f we can take g, as before, and for initial guess for h we can take trivial PSF, or any simple form that would look similar to observed image degradation. This algorithm also works quit fine on the simulated data.
Now I consider the multiframe blind deconvolution problem with the following acquisition model:

Is there a way to develop Richardson-Lucy algorithm for solving the problem in this formulation? If no, is there any other iterative procedure for recovering f, that wouldn't be much more complicated than the previous ones?
",<algorithm><image-processing><signal-processing><inverse><deconvolution>,8,"algorithm,image-processing,signal-processing,inverse,deconvolution",['multichannel blind deconvolution in the simplest formulation how to solve'],"['recently i began to study deconvolution algorithms and met the following acquisition model where f is the original latent image g is the input observed image h is the point spread function degradation kernel n is a random additive noise and is the convolution operator', 'if we know g and h then we can recover f using richardsonlucy algorithm where wh is the size of rectangular support of h and multiplication and division are pointwise', 'simple enough to code in c so i did just so', 'it turned out that approximates to f while i is less then some m and then it starts rapidly decay', 'so the algorithm just needed to be stopped at this m the most satisfactory iteration', 'if the point spread function g is also unknown then the problem is said to be blind and the modification of richardsonlucy algorithm can be applied for initial guess for f we can take g as before and for initial guess for h we can take trivial psf or any simple form that would look similar to observed image degradation', 'this algorithm also works quit fine on the simulated data', 'now i consider the multiframe blind deconvolution problem with the following acquisition model is there a way to develop richardsonlucy algorithm for solving the problem in this formulation', 'if no is there any other iterative procedure for recovering f that wouldnt be much more complicated than the previous ones']"
Mac OS X 32-bit nasm assembly program using main and scanf/printf?,"I have spent the entire day trying to get some simple programs compiled but so far very little luck. What I want to do is to compile and run programs written in nasm assembly.
I have upgraded to latest nasm (v2.10.09). So let me just jump into code since I do not know a lot about these things yet. Here is a chunk of assembly code that runs on linux using elf format and linked witch gcc (comments are my understanding of what is going on):
bits 32
extern printf
global main

section .data
    message db ""Hello world!"", 10, 0

section .text
main:
    pushad                      ;push all registers on stack
    push dword message                  ;push the string on stack
    call printf                 ;call printf
    add esp, 4                  ;clear stack
    popad                       ;pop all registers back
    ret                     ;return to whoever called me

Nothing too big. However how the hell am I supposed to get this to work on OS X? I cant even get it to compile/link in any way. If it compiles I cant link it (something about i386 and x86 which cant be linked together (I understand that but how to fix it?)). I have tried a dozen ways with no luck.
Further more how can I printf and scanf on OS X assembly?
Here is another futile attempt of a scanf and printf the value back (this one actually compiles and links - and even runs!):
[bits 32] ; why the []?

section .data
    input_string    db  ""Enter limit: %d"", 0
    output_string   db  ""Value %d"", 10, 0
    counter         dd  10
    limit           dd  0

;nasm -f macho -o test.o test.asm 
;ld -lc -o test -arch i386 test.o -macosx_version_min 10.7

section .text

global start
extern _printf
extern _scanf
extern _exit

start:
    push ebp                ;push stack base
    mov ebp, esp            ;base is now current top
    and esp, 0xFFFFFFF0     ;align the stack - WHY? I just googled this?

    sub esp, 16             ;16 bytes for variables - 16 to keep the stack ""aligned"". WHY?

    mov dword[esp], input_string         ;ordinary push just isint good nuff for mac... WHY?
    mov dword[esp + 4], limit
    call _scanf                          ;does scan something but doesnt print the message, it just scans and then prints the message

    mov eax, [limit]                      ;since i cant push this lets put it in eax first


    mov dword[esp + 8], output_string     ;push the output string. WHY again MOV?
    mov dword[esp + 12], eax              ;and the previusly ""scanned"" variable
    call _printf                          ;print it out

    mov dword[esp], 0       ;return value
    call _exit              ;return

Compiled it with: nasm -f macho -o test.o test.asm and linked it with d -lc -o test -arch i386 test.o -macosx_version_min 10.7. Doesnt work properly. On linux its super easy to to this scanf and printf thingie. What's up here? Can it be done simpler?
I do not want to add more stuff to this question since people sometimes see a big question and thing ""meh, too long, wont read"". But if anyone requests more info I'll do my best.
Please help me since I cant figure it out.
EDIT
The first one compiles using nasm -f macho -o out.o test.asm but doest link using gcc -o test out.o or by using ld -lc -o test -arch i386 out.o -macosx_version_min 10.7 and appending flat -arch i386 doesnt solve it either. I would love if I could write that ""linux like"" assembly since I do not have to worry about stack alignment and stuff like that.
gcc error says:
ld: warning: ignoring file out.o, file was built for i386 which is not the architecture being linked (x86_64): out.o
Undefined symbols for architecture x86_64:
  ""_main"", referenced from:
      start in crt1.10.6.o
ld: symbol(s) not found for architecture x86_64

and ld error is as follows:
Undefined symbols for architecture i386:
  ""printf"", referenced from:
      main in out.o
  ""start"", referenced from:
     -u command line option
ld: symbol(s) not found for architecture i386

Please help.
",<c><macos><gcc><assembly><nasm>,5,"c,macos,gcc,assembly,nasm",['mac os x 32bit nasm assembly program using main and scanfprintf'],"['i have spent the entire day trying to get some simple programs compiled but so far very little luck', 'what i want to do is to compile and run programs written in nasm assembly', 'i have upgraded to latest nasm v21009', 'so let me just jump into code since i do not know a lot about these things yet', 'here is a chunk of assembly code that runs on linux using elf format and linked witch gcc comments are my understanding of what is going on bits 32 extern printf global main section data message db hello world', ' 10 0 section text main pushad push all registers on stack push dword message push the string on stack call printf call printf add esp 4 clear stack popad pop all registers back ret return to whoever called me nothing too big', 'however how the hell am i supposed to get this to work on os x', 'i cant even get it to compilelink in any way', 'if it compiles i cant link it something about i386 and x86 which cant be linked together i understand that but how to fix it', 'i have tried a dozen ways with no luck', 'further more how can i printf and scanf on os x assembly', 'here is another futile attempt of a scanf and printf the value back this one actually compiles and links and even runs', ' bits 32 why the ', 'section data inputstring db enter limit d 0 outputstring db value d 10 0 counter dd 10 limit dd 0 nasm f macho o testo testasm ld lc o test arch i386 testo macosxversionmin 107 section text global start extern printf extern scanf extern exit start push ebp push stack base mov ebp esp base is now current top and esp 0xfffffff0 align the stack why', 'i just googled this', 'sub esp 16 16 bytes for variables 16 to keep the stack aligned', 'mov dwordesp inputstring ordinary push just isint good nuff for mac why', 'mov dwordesp 4 limit call scanf does scan something but doesnt print the message it just scans and then prints the message mov eax limit since i cant push this lets put it in eax first mov dwordesp 8 outputstring push the output string', 'why again mov', 'mov dwordesp 12 eax and the previusly scanned variable call printf print it out mov dwordesp 0 return value call exit return compiled it with nasm f macho o testo testasm and linked it with d lc o test arch i386 testo macosxversionmin 107 doesnt work properly', 'on linux its super easy to to this scanf and printf thingie', 'whats up here', 'can it be done simpler', 'i do not want to add more stuff to this question since people sometimes see a big question and thing meh too long wont read', 'but if anyone requests more info ill do my best', 'please help me since i cant figure it out', 'edit the first one compiles using nasm f macho o outo testasm but doest link using gcc o test outo or by using ld lc o test arch i386 outo macosxversionmin 107 and appending flat arch i386 doesnt solve it either', 'i would love if i could write that linux like assembly since i do not have to worry about stack alignment and stuff like that', 'gcc error says ld warning ignoring file outo file was built for i386 which is not the architecture being linked x8664 outo undefined symbols for architecture x8664 main referenced from start in crt1106o ld symbols not found for architecture x8664 and ld error is as follows undefined symbols for architecture i386 printf referenced from main in outo start referenced from u command line option ld symbols not found for architecture i386 please help']"
Why one should prefer using CSS over XPath in IE?,"I am working on an application which is compatible only with IE7 and IE8. I didn't know why but some suggested to use CSS over XPath while identifying the elements in IE. When I visited the official Selenium site. I read the message 

WebDriver uses a browser’s native XPath capabilities wherever possible. On those browsers that don’t have native XPath support, we have provided our own implementation. This can lead to some unexpected behaviour unless you are aware of the differences in the various xpath engines.

I would like to know where I can find the differences in the various xpath engines and in which situations I should use CSS and and in which XPath specifically if I'm using IE. Thanks.
",<java><css><xpath><selenium><webdriver>,5,"java,css,xpath,selenium,webdriver",['why one should prefer using css over xpath in ie'],"['i am working on an application which is compatible only with ie7 and ie8', 'i didnt know why but some suggested to use css over xpath while identifying the elements in ie', 'when i visited the official selenium site', 'i read the message webdriver uses a browsers native xpath capabilities wherever possible', 'on those browsers that dont have native xpath support we have provided our own implementation', 'this can lead to some unexpected behaviour unless you are aware of the differences in the various xpath engines', 'i would like to know where i can find the differences in the various xpath engines and in which situations i should use css and and in which xpath specifically if im using ie', 'thanks']"
Core Audio (Audio Units) audio session and MPVolumeView,"I work on a VOIP app.
I use Core Audio Audio Units for playing and recording audio. I need to be able to manipulate sound volume and output devices. I am trying to use MPVolumeView to set sound volume and choose output devices.
My problem is: When I start using(start playout and capture for RemoteIO Audio Unit) Audio Units it seems MPVolumeView no longer control volume of my session but instead it controls system wide sound preferences. At the same time hardware buttons control volume of sounds played by Audio Units. Also when I start using Audio Units MPVolumeView start showing button to change output devices but before that it doesn't.
It seems that MPVolumeView controls sound volume for some system wide audio session but when I start using Audio Units another app wide (or even Audio Unit wide) audio session is created and used to play sound.
So the question is how to make MPVolumeView control sound volume for my Core Audio audio session? 
I would appreciate any hints on why this happens. I've spent almost all day googling and I see that some people have related problems but none got any hints :(. I can also post more details if needed. 
",<iphone><ios><core-audio><audiounit><mpvolumeview>,5,"iphone,ios,core-audio,audiounit,mpvolumeview",['core audio audio units audio session and mpvolumeview'],"['i work on a voip app', 'i use core audio audio units for playing and recording audio', 'i need to be able to manipulate sound volume and output devices', 'i am trying to use mpvolumeview to set sound volume and choose output devices', 'my problem is when i start usingstart playout and capture for remoteio audio unit audio units it seems mpvolumeview no longer control volume of my session but instead it controls system wide sound preferences', 'at the same time hardware buttons control volume of sounds played by audio units', 'also when i start using audio units mpvolumeview start showing button to change output devices but before that it doesnt', 'it seems that mpvolumeview controls sound volume for some system wide audio session but when i start using audio units another app wide or even audio unit wide audio session is created and used to play sound', 'so the question is how to make mpvolumeview control sound volume for my core audio audio session', 'i would appreciate any hints on why this happens', 'ive spent almost all day googling and i see that some people have related problems but none got any hints ', 'i can also post more details if needed']"
System.NullReferenceException occurs in xaml designer,"I've created a C++ UWP Windows 10 app using Visual Studio 2015.  However, I'm not able to visualize any xaml in the designer because I'm always getting a System.NullReferenceException error.  How can I fix this?
",<xaml><visual-studio-2015><win-universal-app><windows-10><visual-studio-designer>,9,"xaml,visual-studio-2015,win-universal-app,windows-10,visual-studio-designer",['systemnullreferenceexception occurs in xaml designer'],"['ive created a c uwp windows 10 app using visual studio 2015 however im not able to visualize any xaml in the designer because im always getting a systemnullreferenceexception error', 'how can i fix this']"
How do you pass an apostrophe through a URL?,"I'm using Node.js:
var s = 'Who\'s that girl?';
var url = 'http://graph.facebook.com/?text=' + encodeURIComponent(s);

request(url, POST, ...)

This does not work! And Facebook cuts off my text...
Full code:
function postToFacebook(fbid, access_token, data, next){
    var uri = 'https://graph.facebook.com/'+String(fbid)+'/feed?access_token='+access_token;
    var uri += '&' + querystring.stringify(data);
    request({
        'method':'POST',
        'uri': uri,
    },function(err,response,body){
        next();
    });
};


app.get('/test',function(req,res){
    var d = {
        'name':'Who\'s that girl?',
        'link': 'http://example.com',
        'caption': 'some caption...',
        'description': 'some description...',
        'picture': 'http://i.imgur.com/CmlrM.png',
    };
    postToFacebook(req.user.fb.id, req.user.fb.accessToken, d);
    res.send('done');
});

Facebook gets a blank post on the wall. No text shows. Nothing.
When I log my URI, it is this:
https://graph.facebook.com/1290502368/feed?access_token=2067022539347370|d7ae6f314515c918732eab36.1-1230602668|GtOJ-pi3ZBatd41tPvrHb0OIYyk&name=Who's%20that%20girl%3F&link=http%3A%2F%2Fexample.com&caption=some%20caption...&description=some%20description...&picture=http%3A%2F%2Fi.imgur.com%2FCmlrM.png

Obviously if you take a look at that URL, you see that the apostrophe is not being encoded correctly.
",<javascript><string><encoding><node.js><facebook-graph-api>,37,"javascript,string,encoding,node.js,facebook-graph-api",['how do you pass an apostrophe through a url'],"['im using nodejs var s whos that girl', ' var url encodeuricomponents requesturl post this does not work', 'and facebook cuts off my text full code function posttofacebookfbid accesstoken data next var uri var uri querystringstringifydata request methodpost uri uri functionerrresponsebody next appgettestfunctionreqres var d namewhos that girl', ' link caption some caption description some description picture posttofacebookrequserfbid requserfbaccesstoken d ressenddone facebook gets a blank post on the wall', 'no text shows', 'nothing', 'when i log my uri it is this obviously if you take a look at that url you see that the apostrophe is not being encoded correctly']"
array<> can’t simply swap pointers internally,"For the container array<> introduced to STL with TR1, I have a problem below. 
In Page 263 of book ""The C++ standard library A Tutorial and Reference"":

Note, however, that an array<> can’t simply swap pointers internally. For this reason, swap() has linear complexity and the effect that iterators and references don’t swap containers with their elements.

I wondered why array<> cannot considering its constant overhead for swapping pointers? 
",<c++><arrays><c++11><complexity-theory><swap>,5,"c++,arrays,c++11,complexity-theory,swap",['array cant simply swap pointers internally'],"['for the container array introduced to stl with tr1 i have a problem below', 'in page 263 of book the c standard library a tutorial and reference note however that an array cant simply swap pointers internally', 'for this reason swap has linear complexity and the effect that iterators and references dont swap containers with their elements', 'i wondered why array cannot considering its constant overhead for swapping pointers']"
Angular/Typescript - Wildcard module declaration,"I'm trying to implement wildcard modules and i don't seem to get it work:
Right now i have the following code which works:
typings.d.ts
declare module ""*.json"" {
  const value: any;
  export default value;
}

app.component.ts
import { Component, OnInit } from '@angular/core';
import * as es from './i18n/es.json';

@Component({
  selector: 'my-app',
  templateUrl: './app.component.html',
  styleUrls: [ './app.component.css' ]
})
export class AppComponent implements OnInit {
  hello = '-';

  ngOnInit() {
    this.hello = es.default.hello;
  }
}

You may see a live example here, however i want to implement WILDCARDS, as seen here (typescriptlang) and here (sitepen):

Implementation should allow me to do something like this:
typings.d.ts
declare module ""*.json!i18n"" {
  const value: any;
  export default value;
}

declare module ""*.json!static"" {
  const value: any;
  export default value;
}

declare module ""*!text"" {
  const value: any;
  export default value;
}

app.component.ts
import { Component, OnInit } from '@angular/core';
import * as es from './i18n/es.json!i18n';
import * as someObject from './static/someObject.json!static';
import * as template1 from './templates/template1.html!text';

@Component({
  selector: 'my-app',
  templateUrl: './app.component.html',
  styleUrls: [ './app.component.css' ]
})
export class AppComponent implements OnInit {
  hello = '-';

  ngOnInit() {
    this.hello = es.default.hello;
    console.log(someObject.default);
    console.log(template1.default);
  }
}

The issue is that for some reason wildcards are not being correctly recognized... throwing at runtime that ""json"" is not found.

""Module not found: Error: Can't resolve 'json' in ...""
""Module not found: Error: Can't resolve 'static' in ...""
""Module not found: Error: Can't resolve 'text' in ...""

An example of this feature working is here when it was first implemented on Angular 2,
Any idea of what i'm doing wrong??
",<angular><typescript><angular6><angular7><angular-module>,13,"angular,typescript,angular6,angular7,angular-module",['angulartypescript wildcard module declaration'],"['im trying to implement wildcard modules and i dont seem to get it work right now i have the following code which works typingsdts declare module json const value any export default value appcomponentts import component oninit from angularcore import as es from i18nesjson component selector myapp templateurl appcomponenthtml styleurls appcomponentcss export class appcomponent implements oninit hello ngoninit thishello esdefaulthello you may see a live example here however i want to implement wildcards as seen here typescriptlang and here sitepen implementation should allow me to do something like this typingsdts declare module jsoni18n const value any export default value declare module jsonstatic const value any export default value declare module text const value any export default value appcomponentts import component oninit from angularcore import as es from i18nesjsoni18n import as someobject from staticsomeobjectjsonstatic import as template1 from templatestemplate1htmltext component selector myapp templateurl appcomponenthtml styleurls appcomponentcss export class appcomponent implements oninit hello ngoninit thishello esdefaulthello consolelogsomeobjectdefault consolelogtemplate1default the issue is that for some reason wildcards are not being correctly recognized throwing at runtime that json is not found', 'module not found error cant resolve json in module not found error cant resolve static in module not found error cant resolve text in an example of this feature working is here when it was first implemented on angular 2 any idea of what im doing wrong', '']"
Rails: How to downcase non-English string?,"How could I downcase a non-English string in Ruby on Rails 3 ?
str = ""Привет""    # Russian 
puts str[0].ord   # => 1055
str.downcase!
puts str[0].ord   # => 1055 (Should be 1087)

I want it to work in Ruby 1.8.7 as well as Ruby 1.9.2.
",<ruby-on-rails><ruby><string><ruby-on-rails-3><lowercase>,37,"ruby-on-rails,ruby,string,ruby-on-rails-3,lowercase",['rails how to downcase nonenglish string'],"['how could i downcase a nonenglish string in ruby on rails 3 ', 'str russian puts str0ord 1055 strdowncase', 'puts str0ord 1055 should be 1087 i want it to work in ruby 187 as well as ruby 192']"
Autolayout and shadow,"I've got a problem with adding shadow to my UIView which is created in iOS 6 application with Autolayout.
Let's assume I have a method that adds a shadow on the bottom of UIView (this is actually a Category of UIView, so it's reusable):
- (void) addShadowOnBottom {
    self.layer.shadowOffset = CGSizeMake(0, 2);
    self.layer.shadowOpacity = 0.7;
    self.layer.shadowColor = [[UIColor blackColor] CGColor];
    self.layer.shadowPath = [UIBezierPath bezierPathWithRect:self.bounds].CGPath;
}

When I call this method in viewDidLoad of some UIViewController, shadow is not added, probably due to all constraints, that have to be calculated.
When I call this method in viewWillAppear the same situation.
When I call this method in viewDidAppear it works, but when new view shows up there is a short moment when there is no shadow and it appears after a while.
If I resign from setting the shadowPath and remove line self.layer.shadowPath everything works, but view transitions are not smooth.
So my question is what is the right way to add a shadow to view in iOS 6 with Autolayout turned on ?
",<ios><objective-c><xcode><ios6><autolayout>,10,"ios,objective-c,xcode,ios6,autolayout",['autolayout and shadow'],"['ive got a problem with adding shadow to my uiview which is created in ios 6 application with autolayout', 'lets assume i have a method that adds a shadow on the bottom of uiview this is actually a category of uiview so its reusable void addshadowonbottom selflayershadowoffset cgsizemake0 2 selflayershadowopacity 07 selflayershadowcolor uicolor blackcolor cgcolor selflayershadowpath uibezierpath bezierpathwithrectselfboundscgpath when i call this method in viewdidload of some uiviewcontroller shadow is not added probably due to all constraints that have to be calculated', 'when i call this method in viewwillappear the same situation', 'when i call this method in viewdidappear it works but when new view shows up there is a short moment when there is no shadow and it appears after a while', 'if i resign from setting the shadowpath and remove line selflayershadowpath everything works but view transitions are not smooth', 'so my question is what is the right way to add a shadow to view in ios 6 with autolayout turned on ']"
Testing an Entity Framework database connection,"I have an app that connects to a MYSQL database through the entity framework. It works 100% perfectly, but I would like to add a small piece of code that will test the connection to the database upon app startup.
I had the idea of simply running a tiny command to the database and catching any exceptions, however if there is a problem (eg App.Config missing or Database server down) the app takes a huge amount of time to run this code and then throw the exception (~1 min). I imagine this is due to connection timeouts etc but I have fiddled with such properties to no avail.
Would anyone be able to assist with any ideas as to where to go?
",<c#><mysql><entity-framework><testing><database-connection>,69,"c#,mysql,entity-framework,testing,database-connection",['testing an entity framework database connection'],"['i have an app that connects to a mysql database through the entity framework', 'it works 100 perfectly but i would like to add a small piece of code that will test the connection to the database upon app startup', 'i had the idea of simply running a tiny command to the database and catching any exceptions however if there is a problem eg appconfig missing or database server down the app takes a huge amount of time to run this code and then throw the exception 1 min', 'i imagine this is due to connection timeouts etc but i have fiddled with such properties to no avail', 'would anyone be able to assist with any ideas as to where to go']"
ValueError: setting an array element with a sequence. while using SVM in scikit-learn,"I have been working on scikit-learn SVMs for a binary classification problem. I have calculated the features of audio files and wrote them into a CSV file. This is how each row in a CSV file looks like:
""13_10 The Long And Winding Road "" ""[-6.5633095666136669e-16,-1.56E-15,-3.21E-15,-2.20E-
15,-2.52E-15,-3.04E-15,-3.39E-15,-3.47E-15,-3.07E-15,-6.02E-15,-3.00E-15,-4.77E-15,-3.05E-
15,-2.13E-15,-1.57E-15,-1.87E-15,-2.05E-15,-1.76E-15,-1.38E-15,-9.89E-16,-7.89E-16,-8.99E-
16,-1.09E-15,-7.26E-16,-8.68E-16,-4.68E-16,-2.82E-16,-1.99E-16,-1.75E-16,-2.18E-16,-1.43E-
16,-1.56E-16,-1.91E-16,-1.21E-16,-4.82E-17,-4.39E-17,-2.89E-17,-2.05E-17,0.0]"" 0

The first column has the name of the Audio, second column has the feature array and the last element is the label {0,1} for binary classification.
There are 39 float values in the array. I am using the following code to extract them from the CSV file.
with open('File.csv', 'rb') as csvfile:
    albumreader = csv.reader(csvfile, delimiter=' ')
    data = list()
    for row in albumreader:
        data.append(row[0:]) 
data = np.array(data)

X_train = list()
Y_train = list()
k = data.shape[0]

for i in range(k):
    feature = data[i][1]
    x = map(float, feature[1:-2].split(','))
    X_train.append(x)
    label = data[i][2]
    y = float(label)
    Y_train.append(y)    

So when I print X_train and Y_train I get exact values in an array. But when I use
clf = svm.SVC(C=1.0, cache_size=200,kernel='linear', max_iter=-1)
clf.fit(X_train,Y_train)

I get the error saying 
Traceback (most recent call last):
File ""<stdin>"", line 1, in <module>
File ""C:\Python27\lib\site-
packages\spyderlib\widgets\externalshell\sitecustomize.py"",line 540, in runfile
execfile(filename, namespace)
File ""SVM_test.py"", line 55, in <module>
clf.fit(X_train,Y_train)
File ""sklearn\svm\base.py"", line 137, in fit
File ""sklearn\utils\validation.py"", line 165, in atleast2d_or_csr
File ""sklearn\utils\validation.py"", line 142, in _atleast2d_or_sparse
File ""sklearn\utils\validation.py"", line 120, in array2d
File ""C:\Python27\lib\site-packages\numpy\core\numeric.py"", line 460, in asarray
return array(a, dtype, copy=False, order=order)
ValueError: setting an array element with a sequence.

Can someone help me as to what I can do now? I am really not sure what is happening inside. Both the dimensions of X_train and Y_train are same [X_train has 21 vectors with 39 elements and Y_train has 21 floats {0 or 1}, I don't see what made these errors.
Note: I have a feeling that something might be wrong while I convert the numpy array to string and then a string to a numpy array. Thanks in advance. 
Edit: X_Train is very large. Here it is..
[[93812.4999999983, 73189.57452, 48892.17363, 37682.69053, 33709.51536, 20815.68443,   12476.88854, 13364.13645, 9574.010981, 5844.293383, 7910.017736, 12721.38592, 14184.99241, 6988.131481, 9407.380437, 6333.852471, 5688.156663, 7167.61338, 6911.084942, 9210.064235, 5732.338515, 3585.039683, 4433.278772, 4757.658741, 3387.832928, 2711.640327, 2680.255742, 1649.410788, 2024.333977, 997.2348795, 1102.115501, 1386.86396, 1160.477719, 883.941971, 881.2712624, 749.3620066, 885.6355941, 514.1635441, 0.0], [93411.33935126709, 90714.51224, 89773.71828, 61018.71033, 28082.94493, 10120.93228, 11106.07725, 6204.140734, 5968.528906, 4970.099848, 6967.870007, 6990.611982, 7656.630743, 6615.957476, 5573.621516, 8957.245225, 8512.408652, 6976.021692, 7774.215884, 5301.046573, 4666.784091, 2539.587812, 2953.578612, 3529.863917, 2365.101263, 2579.870258, 2890.325096, 3302.179572, 2078.005268, 1425.18236, 1297.961119, 736.4896705, 640.0635888, 819.022382, 659.9559469, 438.2773842, 359.3957991, 193.9937669, 0.0], [95528.45827960827, 79000.64725, 75540.32258, 47915.39365, 29573.63325, 13554.15721, 10101.04124, 6935.685456, 13681.96711, 7726.754596, 9413.96529, 9468.785586, 10479.23762, 10070.81121, 8893.475453, 9517.553541, 8493.077533, 8021.721412, 8568.069341, 7687.282084, 9902.16325, 5442.263263, 5575.258138, 4748.557573, 4580.647869, 3014.91771, 3958.708771, 2851.846841, 3407.31788, 1982.369432, 1937.459179, 1689.049684, 1457.579778, 1055.411047, 1048.471861, 661.6174333, 827.8371903, 414.802354], [101683.46698748806, 62367.04137, 66444.15995, 49621.45404, 31623.19485, 16585.34427, 12271.46378, 12114.5615, 6666.281052, 9335.886213, 19314.70299, 22588.00911, 14133.31813, 12723.03772, 7994.399321, 11447.449, 15457.39519, 7419.208867, 9286.751692, 6128.746537, 5617.886066, 4461.131891, 4651.73188, 5835.270092, 3876.10397, 4499.228748, 2661.999151, 1431.362029, 1378.115091, 1048.827946, 1470.297845, 1087.453644, 825.6318213, 861.5003481, 804.8519616, 397.0719915, 368.8037827, 293.36727], [96614.66763477474, 89674.79785, 73045.22026, 55387.48162, 32450.76131, 26161.93729, 16379.95699, 13446.77762, 6178.297767, 4499.9064, 6128.624979, 4928.968691, 7139.579976, 6442.404748, 7303.917218, 9064.476552, 8246.412739, 4526.169172, 4931.980606, 4022.38625, 3193.080061, 3991.709836, 4894.262891, 4523.545798, 5013.65655, 3165.268896, 2252.272798, 1971.857637, 1543.455559, 1248.305408, 1340.303682, 1069.466847, 1062.971087, 596.4763587, 541.7390803, 481.9598053, 261.6165905, 135.050925], [77116.86410716272, 85174.88022, 48949.81474, 39272.16867, 28721.41507, 26604.82082, 17057.75385, 11417.45143, 12775.94149, 8095.318819, 8318.738856, 7768.406613, 9501.155323, 8215.579012, 5801.439936, 6997.611748, 8358.126592, 6710.072432, 7903.976639, 4770.389995, 4443.449546, 3622.278619, 3628.985312, 4025.879147, 3378.124716, 1681.144815, 1873.675902, 1813.454359, 1203.261884, 734.9896092, 612.7767898, 581.1641439, 554.9952946, 338.9208239, 329.6306536, 210.3361409, 124.684456, 95.1698974], [86000.24134707314, 54315.80346, 61723.06357, 48194.93238, 34145.18298, 18060.21908, 17759.95552, 13594.71484, 10034.81255, 6892.428679, 13609.12234, 11345.97425, 12640.27575, 13636.73634, 8353.154837, 11543.51778, 9620.892875, 5364.536625, 6645.647746, 6939.929388, 6404.367983, 4279.002491, 5473.449778, 5173.72645, 4161.012572, 3189.349797, 1868.016199, 2370.813774, 1991.805589, 1862.750613, 1535.097522, 1195.019326, 824.4997101, 836.5762868, 758.8865079, 739.0096703, 426.339462, 495.362511], [88356.8775920093, 68677.18631, 56499.17126, 41069.83582, 34004.99481, 21584.94408, 16827.63584, 10875.88263, 8838.404327, 10399.33201, 10247.97332, 11592.57345, 6888.99984, 8027.86374, 4396.353004, 4926.542018, 4160.408132, 4829.051031, 5104.507749, 4445.908694, 4113.401198, 2070.059053, 2331.063956, 3091.764189, 2708.490628, 1357.792132, 1476.379979, 1099.46743, 895.2046416, 1017.410994, 855.9326154, 807.2299975, 817.8896259, 688.1633806, 620.1147918, 404.4791452, 355.3012015, 155.124636], [129161.3158422606, 99871.12426, 69682.53863, 42152.57846, 27722.10719, 16851.46834, 12503.65957, 15820.8482, 10208.86252, 3737.281589, 11388.29292, 9216.418551, 8412.969115, 8915.691889, 7214.795344, 6312.935476, 5691.760401, 4452.333587, 6080.803383, 3169.211512, 4640.513939, 2965.070935, 2603.678979, 3427.596811, 2650.097593, 3407.197764, 2399.210804, 1585.540133, 900.6057596, 1562.799097, 1414.458688, 1085.727804, 862.853398, 1046.809149, 1299.422095, 452.1395434, 416.0278005, 342.487369], [97676.58730158686, 85928.37013, 60031.54702, 50283.65633, 30440.49477, 23396.44028, 17693.84492, 13834.72723, 13079.6, 9484.172923, 11026.12866, 15489.77935, 14751.23748, 7719.575611, 6916.062149, 9947.922301, 9860.230801, 6685.554777, 5314.504743, 6412.026375, 5126.472976, 3994.412881, 3469.94381, 3087.75188, 2150.012155, 2510.441776, 1633.896465, 1468.22101, 1451.997957, 1594.288508, 1208.749937, 1539.411357, 846.1440547, 1015.738147, 760.9050287, 531.4752058, 352.2906744, 256.992846], [99873.48353552721, 96128.33417, 56062.95108, 48316.51261, 33803.61475, 20090.40769, 14532.69355, 16973.62408, 11745.412, 10555.56359, 12415.12332, 11311.00716, 13055.02538, 13457.43473, 11949.02017, 13726.34027, 13210.19444, 6924.913491, 7526.293551, 6489.797287, 7504.193589, 3693.345327, 3173.144967, 4589.951959, 3817.607517, 2296.577132, 4241.66248, 2298.259695, 2104.233705, 1894.800787, 1435.902299, 1237.861542, 1008.052264, 743.557111, 447.3644689, 360.231905, 263.6887002, 252.53243], [118318.40927047582, 96894.04475, 72455.95855, 53538.90521, 34270.2485, 14028.66282, 6110.994324, 10831.06944, 6500.061124, 5648.546259, 9746.722376, 11098.67455, 12414.31738, 11859.15818, 5661.36057, 6467.490449, 7160.019668, 4986.101354, 4805.715894, 4384.860917, 4818.433908, 2776.480858, 2906.711958, 4180.355966, 3029.563639, 2121.677425, 2977.055372, 1650.875378, 1328.284924, 1641.967101, 1374.844716, 1269.983055, 756.2822371, 746.9782069, 635.1025738, 901.5181204, 500.4240422, 124.234986], [99496.1074660524, 91134.19642, 64615.65163, 51749.95315, 27017.75136, 17498.19736, 8686.464718, 6354.494714, 6279.181765, 6011.661362, 9583.683802, 16802.58819, 12848.82539, 12448.85086, 9717.906293, 6025.712047, 8968.944145, 6116.427844, 8009.500521, 5857.252734, 5994.629798, 4602.865888, 5568.279578, 3847.961198, 3664.838032, 2285.641295, 2343.300802, 1538.656643, 1595.004126, 1438.685894, 1278.233128, 1138.847548, 1387.660031, 727.3346259, 443.3437923, 399.422316, 202.3671643, 210.818774], [97897.81181619188, 81534.24658, 86124.34023, 55859.41234, 43498.35095, 16317.93548, 9240.704588, 8335.639737, 5398.77203, 2959.587234, 7638.934756, 9237.569061, 9669.92492, 6395.762472, 5297.481894, 4628.757031, 5965.00084, 5360.168945, 4918.802753, 5403.035015, 7760.124783, 4316.46269, 3586.003412, 4862.517393, 2722.334238, 1950.153709, 2308.64693, 1738.602095, 1431.956923, 1195.875585, 903.5619486, 628.8441079, 378.5951575, 279.5559759, 290.8523867, 185.8872588, 124.4224622, 102.6474251], [92929.03125177219, 66037.16827, 85713.22692, 60594.81708, 21299.03928, 9728.745394, 7164.560274, 7530.287996, 3986.197072, 4768.423334, 7965.588661, 6884.742393, 7813.113615, 6783.772795, 5068.375149, 5563.205324, 4549.089711, 4178.977925, 7176.864923, 3595.204266, 4075.654498, 3667.874878, 5018.867408, 4632.204595, 4236.022945, 2419.634542, 1965.732854, 2017.314496, 1125.444672, 1776.994722, 1380.972752, 877.5693874, 1048.039171, 698.4293241, 587.3589805, 425.3561446, 374.9688448, 242.143167], [112279.4547224921, 85626.58906, 82479.88981, 41194.72139, 18581.67331, 17171.661, 11041.06798, 7470.697485, 5647.489476, 5413.921458, 6258.45235, 7817.02576, 5690.588758, 5018.057148, 2835.675844, 4192.365122, 5264.669752, 2899.863762, 4722.075443, 4359.368543, 4475.52712, 4364.193393, 4366.760559, 4466.265791, 3581.127965, 3229.694902, 3061.592084, 2761.368431, 2924.520852, 2278.74424, 1842.130366, 1353.160812, 1061.970453, 801.4987863, 559.7692834, 542.6125554, 365.0923416, 345.207555], [103517.74691357967, 75660.08945, 77823.62831, 44178.34395, 30627.84085, 16822.14795, 12153.82383, 10477.03604, 6737.154621, 3948.567091, 5952.492101, 6657.190597, 8458.524435, 4644.542091, 3262.595869, 6196.748153, 4725.493005, 3131.648336, 3043.832975, 2397.211069, 2221.444205, 1846.007568, 1906.256992, 2565.899774, 1879.678929, 1983.431392, 2057.925713, 1379.158985, 1161.566123, 1269.932159, 1882.60896, 2175.463202, 1945.131584, 2617.451168, 1724.479089, 934.2682688, 703.1608361, 325.546], [93568.70860926574, 94747.49539969431, 46432.77848910925, 34021.920729891295, 20420.991633759644, 11780.466421174959, 11808.677934216039, 8356.053623407755, 5251.866299007888, 1837.1346095714694, 3388.9444867864604, 4160.840941722876, 3099.1858407062873, 2498.7020047692304, 2320.2543950190047, 3123.103649596546, 2353.3994748227874, 2282.188646923959, 2461.343070326571, 1867.3943363024234, 2097.623570329987, 2009.6550578189285, 3308.2027220730074, 2765.1388333698114, 1557.1149504889588, 1365.611056602633, 1960.1916988919656, 1357.4554303292293, 1174.7058492639005, 1132.4243713198962, 845.4972050001261, 1168.2703928255426, 792.9426082625839, 670.3864757268884, 462.94718979251763, 418.287362938786, 440.0999154920886, 177.49705973335398, 0.0], [95355.29766162521, 80982.187596427, 52611.83577098383, 32094.021907352668, 17954.16900608238, 10539.432714398477, 8455.780912660928, 7826.206728864228, 6509.019127983875, 3428.593131775805, 4133.834750579424, 4897.866949416399, 4527.962919676826, 3097.9755890532115, 2644.294656259542, 3715.9623636641186, 2820.3307205895694, 2502.4555417041665, 4294.009887075389, 3305.480815069842, 3473.739729060158, 3436.008663252062, 2646.057627969427, 2915.118003316749, 2807.214040627724, 2182.2047542975124, 2307.7279832228096, 2051.914227220658, 1701.1785697138466, 1387.86622139378, 1717.4780638249865, 1444.4320186566786, 1543.3397450160378, 1008.7972827019012, 804.7763630817929, 727.0076251244793, 661.7971983605773, 328.023137248546, 0.0], [106950.75545607107, 83171.33894927795, 98570.84168082179, 53995.601284217235, 34045.2113137451, 32682.002511908893, 20258.01771044016, 17863.78159524713, 10999.026649078776, 7606.650910143417, 8186.182643934389, 12307.240199947704, 6014.871257290792, 4781.08981401508, 5131.609324634855, 4391.107045269739, 4364.496837469433, 3795.810404058682, 5693.929878923241, 3511.0866864164072, 4967.40355405853, 3290.291028496737, 2401.232195128987, 2787.2578565673602, 2210.985797970096, 2106.714353398232, 1799.725035771931, 2223.1076215378416, 1189.234114777526, 1003.1624544891614, 1046.7700894681655, 812.1805254193989, 750.3209854314467, 893.172975198784, 492.44092578555313, 379.87738447537436, 169.4616484512177, 100.56120686339501, 0.0]]

Y_Train is just the labels for individual sets of features. It is like this:
[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]

Hope that helps!
",<arrays><python-2.7><csv><scikit-learn><svm>,31,"arrays,python-2.7,csv,scikit-learn,svm","['valueerror setting an array element with a sequence', 'while using svm in scikitlearn']","['i have been working on scikitlearn svms for a binary classification problem', 'i have calculated the features of audio files and wrote them into a csv file', 'this is how each row in a csv file looks like 1310 the long and winding road 65633095666136669e16156e15321e15220e 15252e15304e15339e15347e15307e15602e15300e15477e15305e 15213e15157e15187e15205e15176e15138e15989e16789e16899e 16109e15726e16868e16468e16282e16199e16175e16218e16143e 16156e16191e16121e16482e17439e17289e17205e1700 0 the first column has the name of the audio second column has the feature array and the last element is the label 01 for binary classification', 'there are 39 float values in the array', 'i am using the following code to extract them from the csv file', 'with openfilecsv rb as csvfile albumreader csvreadercsvfile delimiter data list for row in albumreader dataappendrow0 data nparraydata xtrain list ytrain list k datashape0 for i in rangek feature datai1 x mapfloat feature12split xtrainappendx label datai2 y floatlabel ytrainappendy so when i print xtrain and ytrain i get exact values in an array', 'but when i use clf svmsvcc10 cachesize200kernellinear maxiter1 clffitxtrainytrain i get the error saying traceback most recent call last file stdin line 1 in module file cpython27libsite packagesspyderlibwidgetsexternalshellsitecustomizepyline 540 in runfile execfilefilename namespace file svmtestpy line 55 in module clffitxtrainytrain file sklearnsvmbasepy line 137 in fit file sklearnutilsvalidationpy line 165 in atleast2dorcsr file sklearnutilsvalidationpy line 142 in atleast2dorsparse file sklearnutilsvalidationpy line 120 in array2d file cpython27libsitepackagesnumpycorenumericpy line 460 in asarray return arraya dtype copyfalse orderorder valueerror setting an array element with a sequence', 'can someone help me as to what i can do now', 'i am really not sure what is happening inside', 'both the dimensions of xtrain and ytrain are same xtrain has 21 vectors with 39 elements and ytrain has 21 floats 0 or 1 i dont see what made these errors', 'note i have a feeling that something might be wrong while i convert the numpy array to string and then a string to a numpy array', 'thanks in advance', 'edit xtrain is very large', 'here it is 938124999999983 7318957452 4889217363 3768269053 3370951536 2081568443 1247688854 1336413645 9574010981 5844293383 7910017736 1272138592 1418499241 6988131481 9407380437 6333852471 5688156663 716761338 6911084942 9210064235 5732338515 3585039683 4433278772 4757658741 3387832928 2711640327 2680255742 1649410788 2024333977 9972348795 1102115501 138686396 1160477719 883941971 8812712624 7493620066 8856355941 5141635441 00 9341133935126709 9071451224 8977371828 6101871033 2808294493 1012093228 1110607725 6204140734 5968528906 4970099848 6967870007 6990611982 7656630743 6615957476 5573621516 8957245225 8512408652 6976021692 7774215884 5301046573 4666784091 2539587812 2953578612 3529863917 2365101263 2579870258 2890325096 3302179572 2078005268 142518236 1297961119 7364896705 6400635888 819022382 6599559469 4382773842 3593957991 1939937669 00 9552845827960827 7900064725 7554032258 4791539365 2957363325 1355415721 1010104124 6935685456 1368196711 7726754596 941396529 9468785586 1047923762 1007081121 8893475453 9517553541 8493077533 8021721412 8568069341 7687282084 990216325 5442263263 5575258138 4748557573 4580647869 301491771 3958708771 2851846841 340731788 1982369432 1937459179 1689049684 1457579778 1055411047 1048471861 6616174333 8278371903 414802354 10168346698748806 6236704137 6644415995 4962145404 3162319485 1658534427 1227146378 121145615 6666281052 9335886213 1931470299 2258800911 1413331813 1272303772 7994399321 11447449 1545739519 7419208867 9286751692 6128746537 5617886066 4461131891 465173188 5835270092 387610397 4499228748 2661999151 1431362029 1378115091 1048827946 1470297845 1087453644 8256318213 8615003481 8048519616 3970719915 3688037827 29336727 9661466763477474 8967479785 7304522026 5538748162 3245076131 2616193729 1637995699 1344677762 6178297767 44999064 6128624979 4928968691 7139579976 6442404748 7303917218 9064476552 8246412739 4526169172 4931980606 402238625 3193080061 3991709836 4894262891 4523545798 501365655 3165268896 2252272798 1971857637 1543455559 1248305408 1340303682 1069466847 1062971087 5964763587 5417390803 4819598053 2616165905 135050925 7711686410716272 8517488022 4894981474 3927216867 2872141507 2660482082 1705775385 1141745143 1277594149 8095318819 8318738856 7768406613 9501155323 8215579012 5801439936 6997611748 8358126592 6710072432 7903976639 4770389995 4443449546 3622278619 3628985312 4025879147 3378124716 1681144815 1873675902 1813454359 1203261884 7349896092 6127767898 5811641439 5549952946 3389208239 3296306536 2103361409 124684456 951698974 8600024134707314 5431580346 6172306357 4819493238 3414518298 1806021908 1775995552 1359471484 1003481255 6892428679 1360912234 1134597425 1264027575 1363673634 8353154837 1154351778 9620892875 5364536625 6645647746 6939929388 6404367983 4279002491 5473449778 517372645 4161012572 3189349797 1868016199 2370813774 1991805589 1862750613 1535097522 1195019326 8244997101 8365762868 7588865079 7390096703 426339462 495362511 883568775920093 6867718631 5649917126 4106983582 3400499481 2158494408 1682763584 1087588263 8838404327 1039933201 1024797332 1159257345 688899984 802786374 4396353004 4926542018 4160408132 4829051031 5104507749 4445908694 4113401198 2070059053 2331063956 3091764189 2708490628 1357792132 1476379979 109946743 8952046416 1017410994 8559326154 8072299975 8178896259 6881633806 6201147918 4044791452 3553012015 155124636 1291613158422606 9987112426 6968253863 4215257846 2772210719 1685146834 1250365957 158208482 1020886252 3737281589 1138829292 9216418551 8412969115 8915691889 7214795344 6312935476 5691760401 4452333587 6080803383 3169211512 4640513939 2965070935 2603678979 3427596811 2650097593 3407197764 2399210804 1585540133 9006057596 1562799097 1414458688 1085727804 862853398 1046809149 1299422095 4521395434 4160278005 342487369 9767658730158686 8592837013 6003154702 5028365633 3044049477 2339644028 1769384492 1383472723 130796 9484172923 1102612866 1548977935 1475123748 7719575611 6916062149 9947922301 9860230801 6685554777 5314504743 6412026375 5126472976 3994412881 346994381 308775188 2150012155 2510441776 1633896465 146822101 1451997957 1594288508 1208749937 1539411357 8461440547 1015738147 7609050287 5314752058 3522906744 256992846 9987348353552721 9612833417 5606295108 4831651261 3380361475 2009040769 1453269355 1697362408 11745412 1055556359 1241512332 1131100716 1305502538 1345743473 1194902017 1372634027 1321019444 6924913491 7526293551 6489797287 7504193589 3693345327 3173144967 4589951959 3817607517 2296577132 424166248 2298259695 2104233705 1894800787 1435902299 1237861542 1008052264 743557111 4473644689 360231905 2636887002 25253243 11831840927047582 9689404475 7245595855 5353890521 342702485 1402866282 6110994324 1083106944 6500061124 5648546259 9746722376 1109867455 1241431738 1185915818 566136057 6467490449 7160019668 4986101354 4805715894 4384860917 4818433908 2776480858 2906711958 4180355966 3029563639 2121677425 2977055372 1650875378 1328284924 1641967101 1374844716 1269983055 7562822371 7469782069 6351025738 9015181204 5004240422 124234986 994961074660524 9113419642 6461565163 5174995315 2701775136 1749819736 8686464718 6354494714 6279181765 6011661362 9583683802 1680258819 1284882539 1244885086 9717906293 6025712047 8968944145 6116427844 8009500521 5857252734 5994629798 4602865888 5568279578 3847961198 3664838032 2285641295 2343300802 1538656643 1595004126 1438685894 1278233128 1138847548 1387660031 7273346259 4433437923 399422316 2023671643 210818774 9789781181619188 8153424658 8612434023 5585941234 4349835095 1631793548 9240704588 8335639737 539877203 2959587234 7638934756 9237569061 966992492 6395762472 5297481894 4628757031 596500084 5360168945 4918802753 5403035015 7760124783 431646269 3586003412 4862517393 2722334238 1950153709 230864693 1738602095 1431956923 1195875585 9035619486 6288441079 3785951575 2795559759 2908523867 1858872588 1244224622 1026474251 9292903125177219 6603716827 8571322692 6059481708 2129903928 9728745394 7164560274 7530287996 3986197072 4768423334 7965588661 6884742393 7813113615 6783772795 5068375149 5563205324 4549089711 4178977925 7176864923 3595204266 4075654498 3667874878 5018867408 4632204595 4236022945 2419634542 1965732854 2017314496 1125444672 1776994722 1380972752 8775693874 1048039171 6984293241 5873589805 4253561446 3749688448 242143167 1122794547224921 8562658906 8247988981 4119472139 1858167331 17171661 1104106798 7470697485 5647489476 5413921458 625845235 781702576 5690588758 5018057148 2835675844 4192365122 5264669752 2899863762 4722075443 4359368543 447552712 4364193393 4366760559 4466265791 3581127965 3229694902 3061592084 2761368431 2924520852 227874424 1842130366 1353160812 1061970453 8014987863 5597692834 5426125554 3650923416 345207555 10351774691357967 7566008945 7782362831 4417834395 3062784085 1682214795 1215382383 1047703604 6737154621 3948567091 5952492101 6657190597 8458524435 4644542091 3262595869 6196748153 4725493005 3131648336 3043832975 2397211069 2221444205 1846007568 1906256992 2565899774 1879678929 1983431392 2057925713 1379158985 1161566123 1269932159 188260896 2175463202 1945131584 2617451168 1724479089 9342682688 7031608361 325546 9356870860926574 9474749539969431 4643277848910925 34021920729891295 20420991633759644 11780466421174959 11808677934216039 8356053623407755 5251866299007888 18371346095714694 33889444867864604 4160840941722876 30991858407062873 24987020047692304 23202543950190047 3123103649596546 23533994748227874 2282188646923959 2461343070326571 18673943363024234 2097623570329987 20096550578189285 33082027220730074 27651388333698114 15571149504889588 1365611056602633 19601916988919656 13574554303292293 11747058492639005 11324243713198962 8454972050001261 11682703928255426 7929426082625839 6703864757268884 46294718979251763 418287362938786 4400999154920886 17749705973335398 00 9535529766162521 80982187596427 5261183577098383 32094021907352668 1795416900608238 10539432714398477 8455780912660928 7826206728864228 6509019127983875 3428593131775805 4133834750579424 4897866949416399 4527962919676826 30979755890532115 2644294656259542 37159623636641186 28203307205895694 25024555417041665 4294009887075389 3305480815069842 3473739729060158 3436008663252062 2646057627969427 2915118003316749 2807214040627724 21822047542975124 23077279832228096 2051914227220658 17011785697138466 138786622139378 17174780638249865 14444320186566786 15433397450160378 10087972827019012 8047763630817929 7270076251244793 6617971983605773 328023137248546 00 10695075545607107 8317133894927795 9857084168082179 53995601284217235 340452113137451 32682002511908893 2025801771044016 1786378159524713 10999026649078776 7606650910143417 8186182643934389 12307240199947704 6014871257290792 478108981401508 5131609324634855 4391107045269739 4364496837469433 3795810404058682 5693929878923241 35110866864164072 496740355405853 3290291028496737 2401232195128987 27872578565673602 2210985797970096 2106714353398232 1799725035771931 22231076215378416 1189234114777526 10031624544891614 10467700894681655 8121805254193989 7503209854314467 893172975198784 49244092578555313 37987738447537436 1694616484512177 10056120686339501 00 ytrain is just the labels for individual sets of features', 'it is like this 00 10 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 10 00 00 hope that helps']"
Android Google maps transparency,"I'm working on a mapping app. And I want to show some views under the MapView.
I'm using the method:
    mapView.setAlpha(0.5f);

Nothing happens to the mapView. When I try to apply this method to my buttons it works fine, even applying it to the parent view of the mapView makes every child view transparent except for the mapView.
How can we make the mapView transparent? I have looked into other questions here  and I cant seem to find a solution.
Is there some special method in the mapView.getMap() that we can use to make it transparent?
",<android><google-maps><google-maps-android-api-2><android-mapview><transparent>,11,"android,google-maps,google-maps-android-api-2,android-mapview,transparent",['android google maps transparency'],"['im working on a mapping app', 'and i want to show some views under the mapview', 'im using the method mapviewsetalpha05f nothing happens to the mapview', 'when i try to apply this method to my buttons it works fine even applying it to the parent view of the mapview makes every child view transparent except for the mapview', 'how can we make the mapview transparent', 'i have looked into other questions here and i cant seem to find a solution', 'is there some special method in the mapviewgetmap that we can use to make it transparent']"
How can I tune neural network architecture using KerasTuner?,"I'm trying to use KerasTuner to automatically tune the neural network architecture, i.e., the number of hidden layers and the number of nodes in each hidden layer. Currently, the neural network architecture is defined using one parameter NN_LAYER_SIZES. For example,
NN_LAYER_SIZES = [128, 128, 128, 128]

indicates the NN has 4 hidden layers and each hidden layer has 128 nodes.
KerasTuner has the following hyperparameter types (https://keras.io/api/keras_tuner/hyperparameters/):

Int
Float
Boolean
Choice

It seems none of these hyperparameter types fits my use case. So I wrote the following code to scan the number of hidden layers and the number of nodes. However, it's not been recognized as a hyperparameter.
number_of_hidden_layer = hp.Int(""layer_number"", min_value=2, max_value=5, step=1)
number_of_nodes = hp.Int(""node_number"", min_value=4, max_value=8, step=1)
NN_LAYER_SIZES = [2**number_of_nodes for _ in range(number of hidden_layer)]

Any suggestions on how to make it right?
",<python><tensorflow><keras><neural-network><keras-tuner>,6,"python,tensorflow,keras,neural-network,keras-tuner",['how can i tune neural network architecture using kerastuner'],"['im trying to use kerastuner to automatically tune the neural network architecture ie the number of hidden layers and the number of nodes in each hidden layer', 'currently the neural network architecture is defined using one parameter nnlayersizes', 'for example nnlayersizes 128 128 128 128 indicates the nn has 4 hidden layers and each hidden layer has 128 nodes', 'kerastuner has the following hyperparameter types int float boolean choice it seems none of these hyperparameter types fits my use case', 'so i wrote the following code to scan the number of hidden layers and the number of nodes', 'however its not been recognized as a hyperparameter', 'numberofhiddenlayer hpintlayernumber minvalue2 maxvalue5 step1 numberofnodes hpintnodenumber minvalue4 maxvalue8 step1 nnlayersizes 2numberofnodes for in rangenumber of hiddenlayer any suggestions on how to make it right']"
How to refresh firebase IdToken with apollo Reactjs client,"I am using a Apollo Client in ReactJS to communicate with GraphQL API. We use Firebase authentication and it's JWT to ensure our API don't expose private data the public but the problem is firebase token expires every one hour or so.
I am currently saving the IdToken localstorage when user login in and use that on the request headers but when token expires graphql returns Non Authorized error. I also tried using customfetch on createHttpLink function from the apollo
const customFetch = async (uri, options) => {
    console.log(firebase.auth.currentUser)
    if (firebase.auth.currentUser) {
        const token = await firebase.auth.currentUser.getIdToken()
        localStorage.setItem('token', token)
        options.headers.authorization = token;
        return fetch(uri, options);
    }
    else {
        firebase.auth.onAuthStateChanged(async (user) => {
            if (user) {
                console.log('Inside on Auth')
                const token = await user.getIdToken()
                localStorage.setItem('token', token)
                options.headers.authorization = token;
                return fetch(uri, options);
            }
        })
    }
    console.log('End of Fetch')
};

but fetch completes before firebase.auth.onAuthStateChanged is completed so it also don't work
",<reactjs><firebase><firebase-authentication><apollo><react-apollo>,5,"reactjs,firebase,firebase-authentication,apollo,react-apollo",['how to refresh firebase idtoken with apollo reactjs client'],"['i am using a apollo client in reactjs to communicate with graphql api', 'we use firebase authentication and its jwt to ensure our api dont expose private data the public but the problem is firebase token expires every one hour or so', 'i am currently saving the idtoken localstorage when user login in and use that on the request headers but when token expires graphql returns non authorized error', 'i also tried using customfetch on createhttplink function from the apollo const customfetch async uri options consolelogfirebaseauthcurrentuser if firebaseauthcurrentuser const token await firebaseauthcurrentusergetidtoken localstoragesetitemtoken token optionsheadersauthorization token return fetchuri options else firebaseauthonauthstatechangedasync user if user consoleloginside on auth const token await usergetidtoken localstoragesetitemtoken token optionsheadersauthorization token return fetchuri options consolelogend of fetch but fetch completes before firebaseauthonauthstatechanged is completed so it also dont work']"
TimeZoneInfo from timezone minutes offset,"From JavaScript I have passed, to the controller, the number of minutes that the user's client date time is offset from UTC using the method getTimezoneOffset on the Date object.  Now that I have this information on the server side I'd like to create a TimeZoneInfo from it.  How is this possible?  If this is not possible then how can I convert UTC dates on the server side into the client's timezone using the minutes offset?
",<c#><javascript><asp.net-mvc-4><datetime><timezone>,11,"c#,javascript,asp.net-mvc-4,datetime,timezone",['timezoneinfo from timezone minutes offset'],"['from javascript i have passed to the controller the number of minutes that the users client date time is offset from utc using the method gettimezoneoffset on the date object', 'now that i have this information on the server side id like to create a timezoneinfo from it', 'how is this possible', 'if this is not possible then how can i convert utc dates on the server side into the clients timezone using the minutes offset']"
Django - Understanding X-Sendfile,"I've been doing some research regarding file downloads with access control, using Django. My goal is to completely block access to a file, except when accessed by a specific user. I've read that when using Django, X-Sendfile is one of the methods of choice for achieving this (based on other SO questions, etc). My rudimentary understanding of using X-Sendfile with Django is:

User requests URI to get a protected file
Django app decides which file to return based on URL, and checks user permission, etc.
Django app returns an HTTP Response with the 'X-Sendfile' header set to the server's file path
The web server finds the file and returns it to the requester (I assume the webs server also strips out the 'X-Sendfile' header along the way)

Compared with chucking the file directly from Django, X-Sendfile seems likely to be a more efficient method of achieving protected downloads (since I can rely on Nginx to serve files, vs Django), but leaves 2 questions for me:

Is my explanation of X-Sendfile at least abstractly correct?
Is it really secure, assuming I don't provide normal, front-end HTTP access (e.g. http://www.example.com/downloads/secret-file.jpg) to the directory that the file is stored (ie, don't keep it in my public_html directory)? Or, could a tech-savvy user examine headers, etc. and reverse engineer a way to access a file (to then distribute)?
Is it really a big difference in performance. Am I going to bog my application server down by providing 8b chunked downloads of 150Mb files directly from Django, or is this sort-of a non-issue? The reason I ask is because if both versions are near equal, the Django version would be preferable due to my ability to do things in Python, like log the number of completed downloads, tally bandwidth of downloads etc.

Thanks in advance.
",<python><django><download><x-sendfile><protected-resource>,38,"python,django,download,x-sendfile,protected-resource",['django understanding xsendfile'],"['ive been doing some research regarding file downloads with access control using django', 'my goal is to completely block access to a file except when accessed by a specific user', 'ive read that when using django xsendfile is one of the methods of choice for achieving this based on other so questions etc', 'my rudimentary understanding of using xsendfile with django is user requests uri to get a protected file django app decides which file to return based on url and checks user permission etc', 'django app returns an http response with the xsendfile header set to the servers file path the web server finds the file and returns it to the requester i assume the webs server also strips out the xsendfile header along the way compared with chucking the file directly from django xsendfile seems likely to be a more efficient method of achieving protected downloads since i can rely on nginx to serve files vs django but leaves 2 questions for me is my explanation of xsendfile at least abstractly correct', 'is it really secure assuming i dont provide normal frontend http access eg', 'to the directory that the file is stored ie dont keep it in my publichtml directory', 'or could a techsavvy user examine headers etc', 'and reverse engineer a way to access a file to then distribute', 'is it really a big difference in performance', 'am i going to bog my application server down by providing 8b chunked downloads of 150mb files directly from django or is this sortof a nonissue', 'the reason i ask is because if both versions are near equal the django version would be preferable due to my ability to do things in python like log the number of completed downloads tally bandwidth of downloads etc', 'thanks in advance']"
Angular 2 CLI Jasmine unit test fails when using beforeAll instead of beforeEach,"I created a new project with NG-CLI (beta.15) and modified the app.component.spec to change the beforeEach to to a beforeAll and it caused the tests to fail with the following error:

Failed: Cannot create the component AppComponent as it was not imported into the testing module!

I don't understand what this error means and of course why I would get it in the first place. 
Here's the modified spec:
import { TestBed, async } from '@angular/core/testing';
import { AppComponent } from './app.component';

describe('App: Ng2CliTest2', () => {
  beforeAll(() => {
    TestBed.configureTestingModule({
      declarations: [
        AppComponent
      ],
    });
  });

  it('should create the app', async(() => {
    let fixture = TestBed.createComponent(AppComponent);
    let app = fixture.debugElement.componentInstance;
    expect(app).toBeTruthy();
  }));

  it(`should have as title 'app works!'`, async(() => {
    let fixture = TestBed.createComponent(AppComponent);
    let app = fixture.debugElement.componentInstance;
    expect(app.title).toEqual('app works!');
  }));

  it('should render title in a h1 tag', async(() => {
    let fixture = TestBed.createComponent(AppComponent);
    fixture.detectChanges();
    let compiled = fixture.debugElement.nativeElement;
    expect(compiled.querySelector('h1').textContent).toContain('app works!');
  }));
});

I then modified the spec to this and the first two tests pass and the third fails with the following message :

Failed: Attempt to use a destroyed view: detectChanges

import { TestBed, async } from '@angular/core/testing';
import { AppComponent } from './app.component';

let fixture;
let app;

describe('App: Ng2CliTest2', () => {
  beforeAll(() => {
    TestBed.configureTestingModule({
      declarations: [
        AppComponent
      ],
    });
    fixture = TestBed.createComponent(AppComponent);
    app = fixture.debugElement.componentInstance;        
  });

  it('should create the app', async(() => {
    expect(app).toBeTruthy();
  }));

  it(`should have as title 'app works!'`, async(() => {
    expect(app.title).toEqual('app works!');
  }));

  it('should render title in a h1 tag', async(() => {
    fixture.detectChanges();
    let compiled = fixture.debugElement.nativeElement;
    expect(compiled.querySelector('h1').textContent).toContain('app works!');
  }));
});

I don't understand why there are any failures.
",<unit-testing><angular><jasmine><angular-cli><angular2-testing>,5,"unit-testing,angular,jasmine,angular-cli,angular2-testing",['angular 2 cli jasmine unit test fails when using beforeall instead of beforeeach'],"['i created a new project with ngcli beta15 and modified the appcomponentspec to change the beforeeach to to a beforeall and it caused the tests to fail with the following error failed cannot create the component appcomponent as it was not imported into the testing module', 'i dont understand what this error means and of course why i would get it in the first place', 'heres the modified spec import testbed async from angularcoretesting import appcomponent from appcomponent describeapp ng2clitest2 beforeall testbedconfiguretestingmodule declarations appcomponent itshould create the app async let fixture testbedcreatecomponentappcomponent let app fixturedebugelementcomponentinstance expectapptobetruthy itshould have as title app works', ' async let fixture testbedcreatecomponentappcomponent let app fixturedebugelementcomponentinstance expectapptitletoequalapp works', ' itshould render title in a h1 tag async let fixture testbedcreatecomponentappcomponent fixturedetectchanges let compiled fixturedebugelementnativeelement expectcompiledqueryselectorh1textcontenttocontainapp works', ' i then modified the spec to this and the first two tests pass and the third fails with the following message failed attempt to use a destroyed view detectchanges import testbed async from angularcoretesting import appcomponent from appcomponent let fixture let app describeapp ng2clitest2 beforeall testbedconfiguretestingmodule declarations appcomponent fixture testbedcreatecomponentappcomponent app fixturedebugelementcomponentinstance itshould create the app async expectapptobetruthy itshould have as title app works', ' async expectapptitletoequalapp works', ' itshould render title in a h1 tag async fixturedetectchanges let compiled fixturedebugelementnativeelement expectcompiledqueryselectorh1textcontenttocontainapp works', ' i dont understand why there are any failures']"
Create multi-message conversations with the GPT API,"I am experimenting with the GPT API by OpenAI and am learning how to use the GPT-3.5-Turbo model. I found a quickstart example on the web:
def generate_chat_completion(messages, model=""gpt-3.5-turbo"", temperature=1, max_tokens=None):
    headers = {
        ""Content-Type"": ""application/json"",
        ""Authorization"": f""Bearer {API_KEY}"",
    }

    data = {
        ""model"": model,
        ""messages"": messages,
        ""temperature"": temperature,
    }

    max_tokens = 100

    if max_tokens is not None:
        data[""max_tokens""] = max_tokens

    response = requests.post(API_ENDPOINT, headers=headers, data=json.dumps(data))

    if response.status_code == 200:
        return response.json()[""choices""][0][""message""][""content""]
    else:
        raise Exception(f""Error {response.status_code}: {response.text}"")

while 1:
    inputText = input(""Enter your message: "")

    messages = [
        {""role"": ""system"", ""content"": inputText},
    ]

    response_text = generate_chat_completion(messages)
    print(response_text)

With the necessary imports and the API key and endpoint defined above the code block. I added the inputText variable to take text inputs and an infinite while loop to keep the input/response cycle going until the program is terminated (probably bad practice).
However, I've noticed that responses from the API aren't able to reference previous parts of the conversation like the ChatGPT web application (rightfully so, as I have not mentioned any form of conversation object). I looked up on the API documentation on chat completion and the conversation request example is as follows:
[
  {""role"": ""system"", ""content"": ""You are a helpful assistant that translates English to French.""},
  {""role"": ""user"", ""content"": 'Translate the following English text to French: ""{text}""'}
]

However, this means I will have to send all the inputted messages into the conversation at once and get a response back for each of them. I cannot seem to find a way (at least as described in the API) to send a message, then get one back, and then send another message in the format of a full conversation with reference to previous messages like a chatbot (or as described before the ChatGPT app). Is there some way to implement this?
Also: the above does not use the OpenAI Python module. It uses the Requests and JSON modules.
",<python><python-requests><openai-api><gpt-3><chatgpt-api>,6,"python,python-requests,openai-api,gpt-3,chatgpt-api",['create multimessage conversations with the gpt api'],"['i am experimenting with the gpt api by openai and am learning how to use the gpt35turbo model', 'i found a quickstart example on the web def generatechatcompletionmessages modelgpt35turbo temperature1 maxtokensnone headers contenttype applicationjson authorization fbearer apikey data model model messages messages temperature temperature maxtokens 100 if maxtokens is not none datamaxtokens maxtokens response requestspostapiendpoint headersheaders datajsondumpsdata if responsestatuscode 200 return responsejsonchoices0messagecontent else raise exceptionferror responsestatuscode responsetext while 1 inputtext inputenter your message messages role system content inputtext responsetext generatechatcompletionmessages printresponsetext with the necessary imports and the api key and endpoint defined above the code block', 'i added the inputtext variable to take text inputs and an infinite while loop to keep the inputresponse cycle going until the program is terminated probably bad practice', 'however ive noticed that responses from the api arent able to reference previous parts of the conversation like the chatgpt web application rightfully so as i have not mentioned any form of conversation object', 'i looked up on the api documentation on chat completion and the conversation request example is as follows role system content you are a helpful assistant that translates english to french', ' role user content translate the following english text to french text however this means i will have to send all the inputted messages into the conversation at once and get a response back for each of them', 'i cannot seem to find a way at least as described in the api to send a message then get one back and then send another message in the format of a full conversation with reference to previous messages like a chatbot or as described before the chatgpt app', 'is there some way to implement this', 'also the above does not use the openai python module', 'it uses the requests and json modules']"
"What's the fastest way to copy and manipulate large, dense 2D arrays in c++","I'm trying to optimize my code, taking advantage of multicore processors, to both copy any manipulate large dense arrays.  
For copying: I have a large dense array (approximately 6000x100000) from which I need to pull 15x100000 subarrays to do several computations down the pipe.  The pipe consists of a lot of linear algebra functions that are being handled by blas, which is multicore.  Whether or not the time to pull data will really matter compared to the linear algebra is an open question, but I'd like to err on the side of caution and make sure the data copying is optimized.
For manipulating: I have many different functions that manipulate arrays by with element or row.  It would be best if each of these was done multicore.
My question is: is it best to use to right framework (OpenML, OpenCL) and let all the magic happen with the compiler, or are there good functions/libraries that do this faster?
",<c++><arrays><performance><parallel-processing><opencl>,10,"c++,arrays,performance,parallel-processing,opencl",['whats the fastest way to copy and manipulate large dense 2d arrays in c'],"['im trying to optimize my code taking advantage of multicore processors to both copy any manipulate large dense arrays', 'for copying i have a large dense array approximately 6000x100000 from which i need to pull 15x100000 subarrays to do several computations down the pipe', 'the pipe consists of a lot of linear algebra functions that are being handled by blas which is multicore', 'whether or not the time to pull data will really matter compared to the linear algebra is an open question but id like to err on the side of caution and make sure the data copying is optimized', 'for manipulating i have many different functions that manipulate arrays by with element or row', 'it would be best if each of these was done multicore', 'my question is is it best to use to right framework openml opencl and let all the magic happen with the compiler or are there good functionslibraries that do this faster']"
ASP.NET Returning JSON with ASHX,"I am creating autocomplete functionality for my website.
So far, the javascript part is over. Also, I can get the MembershipUser object of the user that matches.
I need to return JSON in the following format:
{
 query:'Li',
 suggestions:['Liberia','Libyan Arab Jamahiriya','Liechtenstein','Lithuania'],
 data:['LR','LY','LI','LT']
}

and this is the code in ashx:
public void ProcessRequest (HttpContext context) {
    System.Web.Script.Serialization.JavaScriptSerializer JsonSerializer;   
    string query = context.Request.QueryString[""query""];
    System.Web.Security.MembershipUserCollection Users = System.Web.Security.Membership.GetAllUsers();
    context.Response.ContentType = ""application/json"";
    foreach (System.Web.Security.MembershipUser User in Users)
    {
        if (User.UserName.StartsWith(query.ToLower()))
        {
            context.Response.Write(query + Environment.NewLine);
            context.Response.Write(User.Email);
        }
    }
}

How can I return the json in the desired format?
Thanks.
",<c#><jquery><asp.net><ajax><json>,30,"c#,jquery,asp.net,ajax,json",['aspnet returning json with ashx'],"['i am creating autocomplete functionality for my website', 'so far the javascript part is over', 'also i can get the membershipuser object of the user that matches', 'i need to return json in the following format queryli suggestionsliberialibyan arab jamahiriyaliechtensteinlithuania datalrlylilt and this is the code in ashx public void processrequest httpcontext context systemwebscriptserializationjavascriptserializer jsonserializer string query contextrequestquerystringquery systemwebsecuritymembershipusercollection users systemwebsecuritymembershipgetallusers contextresponsecontenttype applicationjson foreach systemwebsecuritymembershipuser user in users if userusernamestartswithquerytolower contextresponsewritequery environmentnewline contextresponsewriteuseremail how can i return the json in the desired format', 'thanks']"
Using python variable within Jupyter LaTeX Markdown Cell,"I would like to fill in values in a report that I'm generating using a Jupyter notebook. While I am using the nbextension Python Markdown, this appears to only allow variables that can isolated, i.e. I can't fill in values that would be in a fraction.
This works, since it is only symbolic:
Markdown cell:
\begin{equation*}
\xi_b = \frac{\epsilon_c}{\epsilon_c + \epsilon_y}
\end{equation*}

But this code snippet wouldn't:
Code cell:
epsilon_c = 0.003
epsilon_y = 0.005

Markdown cell:
\begin{equation*}
\xi_b = \frac{{{epsilon_c}}}{{{epsilon_c}} + {{epsilon_y}}}
\end{equation*}

Is there some way to inject the python variable values directly into my LaTeX expression?
",<python><latex><jupyter-notebook><jupyter><jupyter-contrib-nbextensions>,7,"python,latex,jupyter-notebook,jupyter,jupyter-contrib-nbextensions",['using python variable within jupyter latex markdown cell'],"['i would like to fill in values in a report that im generating using a jupyter notebook', 'while i am using the nbextension python markdown this appears to only allow variables that can isolated ie', 'i cant fill in values that would be in a fraction', 'this works since it is only symbolic markdown cell beginequation xib fracepsiloncepsilonc epsilony endequation but this code snippet wouldnt code cell epsilonc 0003 epsilony 0005 markdown cell beginequation xib fracepsiloncepsilonc epsilony endequation is there some way to inject the python variable values directly into my latex expression']"
How do I compile and link a 32-bit Windows executable using mingw-w64,"I am using Ubuntu 13.04 and installed mingw-w64 using apt-get install mingw-w64. I can compile and link a working 64-bit version of my program with the following command:
x86_64-w64-mingw32-g++ code.cpp -o app.exe

Which generates a 64-bit app.exe file.
What binary or command line flags do I use to generate a 32-bit version of app.exe?
",<linux><mingw><32bit-64bit><32-bit><mingw-w64>,36,"linux,mingw,32bit-64bit,32-bit,mingw-w64",['how do i compile and link a 32bit windows executable using mingww64'],"['i am using ubuntu 1304 and installed mingww64 using aptget install mingww64', 'i can compile and link a working 64bit version of my program with the following command x8664w64mingw32g codecpp o appexe which generates a 64bit appexe file', 'what binary or command line flags do i use to generate a 32bit version of appexe']"
Pizza & Food - database design,"I want to create a website that allow customer to order food from the website.
There are two food type:

regular food/drink (eg: burger, donner kebab, chip, coke, pepsi etc)
Pizza food (eg: Margherita Pizza, meat Pizza, etc)

If they select pizza from the list - they may need to select Base (thin crust, dep crust), Extras, and the pizza size/Option.
How to design the tables in this situation?
Note: Each item have 1 or more options. An option may have extra (1 or more) or without extra.  If item is pizza type - then it may have Base (crust)
Screenshots prototype
See two screenshots I am trying to implement, I on the right path on the database design or what could have done better?
Pizza customize:

Beef Burger customize:

Extras functionality (Dropdown  / tickboxes)
On the extras, sometime I need to add multiple extras for the dropdown instead tickboxes. That means the customer can only choose 1 from 1, 2 or 3 dropdowns. 

Database design
How would you set up your database modell to implement something like the above customization options? 
Here is what I have came up with:
categories Table:
+----------+--------------+------+-----+---------+----------------+
| Field    | Type         | Null | Key | Default | Extra          |
+----------+--------------+------+-----+---------+----------------+
| cat_id   | int(11)      | NO   | PRI | NULL    | auto_increment |
| cat_name | varchar(100) | NO   |     | NULL    |                |
+----------+--------------+------+-----+---------+----------------+

items Table:
+-----------+--------------+------+-----+---------+----------------+
| Field     | Type         | Null | Key | Default | Extra          |
+-----------+--------------+------+-----+---------+----------------+
| item_id   | int(11)      | NO   | PRI | NULL    | auto_increment |
| cat_id    | int(11)      | NO   |     | NULL    |                |
| item_name | varchar(100) | NO   |     | NULL    |                |
| item_type | int(11)      | NO   |     | NULL    |                |
+-----------+--------------+------+-----+---------+----------------+

- item_type (0 = normal, 1 = pizza, 2 = set meal)
item_options Table:
+-------------+--------------+------+-----+---------+----------------+
| Field       | Type         | Null | Key | Default | Extra          |
+-------------+--------------+------+-----+---------+----------------+
| option_id   | int(11)      | NO   | PRI | NULL    | auto_increment |
| item_id     | int(11)      | NO   |     | NULL    |                |
| option_name | varchar(100) | NO   |     | NULL    |                |
| price       | decimal(6,2) | NO   |     | NULL    |                |
+-------------+--------------+------+-----+---------+----------------+

item_extras Table:
(Do you think should have separate tables for pizza toppin and extras?)
+-----------+--------------+------+-----+---------+----------------+
| Field     | Type         | Null | Key | Default | Extra          |
+-----------+--------------+------+-----+---------+----------------+
| extra_id  | int(11)      | NO   | PRI | NULL    | auto_increment |
| option_id | int(11)      | NO   |     | NULL    |                |
| name      | varchar(50)  | NO   |     | NULL    |                |
| cost      | decimal(6,2) | NO   |     | NULL    |                |
+-----------+--------------+------+-----+---------+----------------+

item_pizza_base Table:
+-----------+--------------+------+-----+---------+----------------+
| Field     | Type         | Null | Key | Default | Extra          |
+-----------+--------------+------+-----+---------+----------------+
| base_id   | int(11)      | NO   | PRI | NULL    | auto_increment |
| option_id | int(11)      | NO   |     | NULL    |                |
| base_name | varchar(50)  | NO   |     | NULL    |                |
| cost      | decimal(6,2) | NO   |     | NULL    |                |
+-----------+--------------+------+-----+---------+----------------+

SQL Result:
mysql> select * from categories;
+--------+----------+
| cat_id | cat_name |
+--------+----------+
|      1 | Pizzas   |
|      2 | Burgers  |

mysql> select * from items;
+---------+--------+------------------+-----------+
| item_id | cat_id | item_name        | item_type |
+---------+--------+------------------+-----------+
|       1 |      1 | Vegetarian Pizza |         1 |
|       2 |      2 | Beef Burger      |         0 |

mysql> select * from item_options;
+-----------+---------+-------------+-------+
| option_id | item_id | option_name | price |
+-----------+---------+-------------+-------+
|         1 |       1 | 12 Inches   |  5.60 |
|         2 |       1 | 14 Inches   |  7.20 |
|         3 |       2 | 1/4lb       |  1.80 |
|         4 |       2 | 1/2lb       |  2.50 |

mysql> select * from item_extras;
+----------+-----------+-----------+------+
| extra_id | option_id | name      | cost |
+----------+-----------+-----------+------+
|        1 |         1 | Mushroom  | 1.00 |
|        2 |         1 | Pepperoni | 1.00 |
|        3 |         2 | Mushroom  | 1.00 |
|        4 |         2 | Pepperoni | 1.00 |
|        5 |         3 | Chips     | 0.50 |
|        6 |         4 | Chips     | 0.50 |

As you can see extras from burger and pizza in 1 table.. should it be separated?   
mysql> select * from item_pizza_base;
+---------+-----------+------------+------+
| base_id | option_id | base_name  | cost |
+---------+-----------+------------+------+
|       1 |         1 | Thin Crust | 0.00 |
|       2 |         1 | Deep Crust | 0.00 |
|       3 |         2 | Thin Crust | 0.00 |
|       4 |         2 | Deep Crust | 0.00 |
+---------+-----------+------------+------+

keep in mind, price extras for each item is not always the same. For example: Pizza size 10"" will cost 1.00 for each extra but 0.50 for 12"" pizzas. Also there will be a case for each pizza will have different cost of extras.
Is the database design correct or what could be improved?
",<mysql><sql><database><database-design><relational-database>,19,"mysql,sql,database,database-design,relational-database",['pizza food database design'],"['i want to create a website that allow customer to order food from the website', 'there are two food type regular fooddrink eg burger donner kebab chip coke pepsi etc pizza food eg margherita pizza meat pizza etc if they select pizza from the list they may need to select base thin crust dep crust extras and the pizza sizeoption', 'how to design the tables in this situation', 'note each item have 1 or more options', 'an option may have extra 1 or more or without extra', 'if item is pizza type then it may have base crust screenshots prototype see two screenshots i am trying to implement i on the right path on the database design or what could have done better', 'pizza customize beef burger customize extras functionality dropdown tickboxes on the extras sometime i need to add multiple extras for the dropdown instead tickboxes', 'that means the customer can only choose 1 from 1 2 or 3 dropdowns', 'database design how would you set up your database modell to implement something like the above customization options', 'here is what i have came up with categories table field type null key default extra catid int11 no pri null autoincrement catname varchar100 no null items table field type null key default extra itemid int11 no pri null autoincrement catid int11 no null itemname varchar100 no null itemtype int11 no null itemtype 0 normal 1 pizza 2 set meal itemoptions table field type null key default extra optionid int11 no pri null autoincrement itemid int11 no null optionname varchar100 no null price decimal62 no null itemextras table do you think should have separate tables for pizza toppin and extras', ' field type null key default extra extraid int11 no pri null autoincrement optionid int11 no null name varchar50 no null cost decimal62 no null itempizzabase table field type null key default extra baseid int11 no pri null autoincrement optionid int11 no null basename varchar50 no null cost decimal62 no null sql result mysql select from categories catid catname 1 pizzas 2 burgers mysql select from items itemid catid itemname itemtype 1 1 vegetarian pizza 1 2 2 beef burger 0 mysql select from itemoptions optionid itemid optionname price 1 1 12 inches 560 2 1 14 inches 720 3 2 14lb 180 4 2 12lb 250 mysql select from itemextras extraid optionid name cost 1 1 mushroom 100 2 1 pepperoni 100 3 2 mushroom 100 4 2 pepperoni 100 5 3 chips 050 6 4 chips 050 as you can see extras from burger and pizza in 1 table should it be separated', 'mysql select from itempizzabase baseid optionid basename cost 1 1 thin crust 000 2 1 deep crust 000 3 2 thin crust 000 4 2 deep crust 000 keep in mind price extras for each item is not always the same', 'for example pizza size 10 will cost 100 for each extra but 050 for 12 pizzas', 'also there will be a case for each pizza will have different cost of extras', 'is the database design correct or what could be improved']"
Alternatives to Firebase Dynamic Links for Deep Linking,"I've been using Firebase Dynamic Links for deep linking in React JS, Next, Node project. However, I recently discovered that the Firebase Dynamic Links server is going to be shut down. As a result, I am in search of alternatives that can provide similar functionality, particularly the ability to display a preview with an image, description, and title for web & mobile.
Could you please suggest some best practices and decent alternatives for achieving deep linking functionality? I would greatly appreciate any insights or recommendations you can provide.
I have explored a few options. Some had only mobile functionality while I need both web & mobile. Some were paid tools that I couldn't check. As a result, I am still in search of a suitable alternative. I can try a paid one only in case I'm sure it meets my needs.
",<firebase><web><mobile><deep-linking><firebase-dynamic-links>,6,"firebase,web,mobile,deep-linking,firebase-dynamic-links",['alternatives to firebase dynamic links for deep linking'],"['ive been using firebase dynamic links for deep linking in react js next node project', 'however i recently discovered that the firebase dynamic links server is going to be shut down', 'as a result i am in search of alternatives that can provide similar functionality particularly the ability to display a preview with an image description and title for web mobile', 'could you please suggest some best practices and decent alternatives for achieving deep linking functionality', 'i would greatly appreciate any insights or recommendations you can provide', 'i have explored a few options', 'some had only mobile functionality while i need both web mobile', 'some were paid tools that i couldnt check', 'as a result i am still in search of a suitable alternative', 'i can try a paid one only in case im sure it meets my needs']"
Problems with X509Store Certificates.Find FindByThumbprint,"I'm having a problem when I use the method X509Store.Certificates.Find
public static X509Certificate2 FromStore(StoreName storeName, 
          StoreLocation storeLocation, X509FindType findType, string findValue)
{
    X509Store store = new X509Store(storeName, storeLocation);
    store.Open(OpenFlags.ReadOnly);
    try
    {
        //findValue = ""7a6fa503ab57b81d6318a51ca265e739a51ce660""
        var results = store.Certificates.Find(findType, findValue, true);

        return results[0];                
    }
    finally
    {
        store.Close();
    }
}

In this case the Find Method returns 0 results (results.Count == 0), but if I put the findValue as constant the method find the certificate.
public static X509Certificate2 FromStore(StoreName storeName, 
           StoreLocation storeLocation, X509FindType findType, string findValue)
{
    X509Store store = new X509Store(storeName, storeLocation);
    store.Open(OpenFlags.ReadOnly);
    try
    {         
        //findValue= ""7a6fa503ab57b81d6318a51ca265e739a51ce660""
        var results = store.Certificates.Find(findType, 
                              ""7a6fa503ab57b81d6318a51ca265e739a51ce660"", true);
        return results[0];
    }
    finally
    {
        store.Close();
    }
}

",<c#><wcf><certificate><ssl-certificate><x509certificate>,99,"c#,wcf,certificate,ssl-certificate,x509certificate",['problems with x509store certificatesfind findbythumbprint'],"['im having a problem when i use the method x509storecertificatesfind public static x509certificate2 fromstorestorename storename storelocation storelocation x509findtype findtype string findvalue x509store store new x509storestorename storelocation storeopenopenflagsreadonly try findvalue 7a6fa503ab57b81d6318a51ca265e739a51ce660 var results storecertificatesfindfindtype findvalue true return results0 finally storeclose in this case the find method returns 0 results resultscount 0 but if i put the findvalue as constant the method find the certificate', 'public static x509certificate2 fromstorestorename storename storelocation storelocation x509findtype findtype string findvalue x509store store new x509storestorename storelocation storeopenopenflagsreadonly try findvalue 7a6fa503ab57b81d6318a51ca265e739a51ce660 var results storecertificatesfindfindtype 7a6fa503ab57b81d6318a51ca265e739a51ce660 true return results0 finally storeclose ']"
fixed position broken on contentEditable ios webkit safari,"I want to create a wysiwyg-editor for ipad and have a toolbar with position:fixed - so that it's always available.
However, when I focus on div with contentEditable=""true"" the toolbar is not fixed any more.
Is this a bug?
Is there a workaround?
",<ios><safari><webkit><contenteditable><css-position>,7,"ios,safari,webkit,contenteditable,css-position",['fixed position broken on contenteditable ios webkit safari'],"['i want to create a wysiwygeditor for ipad and have a toolbar with positionfixed so that its always available', 'however when i focus on div with contenteditabletrue the toolbar is not fixed any more', 'is this a bug', 'is there a workaround']"
How does reflection tell me when a property is hiding an inherited member with the 'new' keyword?,"So if I have:
public class ChildClass : BaseClass
{
    public new virtual string TempProperty { get; set; }
}

public class BaseClass
{
    public virtual string TempProperty { get; set; }
}

How can I use reflection to see that ChildClass is hiding the Base implementation of TempProperty?
I'd like the answer to be agnostic between c# and vb.net
",<c#><vb.net><reflection><inheritance><overriding>,22,"c#,vb.net,reflection,inheritance,overriding",['how does reflection tell me when a property is hiding an inherited member with the new keyword'],"['so if i have public class childclass baseclass public new virtual string tempproperty get set public class baseclass public virtual string tempproperty get set how can i use reflection to see that childclass is hiding the base implementation of tempproperty', 'id like the answer to be agnostic between c and vbnet']"
SQLite SQLSTATE[HY000]: General error: 8 attempt to write a readonly database,"I'm using an SQLite connection and doctrine migrations for functional testing with PHPUnit.
I'm making a DB migration from scratch in the setUp method:
public function setUp()
{
    parent::setUp();
    
    @unlink(__DIR__ . '/../../../../../../../var/sqlite.db');

    exec('./vendor/bin/doctrine-migrations migrations:migrate --db-configuration=migrations-db-test.php --configuration=migrations_test.yml --no-interaction');
}

and then I can write/read from DB. E.g.:
public function test_add_event_should_add_event()
{
    $service = $this->getAdEventComparativesUpdateService();
    $request = AdEventComparativesUpdateServiceRequest::make(self::AD_ID, self::USER_IP);
    $response = $service->execute($request);

    $this->assertEquals(1, $response->getTotal());
}

and it works. And it does work even when I call twice the service with the same arguments. In this case it only has to write the first time:
public function test_add_two_same_events_should_add_one_event()
{
    $service = $this->getAdEventComparativesUpdateService();
    $request = AdEventComparativesUpdateServiceRequest::make(self::AD_ID, self::USER_IP);
    // Call twice
    $service->execute($request);
    $response = $service->execute($request);

    $this->assertEquals(1, $response->getTotal());
}

The problem comes when I have to test two calls that have to write both:
public function test_add_two_different_events_should_add_two_events()
{
    $service = $this->getAdEventComparativesUpdateService();
    $request = AdEventComparativesUpdateServiceRequest::make(self::AD_ID, self::USER_IP);
    $response = $service->execute($request);

    $service = $this->getAdEventComparativesUpdateService();
    $request = AdEventComparativesUpdateServiceRequest::make(self::AD_ID, self::OTHER_USER_IP);
    $response = $service->execute($request); // **** It fails here

    $this->assertEquals(2, $response->getTotal());
}

Here comes the error:


XXX::test_add_two_different_events_should_add_two_event
Doctrine\DBAL\Exception\ReadOnlyException: An exception occurred while executing 'INSERT INTO xxx (xxx, xxx, xxx, xxx) VALUES (?, ?, ?, ?)' with params [xxx, ""xxx"", ""xxx"", ""xxx""]:



SQLSTATE[HY000]: General error: 8 attempt to write a readonly database


xxx/vendor/doctrine/dbal/lib/Doctrine/DBAL/Driver/AbstractSQLiteDriver.php:78
xxx/vendor/doctrine/dbal/lib/Doctrine/DBAL/DBALException.php:128
xxx/vendor/doctrine/dbal/lib/Doctrine/DBAL/Statement.php:178
xxx/vendor/doctrine/orm/lib/Doctrine/ORM/Persisters/Entity/BasicEntityPersister.php:281
xxx/vendor/doctrine/orm/lib/Doctrine/ORM/UnitOfWork.php:1014
xxx/vendor/doctrine/orm/lib/Doctrine/ORM/UnitOfWork.php:378
xxx/vendor/doctrine/orm/lib/Doctrine/ORM/EntityManager.php:356
xxx/vendor/doctrine/orm/lib/Doctrine/ORM/EntityManager.php:235
xxx/DoctrineSession.php:32
xxx/TransactionalApplicationService.php:39
xxx/xxx/test.php:100

I've tried changing the DB file permissions between calls, but nothing changes:
public function test_add_two_different_events_should_add_two_event()
{
    $service = $this->getAdEventComparativesUpdateService();
    $request = AdEventComparativesUpdateServiceRequest::make(self::AD_ID, self::USER_IP);
    $response = $service->execute($request);

    chmod(__DIR__ . '/../../../../../../../var', 0777);
    chmod(__DIR__ . '/../../../../../../../var/sqlite.db', 0777);
    chown(__DIR__ . '/../../../../../../../var', 'www-data');
    chgrp(__DIR__ . '/../../../../../../../var', 'www-data');
    chown(__DIR__ . '/../../../../../../../var/sqlite.db', 'www-data');
    chgrp(__DIR__ . '/../../../../../../../var/sqlite.db', 'www-data');
   //die;
   // Here I checked the /var sqlite.db permissions. They are 0777

    $service = $this->getAdEventComparativesUpdateService();
    $request = AdEventComparativesUpdateServiceRequest::make(self::AD_ID, self::OTHER_USER_IP);
    $response = $service->execute($request);

    $this->assertEquals(2, $response->getTotal());
}

Any idea of where could the error come from? Every service call will call persist + flush in this case.
",<php><sqlite><doctrine><phpunit><doctrine-migrations>,6,"php,sqlite,doctrine,phpunit,doctrine-migrations",['sqlite sqlstatehy000 general error 8 attempt to write a readonly database'],"['im using an sqlite connection and doctrine migrations for functional testing with phpunit', 'im making a db migration from scratch in the setup method public function setup parentsetup unlinkdir ', 'varsqlitedb execvendorbindoctrinemigrations migrationsmigrate dbconfigurationmigrationsdbtestphp configurationmigrationstestyml nointeraction and then i can writeread from db', 'eg', ' public function testaddeventshouldaddevent service thisgetadeventcomparativesupdateservice request adeventcomparativesupdateservicerequestmakeselfadid selfuserip response serviceexecuterequest thisassertequals1 responsegettotal and it works', 'and it does work even when i call twice the service with the same arguments', 'in this case it only has to write the first time public function testaddtwosameeventsshouldaddoneevent service thisgetadeventcomparativesupdateservice request adeventcomparativesupdateservicerequestmakeselfadid selfuserip call twice serviceexecuterequest response serviceexecuterequest thisassertequals1 responsegettotal the problem comes when i have to test two calls that have to write both public function testaddtwodifferenteventsshouldaddtwoevents service thisgetadeventcomparativesupdateservice request adeventcomparativesupdateservicerequestmakeselfadid selfuserip response serviceexecuterequest service thisgetadeventcomparativesupdateservice request adeventcomparativesupdateservicerequestmakeselfadid selfotheruserip response serviceexecuterequest it fails here thisassertequals2 responsegettotal here comes the error xxxtestaddtwodifferenteventsshouldaddtwoevent doctrinedbalexceptionreadonlyexception an exception occurred while executing insert into xxx xxx xxx xxx xxx values ', 'with params xxx xxx xxx xxx sqlstatehy000 general error 8 attempt to write a readonly database xxxvendordoctrinedballibdoctrinedbaldriverabstractsqlitedriverphp78 xxxvendordoctrinedballibdoctrinedbaldbalexceptionphp128 xxxvendordoctrinedballibdoctrinedbalstatementphp178 xxxvendordoctrineormlibdoctrineormpersistersentitybasicentitypersisterphp281 xxxvendordoctrineormlibdoctrineormunitofworkphp1014 xxxvendordoctrineormlibdoctrineormunitofworkphp378 xxxvendordoctrineormlibdoctrineormentitymanagerphp356 xxxvendordoctrineormlibdoctrineormentitymanagerphp235 xxxdoctrinesessionphp32 xxxtransactionalapplicationservicephp39 xxxxxxtestphp100 ive tried changing the db file permissions between calls but nothing changes public function testaddtwodifferenteventsshouldaddtwoevent service thisgetadeventcomparativesupdateservice request adeventcomparativesupdateservicerequestmakeselfadid selfuserip response serviceexecuterequest chmoddir ', 'var 0777 chmoddir ', 'varsqlitedb 0777 chowndir ', 'var wwwdata chgrpdir ', 'var wwwdata chowndir ', 'varsqlitedb wwwdata chgrpdir ', 'varsqlitedb wwwdata die here i checked the var sqlitedb permissions', 'they are 0777 service thisgetadeventcomparativesupdateservice request adeventcomparativesupdateservicerequestmakeselfadid selfotheruserip response serviceexecuterequest thisassertequals2 responsegettotal any idea of where could the error come from', 'every service call will call persist flush in this case']"
Implicit conversion from enumeration type 'UIBarButtonSystemItem' to different enumeration type 'UIBarButtonItemStyle' - iPad - iOS5,"I am getting the warning in the subject line above when running my app under xCode 4.3.
Here is the offending code :
UINavigationController *navigationController = [[UINavigationController alloc]   initWithRootViewController:map];

    UIBarButtonItem *rightButton = [[UIBarButtonItem alloc] initWithTitle:@""Done""
                                                                    style:UIBarButtonSystemItemDone target:self action:@selector(removeCurrent)];
    map.navigationItem.rightBarButtonItem = rightButton;

    [self presentModalViewController:navigationController animated:YES];

Can anyone help ?
Thank you !
",<iphone><objective-c><xcode><ipad><sdk>,7,"iphone,objective-c,xcode,ipad,sdk",['implicit conversion from enumeration type uibarbuttonsystemitem to different enumeration type uibarbuttonitemstyle ipad ios5'],"['i am getting the warning in the subject line above when running my app under xcode 43 here is the offending code uinavigationcontroller navigationcontroller uinavigationcontroller alloc initwithrootviewcontrollermap uibarbuttonitem rightbutton uibarbuttonitem alloc initwithtitledone styleuibarbuttonsystemitemdone targetself actionselectorremovecurrent mapnavigationitemrightbarbuttonitem rightbutton self presentmodalviewcontrollernavigationcontroller animatedyes can anyone help ', 'thank you ']"
Accelerated Scroll on Recycle View,"I have a RecycleView that have a list of CardsViews. The RecycleView is in a NestedScrollView, because i have a collapsible header. The scroll isnt accelerated, it stop scrolling when i take the finger from the screen, and i want accelerated scrolling.
These are my layouts.
<android.support.v4.widget.NestedScrollView xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    xmlns:tools=""http://schemas.android.com/tools""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    app:layout_behavior=""@string/appbar_scrolling_view_behavior""
    tools:context="".articles.ArticlesActivity""
    tools:showIn=""@layout/activity_articles""
    >


    <android.support.v7.widget.RecyclerView
        android:id=""@+id/articles_lista""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:fadeScrollbars=""true""
        android:scrollbars=""vertical""
        />

</android.support.v4.widget.NestedScrollView>

My CardView layout container.
<android.support.v7.widget.CardView xmlns:card_view=""http://schemas.android.com/apk/res-auto""
    xmlns:android=""http://schemas.android.com/apk/res/android""
    android:id=""@+id/articles_card""
    android:layout_width=""match_parent""
    android:layout_height=""wrap_content""
    card_view:cardCornerRadius=""6dp""
    card_view:cardUseCompatPadding=""true""
    card_view:cardPreventCornerOverlap=""true""
    android:layout_marginTop=""0dp""
    android:layout_marginBottom=""0dp""
    android:layout_marginLeft=""10dp""
    android:layout_marginRight=""10dp""
    card_view:cardElevation=""5dp""

    android:overScrollMode=""always""
    android:fadeScrollbars=""true"">

    <LinearLayout
        android:orientation=""vertical""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent"">

        <TextView
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:padding=""10dp""
            android:id=""@+id/article_card_title""
            android:textAppearance=""?android:attr/textAppearanceLarge""
            android:textColor=""#000""/>

    </LinearLayout>

</android.support.v7.widget.CardView>

And the JAVA code:
        RecyclerView recyclerView = (RecyclerView)findViewById(R.id.articles_lista);
        LinearLayoutManager layoutManager = new LinearLayoutManager(this, LinearLayoutManager.VERTICAL, false);
        recyclerView.setLayoutManager(layoutManager);
        ArticlesAdapter adapter = new ArticlesAdapter(Mock.getNoticias(1L), this);
        recyclerView.setAdapter(adapter);

Thanks.
EDIT:
My new layout is working and looks like:
<RelativeLayout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    xmlns:tools=""http://schemas.android.com/tools""
    android:layout_width=""match_parent""
    android:layout_height=""match_parent""
    app:layout_behavior=""@string/appbar_scrolling_view_behavior""
    tools:context=""newser.sab.com.newser.articles.ArticlesActivity2""
    tools:showIn=""@layout/app_bar_articles2"">

    <android.support.v7.widget.RecyclerView
        android:id=""@+id/articles_lista""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:fadeScrollbars=""true""
        android:scrollbars=""vertical""
        />

</RelativeLayout>

",<android><android-layout><android-studio><scrollbar><android-recyclerview>,5,"android,android-layout,android-studio,scrollbar,android-recyclerview",['accelerated scroll on recycle view'],"['i have a recycleview that have a list of cardsviews', 'the recycleview is in a nestedscrollview because i have a collapsible header', 'the scroll isnt accelerated it stop scrolling when i take the finger from the screen and i want accelerated scrolling', 'these are my layouts', 'androidsupportv4widgetnestedscrollview xmlnsandroid xmlnsapp xmlnstools androidlayoutwidthmatchparent androidlayoutheightmatchparent applayoutbehaviorstringappbarscrollingviewbehavior toolscontextarticlesarticlesactivity toolsshowinlayoutactivityarticles androidsupportv7widgetrecyclerview androidididarticleslista androidlayoutwidthmatchparent androidlayoutheightmatchparent androidfadescrollbarstrue androidscrollbarsvertical androidsupportv4widgetnestedscrollview my cardview layout container', 'androidsupportv7widgetcardview xmlnscardview xmlnsandroid androidididarticlescard androidlayoutwidthmatchparent androidlayoutheightwrapcontent cardviewcardcornerradius6dp cardviewcardusecompatpaddingtrue cardviewcardpreventcorneroverlaptrue androidlayoutmargintop0dp androidlayoutmarginbottom0dp androidlayoutmarginleft10dp androidlayoutmarginright10dp cardviewcardelevation5dp androidoverscrollmodealways androidfadescrollbarstrue linearlayout androidorientationvertical androidlayoutwidthmatchparent androidlayoutheightmatchparent textview androidlayoutwidthmatchparent androidlayoutheightwrapcontent androidpadding10dp androidididarticlecardtitle androidtextappearanceandroidattrtextappearancelarge androidtextcolor000 linearlayout androidsupportv7widgetcardview and the java code recyclerview recyclerview recyclerviewfindviewbyidridarticleslista linearlayoutmanager layoutmanager new linearlayoutmanagerthis linearlayoutmanagervertical false recyclerviewsetlayoutmanagerlayoutmanager articlesadapter adapter new articlesadaptermockgetnoticias1l this recyclerviewsetadapteradapter thanks', 'edit my new layout is working and looks like relativelayout xmlnsandroid xmlnsapp xmlnstools androidlayoutwidthmatchparent androidlayoutheightmatchparent applayoutbehaviorstringappbarscrollingviewbehavior toolscontextnewsersabcomnewserarticlesarticlesactivity2 toolsshowinlayoutappbararticles2 androidsupportv7widgetrecyclerview androidididarticleslista androidlayoutwidthmatchparent androidlayoutheightmatchparent androidfadescrollbarstrue androidscrollbarsvertical relativelayout']"
How to use Moq to test a method with no return value?,"This is my first question so please be kind! :)
What I am trying to do is write some tests for a manager class that during construction adds many new instances of a single item class to a list.  When the UpdateAllItems is called in this manager class the intention is to iterate the list and call Increment on each single item.  
The manager class is my code, but the single item class is not so I can't modify it.
I use NUnit for a testing framework and am starting to work with Moq.  Because the manager class uses the single item class I would think I need to use a Moq so I am testing only the manager, not the single item.
How do I write tests for my UpdateAllItems method? (Technically I should be writing the tests first I know).
Here is a some sample code that gives a general idea of what I am working with...
public class SingleItem_CodeCantBeModified
{
    public int CurrentValue { get; private set; }

    public SingleItem_CodeCantBeModified(int startValue)
    {
        CurrentValue = startValue;
    }

    public void Increment()
    {
        CurrentValue++;
    }
}

public class SingleItemManager
{
    List<SingleItem_CodeCantBeModified> items = new List<SingleItem_CodeCantBeModified>();

    public SingleItemManager()
    {
        items.Add(new SingleItem_CodeCantBeModified(100));
        items.Add(new SingleItem_CodeCantBeModified(200));
    }

    public void UpdateAllItems()
    {
        items.ForEach(item => item.Increment());
    }
}

Thanks in advance for all the help!
",<c#><.net><unit-testing><mocking><moq>,6,"c#,.net,unit-testing,mocking,moq",['how to use moq to test a method with no return value'],"['this is my first question so please be kind', ' what i am trying to do is write some tests for a manager class that during construction adds many new instances of a single item class to a list', 'when the updateallitems is called in this manager class the intention is to iterate the list and call increment on each single item', 'the manager class is my code but the single item class is not so i cant modify it', 'i use nunit for a testing framework and am starting to work with moq', 'because the manager class uses the single item class i would think i need to use a moq so i am testing only the manager not the single item', 'how do i write tests for my updateallitems method', 'technically i should be writing the tests first i know', 'here is a some sample code that gives a general idea of what i am working with public class singleitemcodecantbemodified public int currentvalue get private set public singleitemcodecantbemodifiedint startvalue currentvalue startvalue public void increment currentvalue public class singleitemmanager listsingleitemcodecantbemodified items new listsingleitemcodecantbemodified public singleitemmanager itemsaddnew singleitemcodecantbemodified100 itemsaddnew singleitemcodecantbemodified200 public void updateallitems itemsforeachitem itemincrement thanks in advance for all the help']"
What is the simplest way to compare two arrays in QUnit,"I'm writing JavaScript unit tests (with the QUnit library). I need to verify that my array contains expected (and only) elements.
var array = getArrayFunction(a, b);
equal([""one"", ""two"", ""three""], array, ""Test is failing even if 'array' contains needed elements"");

What would be the easiest way to do this?
",<javascript><arrays><exists><element><qunit>,11,"javascript,arrays,exists,element,qunit",['what is the simplest way to compare two arrays in qunit'],"['im writing javascript unit tests with the qunit library', 'i need to verify that my array contains expected and only elements', 'var array getarrayfunctiona b equalone two three array test is failing even if array contains needed elements what would be the easiest way to do this']"
Passing function Pointers in C++,"i want to do this simple piece of code work.
#include <iostream>
#include <windows.h>


    void printSome (int i)
    {
        std::cout << i << std::endl;
    }

    void spawnThread (void (*threadName)(int i))
    {
        CreateThread 
            (
                0,      // default security attributes
                0,          // use default stack size 
                (LPTHREAD_START_ROUTINE)threadName,  // thread function name
                (LPVOID)i,          // argument to thread function 
                0,          // use default creation flags 
                0       // returns the thread identifier 
            );  
    }

    int main ()
    {
        spawnThread(printSome(155));
    }

i am on windows, using vs. Any help will be greatly appriciated.
",<c++><windows><multithreading><function><pointers>,5,"c++,windows,multithreading,function,pointers",['passing function pointers in c'],"['i want to do this simple piece of code work', 'include iostream include windowsh void printsome int i stdcout i stdendl void spawnthread void threadnameint i createthread 0 default security attributes 0 use default stack size lpthreadstartroutinethreadname thread function name lpvoidi argument to thread function 0 use default creation flags 0 returns the thread identifier int main spawnthreadprintsome155 i am on windows using vs any help will be greatly appriciated']"
How to implement interactive transitions in a custom container view controller,"I implemented my own custom container view controller and I try to make it compatible with iOS 7 view controller transitions. I make my custom container view controller conform to UIViewControllerContextTransitioning and I send self when I call transitionDuration: and animateTransition:. It all works fine as long as I use only animated transitions.
Now I want to make it work with interactive transitions, so I call the interaction controller's startInteractiveTransition: instead of the animation controller's animateTransition:, using self again as a parameter. However, if I use a UIPercentDrivenInteractiveTransition as the interaction controller, it then calls a _animator method on my context (which is the container view controller itself). Of course, I haven't implemented this method which is private and undocumented, so it crashes...
Am I missing something in my implementation? Is UIPercentDrivenInteractiveTransition only compatible with Apple classes because it uses some implementation magic (as when it requires that everything should be in a UIView animation block)? The documentation and header files make it look like we can implement our own container view controllers and still use custom transitions, but is it really true or just wishful thinking because nobody would actually do that?
If I can't use UIPercentDrivenInteractiveTransition, then where exactly should the interaction/animation logic be? In the UIViewControllerTransitionCoordinatorContext object? In the UIViewControllerInteractiveTransitioning object (most likely, this object is the driver...)? Or in the UIViewControllerAnimatedTransitioning object (this is probably where the real animation should happen, but would that mean calling animateTransition: several times during the interaction? Or adding new methods for each step of the interactive transition?)
Edit: The documentation says:

A percent-driven interactive transition object drives the custom animation between the disappearance of one view controller and the appearance of another. It relies on a transition animator delegate—a custom object that adopts the UIViewControllerAnimatorTransitioning protocol—to set up and perform the animations.

There is no UIViewControllerAnimatorTransitioning protocol. Assuming it is a mistake, or a name change that happened during iOS 7 development and it is actually the UIViewControllerAnimatedTransitioning protocol, how do we link the interaction controller with the animation controller? I guess it's the responsibility of the view controller driving the transition but I don't see any API to make this link, so it would mean that UIPercentDrivenInteractiveTransition is indeed reserved for Apple classes?
",<ios><uiviewcontroller><containers><transition><interactive>,5,"ios,uiviewcontroller,containers,transition,interactive",['how to implement interactive transitions in a custom container view controller'],"['i implemented my own custom container view controller and i try to make it compatible with ios 7 view controller transitions', 'i make my custom container view controller conform to uiviewcontrollercontexttransitioning and i send self when i call transitionduration and animatetransition', 'it all works fine as long as i use only animated transitions', 'now i want to make it work with interactive transitions so i call the interaction controllers startinteractivetransition instead of the animation controllers animatetransition using self again as a parameter', 'however if i use a uipercentdriveninteractivetransition as the interaction controller it then calls a animator method on my context which is the container view controller itself', 'of course i havent implemented this method which is private and undocumented so it crashes am i missing something in my implementation', 'is uipercentdriveninteractivetransition only compatible with apple classes because it uses some implementation magic as when it requires that everything should be in a uiview animation block', 'the documentation and header files make it look like we can implement our own container view controllers and still use custom transitions but is it really true or just wishful thinking because nobody would actually do that', 'if i cant use uipercentdriveninteractivetransition then where exactly should the interactionanimation logic be', 'in the uiviewcontrollertransitioncoordinatorcontext object', 'in the uiviewcontrollerinteractivetransitioning object most likely this object is the driver', 'or in the uiviewcontrolleranimatedtransitioning object this is probably where the real animation should happen but would that mean calling animatetransition several times during the interaction', 'or adding new methods for each step of the interactive transition', 'edit the documentation says a percentdriven interactive transition object drives the custom animation between the disappearance of one view controller and the appearance of another', 'it relies on a transition animator delegatea custom object that adopts the uiviewcontrolleranimatortransitioning protocolto set up and perform the animations', 'there is no uiviewcontrolleranimatortransitioning protocol', 'assuming it is a mistake or a name change that happened during ios 7 development and it is actually the uiviewcontrolleranimatedtransitioning protocol how do we link the interaction controller with the animation controller', 'i guess its the responsibility of the view controller driving the transition but i dont see any api to make this link so it would mean that uipercentdriveninteractivetransition is indeed reserved for apple classes']"
Can wrapping a type in a struct cause additional padding?,"
Possible Duplicate:
Size of struct with a single element 

Given any type A and the following struct:
struct S
{
    A a;
};

Are there any cases where sizeof(S) is greater than sizeof(A)?
For example, can sizeof(std::array<T, n>) be greater than sizeof(T[n])?
",<c++><arrays><class><struct><padding>,12,"c++,arrays,class,struct,padding",['can wrapping a type in a struct cause additional padding'],"[' possible duplicate size of struct with a single element given any type a and the following struct struct s a a are there any cases where sizeofs is greater than sizeofa', 'for example can sizeofstdarrayt n be greater than sizeoftn']"
How to Create Grid/Tile View?,"For example, I have some class .article, and I want to view this class as grid view. So I applied this style:
.article{
  width:100px;
  height:100px;
  background:#333;
  float:left;
  margin:5px;
}

That style will make the .article look tiled/grid. It's work fine with fixed height. But if I want to set the height to auto (automatically stretch according to the data within it), the grid look nasty. 

And I want to make the view like this:

",<css><grid><positioning><css-float><tiles>,140,"css,grid,positioning,css-float,tiles",['how to create gridtile view'],"['for example i have some class article and i want to view this class as grid view', 'so i applied this style article width100px height100px background333 floatleft margin5px that style will make the article look tiledgrid', 'its work fine with fixed height', 'but if i want to set the height to auto automatically stretch according to the data within it the grid look nasty', 'and i want to make the view like this']"
Scope Bootstrap Css in Vue,"I'm trying to use Bootstrap in a Vue component, and I want all CSS to be scoped. I tried something like this:
<style scoped>
@import ""~bootstrap/dist/css/bootstrap.css"";
@import ""~bootstrap-vue/dist/bootstrap-vue.css"";
</style>

But it doesn't seem like the css is scoped. Is there any way to do that?
",<css><twitter-bootstrap><webpack><vue.js><vue-loader>,19,"css,twitter-bootstrap,webpack,vue.js,vue-loader",['scope bootstrap css in vue'],"['im trying to use bootstrap in a vue component and i want all css to be scoped', 'i tried something like this style scoped import bootstrapdistcssbootstrapcss import bootstrapvuedistbootstrapvuecss style but it doesnt seem like the css is scoped', 'is there any way to do that']"
Using BeautifulSoup to select div blocks within HTML,"I am trying to parse several div blocks using Beautiful Soup using some html from a website. However, I cannot work out which function should be used to select these div blocks. I have tried the following:
import urllib2
from bs4 import BeautifulSoup

def getData():

    html = urllib2.urlopen(""http://www.racingpost.com/horses2/results/home.sd?r_date=2013-09-22"", timeout=10).read().decode('UTF-8')

    soup = BeautifulSoup(html)

    print(soup.title)
    print(soup.find_all('<div class=""crBlock "">'))

getData()

I want to be able to select everything between <div class=""crBlock ""> and its correct end </div>. (Obviously there are other div tags but I want to select the block all the way down to the one that represents the end of this section of html.)
",<python><html><python-2.7><beautifulsoup><urllib2>,5,"python,html,python-2.7,beautifulsoup,urllib2",['using beautifulsoup to select div blocks within html'],"['i am trying to parse several div blocks using beautiful soup using some html from a website', 'however i cannot work out which function should be used to select these div blocks', 'i have tried the following import urllib2 from bs4 import beautifulsoup def getdata html urllib2urlopen timeout10readdecodeutf8 soup beautifulsouphtml printsouptitle printsoupfindalldiv classcrblock getdata i want to be able to select everything between div classcrblock and its correct end div', 'obviously there are other div tags but i want to select the block all the way down to the one that represents the end of this section of html']"
Is it possible to support both Facebook Login and Google Plus login in the same iOS app?,"I integrated Google plus login in my iOS App. But I dont know how to add FB integration in the same app. Is it possible to use both logins in the same app? 
",<ios><iphone><facebook><integration><google-plus>,9,"ios,iphone,facebook,integration,google-plus",['is it possible to support both facebook login and google plus login in the same ios app'],"['i integrated google plus login in my ios app', 'but i dont know how to add fb integration in the same app', 'is it possible to use both logins in the same app']"
Make Maven to copy dependencies into target/lib,"How do I get my project's runtime dependencies copied into the target/lib folder?  
As it is right now, after mvn clean install the target folder contains only my project's jar, but none of the runtime dependencies.
",<java><maven><dependencies><maven-2><maven-3>,295,"java,maven,dependencies,maven-2,maven-3",['make maven to copy dependencies into targetlib'],"['how do i get my projects runtime dependencies copied into the targetlib folder', 'as it is right now after mvn clean install the target folder contains only my projects jar but none of the runtime dependencies']"
How to change nginx config in amazon elastic beanstalk running a docker instance,"After i login and the cookie is set I get error 502. When i read the log i get the error:
014/05/17 01:54:43 [error] 11013#0: *8 upstream sent too big header while reading response
header from upstream, client: 83.248.134.236, server: , request: ""GET /administration
HTTP/1.1"", upstream:

After some fast googling i found:
http://developernote.com/2012/09/how-i-fixed-nginx-502-bad-gateway-error/
and I want to try to set fastcgi_buffers and fastcgi_buffer_size to a different value. 
But how do i set variable on nginx in amazon elasticbeanstalk? 
The nginx server is before my docker instance.
",<codeigniter><amazon-web-services><nginx><amazon-elastic-beanstalk><docker>,39,"codeigniter,amazon-web-services,nginx,amazon-elastic-beanstalk,docker",['how to change nginx config in amazon elastic beanstalk running a docker instance'],"['after i login and the cookie is set i get error 502 when i read the log i get the error 0140517 015443 error 110130 8 upstream sent too big header while reading response header from upstream client 83248134236 server request get administration http11 upstream after some fast googling i found and i want to try to set fastcgibuffers and fastcgibuffersize to a different value', 'but how do i set variable on nginx in amazon elasticbeanstalk', 'the nginx server is before my docker instance']"
Resizing UIViews within UICollectionViewCell in iOS7 using iOS8 SDK,"I have an UICollectionView with subviews in the cells. They don't resize in iOS7 using the iOS8 SDK. When running the app on iOS8 seems to be ok
It seems that in the drawForRect of the subviews the frame is not resized as it's all the time returning the same value.
I am using auto layout attaching the the subviews to the edge of the cells.
Any clue?
Thanks a lot.
EDIT
This is the solution. I will keep this in case it's easier to find for you with my question.
https://stackoverflow.com/a/25768887/1523444
",<ios><objective-c><uiview><uicollectionview><autolayout>,8,"ios,objective-c,uiview,uicollectionview,autolayout",['resizing uiviews within uicollectionviewcell in ios7 using ios8 sdk'],"['i have an uicollectionview with subviews in the cells', 'they dont resize in ios7 using the ios8 sdk', 'when running the app on ios8 seems to be ok it seems that in the drawforrect of the subviews the frame is not resized as its all the time returning the same value', 'i am using auto layout attaching the the subviews to the edge of the cells', 'any clue', 'thanks a lot', 'edit this is the solution', 'i will keep this in case its easier to find for you with my question']"
boost::exception_detail::clone_impl<boost::exception_detail::error_info_injector<boost::thread_resource_error> >,"I need some help with this exception, I am implementing a NPAPI plugin to be able to use local sockets from browser extensions, to do that I am using Firebreath framework.
For socket and connectivity I am using Boost asio with async calls and a thread pool of 5 worker threads.
Also I have a deadline per thread to implement a transmission timeout.
My extension workflow with the plugin is as this:

Open socket 1(this starts a async_receive and the deadline
async_wait) 
Write in the socket 1
Get response 1
Open another socket 2
Write in the socket 2
Write socket 1
Close socket 1
(socket.cancel(), deadline.cancel(), socket.shutdown(), socket
release). 
Get response 2
Write socket 2
Close socket 2

As everything is cross language and async is really hard to debug but all open, write or close are called from javascript and the read from socket 1 that calls open 2, write 2,  write 1 and close 1 in that order.
Maybe evrything I am telling is unrelated as the call stack when the exception is thrown does not show any of my functions and only show that it is inside a malloc that calls _heap_alloc_dbg_impl
As it is it usually fails in the 2nd or 3rd full cycle and it seems that happens between steps 5 and 7.
But, I think that it must be asio related as doing everything with a single worker thread just crashes with the exception on the first cycle.
I am open to publish more information code if you need it.
Update 1:

Update 2:
There are 10 threads are launched with:
workPtr.reset( new boost::asio::io_service::work(io_service));

for ( int i = 0; i < 10; ++i) {
    m_threadGroup.create_thread( boost::bind(&boost::asio::io_service::run, &io_service) );
}

The 11th _threadstartex I don't know who launched it
On another thread (not the one that VS claims as causing the crash) there is a join_all() in process because my class is being destroyed but I think it shouldn't, so maybe this crash is due to another exception and the Firebreath process to close everything when it crashes.
",<c++><visual-c++><boost-asio><boost-thread><firebreath>,7,"c++,visual-c++,boost-asio,boost-thread,firebreath",['boostexceptiondetailcloneimplboostexceptiondetailerrorinfoinjectorboostthreadresourceerror '],"['i need some help with this exception i am implementing a npapi plugin to be able to use local sockets from browser extensions to do that i am using firebreath framework', 'for socket and connectivity i am using boost asio with async calls and a thread pool of 5 worker threads', 'also i have a deadline per thread to implement a transmission timeout', 'my extension workflow with the plugin is as this open socket 1this starts a asyncreceive and the deadline asyncwait write in the socket 1 get response 1 open another socket 2 write in the socket 2 write socket 1 close socket 1 socketcancel deadlinecancel socketshutdown socket release', 'get response 2 write socket 2 close socket 2 as everything is cross language and async is really hard to debug but all open write or close are called from javascript and the read from socket 1 that calls open 2 write 2 write 1 and close 1 in that order', 'maybe evrything i am telling is unrelated as the call stack when the exception is thrown does not show any of my functions and only show that it is inside a malloc that calls heapallocdbgimpl as it is it usually fails in the 2nd or 3rd full cycle and it seems that happens between steps 5 and 7 but i think that it must be asio related as doing everything with a single worker thread just crashes with the exception on the first cycle', 'i am open to publish more information code if you need it', 'update 1 update 2 there are 10 threads are launched with workptrreset new boostasioioserviceworkioservice for int i 0 i 10 i mthreadgroupcreatethread boostbindboostasioioservicerun ioservice the 11th threadstartex i dont know who launched it on another thread not the one that vs claims as causing the crash there is a joinall in process because my class is being destroyed but i think it shouldnt so maybe this crash is due to another exception and the firebreath process to close everything when it crashes']"
Is it correct to convert a CompletableFuture<Stream<T>> to a Publisher<T>?,"To allow multiple iterations on the resulting stream from a CompletableFuture<Stream<String>> I am considering one of the following approaches:

Convert the resulting future to CompletableFuture<List<String>> through: teams.thenApply(st -> st.collect(toList()))
Convert the resulting future to Flux<String> with cache: Flux.fromStream(teams::join).cache();

Flux<T> is the implementation of Publisher<T> in project reactor.
Use case:
I would like to get a sequence with the premier league teams names (e.g. Stream<String>) from a data source which provides a League object with a Standing[] (based on football-data RESTful API, e.g. http://api.football-data.org/v1/soccerseasons/445/leagueTable). Using AsyncHttpClient and Gson we have:
CompletableFuture<Stream<String>> teams = asyncHttpClient
    .prepareGet(""http://api.football-data.org/v1/soccerseasons/445/leagueTable"")
    .execute()
    .toCompletableFuture()
    .thenApply(Response::getResponseBody)
    .thenApply(body -> gson.fromJson(body, League.class));
    .thenApply(l -> stream(l.standings).map(s -> s.teamName));

To re-use the resulting stream I have two options:
1. CompletableFuture<List<String>> res = teams.thenApply(st -> st.collect(toList()))

2. Flux<String> res = Flux.fromStream(teams::join).cache()

Flux<T> is less verbose and provides all that I need. Yet, is it correct to use it in this scenario?
Or should I use CompletableFuture<List<String>> instead? Or is there any other better alternative?
UPDATED with some thoughts (2018-03-16): 
CompletableFuture<List<String>>:

[PROS] The List<String> will be collected in a continuation and when we need to proceed with the result of the future, maybe it is already completed.
[CONS] Declaration verbosity.
[CONS] If we just want to use it once, then we did not need to collect those items in a List<T>.

Flux<String>:

[PROS] Declaration conciseness
[PROS] If we just want to use it once, then we can omit .cache() and forward it to the next layer, which can take advantage of the reactive API, e.g. web flux reactive controller, e.g. @GetMapping(produces =MediaType.TEXT_EVENT_STREAM)   public Flux<String> getTeams() {…}
[CONS] If we want to reuse that Flux<T> we have to wrap it in a cacheable Flux<T> (….cache()) which in turn will  add overhead on the first traversal, because it has to store the resulting items in an internal cache.

",<java><java-8><rx-java><project-reactor><completable-future>,25,"java,java-8,rx-java,project-reactor,completable-future",['is it correct to convert a completablefuturestreamt to a publishert'],"['to allow multiple iterations on the resulting stream from a completablefuturestreamstring i am considering one of the following approaches convert the resulting future to completablefutureliststring through teamsthenapplyst stcollecttolist convert the resulting future to fluxstring with cache fluxfromstreamteamsjoincache fluxt is the implementation of publishert in project reactor', 'use case i would like to get a sequence with the premier league teams names eg', 'streamstring from a data source which provides a league object with a standing based on footballdata restful api eg', 'using asynchttpclient and gson we have completablefuturestreamstring teams asynchttpclient prepareget execute tocompletablefuture thenapplyresponsegetresponsebody thenapplybody gsonfromjsonbody leagueclass thenapplyl streamlstandingsmaps steamname to reuse the resulting stream i have two options 1 completablefutureliststring res teamsthenapplyst stcollecttolist 2 fluxstring res fluxfromstreamteamsjoincache fluxt is less verbose and provides all that i need', 'yet is it correct to use it in this scenario', 'or should i use completablefutureliststring instead', 'or is there any other better alternative', 'updated with some thoughts 20180316 completablefutureliststring pros the liststring will be collected in a continuation and when we need to proceed with the result of the future maybe it is already completed', 'cons declaration verbosity', 'cons if we just want to use it once then we did not need to collect those items in a listt', 'fluxstring pros declaration conciseness pros if we just want to use it once then we can omit cache and forward it to the next layer which can take advantage of the reactive api eg', 'web flux reactive controller eg', 'getmappingproduces mediatypetexteventstream public fluxstring getteams cons if we want to reuse that fluxt we have to wrap it in a cacheable fluxt cache which in turn will add overhead on the first traversal because it has to store the resulting items in an internal cache']"
Bare Minimum Configuration for RESTful WCF,"What is the bare minimum I need to put in web.config to get WCF working with REST? I have annotated my methods with [WebGet], but they are not getting the message.
",<.net><asp.net><wcf><rest><web-config>,6,".net,asp.net,wcf,rest,web-config",['bare minimum configuration for restful wcf'],"['what is the bare minimum i need to put in webconfig to get wcf working with rest', 'i have annotated my methods with webget but they are not getting the message']"
"scanf(), field width, inf and nan","Per the C standard from 1999, scanf() and strtod() should accept infinity and NaN as inputs (if supported by the implementation).
The descriptions of both functions have peculiar language, which may be open to interpretations.
scanf():

An input item is defined as the longest sequence of input characters
  which does not exceed any specified field width and which is, or is a
  prefix of, a matching input sequence.

strtod():

The subject sequence is defined as the longest initial subsequence of
  the input string, starting with the first non-white-space character,
  that is of the expected form.

While the latter excerpt appears to be strict in requiring the specific forms of ""INF"", ""INFINITY"", ""NAN"" or ""NAN(n-char-sequence-opt)"", the former isn't and one would think that the following code should produce infinity and NaN because the field width covers prefixes of matching input sequences:
int r;
double d;
d = 0; r = sscanf(""inf"", ""%2le"", &d);
printf(""%d %e\n"", r, d);
d = 0; r = sscanf(""nan"", ""%2le"", &d);
printf(""%d %e\n"", r, d);

There's also this bit on scanf():

a,e,f,g Matches an optionally signed floating-point number, infinity,
  or NaN, whose format is the same as expected for the subject sequence
  of the strtod function. The corresponding argument shall be a pointer
  to floating.

Is this simply a failure to document that a field width of 2, which is shorter than the expected shortest forms (""inf"" or ""nan""), does not make the otherwise matching prefixes ""in"" and ""na"" valid matches?
",<c><parsing><floating-point><language-lawyer><scanf>,5,"c,parsing,floating-point,language-lawyer,scanf",['scanf field width inf and nan'],"['per the c standard from 1999 scanf and strtod should accept infinity and nan as inputs if supported by the implementation', 'the descriptions of both functions have peculiar language which may be open to interpretations', 'scanf an input item is defined as the longest sequence of input characters which does not exceed any specified field width and which is or is a prefix of a matching input sequence', 'strtod the subject sequence is defined as the longest initial subsequence of the input string starting with the first nonwhitespace character that is of the expected form', 'while the latter excerpt appears to be strict in requiring the specific forms of inf infinity nan or nanncharsequenceopt the former isnt and one would think that the following code should produce infinity and nan because the field width covers prefixes of matching input sequences int r double d d 0 r sscanfinf 2le d printfd en r d d 0 r sscanfnan 2le d printfd en r d theres also this bit on scanf aefg matches an optionally signed floatingpoint number infinity or nan whose format is the same as expected for the subject sequence of the strtod function', 'the corresponding argument shall be a pointer to floating', 'is this simply a failure to document that a field width of 2 which is shorter than the expected shortest forms inf or nan does not make the otherwise matching prefixes in and na valid matches']"
XSLT 2.0 transformation via linux shell,"I want to perform an XSLT 2.0 transformation by the use of command line executions. I heard that i could use the Saxon library by a shell command like:
java -jar sax.jar -input foo.xml -xsl foo.xsl -output bar.xml

Does anyone know how exactly I can achieve that goal?
By the way, i am not limited to Java. Any other shell solution is fine.
",<java><shell><xslt><jar><saxon>,17,"java,shell,xslt,jar,saxon",['xslt 20 transformation via linux shell'],"['i want to perform an xslt 20 transformation by the use of command line executions', 'i heard that i could use the saxon library by a shell command like java jar saxjar input fooxml xsl fooxsl output barxml does anyone know how exactly i can achieve that goal', 'by the way i am not limited to java', 'any other shell solution is fine']"
Difference between DTO and Response Object?,"What is the difference between a Response Object and DTO in software architecture? Say I want to get a list of Products in a catalog.
If ProductDTO is this,  how is a Product Response class different? Is a Product Response typically just a wrapper with a datetime, error log, or guid, or what is the prime difference? If there is not an exact or multiple answers, would like to hear top reasons in industry.
public class ProductDto
{
    public int ProductId { get; set;},
    public string ProductName { get; set;},
    public string ProductDescription { get; set;},
    public float SalesAmount { get; set;}
}

I tried googling these answers, they did not have specific answer for this question,
Reusing DTO for various request/response types vs explicitness of what is required / what should be returned
Data Objects for each layer(DTO vs Entity vs Response objects)
Update:
Trying to validate answer. Seems Rahul answer is answering difference between Domain object and DTO . Thought Response is a wrapper around DTO, not sure if true-
http://themoderndeveloper.com/the-modern-developer/requesting-a-response/
Posted here now: 
https://softwareengineering.stackexchange.com/questions/398783/what-is-difference-between-dto-and-response-object
",<c#><.net><asp.net-core><architecture><request-response>,5,"c#,.net,asp.net-core,architecture,request-response",['difference between dto and response object'],"['what is the difference between a response object and dto in software architecture', 'say i want to get a list of products in a catalog', 'if productdto is this how is a product response class different', 'is a product response typically just a wrapper with a datetime error log or guid or what is the prime difference', 'if there is not an exact or multiple answers would like to hear top reasons in industry', 'public class productdto public int productid get set public string productname get set public string productdescription get set public float salesamount get set i tried googling these answers they did not have specific answer for this question reusing dto for various requestresponse types vs explicitness of what is required what should be returned data objects for each layerdto vs entity vs response objects update trying to validate answer', 'seems rahul answer is answering difference between domain object and dto ', 'thought response is a wrapper around dto not sure if true posted here now']"
Time slicing in Oracle/SQL,"I have a large-ish Oracle table containing rows representing units of work, with columns for start time and end time in addition to other meta-data.
I need to generate usage graphs from this data, given some arbitrary filtering criteria and a reporting time period.  E.g., show me a graph of all of Alice's jobs for the 24-hour period starting last Tuesday at 7:00am.  Each DB row will stack vertically in the graph.
I could do this in a high-level language by querying all potentially relevant rows, time slicing each one into 1-minute buckets, and graphing the result.  But is there an efficient way to do this time slicing in SQL?  Or is there an existing Oracle technology that does this?
Thanks!
",<sql><oracle><optimization><reporting><graphing>,5,"sql,oracle,optimization,reporting,graphing",['time slicing in oraclesql'],"['i have a largeish oracle table containing rows representing units of work with columns for start time and end time in addition to other metadata', 'i need to generate usage graphs from this data given some arbitrary filtering criteria and a reporting time period', 'eg show me a graph of all of alices jobs for the 24hour period starting last tuesday at 700am', 'each db row will stack vertically in the graph', 'i could do this in a highlevel language by querying all potentially relevant rows time slicing each one into 1minute buckets and graphing the result', 'but is there an efficient way to do this time slicing in sql', 'or is there an existing oracle technology that does this', 'thanks']"
How to use priority in celery task.apply_async,"I have a test queue in celery and I have defined a task for it:
@celery_app.task(queue='test', ignore_result=True)
def priority_test(priority):
    print(priority)

which just print the argument.I want to set the priority attribute which is defined here for appy_async. So, I wrote a for loop like this:
for i in range(100):
    priority_test.apply_async((i%10,), queue=""test"", priority=i%10)

I excpected to see some result like this:
[2017-12-26 17:21:37,309: WARNING/ForkPoolWorker-1] 10
[2017-12-26 17:21:37,311: WARNING/ForkPoolWorker-1] 10
[2017-12-26 17:21:37,314: WARNING/ForkPoolWorker-1] 10
[2017-12-26 17:21:37,317: WARNING/ForkPoolWorker-1] 9
[2017-12-26 17:21:37,319: WARNING/ForkPoolWorker-1] 9
[2017-12-26 17:21:37,321: WARNING/ForkPoolWorker-1] 9
[2017-12-26 17:21:37,323: WARNING/ForkPoolWorker-1] 8
[2017-12-26 17:21:37,326: WARNING/ForkPoolWorker-1] 8
[2017-12-26 17:21:37,329: WARNING/ForkPoolWorker-1] 8
[2017-12-26 17:21:37,332: WARNING/ForkPoolWorker-1] 7
[2017-12-26 17:21:37,334: WARNING/ForkPoolWorker-1] 7
[2017-12-26 17:21:37,336: WARNING/ForkPoolWorker-1] 7
[2017-12-26 17:21:37,341: WARNING/ForkPoolWorker-1] 6
[2017-12-26 17:21:37,344: WARNING/ForkPoolWorker-1] 6
[2017-12-26 17:21:37,346: WARNING/ForkPoolWorker-1] 6
[2017-12-26 17:21:37,349: WARNING/ForkPoolWorker-1] 5
[2017-12-26 17:21:37,351: WARNING/ForkPoolWorker-1] 5
[2017-12-26 17:21:37,353: WARNING/ForkPoolWorker-1] 5
[2017-12-26 17:21:37,355: WARNING/ForkPoolWorker-1] 4
[2017-12-26 17:21:37,358: WARNING/ForkPoolWorker-1] 4
[2017-12-26 17:21:37,360: WARNING/ForkPoolWorker-1] 4

means execute the same priorities after each other but it executed them in the normal way:
[2017-12-26 17:21:37,309: WARNING/ForkPoolWorker-1] 10
[2017-12-26 17:21:37,311: WARNING/ForkPoolWorker-1] 9
[2017-12-26 17:21:37,314: WARNING/ForkPoolWorker-1] 8
[2017-12-26 17:21:37,317: WARNING/ForkPoolWorker-1] 7
[2017-12-26 17:21:37,319: WARNING/ForkPoolWorker-1] 6
[2017-12-26 17:21:37,321: WARNING/ForkPoolWorker-1] 5
[2017-12-26 17:21:37,323: WARNING/ForkPoolWorker-1] 4
[2017-12-26 17:21:37,326: WARNING/ForkPoolWorker-1] 3
[2017-12-26 17:21:37,329: WARNING/ForkPoolWorker-1] 2
[2017-12-26 17:21:37,332: WARNING/ForkPoolWorker-1] 1
[2017-12-26 17:21:37,334: WARNING/ForkPoolWorker-1] 10
[2017-12-26 17:21:37,336: WARNING/ForkPoolWorker-1] 9
[2017-12-26 17:21:37,341: WARNING/ForkPoolWorker-1] 8
[2017-12-26 17:21:37,344: WARNING/ForkPoolWorker-1] 7
[2017-12-26 17:21:37,346: WARNING/ForkPoolWorker-1] 6
[2017-12-26 17:21:37,349: WARNING/ForkPoolWorker-1] 5
[2017-12-26 17:21:37,351: WARNING/ForkPoolWorker-1] 4
[2017-12-26 17:21:37,353: WARNING/ForkPoolWorker-1] 3
[2017-12-26 17:21:37,355: WARNING/ForkPoolWorker-1] 2
[2017-12-26 17:21:37,358: WARNING/ForkPoolWorker-1] 1
[2017-12-26 17:21:37,360: WARNING/ForkPoolWorker-1] 10
[2017-12-26 17:21:37,362: WARNING/ForkPoolWorker-1] 9
[2017-12-26 17:21:37,364: WARNING/ForkPoolWorker-1] 8
[2017-12-26 17:21:37,365: WARNING/ForkPoolWorker-1] 7
[2017-12-26 17:21:37,367: WARNING/ForkPoolWorker-1] 6
[2017-12-26 17:21:37,369: WARNING/ForkPoolWorker-1] 5
[2017-12-26 17:21:37,371: WARNING/ForkPoolWorker-1] 4
[2017-12-26 17:21:37,373: WARNING/ForkPoolWorker-1] 3
[2017-12-26 17:21:37,374: WARNING/ForkPoolWorker-1] 2
[2017-12-26 17:21:37,376: WARNING/ForkPoolWorker-1] 1

How should I apply priority in celery with rabbitmq and what is the priority attribute in the doc above?
",<python><rabbitmq><queue><celery><priority-queue>,10,"python,rabbitmq,queue,celery,priority-queue",['how to use priority in celery taskapplyasync'],"['i have a test queue in celery and i have defined a task for it celeryapptaskqueuetest ignoreresulttrue def prioritytestpriority printpriority which just print the argumenti want to set the priority attribute which is defined here for appyasync', 'so i wrote a for loop like this for i in range100 prioritytestapplyasynci10 queuetest priorityi10 i excpected to see some result like this 20171226 172137309 warningforkpoolworker1 10 20171226 172137311 warningforkpoolworker1 10 20171226 172137314 warningforkpoolworker1 10 20171226 172137317 warningforkpoolworker1 9 20171226 172137319 warningforkpoolworker1 9 20171226 172137321 warningforkpoolworker1 9 20171226 172137323 warningforkpoolworker1 8 20171226 172137326 warningforkpoolworker1 8 20171226 172137329 warningforkpoolworker1 8 20171226 172137332 warningforkpoolworker1 7 20171226 172137334 warningforkpoolworker1 7 20171226 172137336 warningforkpoolworker1 7 20171226 172137341 warningforkpoolworker1 6 20171226 172137344 warningforkpoolworker1 6 20171226 172137346 warningforkpoolworker1 6 20171226 172137349 warningforkpoolworker1 5 20171226 172137351 warningforkpoolworker1 5 20171226 172137353 warningforkpoolworker1 5 20171226 172137355 warningforkpoolworker1 4 20171226 172137358 warningforkpoolworker1 4 20171226 172137360 warningforkpoolworker1 4 means execute the same priorities after each other but it executed them in the normal way 20171226 172137309 warningforkpoolworker1 10 20171226 172137311 warningforkpoolworker1 9 20171226 172137314 warningforkpoolworker1 8 20171226 172137317 warningforkpoolworker1 7 20171226 172137319 warningforkpoolworker1 6 20171226 172137321 warningforkpoolworker1 5 20171226 172137323 warningforkpoolworker1 4 20171226 172137326 warningforkpoolworker1 3 20171226 172137329 warningforkpoolworker1 2 20171226 172137332 warningforkpoolworker1 1 20171226 172137334 warningforkpoolworker1 10 20171226 172137336 warningforkpoolworker1 9 20171226 172137341 warningforkpoolworker1 8 20171226 172137344 warningforkpoolworker1 7 20171226 172137346 warningforkpoolworker1 6 20171226 172137349 warningforkpoolworker1 5 20171226 172137351 warningforkpoolworker1 4 20171226 172137353 warningforkpoolworker1 3 20171226 172137355 warningforkpoolworker1 2 20171226 172137358 warningforkpoolworker1 1 20171226 172137360 warningforkpoolworker1 10 20171226 172137362 warningforkpoolworker1 9 20171226 172137364 warningforkpoolworker1 8 20171226 172137365 warningforkpoolworker1 7 20171226 172137367 warningforkpoolworker1 6 20171226 172137369 warningforkpoolworker1 5 20171226 172137371 warningforkpoolworker1 4 20171226 172137373 warningforkpoolworker1 3 20171226 172137374 warningforkpoolworker1 2 20171226 172137376 warningforkpoolworker1 1 how should i apply priority in celery with rabbitmq and what is the priority attribute in the doc above']"
Accessing array values via pointer arithmetic vs. subscripting in C,"I keep reading that, in C, using pointer arithmetic is generally faster than subscripting for array access. Is this true even with modern (supposedly-optimizing) compilers?
If so, is this still the case as I begin to move away from learning C into Objective-C and Cocoa on Macs?
Which is the preferred coding style for array access, in both C and Objective-C? Which is considered (by professionals of their respective languages) more legible, more ""correct"" (for lack of a better term)?
",<objective-c><c><arrays><pointers><pointer-arithmetic>,39,"objective-c,c,arrays,pointers,pointer-arithmetic",['accessing array values via pointer arithmetic vs subscripting in c'],"['i keep reading that in c using pointer arithmetic is generally faster than subscripting for array access', 'is this true even with modern supposedlyoptimizing compilers', 'if so is this still the case as i begin to move away from learning c into objectivec and cocoa on macs', 'which is the preferred coding style for array access in both c and objectivec', 'which is considered by professionals of their respective languages more legible more correct for lack of a better term']"
Reverse proxy header should be provided,"I use reverse proxy from the following module in node app-:
https://github.com/nodejitsu/node-http-proxy
My question is whether I need to modify the header for state of reverse proxy to work like standard?
http://httpd.apache.org/docs/2.2/mod/mod_proxy.html
",<node.js><proxy><reverse-proxy><http-proxy><node-http-proxy>,10,"node.js,proxy,reverse-proxy,http-proxy,node-http-proxy",['reverse proxy header should be provided'],['i use reverse proxy from the following module in node app my question is whether i need to modify the header for state of reverse proxy to work like standard']
Why is Jenkins Android Emulator Plugin recreating my Emulator Snapshots in every build?,"I use Jenkins to build one of my projects. The Android Emulator Plugin automatically starts an emulator with the following configuration: 

Configuration of the Emulator Plugin: 
.
Every time the job is running I get the following output: 
Erasing existing emulator data... $
/ci/home/tools/android-sdk//tools/emulator -no-boot-anim -ports
64470,64471 -prop persist.sys.language=de -prop persist.sys.country=DE
-avd hudson_de-DE_240_480x720_Google_Inc._Google_APIs_8 -no-snapshot-load -no-snapshot-save -wipe-data

.
.

shell input keyevent 4 [android] Giving the system some time to settle
before creating initial snapshot... $

.
.

localhost:64471 shell log -p v -t Jenkins ""Creating snapshot...""
[android] Creating snapshot... $

Full log below. 
It seems that the plugin is creating a new emulator every time and is not using snapshots. 
This takes something between 2 and 4 minutes depending on the emulator configuration. 
The plugin creates .avd and .ini files in the .android/avd directory inside the job folder. The avds are not deleted after the run process.
If I disable the use snapshots config the emulator needs less then a minute to start. 
Is this an issue with the emulator plugin or are snapshots not possible because of my configuration? 
I hope that using snapshots will speed up my building process a lot.

Full log:  
$ /ci/home/tools/android-sdk//tools/android list target [android]
Using Android SDK: /ci/home/tools/android-sdk/ [android] Adding 200M
SD card to AVD 'hudson_de-DE_240_480x720_Google_Inc._Google_APIs_8'...
[android] Setting hardware properties:  hw.ramSize: 512
$ /ci/home/tools/android-sdk//platform-tools/adb start-server
$ /ci/home/tools/android-sdk//tools/emulator -snapshot-list -no-window -avd hudson_de-DE_240_480x720_Google_Inc._Google_APIs_8
[android] Starting Android emulator and creating initial snapshot
[android] Erasing existing emulator data...
$ /ci/home/tools/android-sdk//tools/emulator -no-boot-anim -ports 64470,64471 -prop persist.sys.language=de -prop persist.sys.country=DE -avd hudson_de-DE_240_480x720_Google_Inc._Google_APIs_8 -no-snapshot-load -no-snapshot-save -wipe-data
* daemon not running. starting it now on port 64472 *
* daemon started successfully *
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
[android] Waiting for emulator to finish booting...
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 
shell getprop dev.bootcomplete error: device offline
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 shell getprop dev.bootcomplete
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 shell getprop dev.bootcomplete
$ /ci/home/tools/android-sdk//platform-tools/adb disconnect localhost:64471
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 shell getprop dev.bootcomplete
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 shell getprop dev.bootcomplete
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 shell getprop dev.bootcomplete
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 logcat -v time
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
[android] Attempting to unlock emulator screen
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 shell input keyevent 82
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 shell input keyevent 4
[android] Giving the system some time to settle before creating initial snapshot...
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 logcat -c
$ /ci/home/tools/android-sdk//platform-tools/adb -s localhost:64471 shell log -p v -t Jenkins ""Creating snapshot...""
[android] Creating snapshot...
$ /ci/home/tools/android-sdk//platform-tools/adb connect localhost:64471
[android] Emulator is ready for use (took 158 seconds)


Buildfile for an example job: 
<?xml version='1.0' encoding='UTF-8'?>
<project>
  <actions/>
  <description></description>
  <keepDependencies>false</keepDependencies>
  <properties/>
  <scm class=""hudson.plugins.git.GitSCM"">
    <configVersion>2</configVersion>
    <userRemoteConfigs>
      <hudson.plugins.git.UserRemoteConfig>
        <name></name>
        <refspec></refspec>
        <url>git@project...</url>
      </hudson.plugins.git.UserRemoteConfig>
    </userRemoteConfigs>
    <branches>
      <hudson.plugins.git.BranchSpec>
        <name>master</name>
      </hudson.plugins.git.BranchSpec>
    </branches>
    <disableSubmodules>false</disableSubmodules>
    <recursiveSubmodules>false</recursiveSubmodules>
    <doGenerateSubmoduleConfigurations>false</doGenerateSubmoduleConfigurations>
    <authorOrCommitter>false</authorOrCommitter>
    <clean>false</clean>
    <wipeOutWorkspace>false</wipeOutWorkspace>
    <pruneBranches>false</pruneBranches>
    <remotePoll>false</remotePoll>
    <ignoreNotifyCommit>false</ignoreNotifyCommit>
    <useShallowClone>false</useShallowClone>
    <buildChooser class=""hudson.plugins.git.util.DefaultBuildChooser""/>
    <gitTool>default</gitTool>
    <submoduleCfg class=""list""/>
    <relativeTargetDir></relativeTargetDir>
    <reference></reference>
    <excludedRegions></excludedRegions>
    <excludedUsers></excludedUsers>
    <gitConfigName></gitConfigName>
    <gitConfigEmail></gitConfigEmail>
    <skipTag>false</skipTag>
    <includedRegions></includedRegions>
    <scmName></scmName>
  </scm>
  <canRoam>true</canRoam>
  <disabled>false</disabled>
  <blockBuildWhenDownstreamBuilding>true</blockBuildWhenDownstreamBuilding>
  <blockBuildWhenUpstreamBuilding>true</blockBuildWhenUpstreamBuilding>
  <triggers class=""vector"">
    <hudson.triggers.SCMTrigger>
      <spec>*/5 * * * *</spec>
    </hudson.triggers.SCMTrigger>
  </triggers>
  <concurrentBuild>false</concurrentBuild>
  <builders>
    <hudson.tasks.Ant>
      <targets>clean debug install</targets>
      <antName>(Default)</antName>
    </hudson.tasks.Ant>
    <hudson.tasks.Ant>
      <targets></targets>
      <antName>(Default)</antName>
      <buildFile>checkstyle-ant.xml</buildFile>
    </hudson.tasks.Ant>
    <hudson.tasks.Shell>
      <command>os_opts=&quot;-Djava.awt.headless=true&quot; lint --xml lint-results.xml .</command>
    </hudson.tasks.Shell>
    <hudson.plugins.android__emulator.monkey.MonkeyBuilder>
      <packageId>de....</packageId>
      <eventCount>1000</eventCount>
      <throttleMs>10</throttleMs>
      <seed>timestamp</seed>
    </hudson.plugins.android__emulator.monkey.MonkeyBuilder>
    <hudson.tasks.Shell>
        ... distribution script
    </hudson.tasks.Shell>
  </builders>
  <publishers>
    <org.jenkinsci.plugins.android__lint.LintPublisher>
      <healthy></healthy>
      <thresholdLimit>low</thresholdLimit>
      <pluginName>[android-lint] </pluginName>
      <defaultEncoding></defaultEncoding>
      <canRunOnFailed>false</canRunOnFailed>
      <useStableBuildAsReference>false</useStableBuildAsReference>
      <useDeltaValues>false</useDeltaValues>
      <thresholds>
        <unstableTotalAll></unstableTotalAll>
        <unstableTotalHigh></unstableTotalHigh>
        <unstableTotalNormal></unstableTotalNormal>
        <unstableTotalLow></unstableTotalLow>
        <unstableNewAll></unstableNewAll>
        <unstableNewHigh></unstableNewHigh>
        <unstableNewNormal></unstableNewNormal>
        <unstableNewLow></unstableNewLow>
        <failedTotalAll></failedTotalAll>
        <failedTotalHigh></failedTotalHigh>
        <failedTotalNormal></failedTotalNormal>
        <failedTotalLow></failedTotalLow>
        <failedNewAll></failedNewAll>
        <failedNewHigh></failedNewHigh>
        <failedNewNormal></failedNewNormal>
        <failedNewLow></failedNewLow>
      </thresholds>
      <shouldDetectModules>false</shouldDetectModules>
      <dontComputeNew>false</dontComputeNew>
      <doNotResolveRelativePaths>false</doNotResolveRelativePaths>
      <pattern></pattern>
    </org.jenkinsci.plugins.android__lint.LintPublisher>
    <hudson.plugins.checkstyle.CheckStylePublisher>
      <healthy></healthy>
      <unHealthy></unHealthy>
      <thresholdLimit>low</thresholdLimit>
      <pluginName>[CHECKSTYLE] </pluginName>
      <defaultEncoding></defaultEncoding>
      <canRunOnFailed>false</canRunOnFailed>
      <useStableBuildAsReference>false</useStableBuildAsReference>
      <useDeltaValues>false</useDeltaValues>
      <thresholds>
        <unstableTotalAll></unstableTotalAll>
        <unstableTotalHigh></unstableTotalHigh>
        <unstableTotalNormal></unstableTotalNormal>
        <unstableTotalLow></unstableTotalLow>
        <failedTotalAll></failedTotalAll>
        <failedTotalHigh></failedTotalHigh>
        <failedTotalNormal></failedTotalNormal>
        <failedTotalLow></failedTotalLow>
      </thresholds>
      <shouldDetectModules>false</shouldDetectModules>
      <dontComputeNew>true</dontComputeNew>
      <doNotResolveRelativePaths>false</doNotResolveRelativePaths>
      <pattern></pattern>
    </hudson.plugins.checkstyle.CheckStylePublisher>
    <hudson.plugins.warnings.WarningsPublisher>
      <healthy></healthy>
      <unHealthy></unHealthy>
      <thresholdLimit>low</thresholdLimit>
      <pluginName>[WARNINGS] </pluginName>
      <defaultEncoding></defaultEncoding>
      <canRunOnFailed>false</canRunOnFailed>
      <useStableBuildAsReference>false</useStableBuildAsReference>
      <useDeltaValues>false</useDeltaValues>
      <thresholds>
        <unstableTotalAll></unstableTotalAll>
        <unstableTotalHigh></unstableTotalHigh>
        <unstableTotalNormal></unstableTotalNormal>
        <unstableTotalLow></unstableTotalLow>
        <failedTotalAll></failedTotalAll>
        <failedTotalHigh></failedTotalHigh>
        <failedTotalNormal></failedTotalNormal>
        <failedTotalLow></failedTotalLow>
      </thresholds>
      <shouldDetectModules>false</shouldDetectModules>
      <dontComputeNew>true</dontComputeNew>
      <doNotResolveRelativePaths>true</doNotResolveRelativePaths>
      <parserConfigurations/>
      <consoleParsers>
        <hudson.plugins.warnings.ConsoleParser>
          <parserName>Java Compiler (Eclipse)</parserName>
        </hudson.plugins.warnings.ConsoleParser>
      </consoleParsers>
    </hudson.plugins.warnings.WarningsPublisher>
    <hudson.plugins.analysis.collector.AnalysisPublisher>
      <healthy></healthy>
      <unHealthy></unHealthy>
      <thresholdLimit>low</thresholdLimit>
      <pluginName>[ANALYSIS-COLLECTOR] </pluginName>
      <defaultEncoding></defaultEncoding>
      <canRunOnFailed>false</canRunOnFailed>
      <useStableBuildAsReference>false</useStableBuildAsReference>
      <useDeltaValues>false</useDeltaValues>
      <thresholds>
        <unstableTotalAll></unstableTotalAll>
        <unstableTotalHigh></unstableTotalHigh>
        <unstableTotalNormal></unstableTotalNormal>
        <unstableTotalLow></unstableTotalLow>
        <failedTotalAll></failedTotalAll>
        <failedTotalHigh></failedTotalHigh>
        <failedTotalNormal></failedTotalNormal>
        <failedTotalLow></failedTotalLow>
      </thresholds>
      <shouldDetectModules>false</shouldDetectModules>
      <dontComputeNew>true</dontComputeNew>
      <doNotResolveRelativePaths>true</doNotResolveRelativePaths>
      <isCheckStyleDeactivated>false</isCheckStyleDeactivated>
      <isDryDeactivated>true</isDryDeactivated>
      <isFindBugsDeactivated>true</isFindBugsDeactivated>
      <isPmdDeactivated>true</isPmdDeactivated>
      <isOpenTasksDeactivated>true</isOpenTasksDeactivated>
      <isWarningsDeactivated>false</isWarningsDeactivated>
    </hudson.plugins.analysis.collector.AnalysisPublisher>
    <hudson.plugins.android__emulator.monkey.MonkeyRecorder>
      <failureOutcome>FAILURE</failureOutcome>
    </hudson.plugins.android__emulator.monkey.MonkeyRecorder>
    <hudson.plugins.cigame.GamePublisher/>
    <hudson.tasks.Mailer>
      <recipients></recipients>
      <dontNotifyEveryUnstableBuild>false</dontNotifyEveryUnstableBuild>
      <sendToIndividuals>true</sendToIndividuals>
    </hudson.tasks.Mailer>
  </publishers>
  <buildWrappers>
    <hudson.plugins.locksandlatches.LockWrapper>
      <locks>
        <hudson.plugins.locksandlatches.LockWrapper_-LockWaitConfig>
          <name>AndroidEmulator</name>
        </hudson.plugins.locksandlatches.LockWrapper_-LockWaitConfig>
      </locks>
    </hudson.plugins.locksandlatches.LockWrapper>
    <hudson.plugins.android__emulator.AndroidEmulator>
      <osVersion>Google Inc.:Google APIs:8</osVersion>
      <screenDensity>240</screenDensity>
      <screenResolution>480x720</screenResolution>
      <deviceLocale>de_DE</deviceLocale>
      <sdCardSize>200M</sdCardSize>
      <hardwareProperties>
        <hudson.plugins.android__emulator.AndroidEmulator_-HardwareProperty>
          <key>hw.ramSize</key>
          <value>512</value>
        </hudson.plugins.android__emulator.AndroidEmulator_-HardwareProperty>
      </hardwareProperties>
      <wipeData>false</wipeData>
      <showWindow>true</showWindow>
      <useSnapshots>true</useSnapshots>
      <deleteAfterBuild>false</deleteAfterBuild>
      <startupDelay>0</startupDelay>
      <commandLineOptions></commandLineOptions>
    </hudson.plugins.android__emulator.AndroidEmulator>
  </buildWrappers>
</project>

",<android><android-emulator><jenkins><hudson><android-emulator-plugin>,17,"android,android-emulator,jenkins,hudson,android-emulator-plugin",['why is jenkins android emulator plugin recreating my emulator snapshots in every build'],"['i use jenkins to build one of my projects', 'the android emulator plugin automatically starts an emulator with the following configuration configuration of the emulator plugin ', 'every time the job is running i get the following output erasing existing emulator data cihometoolsandroidsdktoolsemulator nobootanim ports 6447064471 prop persistsyslanguagede prop persistsyscountryde avd hudsondede240480x720googleincgoogleapis8 nosnapshotload nosnapshotsave wipedata ', '', 'shell input keyevent 4 android giving the system some time to settle before creating initial snapshot ', '', 'localhost64471 shell log p v t jenkins creating snapshot android creating snapshot full log below', 'it seems that the plugin is creating a new emulator every time and is not using snapshots', 'this takes something between 2 and 4 minutes depending on the emulator configuration', 'the plugin creates avd and ini files in the androidavd directory inside the job folder', 'the avds are not deleted after the run process', 'if i disable the use snapshots config the emulator needs less then a minute to start', 'is this an issue with the emulator plugin or are snapshots not possible because of my configuration', 'i hope that using snapshots will speed up my building process a lot', 'full log cihometoolsandroidsdktoolsandroid list target android using android sdk cihometoolsandroidsdk android adding 200m sd card to avd hudsondede240480x720googleincgoogleapis8 android setting hardware properties hwramsize 512 cihometoolsandroidsdkplatformtoolsadb startserver cihometoolsandroidsdktoolsemulator snapshotlist nowindow avd hudsondede240480x720googleincgoogleapis8 android starting android emulator and creating initial snapshot android erasing existing emulator data cihometoolsandroidsdktoolsemulator nobootanim ports 6447064471 prop persistsyslanguagede prop persistsyscountryde avd hudsondede240480x720googleincgoogleapis8 nosnapshotload nosnapshotsave wipedata daemon not running', 'starting it now on port 64472 daemon started successfully cihometoolsandroidsdkplatformtoolsadb connect localhost64471 android waiting for emulator to finish booting cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell getprop devbootcomplete error device offline cihometoolsandroidsdkplatformtoolsadb connect localhost64471 cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell getprop devbootcomplete cihometoolsandroidsdkplatformtoolsadb connect localhost64471 cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell getprop devbootcomplete cihometoolsandroidsdkplatformtoolsadb disconnect localhost64471 cihometoolsandroidsdkplatformtoolsadb connect localhost64471 cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell getprop devbootcomplete cihometoolsandroidsdkplatformtoolsadb connect localhost64471 cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell getprop devbootcomplete cihometoolsandroidsdkplatformtoolsadb connect localhost64471 cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell getprop devbootcomplete cihometoolsandroidsdkplatformtoolsadb s localhost64471 logcat v time cihometoolsandroidsdkplatformtoolsadb connect localhost64471 android attempting to unlock emulator screen cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell input keyevent 82 cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell input keyevent 4 android giving the system some time to settle before creating initial snapshot cihometoolsandroidsdkplatformtoolsadb connect localhost64471 cihometoolsandroidsdkplatformtoolsadb s localhost64471 logcat c cihometoolsandroidsdkplatformtoolsadb s localhost64471 shell log p v t jenkins creating snapshot android creating snapshot cihometoolsandroidsdkplatformtoolsadb connect localhost64471 android emulator is ready for use took 158 seconds buildfile for an example job xml version10 encodingutf8 project actions descriptiondescription keepdependenciesfalsekeepdependencies properties scm classhudsonpluginsgitgitscm configversion2configversion userremoteconfigs hudsonpluginsgituserremoteconfig namename refspecrefspec urlgitprojecturl hudsonpluginsgituserremoteconfig userremoteconfigs branches hudsonpluginsgitbranchspec namemastername hudsonpluginsgitbranchspec branches disablesubmodulesfalsedisablesubmodules recursivesubmodulesfalserecursivesubmodules dogeneratesubmoduleconfigurationsfalsedogeneratesubmoduleconfigurations authororcommitterfalseauthororcommitter cleanfalseclean wipeoutworkspacefalsewipeoutworkspace prunebranchesfalseprunebranches remotepollfalseremotepoll ignorenotifycommitfalseignorenotifycommit useshallowclonefalseuseshallowclone buildchooser classhudsonpluginsgitutildefaultbuildchooser gittooldefaultgittool submodulecfg classlist relativetargetdirrelativetargetdir referencereference excludedregionsexcludedregions excludedusersexcludedusers gitconfignamegitconfigname gitconfigemailgitconfigemail skiptagfalseskiptag includedregionsincludedregions scmnamescmname scm canroamtruecanroam disabledfalsedisabled blockbuildwhendownstreambuildingtrueblockbuildwhendownstreambuilding blockbuildwhenupstreambuildingtrueblockbuildwhenupstreambuilding triggers classvector hudsontriggersscmtrigger spec5 spec hudsontriggersscmtrigger triggers concurrentbuildfalseconcurrentbuild builders hudsontasksant targetsclean debug installtargets antnamedefaultantname hudsontasksant hudsontasksant targetstargets antnamedefaultantname buildfilecheckstyleantxmlbuildfile hudsontasksant hudsontasksshell commandosoptsquotdjavaawtheadlesstruequot lint xml lintresultsxml command hudsontasksshell hudsonpluginsandroidemulatormonkeymonkeybuilder packageiddepackageid eventcount1000eventcount throttlems10throttlems seedtimestampseed hudsonpluginsandroidemulatormonkeymonkeybuilder hudsontasksshell distribution script hudsontasksshell builders publishers orgjenkinscipluginsandroidlintlintpublisher healthyhealthy thresholdlimitlowthresholdlimit pluginnameandroidlint pluginname defaultencodingdefaultencoding canrunonfailedfalsecanrunonfailed usestablebuildasreferencefalseusestablebuildasreference usedeltavaluesfalseusedeltavalues thresholds unstabletotalallunstabletotalall unstabletotalhighunstabletotalhigh unstabletotalnormalunstabletotalnormal unstabletotallowunstabletotallow unstablenewallunstablenewall unstablenewhighunstablenewhigh unstablenewnormalunstablenewnormal unstablenewlowunstablenewlow failedtotalallfailedtotalall failedtotalhighfailedtotalhigh failedtotalnormalfailedtotalnormal failedtotallowfailedtotallow failednewallfailednewall failednewhighfailednewhigh failednewnormalfailednewnormal failednewlowfailednewlow thresholds shoulddetectmodulesfalseshoulddetectmodules dontcomputenewfalsedontcomputenew donotresolverelativepathsfalsedonotresolverelativepaths patternpattern orgjenkinscipluginsandroidlintlintpublisher hudsonpluginscheckstylecheckstylepublisher healthyhealthy unhealthyunhealthy thresholdlimitlowthresholdlimit pluginnamecheckstyle pluginname defaultencodingdefaultencoding canrunonfailedfalsecanrunonfailed usestablebuildasreferencefalseusestablebuildasreference usedeltavaluesfalseusedeltavalues thresholds unstabletotalallunstabletotalall unstabletotalhighunstabletotalhigh unstabletotalnormalunstabletotalnormal unstabletotallowunstabletotallow failedtotalallfailedtotalall failedtotalhighfailedtotalhigh failedtotalnormalfailedtotalnormal failedtotallowfailedtotallow thresholds shoulddetectmodulesfalseshoulddetectmodules dontcomputenewtruedontcomputenew donotresolverelativepathsfalsedonotresolverelativepaths patternpattern hudsonpluginscheckstylecheckstylepublisher hudsonpluginswarningswarningspublisher healthyhealthy unhealthyunhealthy thresholdlimitlowthresholdlimit pluginnamewarnings pluginname defaultencodingdefaultencoding canrunonfailedfalsecanrunonfailed usestablebuildasreferencefalseusestablebuildasreference usedeltavaluesfalseusedeltavalues thresholds unstabletotalallunstabletotalall unstabletotalhighunstabletotalhigh unstabletotalnormalunstabletotalnormal unstabletotallowunstabletotallow failedtotalallfailedtotalall failedtotalhighfailedtotalhigh failedtotalnormalfailedtotalnormal failedtotallowfailedtotallow thresholds shoulddetectmodulesfalseshoulddetectmodules dontcomputenewtruedontcomputenew donotresolverelativepathstruedonotresolverelativepaths parserconfigurations consoleparsers hudsonpluginswarningsconsoleparser parsernamejava compiler eclipseparsername hudsonpluginswarningsconsoleparser consoleparsers hudsonpluginswarningswarningspublisher hudsonpluginsanalysiscollectoranalysispublisher healthyhealthy unhealthyunhealthy thresholdlimitlowthresholdlimit pluginnameanalysiscollector pluginname defaultencodingdefaultencoding canrunonfailedfalsecanrunonfailed usestablebuildasreferencefalseusestablebuildasreference usedeltavaluesfalseusedeltavalues thresholds unstabletotalallunstabletotalall unstabletotalhighunstabletotalhigh unstabletotalnormalunstabletotalnormal unstabletotallowunstabletotallow failedtotalallfailedtotalall failedtotalhighfailedtotalhigh failedtotalnormalfailedtotalnormal failedtotallowfailedtotallow thresholds shoulddetectmodulesfalseshoulddetectmodules dontcomputenewtruedontcomputenew donotresolverelativepathstruedonotresolverelativepaths ischeckstyledeactivatedfalseischeckstyledeactivated isdrydeactivatedtrueisdrydeactivated isfindbugsdeactivatedtrueisfindbugsdeactivated ispmddeactivatedtrueispmddeactivated isopentasksdeactivatedtrueisopentasksdeactivated iswarningsdeactivatedfalseiswarningsdeactivated hudsonpluginsanalysiscollectoranalysispublisher hudsonpluginsandroidemulatormonkeymonkeyrecorder failureoutcomefailurefailureoutcome hudsonpluginsandroidemulatormonkeymonkeyrecorder hudsonpluginscigamegamepublisher hudsontasksmailer recipientsrecipients dontnotifyeveryunstablebuildfalsedontnotifyeveryunstablebuild sendtoindividualstruesendtoindividuals hudsontasksmailer publishers buildwrappers hudsonpluginslocksandlatcheslockwrapper locks hudsonpluginslocksandlatcheslockwrapperlockwaitconfig nameandroidemulatorname hudsonpluginslocksandlatcheslockwrapperlockwaitconfig locks hudsonpluginslocksandlatcheslockwrapper hudsonpluginsandroidemulatorandroidemulator osversiongoogle incgoogle apis8osversion screendensity240screendensity screenresolution480x720screenresolution devicelocaledededevicelocale sdcardsize200msdcardsize hardwareproperties hudsonpluginsandroidemulatorandroidemulatorhardwareproperty keyhwramsizekey value512value hudsonpluginsandroidemulatorandroidemulatorhardwareproperty hardwareproperties wipedatafalsewipedata showwindowtrueshowwindow usesnapshotstrueusesnapshots deleteafterbuildfalsedeleteafterbuild startupdelay0startupdelay commandlineoptionscommandlineoptions hudsonpluginsandroidemulatorandroidemulator buildwrappers project']"
Retrofit usage in with API in Java,"According to information from official site I added latest depedency and started to develop.
First I created model with data I'm interested:
public class Data{
    String parametr1;
    //geters and setters ommited
}

second step was to add service:
public interface GitHubService {
    @GET(""/repos/{owner}/{repo}"")
    Call<Data> repoInfos(@Path(""user"") String owner, @Path(""repo"") String repo);

    Retrofit retrofit = new Retrofit.Builder().baseUrl(""https://api.github.com/"").build();
}

Third one was to add implementation:
@Service
public class GitHubServiceImpl implements GitHubService {

    final GitHubService gitHubService = GitHubService.retrofit.create(GitHubService.class);

    @Override
    public Call<DetailDto> repoDetails(String owner, String repo) {
        return gitHubService.repoDetails(owner, repo);
    }
}

But there is an error:
java.lang.IllegalArgumentException: Could not locate ResponseBody converter for class model.Data.

Here is full error log trace
",<java><github><retrofit><retrofit2><github-api>,5,"java,github,retrofit,retrofit2,github-api",['retrofit usage in with api in java'],"['according to information from official site i added latest depedency and started to develop', 'first i created model with data im interested public class data string parametr1 geters and setters ommited second step was to add service public interface githubservice getreposownerrepo calldata repoinfospathuser string owner pathrepo string repo retrofit retrofit new retrofitbuilderbaseurl third one was to add implementation service public class githubserviceimpl implements githubservice final githubservice githubservice githubserviceretrofitcreategithubserviceclass override public calldetaildto repodetailsstring owner string repo return githubservicerepodetailsowner repo but there is an error javalangillegalargumentexception could not locate responsebody converter for class modeldata', 'here is full error log trace']"
Difference between iron-session and next-auth?,"Why would one use iron-session instead of next-auth? Doesn't next-auth do normal username/password log-in in addition to Social (while iron-session only does the former)?
",<authentication><session><next.js><authorization><next-auth>,5,"authentication,session,next.js,authorization,next-auth",['difference between ironsession and nextauth'],"['why would one use ironsession instead of nextauth', 'doesnt nextauth do normal usernamepassword login in addition to social while ironsession only does the former']"
how do i load a view(cshtml) into an iframe?,"I'm trying to load a view into an iframe in another(parent) view using javascript and razor.
I'v tried setting the iframe's src to this
 var url = '@Url.Action(""myaction"", ""MyController"")';
and this:
 var url = '@Href(""~/myform.cshtml"")';
without success.
Thanks
Thanks
",<javascript><jquery><asp.net-mvc><iframe><razor>,5,"javascript,jquery,asp.net-mvc,iframe,razor",['how do i load a viewcshtml into an iframe'],"['im trying to load a view into an iframe in anotherparent view using javascript and razor', 'iv tried setting the iframes src to this var url urlactionmyaction mycontroller and this var url hrefmyformcshtml without success', 'thanks thanks']"
How to compile ruby with RVM on a low memory system?,"rvm install 1.9.3

leads to the error in the make.log:
...
compiling ./enc/trans/emoji_sjis_docomo.c
compiling ./enc/trans/emoji_sjis_kddi.c
gcc: internal compiler error: Killed (program cc1)
gcc: internal compiler error: Killed (program cc1)
gcc: internal compiler error: Killed (program cc1)
Please submit a full bug report,
with preprocessed source if appropriate.
...

dmesg shows
[180031.341709] send sigkill to 3705 (cc1), adj 0, size 3394

free shows at some point running configure process:
             total       used       free     shared    buffers     cached
Mem:        241668     238676       2992          0         92       2020
-/+ buffers/cache:     236564       5104
Swap:       262140     262140          0

So I assume that 256MB RAM and 256MB Swap is not enough to compile Ruby on it.
I read that it should be possible using some parameters for gcc, see:
http://hostingfu.com/article/compiling-with-gcc-on-low-memory-vps
But 
  rvm install 1.9.3 --with-CFLAGS=""$CFLAGS --param ggc-min-expand=0 --param ggc-min-heapsize=8192""

Does not work to give the flags to gcc, log is still the same for the flags:
command(2): __rvm_make -j4
        CC = gcc
        LD = ld
        LDSHARED = gcc -shared
        CFLAGS = -O3 -ggdb -Wall -Wextra -Wno-unused-parameter -Wno-parentheses -Wno-long-long -Wno-missing-fiel$
        XCFLAGS = -include ruby/config.h -include ruby/missing.h -fvisibility=hidden -DRUBY_EXPORT
        CPPFLAGS =   -I. -I.ext/include/x86_64-linux -I./include -I.
        DLDFLAGS = -Wl,-soname,libruby.so.1.9
        SOLIBS = -lpthread -lrt -ldl -lcrypt -lm

How to compile ruby on that machine?
",<ruby><gcc><installation><rvm><low-memory>,12,"ruby,gcc,installation,rvm,low-memory",['how to compile ruby with rvm on a low memory system'],"['rvm install 193 leads to the error in the makelog compiling enctransemojisjisdocomoc compiling enctransemojisjiskddic gcc internal compiler error killed program cc1 gcc internal compiler error killed program cc1 gcc internal compiler error killed program cc1 please submit a full bug report with preprocessed source if appropriate', ' dmesg shows 180031341709 send sigkill to 3705 cc1 adj 0 size 3394 free shows at some point running configure process total used free shared buffers cached mem 241668 238676 2992 0 92 2020 bufferscache 236564 5104 swap 262140 262140 0 so i assume that 256mb ram and 256mb swap is not enough to compile ruby on it', 'i read that it should be possible using some parameters for gcc see but rvm install 193 withcflagscflags param ggcminexpand0 param ggcminheapsize8192 does not work to give the flags to gcc log is still the same for the flags command2 rvmmake j4 cc gcc ld ld ldshared gcc shared cflags o3 ggdb wall wextra wnounusedparameter wnoparentheses wnolonglong wnomissingfiel xcflags include rubyconfigh include rubymissingh fvisibilityhidden drubyexport cppflags i', 'iextincludex8664linux iinclude i dldflags wlsonamelibrubyso19 solibs lpthread lrt ldl lcrypt lm how to compile ruby on that machine']"
Is it possible to partition across single file in spring batch?,"I have read about partitioning in spring-batch I've found an example which demonstrates partitioning. The example reads persons from CSV files, does some processing and insert data into the database. So at this example 1 partitioning = 1 file and so partitioner implementation looks like this:
public class MultiResourcePartitioner implements Partitioner {

    private final Logger logger = LoggerFactory.getLogger(MultiResourcePartitioner.class);
    public static final String FILE_PATH = ""filePath"";

    private static final String PARTITION_KEY = ""partition"";

    private final Collection<Resource> resources;


    public MultiResourcePartitioner(Collection<Resource> resources) {
        this.resources = resources;
    }

    @Override
    public Map<String, ExecutionContext> partition(int gridSize) {
        Map<String, ExecutionContext> map = new HashMap<>(gridSize);
        int i = 0;
        for (Resource resource : resources) {
            ExecutionContext context = new ExecutionContext();
            context.putString(FILE_PATH, getPath(resource)); //Depends on what logic you want to use to split
            map.put(PARTITION_KEY + i++, context);
        }
        return map;
    }

    private String getPath(Resource resource) {
        try {
            return resource.getFile().getPath();
        } catch (IOException e) {
            logger.warn(""Can't get file from from resource {}"", resource);
            throw new RuntimeException(e);
        }
    }
}

But what if I have single 10TB file? Does spring batch allow to partition it in some way?
update:
I tried following approach to achieve what I want:
make 2 steps - first step to divide file into pieces and second step to process pieces we got after the first step:
@Configuration
public class SingleFilePartitionedJob {

    @Autowired
    private JobBuilderFactory jobBuilderFactory;

    @Autowired
    private StepBuilderFactory stepBuilderFactory;

    @Autowired
    private ToLowerCasePersonProcessor toLowerCasePersonProcessor;

    @Autowired
    private DbPersonWriter dbPersonWriter;

    @Autowired
    private ResourcePatternResolver resourcePatternResolver;

    @Value(""${app.file-to-split}"")
    private Resource resource;


    @Bean
    public Job splitFileProcessingJob() throws IOException {
        return jobBuilderFactory.get(""splitFileProcessingJob"")
                .incrementer(new RunIdIncrementer())
                .flow(splitFileIntoPiecesStep())
                .next(csvToDbLowercaseMasterStep())
                .end()
                .build();
    }

    private Step splitFileIntoPiecesStep() throws IOException {
        return stepBuilderFactory.get(""splitFile"")
                .tasklet(new FileSplitterTasklet(resource.getFile()))
                .build();
    }

    @Bean
    public Step csvToDbLowercaseMasterStep() throws IOException {
        MultiResourcePartitioner partitioner = new MultiResourcePartitioner();
        partitioner.setResources(resourcePatternResolver.getResources(""split/*.csv""));
        return stepBuilderFactory.get(""csvReaderMasterStep"")
                .partitioner(""csvReaderMasterStep"", partitioner)
                .gridSize(10)
                .step(csvToDataBaseSlaveStep())
                .taskExecutor(jobTaskExecutorSplitted())
                .build();
    }

    @Bean
    public Step csvToDataBaseSlaveStep() throws MalformedURLException {
        return stepBuilderFactory.get(""csvToDatabaseStep"")
                .<Person, Person>chunk(50)
                .reader(csvPersonReaderSplitted(null))
                .processor(toLowerCasePersonProcessor)
                .writer(dbPersonWriter)
                .build();

    }

    @Bean
    @StepScope
    public FlatFileItemReader csvPersonReaderSplitted(@Value(""#{stepExecutionContext[fileName]}"") String fileName) throws MalformedURLException {
        return new FlatFileItemReaderBuilder()
                .name(""csvPersonReaderSplitted"")
                .resource(new UrlResource(fileName))
                .delimited()
                .names(new String[]{""firstName"", ""lastName""})
                .fieldSetMapper(new BeanWrapperFieldSetMapper<Person>() {{
                    setTargetType(Person.class);
                }})
                .build();

    }

    @Bean
    public TaskExecutor jobTaskExecutorSplitted() {
        ThreadPoolTaskExecutor taskExecutor = new ThreadPoolTaskExecutor();
        taskExecutor.setMaxPoolSize(30);
        taskExecutor.setCorePoolSize(25);
        taskExecutor.setThreadNamePrefix(""cust-job-exec2-"");
        taskExecutor.afterPropertiesSet();
        return taskExecutor;
    }

}

tasklet:
public class FileSplitterTasklet implements Tasklet {
    private final Logger logger = LoggerFactory.getLogger(FileSplitterTasklet.class);
    private File file;

    public FileSplitterTasklet(File file) {
        this.file = file;
    }

    @Override
    public RepeatStatus execute(StepContribution contribution, ChunkContext chunkContext) throws Exception {
        int count = FileSplitter.splitTextFiles(file, 100);
        logger.info(""File was split on {} files"", count);
        return RepeatStatus.FINISHED;

    }
}

logic for splitting file:
  public static int splitTextFiles(File bigFile, int maxRows) throws IOException {    
        int fileCount = 1;
        try (BufferedReader reader = Files.newBufferedReader(Paths.get(bigFile.getPath()))) {
            String line = null;
            int lineNum = 1;
            Path splitFile = Paths.get(bigFile.getParent() + ""/"" + fileCount + ""split.txt"");
            BufferedWriter writer = Files.newBufferedWriter(splitFile, StandardOpenOption.CREATE);

            while ((line = reader.readLine()) != null) {

                if (lineNum > maxRows) {
                    writer.close();
                    lineNum = 1;
                    fileCount++;
                    splitFile = Paths.get(""split/"" + fileCount + ""split.txt"");
                    writer = Files.newBufferedWriter(splitFile, StandardOpenOption.CREATE);
                }

                writer.append(line);
                writer.newLine();
                lineNum++;
            }
            writer.close();
        }

        return fileCount;
    }

So I put all file pieces to the special directory.
But this doesn't work because on the moment of context initialization folder /split does not exist yet.
update
I've generated workaround which works:
public class MultiResourcePartitionerWrapper implements Partitioner {
    private final MultiResourcePartitioner multiResourcePartitioner = new MultiResourcePartitioner();
    private final ResourcePatternResolver resourcePatternResolver;
    private final String pathPattern;

    public MultiResourcePartitionerWrapper(ResourcePatternResolver resourcePatternResolver, String pathPattern) {
        this.resourcePatternResolver = resourcePatternResolver;
        this.pathPattern = pathPattern;
    }

    @Override
    public Map<String, ExecutionContext> partition(int gridSize) {
        try {
            Resource[] resources = resourcePatternResolver.getResources(pathPattern);
            multiResourcePartitioner.setResources(resources);
            return multiResourcePartitioner.partition(gridSize);

        } catch (IOException e) {
            throw new RuntimeException(e);
        }
    }
}

But it looks ugly. Is it a correct solution?
",<java><spring><multithreading><spring-batch><partitioning>,5,"java,spring,multithreading,spring-batch,partitioning",['is it possible to partition across single file in spring batch'],"['i have read about partitioning in springbatch ive found an example which demonstrates partitioning', 'the example reads persons from csv files does some processing and insert data into the database', 'so at this example 1 partitioning 1 file and so partitioner implementation looks like this public class multiresourcepartitioner implements partitioner private final logger logger loggerfactorygetloggermultiresourcepartitionerclass public static final string filepath filepath private static final string partitionkey partition private final collectionresource resources public multiresourcepartitionercollectionresource resources thisresources resources override public mapstring executioncontext partitionint gridsize mapstring executioncontext map new hashmapgridsize int i 0 for resource resource resources executioncontext context new executioncontext contextputstringfilepath getpathresource depends on what logic you want to use to split mapputpartitionkey i context return map private string getpathresource resource try return resourcegetfilegetpath catch ioexception e loggerwarncant get file from from resource resource throw new runtimeexceptione but what if i have single 10tb file', 'does spring batch allow to partition it in some way', 'update i tried following approach to achieve what i want make 2 steps first step to divide file into pieces and second step to process pieces we got after the first step configuration public class singlefilepartitionedjob autowired private jobbuilderfactory jobbuilderfactory autowired private stepbuilderfactory stepbuilderfactory autowired private tolowercasepersonprocessor tolowercasepersonprocessor autowired private dbpersonwriter dbpersonwriter autowired private resourcepatternresolver resourcepatternresolver valueappfiletosplit private resource resource bean public job splitfileprocessingjob throws ioexception return jobbuilderfactorygetsplitfileprocessingjob incrementernew runidincrementer flowsplitfileintopiecesstep nextcsvtodblowercasemasterstep end build private step splitfileintopiecesstep throws ioexception return stepbuilderfactorygetsplitfile taskletnew filesplittertaskletresourcegetfile build bean public step csvtodblowercasemasterstep throws ioexception multiresourcepartitioner partitioner new multiresourcepartitioner partitionersetresourcesresourcepatternresolvergetresourcessplitcsv return stepbuilderfactorygetcsvreadermasterstep partitionercsvreadermasterstep partitioner gridsize10 stepcsvtodatabaseslavestep taskexecutorjobtaskexecutorsplitted build bean public step csvtodatabaseslavestep throws malformedurlexception return stepbuilderfactorygetcsvtodatabasestep person personchunk50 readercsvpersonreadersplittednull processortolowercasepersonprocessor writerdbpersonwriter build bean stepscope public flatfileitemreader csvpersonreadersplittedvaluestepexecutioncontextfilename string filename throws malformedurlexception return new flatfileitemreaderbuilder namecsvpersonreadersplitted resourcenew urlresourcefilename delimited namesnew stringfirstname lastname fieldsetmappernew beanwrapperfieldsetmapperperson settargettypepersonclass build bean public taskexecutor jobtaskexecutorsplitted threadpooltaskexecutor taskexecutor new threadpooltaskexecutor taskexecutorsetmaxpoolsize30 taskexecutorsetcorepoolsize25 taskexecutorsetthreadnameprefixcustjobexec2 taskexecutorafterpropertiesset return taskexecutor tasklet public class filesplittertasklet implements tasklet private final logger logger loggerfactorygetloggerfilesplittertaskletclass private file file public filesplittertaskletfile file thisfile file override public repeatstatus executestepcontribution contribution chunkcontext chunkcontext throws exception int count filesplittersplittextfilesfile 100 loggerinfofile was split on files count return repeatstatusfinished logic for splitting file public static int splittextfilesfile bigfile int maxrows throws ioexception int filecount 1 try bufferedreader reader filesnewbufferedreaderpathsgetbigfilegetpath string line null int linenum 1 path splitfile pathsgetbigfilegetparent filecount splittxt bufferedwriter writer filesnewbufferedwritersplitfile standardopenoptioncreate while line readerreadline null if linenum maxrows writerclose linenum 1 filecount splitfile pathsgetsplit filecount splittxt writer filesnewbufferedwritersplitfile standardopenoptioncreate writerappendline writernewline linenum writerclose return filecount so i put all file pieces to the special directory', 'but this doesnt work because on the moment of context initialization folder split does not exist yet', 'update ive generated workaround which works public class multiresourcepartitionerwrapper implements partitioner private final multiresourcepartitioner multiresourcepartitioner new multiresourcepartitioner private final resourcepatternresolver resourcepatternresolver private final string pathpattern public multiresourcepartitionerwrapperresourcepatternresolver resourcepatternresolver string pathpattern thisresourcepatternresolver resourcepatternresolver thispathpattern pathpattern override public mapstring executioncontext partitionint gridsize try resource resources resourcepatternresolvergetresourcespathpattern multiresourcepartitionersetresourcesresources return multiresourcepartitionerpartitiongridsize catch ioexception e throw new runtimeexceptione but it looks ugly', 'is it a correct solution']"
Testing (test-unit) a meta tag's name and content to make sure the content is not empty,"I'm having a really hard time figuring out how to make sure a meta title's content attribute is not empty using either assert_select or assert_tag. I can't figure out how to get it to work together.
To give you a better idea, here's an example of how I would like the test to work:
This should pass:
[meta name=""title"" content=""Hello"" /]
This should fail:
[meta name=""title"" content="""" /]
[note: Having no tag at all should also fail]
",<ruby-on-rails><ruby><testing><attributes><assert>,5,"ruby-on-rails,ruby,testing,attributes,assert",['testing testunit a meta tags name and content to make sure the content is not empty'],"['im having a really hard time figuring out how to make sure a meta titles content attribute is not empty using either assertselect or asserttag', 'i cant figure out how to get it to work together', 'to give you a better idea heres an example of how i would like the test to work this should pass meta nametitle contenthello this should fail meta nametitle content note having no tag at all should also fail']"
Is C++ context-free or context-sensitive?,"I often hear claims that C++ is a context-sensitive language. Take the following example:
a b(c);

Is this a variable definition or a function declaration? That depends on the meaning of the symbol c. If c is a variable, then a b(c); defines a variable named b of type a. It is directly initialized with c. But if c is a type, then a b(c); declares a function named b that takes a c and returns an a.
If you look up the definition of context-free languages, it will basically tell you that all grammar rules must have left-hand sides that consist of exactly one non-terminal symbol. Context-sensitive grammars, on the other hand, allow arbitrary strings of terminal and non-terminal symbols on the left-hand side.
Browsing through Appendix A of ""The C++ Programming Language"", I couldn't find a single grammar rule that had anything else besides a single non-terminal symbol on its left-hand side. That would imply that C++ is context-free. (Of course, every context-free language is also context-sensitive in the sense that the context-free languages form a subset of the context-sensitive languages, but that is not the point.)
So, is C++ context-free or context-sensitive?
",<c++><syntax><grammar><context-free-grammar><context-sensitive-grammar>,443,"c++,syntax,grammar,context-free-grammar,context-sensitive-grammar",['is c contextfree or contextsensitive'],"['i often hear claims that c is a contextsensitive language', 'take the following example a bc is this a variable definition or a function declaration', 'that depends on the meaning of the symbol c if c is a variable then a bc defines a variable named b of type a it is directly initialized with c but if c is a type then a bc declares a function named b that takes a c and returns an a if you look up the definition of contextfree languages it will basically tell you that all grammar rules must have lefthand sides that consist of exactly one nonterminal symbol', 'contextsensitive grammars on the other hand allow arbitrary strings of terminal and nonterminal symbols on the lefthand side', 'browsing through appendix a of the c programming language i couldnt find a single grammar rule that had anything else besides a single nonterminal symbol on its lefthand side', 'that would imply that c is contextfree', 'of course every contextfree language is also contextsensitive in the sense that the contextfree languages form a subset of the contextsensitive languages but that is not the point', 'so is c contextfree or contextsensitive']"
Unable to remove the page outer margin of the pdf which is created using html/css in flutter iOS,"I am trying to remove the outer white margin of PDF which is created using Html/css in flutter-iOS-app. In case of android the layout is working fine but incase of iOS there is left-margin issue as shown in the attachment of iOS. 
Issue at Github using DartPdf: Issue at DartPdf
Issue at Github using flutter_html_to_pdf: Issue at flutter_html_to_pdf
I have used these libraries in order to convert and render html to pdf. 
pubspec.yaml
dev_dependencies:
  flutter_test:
    sdk: flutter
  pdf: ^1.3.17
  printing: ^2.0.0
  flutter_full_pdf_viewer: ^1.0.4

Method to print html as PDF:
Future<void> printPdfMethod() async {
  print('Print ...');
  await Printing.layoutPdf(onLayout: (PdfPageFormat format) async {
    return await Printing.convertHtml(
        format: PdfPageFormat.a4
            .applyMargin(left: 0, top: 0, right: 0, bottom: 0),
        html:
            '<?xml version=""1.0""?> <html> <head> <title>CSS Template</title> <meta charset=""utf-8""> <meta name=""viewport"" content=""width=device-width, initial-scale=1""> <style> @page { size: A4; margin: 0mm 0mm 0mm 0mm; padding:0mm 0mm 0mm 0mm; } body { margin: 0px; padding: 0px; position: static; width:100%; height:100%; } </style> </head> <body style=""margin:0;padding:10"" bgcolor=""#144434""> <h1 style=""color:white"">Test Layout Margin</h1></body> </html>');
  });
}

style-property: Using this property the margin issue resolves in android but still not working on iOS case.
@page {
        size: A4;
        margin: 0mm 0mm 0mm 0mm;
    }

body {
        margin: 0px;
        padding: 0px;
    }

Android Screenshot:

iOS Screenshot:

Required Result:
The pdf will only contain the dark green layout and remove that outer white spacing in both iOS and android.
Note(When 2 or more pages): Incase of iOS when using this format property (format: PdfPageFormat.a4
            .applyMargin(left: 0, top: 0, right: 0, bottom: 0)), when the PDF splits the some of the views or data are invisible or hidden.
",<html><ios><css><flutter><pdf-generation>,8,"html,ios,css,flutter,pdf-generation",['unable to remove the page outer margin of the pdf which is created using htmlcss in flutter ios'],"['i am trying to remove the outer white margin of pdf which is created using htmlcss in flutteriosapp', 'in case of android the layout is working fine but incase of ios there is leftmargin issue as shown in the attachment of ios', 'issue at github using dartpdf issue at dartpdf issue at github using flutterhtmltopdf issue at flutterhtmltopdf i have used these libraries in order to convert and render html to pdf', 'pubspecyaml devdependencies fluttertest sdk flutter pdf 1317 printing 200 flutterfullpdfviewer 104 method to print html as pdf futurevoid printpdfmethod async printprint await printinglayoutpdfonlayout pdfpageformat format async return await printingconverthtml format pdfpageformata4 applymarginleft 0 top 0 right 0 bottom 0 html xml version10 html head titlecss templatetitle meta charsetutf8 meta nameviewport contentwidthdevicewidth initialscale1 style page size a4 margin 0mm 0mm 0mm 0mm padding0mm 0mm 0mm 0mm body margin 0px padding 0px position static width100 height100 style head body stylemargin0padding10 bgcolor144434 h1 stylecolorwhitetest layout marginh1body html styleproperty using this property the margin issue resolves in android but still not working on ios case', 'page size a4 margin 0mm 0mm 0mm 0mm body margin 0px padding 0px android screenshot ios screenshot required result the pdf will only contain the dark green layout and remove that outer white spacing in both ios and android', 'notewhen 2 or more pages incase of ios when using this format property format pdfpageformata4 applymarginleft 0 top 0 right 0 bottom 0 when the pdf splits the some of the views or data are invisible or hidden']"
Cannot find source for binding with reference 'RelativeSource FindAncestor',"I get this error:
Cannot find source for binding with reference 'RelativeSource FindAncestor,
AncestorType='System.Windows.Controls.UserControl', AncestorLevel='1''

On this Binding:
<DataGridTemplateColumn Visibility=""{Binding DataContext.IsVisible,
     RelativeSource={RelativeSource AncestorType={x:Type UserControl}},
     Converter={StaticResource BooleanToVisibilityConverter}}"">

The ViewModel is sitting as DataContext in UserControl. The DataContext of the DataGrid (sitting in UserControl) is property within the ViewModel, in ViewModel I have a variable that says whether to show a certain line or not, its binding fails, why?
Here my property :
private bool _isVisible=false;
public bool IsVisible
{
    get { return _isVisible; }
    set
    {
        _isVisible= value;
        NotifyPropertyChanged(""IsVisible"");
    }
}

When it comes to the function: NotifyPropertyChanged the PropertyChanged event null - mean he failed to register for the binding.
It should be noted that I have more bindings to ViewModel in such a way that works, here is an example:
Command=""{Binding DataContext.Cmd,
RelativeSource={RelativeSource AncestorType={x:Type UserControl}}}"" 

",<c#><wpf><xaml><mvvm><binding>,45,"c#,wpf,xaml,mvvm,binding",['cannot find source for binding with reference relativesource findancestor'],"['i get this error cannot find source for binding with reference relativesource findancestor ancestortypesystemwindowscontrolsusercontrol ancestorlevel1 on this binding datagridtemplatecolumn visibilitybinding datacontextisvisible relativesourcerelativesource ancestortypextype usercontrol converterstaticresource booleantovisibilityconverter the viewmodel is sitting as datacontext in usercontrol', 'the datacontext of the datagrid sitting in usercontrol is property within the viewmodel in viewmodel i have a variable that says whether to show a certain line or not its binding fails why', 'here my property private bool isvisiblefalse public bool isvisible get return isvisible set isvisible value notifypropertychangedisvisible when it comes to the function notifypropertychanged the propertychanged event null mean he failed to register for the binding', 'it should be noted that i have more bindings to viewmodel in such a way that works here is an example commandbinding datacontextcmd relativesourcerelativesource ancestortypextype usercontrol']"
Google Chrome v.30 : CSS overflow attribute on input elements cause other inputs to jump on focus state,"This bug seems to only appear on Chrome version 30.0 +
When I focus on an input element with overflow: hidden, it cause other input elements to jump. Any idea why this happen?
Fiddle : http://jsfiddle.net/8JHd6/3/
",<html><css><google-chrome><input><overflow>,5,"html,css,google-chrome,input,overflow",['google chrome v30 css overflow attribute on input elements cause other inputs to jump on focus state'],"['this bug seems to only appear on chrome version 300 when i focus on an input element with overflow hidden it cause other input elements to jump', 'any idea why this happen', 'fiddle ']"
How to extend instead of overriding WPF Styles,"I want to use custom theme in my application and as far as I know I can accomplish this by using resource dictionary and referencing it in App.xaml. Styles would override the defaults like this:
<Style TargetType=""{x:Type Label"">
    <Setter Property=""Foreground"" Value=""Green"" />
</Style>

Now as I guess the default Label style is overriden with same values but all my label fonts are green. The problem starts when I want to style one label somewhere again. When I want to change some other property in my Grid like this
<Grid.Resources>
    <Style TargetType=""{x:Type Label"">
        <Setter Property=""FontSize"" Value=""28"" />
    </Style>
</Grid.Resources>

All labels inside my grid are losing their foreground color and have default one again (didn't I override defaults in previous step?). After some tries I found out that to do this properly i have to add another property to Style declaration BasedOn={StaticResource {x:Type Label}}"" and it works. This is kind of weird for me because now I will have to repeat same BasedOn code in whole app and this is not how styling works - this should be done automatically! For example in HTML + CSS styles are inherited and merged and in WPF they are replaced...
Notice that when I don't use any styles controls still get their look from somehwere (System Themes?). How can I tell them to look for defaults somewhere else so without any additional code on styles they will think that they should be green by default?
Is there any way I can automate setting BasedOn property? Or maybe there is a better to do this overally?
",<wpf><styles><themes><skin><basedon>,41,"wpf,styles,themes,skin,basedon",['how to extend instead of overriding wpf styles'],"['i want to use custom theme in my application and as far as i know i can accomplish this by using resource dictionary and referencing it in appxaml', 'styles would override the defaults like this style targettypextype label setter propertyforeground valuegreen style now as i guess the default label style is overriden with same values but all my label fonts are green', 'the problem starts when i want to style one label somewhere again', 'when i want to change some other property in my grid like this gridresources style targettypextype label setter propertyfontsize value28 style gridresources all labels inside my grid are losing their foreground color and have default one again didnt i override defaults in previous step', 'after some tries i found out that to do this properly i have to add another property to style declaration basedonstaticresource xtype label and it works', 'this is kind of weird for me because now i will have to repeat same basedon code in whole app and this is not how styling works this should be done automatically', 'for example in html css styles are inherited and merged and in wpf they are replaced notice that when i dont use any styles controls still get their look from somehwere system themes', 'how can i tell them to look for defaults somewhere else so without any additional code on styles they will think that they should be green by default', 'is there any way i can automate setting basedon property', 'or maybe there is a better to do this overally']"
Wrong sorting with Collator using Locale.SIMPLIFIED_CHINESE,"I'm trying to order a list of countries in Chinese using Locale.SIMPLIFIED_CHINESE, which seems that it orders using pinyin (phonetic alphabet, that is characters are ordered according to their latin correspondent combination, from A to Z). 
But I've found some cases when it orders bad. For example:

'中' character is zhong1
'梵' character is fan4

The correct order should be 梵 < 中, but instead it is ordered in the other way.
String[] characters = new String[] {""梵"", ""中""};
List<String> list = Arrays.asList(characters);
System.out.println(""Before sorting..."");
System.out.println(list.toString());

Collator collator = Collator.getInstance(Locale.SIMPLIFIED_CHINESE);
collator.setStrength(Collator.PRIMARY);
Collections.sort(list, collator);

System.out.println(""After sorting..."");
System.out.println(list.toString());

Results of this snippet are:
Before sorting...
[梵, 中]
After sorting...
[中, 梵]

Going deeper, I found the rules that Java applies with Locale.SIMPLIFIED_CHINESE. You can find in next image:
https://postimg.cc/image/4t915a7gp/full/ (Notice that 梵 is after 中)
I realized before the <口<口<口<口<口 that I highlighted in red, all characters are ordered according to their latin correspondent combination, from A to Z. However, after the <口<口<口<口<口 sign, the characters are ordered by the composition of the character. For example, if all the characters have a same part (usually the left part of the character), they are then grouped together, not according to the A to Z rule. 
Also, all the characters after the <口<口<口<口<口 are less common Chinese characters. So, 梵 is a less common character than 中, so it is put after <口<口<口<口<口.
I wonder why this decision, if it is intentionally. But it results in wrong sortings. I don't know how to find a solution for this.
",<java><sorting><character><collation><chinese-locale>,12,"java,sorting,character,collation,chinese-locale",['wrong sorting with collator using localesimplifiedchinese'],"['im trying to order a list of countries in chinese using localesimplifiedchinese which seems that it orders using pinyin phonetic alphabet that is characters are ordered according to their latin correspondent combination from a to z', 'but ive found some cases when it orders bad', 'for example character is zhong1 character is fan4 the correct order should be but instead it is ordered in the other way', 'string characters new string liststring list arraysaslistcharacters systemoutprintlnbefore sorting systemoutprintlnlisttostring collator collator collatorgetinstancelocalesimplifiedchinese collatorsetstrengthcollatorprimary collectionssortlist collator systemoutprintlnafter sorting systemoutprintlnlisttostring results of this snippet are before sorting after sorting going deeper i found the rules that java applies with localesimplifiedchinese', 'you can find in next image notice that is after i realized before the that i highlighted in red all characters are ordered according to their latin correspondent combination from a to z however after the sign the characters are ordered by the composition of the character', 'for example if all the characters have a same part usually the left part of the character they are then grouped together not according to the a to z rule', 'also all the characters after the are less common chinese characters', 'so is a less common character than so it is put after ', 'i wonder why this decision if it is intentionally', 'but it results in wrong sortings', 'i dont know how to find a solution for this']"
Vuejs 3 emit event from child to parent component,"I've recently started working with VueJS, I'm using v3 and seem to be having an issue calling a method on a parent. The emit function in the child doesn't seem to be emitting the event and nothing is getting picked up in the parent.
I've included the parent and child to show how I have it set up
Parent
<template>
  <First/>
  < Child v-bind:sample=""sample"" @enlarge-text=""onEnlargeText""/>
</template>

<script lang=""ts"">
import { defineComponent } from 'vue';
import axios from 'axios';
import First from './First.vue';
import Child from './Child.vue';

export default defineComponent({
  name: 'Container',
  components: {
    First,
    Child,
  },
  methods: {
    onEnlargeText() {
      console.log('enlargeText');
    },
  },
  data: () => ({
    sample: [],
    parentmessage: '',
  }),
  created() {
    axios.get('http://localhost:8080/getData')
      .then((response) => {
        console.log(response);
        this.sample = response.data;
      })
      .catch((error) => {
        console.log(error);
      });
  },
});
</script>


Child
<template>
  <div id=""add"">
    <form id=""signup-form"" @submit.prevent=""submit"">
      <label for=""text"">Text:</label>
      <input type=""text"" v-model=""text"" required>
      <p class=""error"" >{{ error }}</p>
      <div class=""field has-text-right"">
        <button type=""submit"" class=""button is-danger"">Submit</button>
      </div>
    </form>
    <button v-on:click=""tryThis"">
      Enlarge text
    </button>
</div>
</template>

<script lang=""ts"">
import { defineComponent, ref } from 'vue';
import axios from 'axios';

interface SampleInterface {
  text: string;
  error: string;
}

export default defineComponent({
  name: 'Add',
  data: (): AddInterface => ({
    text: '',
    error: '',
  }),
  methods: {
    tryThis() {
      this.$emit('enlarge-text');
    },
    submit() {
      this.$emit('enlarge-text');
    },
  },
});
</script>

How should this be done? Is there something I've missed?
I was wondering can I still use $emit here?
",<typescript><vue.js><vuejs3><vue-composition-api><vue-script-setup>,26,"typescript,vue.js,vuejs3,vue-composition-api,vue-script-setup",['vuejs 3 emit event from child to parent component'],"['ive recently started working with vuejs im using v3 and seem to be having an issue calling a method on a parent', 'the emit function in the child doesnt seem to be emitting the event and nothing is getting picked up in the parent', 'ive included the parent and child to show how i have it set up parent template first child vbindsamplesample enlargetextonenlargetext template script langts import definecomponent from vue import axios from axios import first from firstvue import child from childvue export default definecomponent name container components first child methods onenlargetext consolelogenlargetext data sample parentmessage created axiosget thenresponse consolelogresponse thissample responsedata catcherror consolelogerror script child template div idadd form idsignupform submitpreventsubmit label fortexttextlabel input typetext vmodeltext required p classerror error p div classfield hastextright button typesubmit classbutton isdangersubmitbutton div form button vonclicktrythis enlarge text button div template script langts import definecomponent ref from vue import axios from axios interface sampleinterface text string error string export default definecomponent name add data addinterface text error methods trythis thisemitenlargetext submit thisemitenlargetext script how should this be done', 'is there something ive missed', 'i was wondering can i still use emit here']"
migrating ssdt project from visual studio 2012 to 2017 cdc source not opening,"We migrated packages from Visual Studio 2012 to 2017 
There is no cdc source component in the ssis toolbox:

and the cdc source component looks like:

And cannot be opened as well.
If I create a new Visual Studio 2017 Project it has the cdc source component in the ssis toolbox:

and I can work with it:

",<sql-server><visual-studio><ssis><ssis-2012><ssis-2017>,7,"sql-server,visual-studio,ssis,ssis-2012,ssis-2017",['migrating ssdt project from visual studio 2012 to 2017 cdc source not opening'],"['we migrated packages from visual studio 2012 to 2017 there is no cdc source component in the ssis toolbox and the cdc source component looks like and cannot be opened as well', 'if i create a new visual studio 2017 project it has the cdc source component in the ssis toolbox and i can work with it']"
"Add a signature, with annotations, to extension methods","When embedding Python in my application, and writing an extension type, I can add a signature to the method by using a properly crafted .tp_doc string.
static PyMethodDef Answer_methods[] = {
  { ""ultimate"", (PyCFunction)Answer_ultimate, METH_VARARGS, 
    ""ultimate(self, question='Life, the universe, everything!')\n""
    ""--\n""
    ""\n""
    ""Return the ultimate answer to the given question."" },
  { NULL }
};

When help(Answer) is executed, the following is returned (abbreviated):
class Answer(builtins.object)
 |
 |  ultimate(self, question='Life, the universe, everything!')
 |      Return the ultimate answer to the given question.

This is good, but I'm using Python3.6, which has support for annotations.  I'd like to annotate question to be a string, and the function to return an int.  I've tried:
static PyMethodDef Answer_methods[] = {
  { ""ultimate"", (PyCFunction)Answer_is_ultimate, METH_VARARGS, 
    ""ultimate(self, question:str='Life, the universe, everything!') -> int\n""
    ""--\n""
    ""\n""
    ""Return the ultimate answer to the given question."" },
  { NULL }
};

but this reverts to the (...) notation, and the documentation becomes:
 |  ultimate(...)
 |      ultimate(self, question:str='Life, the universe, everything!') -> int
 |      --
 |
 |      Return the ultimate answer to the given question.

and asking for inspect.signature(Answer.ultimate) results in an exception.
Traceback (most recent call last):
  File ""<string>"", line 11, in <module>
  File ""inspect.py"", line 3037, in signature
  File ""inspect.py"", line 2787, in from_callable
  File ""inspect.py"", line 2266, in _signature_from_callable
  File ""inspect.py"", line 2090, in _signature_from_builtin
ValueError: no signature found for builtin <built-in method ultimate of example.Answer object at 0x000002179F3A11B0>

I've tried to add the annotations after the fact with Python code:
example.Answer.ultimate.__annotations__ = {'return': bool}

But the builtin method descriptors can't have annotations added this way.
Traceback (most recent call last):
  File ""<string>"", line 2, in <module>
AttributeError: 'method_descriptor' object has no attribute '__annotations__'

Is there a way to add annotations to extension methods, using the C-API?

Argument Clinic looked promising and may still be very useful, but as of 3.6.5, it doesn't support annotations.

annotation
  The annotation value for this parameter. Not currently supported, because PEP 8 mandates that the Python library may not use annotations.

",<python><python-3.6><signature><python-c-api><python-internals>,11,"python,python-3.6,signature,python-c-api,python-internals",['add a signature with annotations to extension methods'],"['when embedding python in my application and writing an extension type i can add a signature to the method by using a properly crafted tpdoc string', 'static pymethoddef answermethods ultimate pycfunctionanswerultimate methvarargs ultimateself questionlife the universe everything', 'n n n return the ultimate answer to the given question', ' null when helpanswer is executed the following is returned abbreviated class answerbuiltinsobject ultimateself questionlife the universe everything', ' return the ultimate answer to the given question', 'this is good but im using python36 which has support for annotations', 'id like to annotate question to be a string and the function to return an int', 'ive tried static pymethoddef answermethods ultimate pycfunctionanswerisultimate methvarargs ultimateself questionstrlife the universe everything', ' intn n n return the ultimate answer to the given question', ' null but this reverts to the notation and the documentation becomes ultimate ultimateself questionstrlife the universe everything', ' int return the ultimate answer to the given question', 'and asking for inspectsignatureanswerultimate results in an exception', 'traceback most recent call last file string line 11 in module file inspectpy line 3037 in signature file inspectpy line 2787 in fromcallable file inspectpy line 2266 in signaturefromcallable file inspectpy line 2090 in signaturefrombuiltin valueerror no signature found for builtin builtin method ultimate of exampleanswer object at 0x000002179f3a11b0 ive tried to add the annotations after the fact with python code exampleanswerultimateannotations return bool but the builtin method descriptors cant have annotations added this way', 'traceback most recent call last file string line 2 in module attributeerror methoddescriptor object has no attribute annotations is there a way to add annotations to extension methods using the capi', 'argument clinic looked promising and may still be very useful but as of 365 it doesnt support annotations', 'annotation the annotation value for this parameter', 'not currently supported because pep 8 mandates that the python library may not use annotations']"
Enabling pretty permalinks on Wordpress - apache configuration does not work,"Probably this error has a pretty easy solution but I've been looking way to long at this and still don't get the error. I think I've tried whatever I could.
Problem: when I enable pretty permalinks on my wordpress installation (so, that it is using /%postname%/), it doesn't work. I get a 404 on all pages except for the homepage.
This page http://codex.wordpress.org/Permalinks tells me the requirements for permalinks to work:

Apache web server with the mod_rewrite module installed
In WordPress's home directory,


The FollowSymLinks option enabled
FileInfo directives allowed (e.g. AllowOverride FileInfo or AllowOverride All)
An .htaccess file (if this file is missing, WordPress will try to create it when you activate ""pretty"" permalinks)
If you want WordPress to update the .htaccess file automatically, WordPress will need write access to the file.


Apache web server has been installed, the mod_rewrite module has been loaded with a2enmod rewrite command (and the server has been restarted multiple times after). So, under /etc/apache2/mods-enabled, the symlink to rewrite.load is present. Also, when I run phpinfo command, I see that the mod_rewrite module has been loaded. You can check this as well here: http://namorti.com/phpinfo.php
Then, in /etc/apache2/sites-enabled, there was no ""default"" present. I copied 000-default.conf to default and edited default afterwards. It contains the following: 
        DocumentRoot /var/www
    <Directory />
            Options FollowSymLinks Indexes
            AllowOverride FileInfo
    </Directory>

So as far as I'm concerned, FollowSymLinks has been enabled and FileInfo directives are allowed. 
As for the last two points, in my wordpress home directory (/var/www), .htaccess is present and writeable by Wordpress (I updated the permalink structure a couple of times and it updates the .htaccess file accordingly). Right now it contains the following:
# BEGIN WordPress
<IfModule mod_rewrite.c>
RewriteEngine On
RewriteBase /
RewriteRule ^index\.php$ - [L]
RewriteCond %{REQUEST_FILENAME} !-f
RewriteCond %{REQUEST_FILENAME} !-d
RewriteRule . /index.php [L]
</IfModule>

# END WordPress

So, as far as I know, it SHOULD be working. I restarted the server (service apache2 restart) several times. I don't see what I'm missing. Anyone has a clue here? 
Thanks in advance!
* EDIT *
So, I did what calcinai told me to do... I edited my /etc/apache2/sites-enabled/default file (containing the vhost). It now looks like this:
<VirtualHost *:80>
    # The ServerName directive sets the request scheme, hostname and port that
    # the server uses to identify itself. This is used when creating
    # redirection URLs. In the context of virtual hosts, the ServerName
    # specifies what hostname must appear in the request's Host: header to
    # match this virtual host. For the default virtual host (this file) this
    # value is not decisive as it is used as a last resort host regardless.
    # However, you must set it for any further virtual host explicitly.
    #ServerName www.example.com

    ServerAdmin www.namorti.com
    DocumentRoot /var/www

    <Directory /var/www>
            Options MultiViews
            AllowOverride None
            Order allow,deny
            allow from all

            RewriteEngine On
            RewriteBase /
            RewriteRule ^index\.php$ - [L]
            RewriteCond %{REQUEST_FILENAME} !-f
            RewriteCond %{REQUEST_FILENAME} !-d
            RewriteRule . /index.php [L]
    </Directory>
    # Available loglevels: trace8, ..., trace1, debug, info, notice, warn,
    # error, crit, alert, emerg.
    # It is also possible to configure the loglevel for particular
    # modules, e.g.
    #LogLevel info ssl:warn

    ErrorLog ${APACHE_LOG_DIR}/error.log
    CustomLog ${APACHE_LOG_DIR}/access.log combined

    # For most configuration files from conf-available/, which are
    # enabled or disabled at a global level, it is possible to
    # include a line for only one particular virtual host. For example the
    # following line enables the CGI configuration for this host only
    # after it has been globally disabled with ""a2disconf"".
    #Include conf-available/serve-cgi-bin.conf
</VirtualHost>

# vim: syntax=apache ts=4 sw=4 sts=4 sr noet

I've restarted apache again, but unfortunately it still doesn't work. Honestly it would have surprised me, because moving the directives from the .htaccess file to the vhost would work if the htaccess on itself would work, as everything else seemed correct enough to me... 
Any other suggestions? Thanks for the effort!
",<php><wordpress><apache><.htaccess><mod-rewrite>,12,"php,wordpress,apache,.htaccess,mod-rewrite",['enabling pretty permalinks on wordpress apache configuration does not work'],"['probably this error has a pretty easy solution but ive been looking way to long at this and still dont get the error', 'i think ive tried whatever i could', 'problem when i enable pretty permalinks on my wordpress installation so that it is using postname it doesnt work', 'i get a 404 on all pages except for the homepage', 'this page tells me the requirements for permalinks to work apache web server with the modrewrite module installed in wordpresss home directory the followsymlinks option enabled fileinfo directives allowed eg', 'allowoverride fileinfo or allowoverride all an htaccess file if this file is missing wordpress will try to create it when you activate pretty permalinks if you want wordpress to update the htaccess file automatically wordpress will need write access to the file', 'apache web server has been installed the modrewrite module has been loaded with a2enmod rewrite command and the server has been restarted multiple times after', 'so under etcapache2modsenabled the symlink to rewriteload is present', 'also when i run phpinfo command i see that the modrewrite module has been loaded', 'you can check this as well here then in etcapache2sitesenabled there was no default present', 'i copied 000defaultconf to default and edited default afterwards', 'it contains the following documentroot varwww directory options followsymlinks indexes allowoverride fileinfo directory so as far as im concerned followsymlinks has been enabled and fileinfo directives are allowed', 'as for the last two points in my wordpress home directory varwww htaccess is present and writeable by wordpress i updated the permalink structure a couple of times and it updates the htaccess file accordingly', 'right now it contains the following begin wordpress ifmodule modrewritec rewriteengine on rewritebase rewriterule indexphp l rewritecond requestfilename f rewritecond requestfilename d rewriterule ', 'indexphp l ifmodule end wordpress so as far as i know it should be working', 'i restarted the server service apache2 restart several times', 'i dont see what im missing', 'anyone has a clue here', 'thanks in advance', ' edit so i did what calcinai told me to do i edited my etcapache2sitesenableddefault file containing the vhost', 'it now looks like this virtualhost 80 the servername directive sets the request scheme hostname and port that the server uses to identify itself', 'this is used when creating redirection urls', 'in the context of virtual hosts the servername specifies what hostname must appear in the requests host header to match this virtual host', 'for the default virtual host this file this value is not decisive as it is used as a last resort host regardless', ' however you must set it for any further virtual host explicitly', 'servername serveradmin documentroot varwww directory varwww options multiviews allowoverride none order allowdeny allow from all rewriteengine on rewritebase rewriterule indexphp l rewritecond requestfilename f rewritecond requestfilename d rewriterule ', 'indexphp l directory available loglevels trace8 trace1 debug info notice warn error crit alert emerg', ' it is also possible to configure the loglevel for particular modules eg', 'loglevel info sslwarn errorlog apachelogdirerrorlog customlog apachelogdiraccesslog combined for most configuration files from confavailable which are enabled or disabled at a global level it is possible to include a line for only one particular virtual host', 'for example the following line enables the cgi configuration for this host only after it has been globally disabled with a2disconf', 'include confavailableservecgibinconf virtualhost vim syntaxapache ts4 sw4 sts4 sr noet ive restarted apache again but unfortunately it still doesnt work', 'honestly it would have surprised me because moving the directives from the htaccess file to the vhost would work if the htaccess on itself would work as everything else seemed correct enough to me any other suggestions', 'thanks for the effort']"
iOS8 check if device has Touch ID,"LAContext has method to check if device can evaluate touch ID and gives error message.
Problem is that same error message ""LAErrorPasscodeNotSet"" is given by system in two cases:
1) If user has Touch ID, but turned it off in settings (iPhone 5s with iOS8)
2) If device doesn't have Touch ID (iPad with iOS8)
Q: How to check if device supports Touch ID, but haven't turned it on in settings?
Update:
Had created ticket to Apple regarding this bug (ID# 18364575) and received answer:
""Engineering has determined that this issue behaves as intended based on the following information:
If passcode is not set, you will not be able to detect Touch ID presence. Once the passcode is set, canEvaluatePolicy will eventually return LAErrorTouchIDNotAvailable or LAErrorTouchIdNotEnrolled and you will be able to detect Touch ID presence/state. 
If users have disabled passcode on phone with Touch ID, they knew that they will not be able to use Touch ID, so the apps don't need to detect Touch ID presence or promote Touch ID based features. ""
",<ios><iphone><ios8><touch-id><face-id>,17,"ios,iphone,ios8,touch-id,face-id",['ios8 check if device has touch id'],"['lacontext has method to check if device can evaluate touch id and gives error message', 'problem is that same error message laerrorpasscodenotset is given by system in two cases 1 if user has touch id but turned it off in settings iphone 5s with ios8 2 if device doesnt have touch id ipad with ios8 q how to check if device supports touch id but havent turned it on in settings', 'update had created ticket to apple regarding this bug id 18364575 and received answer engineering has determined that this issue behaves as intended based on the following information if passcode is not set you will not be able to detect touch id presence', 'once the passcode is set canevaluatepolicy will eventually return laerrortouchidnotavailable or laerrortouchidnotenrolled and you will be able to detect touch id presencestate', 'if users have disabled passcode on phone with touch id they knew that they will not be able to use touch id so the apps dont need to detect touch id presence or promote touch id based features ']"
How to integrate FluentValidation into MVC4,"I have made a simple model that has FluentValidation in it but it does not seem to work.

My database is updating with empty name and passing
TryUpdateModel()
I don't get client-side validation errors when I submit my form

I have tried to add FluentValidationModelValidatorProvider.Configure(); in Application_Start() but it shows that it cannot find FluentValidationModelValidatorProvider even though I added using class. I also tried to add [Validator(typeof(Category))] on top of my model class but didn't do anything. This us the resource I've been looking for information.
Model
public class Category
{
    public int ID { get; set; }
    public string Name { get; set; }
    virtual public ICollection<Image> Images { get; set; }
}

public class CategoryValidator : AbstractValidator<Category>
{
    public CategoryValidator()
    {
        RuleFor(x => x.Name).NotEmpty().WithMessage(""Category name is required."");
    }
}

Controller
[HttpPost]
[ValidateAntiForgeryToken]
public ActionResult Edit(Category c)
{
    var category = _db.Categories.Where(x => x.ID == c.ID).SingleOrDefault();
    if (category == null) return HttpNotFound();

    // Update model and return to category list
    if (TryUpdateModel(category)) // it passes with empty name and saves changes
    {
        _db.SaveChanges();
        return RedirectToAction(""index"", ""category"");
    }

    // Something is wrong, return view back
    return View(c);
}

",<c#><asp.net><asp.net-mvc><asp.net-mvc-4><fluentvalidation>,5,"c#,asp.net,asp.net-mvc,asp.net-mvc-4,fluentvalidation",['how to integrate fluentvalidation into mvc4'],"['i have made a simple model that has fluentvalidation in it but it does not seem to work', 'my database is updating with empty name and passing tryupdatemodel i dont get clientside validation errors when i submit my form i have tried to add fluentvalidationmodelvalidatorproviderconfigure in applicationstart but it shows that it cannot find fluentvalidationmodelvalidatorprovider even though i added using class', 'i also tried to add validatortypeofcategory on top of my model class but didnt do anything', 'this us the resource ive been looking for information', 'model public class category public int id get set public string name get set virtual public icollectionimage images get set public class categoryvalidator abstractvalidatorcategory public categoryvalidator ruleforx xnamenotemptywithmessagecategory name is required', ' controller httppost validateantiforgerytoken public actionresult editcategory c var category dbcategorieswherex xid cidsingleordefault if category null return httpnotfound update model and return to category list if tryupdatemodelcategory it passes with empty name and saves changes dbsavechanges return redirecttoactionindex category something is wrong return view back return viewc ']"
Rails 6 - constant ActionController::InvalidAuthenticityToken,"I'm tinkering with Rails 6 and I am constantly getting ActionController::InvalidAuthenticityToken on forms generated by rails, such as (implementing the rails tutorial book register/login flow)
<%= form_for(@user, url: 'signup') do |f| %>
     <%= render 'partials/error_messages' %>
     <%= f.label :name, ""Nimi"" %>
     <%= f.text_field :name %>
     <%= f.label :email, ""E-mail"" %>
     <%= f.email_field :email %>
     <%= f.label :password, ""Parool"" %>
     <%= f.password_field :password %>
     <%= f.label :password_confirmation, ""Korda parooli"" %>
     <%= f.password_field :password_confirmation %>
     <%= f.submit ""Loo konto"", class: ""button-green"" %>
<% end %>

this happens on all forms, and the output dumps look like this

application.html.erb
<!DOCTYPE html>
<html>
  <head>
    <title>Storebase - kaasaegsed e-poed!</title>
    <%= csrf_meta_tags %>
    <%= csp_meta_tag %>

    <%= javascript_pack_tag 'application', 'data-turbolinks-track': 'reload' %>
    <%= stylesheet_link_tag 'application', media: 'all', 'data-turbolinks-track': 'reload' %>
    <%= stylesheet_pack_tag 'application', 'data-turbolinks-track': 'reload' %>
  </head>

  <body class=""bg-gray-100 text-gray-900"">
    <% flash.each do |message_type, message| %>
      <div class=""bg-blue-100 text-blue-500 flex items-center h-12 px-12 shadow-lg flash-<%= message_type %>""><%= message %></div>
    <% end %>

    <%= yield %>
    <%= debug(params) if Rails.env.development? %>
  </body>
</html>

What should I do?
",<ruby-on-rails><csrf><actioncontroller><ruby-on-rails-6><authenticity-token>,10,"ruby-on-rails,csrf,actioncontroller,ruby-on-rails-6,authenticity-token",['rails 6 constant actioncontrollerinvalidauthenticitytoken'],"['im tinkering with rails 6 and i am constantly getting actioncontrollerinvalidauthenticitytoken on forms generated by rails such as implementing the rails tutorial book registerlogin flow formforuser url signup do f render partialserrormessages flabel name nimi ftextfield name flabel email email femailfield email flabel password parool fpasswordfield password flabel passwordconfirmation korda parooli fpasswordfield passwordconfirmation fsubmit loo konto class buttongreen end this happens on all forms and the output dumps look like this applicationhtmlerb doctype html html head titlestorebase kaasaegsed epoedtitle csrfmetatags cspmetatag javascriptpacktag application dataturbolinkstrack reload stylesheetlinktag application media all dataturbolinkstrack reload stylesheetpacktag application dataturbolinkstrack reload head body classbggray100 textgray900 flasheach do messagetype message div classbgblue100 textblue500 flex itemscenter h12 px12 shadowlg flash messagetype message div end yield debugparams if railsenvdevelopment', ' body html what should i do']"
Rmarkdown of Stargazer: LaTeX Error if align is set to TRUE,"I am working with stargazer and I want to produce a LaTeX output for a simple lm object. The problem is that I cannot set align = TRUE without getting an error.

LaTeX Error: \caption outside float.

I checked it and what the message says is wrong. Copying the Stargazer output directly into an Latex document works fine. Copying it into an rmarkdown document produces the same error (which is no surprise but I just wanted to be sure). After playing around a bit I figured out that it is working in rmarkdown if the significance stars(*) are removed (or to precise the ^{***}). However, stargazer is producing them by default and they are also an important part of the output.
Is there a way to make it work?
---
header-includes:
- \usepackage{dcolumn}
output: pdf_document
---

## R Markdown
```{r, include = FALSE}
library(stargazer)
df <- data.frame(x = 1:10 + rnorm(100),
                 y = 1:10 + rnorm(100))
reg <- lm(y ~ x, data = df)
```

```{r, results='asis', echo = FALSE}
stargazer(reg, header = FALSE, align = TRUE)
```

",<r><knitr><r-markdown><pandoc><stargazer>,7,"r,knitr,r-markdown,pandoc,stargazer",['rmarkdown of stargazer latex error if align is set to true'],"['i am working with stargazer and i want to produce a latex output for a simple lm object', 'the problem is that i cannot set align true without getting an error', 'latex error caption outside float', 'i checked it and what the message says is wrong', 'copying the stargazer output directly into an latex document works fine', 'copying it into an rmarkdown document produces the same error which is no surprise but i just wanted to be sure', 'after playing around a bit i figured out that it is working in rmarkdown if the significance stars are removed or to precise the ', 'however stargazer is producing them by default and they are also an important part of the output', 'is there a way to make it work', ' headerincludes usepackagedcolumn output pdfdocument r markdown r include false librarystargazer df dataframex 110 rnorm100 y 110 rnorm100 reg lmy x data df r resultsasis echo false stargazerreg header false align true ']"
Kafka cluster loses or duplicates messages,"While working to adapt Java's KafkaIOIT to work with a large dataset I encountered a problem. I want to push 100M records through a Kafka topic, verify data correctness and at the same time check the performance of KafkaIO.Write and KafkaIO.Read.
To perform the tests I'm using a Kafka cluster on Kubernetes from the Beam repo (here).
The expected result would be that first the records are generated in a deterministic way, next they are written to Kafka - this concludes the write pipeline.
As for reading and correctness checking - first, the data is read from the topic and after being decoded into String representations, a hashcode of the whole PCollection is calculated (For details, check KafkaIOIT.java).
During the testing I ran into several problems:

When the predermined number of records is read from the Kafka topic, the hash is different each time.
Sometimes not all the records are read and the Dataflow task waits for the input indefinitely, occasionally throwing exceptions.

I believe there are two possible causes of this behavior:
either there is something wrong with the Kafka cluster configuration
or KafkaIO behaves erratically on high data volumes, duplicating and/or dropping records.
I found a Stack answer that I believe might explain the first behavior:
link - if messages are delivered more than once, it's obvious that the hash of the whole collection would change. 
In this case, I don't really know how to configure KafkaIO.Write in Beam to produce exactly once.
This leaves the issue of messages being dropped unsolved. Can you help?
",<kubernetes><apache-kafka><bigdata><google-cloud-dataflow><apache-beam>,7,"kubernetes,apache-kafka,bigdata,google-cloud-dataflow,apache-beam",['kafka cluster loses or duplicates messages'],"['while working to adapt javas kafkaioit to work with a large dataset i encountered a problem', 'i want to push 100m records through a kafka topic verify data correctness and at the same time check the performance of kafkaiowrite and kafkaioread', 'to perform the tests im using a kafka cluster on kubernetes from the beam repo here', 'the expected result would be that first the records are generated in a deterministic way next they are written to kafka this concludes the write pipeline', 'as for reading and correctness checking first the data is read from the topic and after being decoded into string representations a hashcode of the whole pcollection is calculated for details check kafkaioitjava', 'during the testing i ran into several problems when the predermined number of records is read from the kafka topic the hash is different each time', 'sometimes not all the records are read and the dataflow task waits for the input indefinitely occasionally throwing exceptions', 'i believe there are two possible causes of this behavior either there is something wrong with the kafka cluster configuration or kafkaio behaves erratically on high data volumes duplicating andor dropping records', 'i found a stack answer that i believe might explain the first behavior link if messages are delivered more than once its obvious that the hash of the whole collection would change', 'in this case i dont really know how to configure kafkaiowrite in beam to produce exactly once', 'this leaves the issue of messages being dropped unsolved', 'can you help']"
PHP script stops working suddenly without reason,"I'm running a BIG PHP script, it might take a full day to finish its job,
this script grabs data from MySQL database and use it with curl to test stuff.. it does it with about 40,000 records..
So to make it run on background for as long as it needs, i used the terminal to execute it.. in the PHP script itself it has those settings to make sure it runs as long as possible until it finishes :
set_time_limit(0); // run without timeout limit

and because i execute it from another separated PHP script i use this function
ignore_user_abort(1); // ignore my abort

because executing it directly from the command line, it will give me two choices.. 1 ) to wait till the script finishes 2 ) cancel the whole process
and after searching, there was an article that gives me a third choice and its to run it in background for longest possible by creating an external PHP script to excute the main BIG PHP script in background using this function:
exec(""php bigfile.php"");

that means i can open this external page normally from a browser and exit it without worry since ignore_user_abort will keep it running in background.. That's still not the problem
the problem is.. after an unknown period, the script stops its job.. how do i know ? I told it to write in an external file the current date time on each record it works on, so i refresh everytime to that external page to see if it stopped updating,
after an unknown period it actually stops for no reason, the script has nothing that says stop or anything.. and if anything wrong happened, i told it to skip the record ( nothing wrong happens tho, they all work in the same line, if one works then all should work )
However my main doubts are in the following :

Apache has a timeout that kills it
That was not the proper way to execute PHP script in background
There is a timeout somewhere, whether in PHP or Apache or (MySQL !?)
     that's where my biggest doubt goes.. MySQL, Would it ever stop giving records to the PHP loop from while ? Would it crash the whole script if an error occurred ? Does it has any timeout at anything that crashes the whole script ? 

If none of those could apply to it, Is there any way to log what is exactly going on the script now ? Or why would it crash ? any detailed way to log everything ?

UPDATE:
I FOUND this in messages file in /var/log/ :
Dec 29 16:29:56 i0sa shutdown[5609]: shutting down for system halt
Dec 29 16:30:14 i0sa exiting on signal 15
Dec 29 16:30:28 i0sa syslogd 1.5.0#6: restart.
Dec 29 16:50:28 i0sa -- MARK --
            .....
Dec 29 18:50:31 i0sa -- MARK --
Dec 29 19:02:36 i0sa shutdown[3641]: shutting down for system halt
Dec 29 19:03:11 i0sa exiting on signal 15
Dec 29 19:03:48 i0sa syslogd 1.5.0#6: restart.

it says for system halt.. I'll try to make sure that this could be it in the future crashes and match times, COULD this be causing it ? and why ? memory_limit is 128M while i have 2GB of server memory ram, could this be it ?
P.S.: I restarted the server several times manually.. But this one says shutdown and halt ?
",<php><mysql><linux><apache><shell>,8,"php,mysql,linux,apache,shell",['php script stops working suddenly without reason'],"['im running a big php script it might take a full day to finish its job this script grabs data from mysql database and use it with curl to test stuff it does it with about 40000 records so to make it run on background for as long as it needs i used the terminal to execute it in the php script itself it has those settings to make sure it runs as long as possible until it finishes settimelimit0 run without timeout limit and because i execute it from another separated php script i use this function ignoreuserabort1 ignore my abort because executing it directly from the command line it will give me two choices 1 to wait till the script finishes 2 cancel the whole process and after searching there was an article that gives me a third choice and its to run it in background for longest possible by creating an external php script to excute the main big php script in background using this function execphp bigfilephp that means i can open this external page normally from a browser and exit it without worry since ignoreuserabort will keep it running in background thats still not the problem the problem is after an unknown period the script stops its job how do i know ', 'i told it to write in an external file the current date time on each record it works on so i refresh everytime to that external page to see if it stopped updating after an unknown period it actually stops for no reason the script has nothing that says stop or anything and if anything wrong happened i told it to skip the record nothing wrong happens tho they all work in the same line if one works then all should work however my main doubts are in the following apache has a timeout that kills it that was not the proper way to execute php script in background there is a timeout somewhere whether in php or apache or mysql ', '', 'thats where my biggest doubt goes mysql would it ever stop giving records to the php loop from while ', 'would it crash the whole script if an error occurred ', 'does it has any timeout at anything that crashes the whole script ', 'if none of those could apply to it is there any way to log what is exactly going on the script now ', 'or why would it crash ', 'any detailed way to log everything ', 'update i found this in messages file in varlog dec 29 162956 i0sa shutdown5609 shutting down for system halt dec 29 163014 i0sa exiting on signal 15 dec 29 163028 i0sa syslogd 1506 restart', 'dec 29 165028 i0sa mark dec 29 185031 i0sa mark dec 29 190236 i0sa shutdown3641 shutting down for system halt dec 29 190311 i0sa exiting on signal 15 dec 29 190348 i0sa syslogd 1506 restart', 'it says for system halt ill try to make sure that this could be it in the future crashes and match times could this be causing it ', 'and why ', 'memorylimit is 128m while i have 2gb of server memory ram could this be it ', 'p', ' i restarted the server several times manually but this one says shutdown and halt ']"
Can't edit HTML in Chrome dev tools Sources tab,"I have a noob question about the Sources panel in dev tools: when in the Elements tab I see my CSS to the right. I click on a CSS file and am brought to the Sources tab where I can make live edits. 
I can bring up the JS and do the same, but...
If I bring up the HTML file, I am unable to make any edits to the HTML. Why is this? Is this by design? What am I missing?
",<javascript><html><css><google-chrome><google-chrome-devtools>,7,"javascript,html,css,google-chrome,google-chrome-devtools",['cant edit html in chrome dev tools sources tab'],"['i have a noob question about the sources panel in dev tools when in the elements tab i see my css to the right', 'i click on a css file and am brought to the sources tab where i can make live edits', 'i can bring up the js and do the same but if i bring up the html file i am unable to make any edits to the html', 'why is this', 'is this by design', 'what am i missing']"
How to save enum field in the database room?,"I must write the value from the enum enumeration to the database. An error occurs during compilation. What am I doing wrong?

Cannot figure out how to save this field into database. You can consider adding a type converter for it.

@ColumnInfo(name = ""state_of_health"")
@TypeConverters(HealthConverter::class)
var health: Health

enum class Health(val value: Int){
    NONE(-1),
    VERY_BAD(0),
    ...
}

class HealthConverter{

    @TypeConverter
    fun fromHealth(value: Health): Int{
        return value.ordinal
    }

    @TypeConverter
    fun toHealth(value: Int): Health{
        return when(value){
            -1 -> Health.NONE
            0 -> Health.VERY_BAD
            ...
            else -> Health.EXCELLENT
        }
    }

}

",<android><kotlin><enums><android-room><converters>,53,"android,kotlin,enums,android-room,converters",['how to save enum field in the database room'],"['i must write the value from the enum enumeration to the database', 'an error occurs during compilation', 'what am i doing wrong', 'cannot figure out how to save this field into database', 'you can consider adding a type converter for it', 'columninfoname stateofhealth typeconvertershealthconverterclass var health health enum class healthval value int none1 verybad0 class healthconverter typeconverter fun fromhealthvalue health int return valueordinal typeconverter fun tohealthvalue int health return whenvalue 1 healthnone 0 healthverybad else healthexcellent ']"
"C# compile error: ""Invoke or BeginInvoke cannot be called on a control until the window handle has been created.""","I just posted a question about how to get a delegate to update a textbox on another form. Just when I thought I had the answer using Invoke...this happens. Here is my code:
Main Form Code:
using System;
using System.Drawing;
using System.Collections;
using System.ComponentModel;
using System.Windows.Forms;
using System.Data;
using System.IO;
using System.Data.OleDb;
using System.Collections.Specialized;
using System.Text;
using System.Threading;

delegate void logAdd(string message);

namespace LCR_ShepherdStaffupdater_1._0
{
    public partial class Main : Form
    {
        public Main()
        {
            InitializeComponent();
        }

        public void add(string message)
        {
            this.Log.Items.Add(message);
        }
        public void logAdd(string message)
        {   /////////////////////////// COMPILER ERROR BELOW ///////////
            this.Invoke(new logAdd(add), new object[] { message }); // Compile error occurs here     
        }////////////////////////////// COMPILER ERROR ABOVE ///////////

        private void exitProgramToolStripMenuItem_Click(object sender, EventArgs e) 
        {
            Application.Exit(); 
        }
        private void aboutToolStripMenuItem1_Click(object sender, EventArgs e)
        {
            Form aboutBox = new AboutBox1(); 
            aboutBox.ShowDialog(); 
        }

        private void settingsToolStripMenuItem_Click(object sender, EventArgs e)
        {
        }

        private void settingsToolStripMenuItem1_Click(object sender, EventArgs e)
        {
            settingsForm.settings.ShowDialog();
        }

        private void synchronize_Click(object sender, EventArgs e)
        {
            string message = ""Here my message is""; // changed this
            ErrorLogging.updateLog(message);  // changed this
        }

    }

    public class settingsForm 
    {
        public static Form settings = new Settings();
    }

}

Logging Class Code:
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;

namespace LCR_ShepherdStaffupdater_1._0
{
    public class Logging
    {
        static Main mainClass = new Main();
        static logAdd logAddDelegate;

        public static void updateLog(string message)
        {
            logAddDelegate = mainClass.logAdd;
            logAddDelegate(message);
        }
    }
}


Compile Error: 
InvalidOperationException was
unhandled - Invoke or BeginInvoke
cannot be called on a control until
the window handle has been created.

I already tried to create a handle on the Log item...but that didn't work. The problem is I have NO CLUE what I am doing and I have searched Google extensively only to find vague answers.
Please tell me how to create the handle before I invoke this delegate. While you are at it, give me some ways I can make this code more simple. For example, I dont want two Add functions... I had to do that because there was no way for me to find an item to invoke from the Logging class. Is there a better way to accomplish what I need to do?
Thank you!!!
EDIT:
My project is fairly large, but these are the only items causing this specific problem.
Log is my RichTextBox1 (Log.Items.Add(message)) I renamed it to Log so it is easier to retype.
I am calling updateLog(message) from a different form though...let me update that in here (although it makes no difference where I call updateLog(message) from it still gives me this error)
You guys are going to have to make things more simpler for me...and provide examples. I don't understand HALF of everything you guys are saying here...I have no clue on how to work with Invoking of methods and Handles. I've researched the crap out of it too...
SECOND EDIT:
I believe I have located the problem, but do not know how to fix it.
In my logging class I use this code to create mainClass:
static Main mainClass = new Main();
I am creating a entirely new blueprint replica to Main(), including Log (the richtextbox I am trying to update)
When I call updateLog(message) I believe I am trying to update the Log (richtextbox) on the second entity of Main() otherwise known as mainClass. Of course, doing so will throw me this exception because I haven't even seen that replica of the current Main I am using.
This is what I am shooting for, thanks to one of the people that gave an answer:
Main mainClass = Application.OpenForms.OfType<Main>().First();
logAddDelegate = mainClass.logAdd; 
logAddDelegate(message);

I need to create mainClass not with the new() operator because I dont want to create a new blueprint of the form I want to be able to edit the current form.
The above code doesn't work though, I can't even find Application. Is that even C# syntax?
If I can get the above code to work, I think I can resolve my issue and finally lay this problem to rest after a couple of HOURS of seeking for answers.
FINAL EDIT:
I figured it out thanks to one of the users below. Here is my updated code:
Main Form Code:
using System;
using System.Drawing;
using System.Collections;
using System.ComponentModel;
using System.Windows.Forms;
using System.Data;
using System.IO;
using System.Data.OleDb;
using System.Collections.Specialized;
using System.Text;
using System.Threading;

delegate void logAdd(string message);

namespace LCR_ShepherdStaffupdater_1._0
{
    public partial class Main : Form
    {
        private static Main mainFormForLogging;
        public static Main MainFormForLogging
        {
            get
            {
                return mainFormForLogging;
            }
        }

        public Main()
        {
            InitializeComponent();
            if (mainFormForLogging == null)
            {
                mainFormForLogging = this;
            }
        }

        public void add(string message)
        {
            this.Log.Items.Add(message);
        }
        public void logAdd(string message)
        {
            this.Log.BeginInvoke(new logAdd(add), new object[] { message });
        }

        private void exitProgramToolStripMenuItem_Click(object sender, EventArgs e) 
        {
            Application.Exit(); 
        }
        private void aboutToolStripMenuItem1_Click(object sender, EventArgs e)
        {
            Form aboutBox = new AboutBox1(); 
            aboutBox.ShowDialog(); 
        }

        private void settingsToolStripMenuItem_Click(object sender, EventArgs e)
        {
        }

        private void settingsToolStripMenuItem1_Click(object sender, EventArgs e)
        {
            settingsForm.settings.ShowDialog();
        }

        private void synchronize_Click(object sender, EventArgs e)
        {
            add(""test"");
            Logging.updateLog(""testthisone"");
            //DatabaseHandling.createDataSet();
        }

    }

    public class settingsForm 
    {
        public static Form settings = new Settings();
    }

}

Logging Class Code:
using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;

namespace LCR_ShepherdStaffupdater_1._0
{
    public class Logging
    {

        static Main mainClass = Main.MainFormForLogging;
        static logAdd logAddDelegate;

        public static void updateLog(string message)
        {
            logAddDelegate = mainClass.logAdd;
            logAddDelegate(message);
        }
    }
}

",<c#><delegates><invoke><handle><runtime-error>,8,"c#,delegates,invoke,handle,runtime-error",['c compile error invoke or begininvoke cannot be called on a control until the window handle has been created'],"['i just posted a question about how to get a delegate to update a textbox on another form', 'just when i thought i had the answer using invokethis happens', 'here is my code main form code using system using systemdrawing using systemcollections using systemcomponentmodel using systemwindowsforms using systemdata using systemio using systemdataoledb using systemcollectionsspecialized using systemtext using systemthreading delegate void logaddstring message namespace lcrshepherdstaffupdater10 public partial class main form public main initializecomponent public void addstring message thislogitemsaddmessage public void logaddstring message compiler error below thisinvokenew logaddadd new object message compile error occurs here compiler error above private void exitprogramtoolstripmenuitemclickobject sender eventargs e applicationexit private void abouttoolstripmenuitem1clickobject sender eventargs e form aboutbox new aboutbox1 aboutboxshowdialog private void settingstoolstripmenuitemclickobject sender eventargs e private void settingstoolstripmenuitem1clickobject sender eventargs e settingsformsettingsshowdialog private void synchronizeclickobject sender eventargs e string message here my message is changed this errorloggingupdatelogmessage changed this public class settingsform public static form settings new settings logging class code using system using systemcollectionsgeneric using systemlinq using systemtext namespace lcrshepherdstaffupdater10 public class logging static main mainclass new main static logadd logadddelegate public static void updatelogstring message logadddelegate mainclasslogadd logadddelegatemessage compile error invalidoperationexception was unhandled invoke or begininvoke cannot be called on a control until the window handle has been created', 'i already tried to create a handle on the log itembut that didnt work', 'the problem is i have no clue what i am doing and i have searched google extensively only to find vague answers', 'please tell me how to create the handle before i invoke this delegate', 'while you are at it give me some ways i can make this code more simple', 'for example i dont want two add functions i had to do that because there was no way for me to find an item to invoke from the logging class', 'is there a better way to accomplish what i need to do', 'thank you', 'edit my project is fairly large but these are the only items causing this specific problem', 'log is my richtextbox1 logitemsaddmessage i renamed it to log so it is easier to retype', 'i am calling updatelogmessage from a different form thoughlet me update that in here although it makes no difference where i call updatelogmessage from it still gives me this error you guys are going to have to make things more simpler for meand provide examples', 'i dont understand half of everything you guys are saying herei have no clue on how to work with invoking of methods and handles', 'ive researched the crap out of it too second edit i believe i have located the problem but do not know how to fix it', 'in my logging class i use this code to create mainclass static main mainclass new main i am creating a entirely new blueprint replica to main including log the richtextbox i am trying to update when i call updatelogmessage i believe i am trying to update the log richtextbox on the second entity of main otherwise known as mainclass', 'of course doing so will throw me this exception because i havent even seen that replica of the current main i am using', 'this is what i am shooting for thanks to one of the people that gave an answer main mainclass applicationopenformsoftypemainfirst logadddelegate mainclasslogadd logadddelegatemessage i need to create mainclass not with the new operator because i dont want to create a new blueprint of the form i want to be able to edit the current form', 'the above code doesnt work though i cant even find application', 'is that even c syntax', 'if i can get the above code to work i think i can resolve my issue and finally lay this problem to rest after a couple of hours of seeking for answers', 'final edit i figured it out thanks to one of the users below', 'here is my updated code main form code using system using systemdrawing using systemcollections using systemcomponentmodel using systemwindowsforms using systemdata using systemio using systemdataoledb using systemcollectionsspecialized using systemtext using systemthreading delegate void logaddstring message namespace lcrshepherdstaffupdater10 public partial class main form private static main mainformforlogging public static main mainformforlogging get return mainformforlogging public main initializecomponent if mainformforlogging null mainformforlogging this public void addstring message thislogitemsaddmessage public void logaddstring message thislogbegininvokenew logaddadd new object message private void exitprogramtoolstripmenuitemclickobject sender eventargs e applicationexit private void abouttoolstripmenuitem1clickobject sender eventargs e form aboutbox new aboutbox1 aboutboxshowdialog private void settingstoolstripmenuitemclickobject sender eventargs e private void settingstoolstripmenuitem1clickobject sender eventargs e settingsformsettingsshowdialog private void synchronizeclickobject sender eventargs e addtest loggingupdatelogtestthisone databasehandlingcreatedataset public class settingsform public static form settings new settings logging class code using system using systemcollectionsgeneric using systemlinq using systemtext namespace lcrshepherdstaffupdater10 public class logging static main mainclass mainmainformforlogging static logadd logadddelegate public static void updatelogstring message logadddelegate mainclasslogadd logadddelegatemessage ']"
Does the C++ standard guarantee that a failed insertion into an associative container will not modify the rvalue-reference argument?,"#include <set>
#include <string>
#include <cassert>

using namespace std::literals;

int main()
{
    auto coll = std::set{ ""hello""s };
    auto s = ""hello""s;
    coll.insert(std::move(s));
    assert(""hello""s == s); // Always OK?
}

Does the C++ standard guarantee that a failed insertion into an associative container will not modify the rvalue-reference argument?
",<c++><stl><language-lawyer><rvalue-reference><pass-by-rvalue-reference>,33,"c++,stl,language-lawyer,rvalue-reference,pass-by-rvalue-reference",['does the c standard guarantee that a failed insertion into an associative container will not modify the rvaluereference argument'],"['include set include string include cassert using namespace stdliterals int main auto coll stdset hellos auto s hellos collinsertstdmoves asserthellos s always ok ', 'does the c standard guarantee that a failed insertion into an associative container will not modify the rvaluereference argument']"
Android studio 1.5.1: Could not find property 'vectorDrawables',"I'm using Android Studio 1.5.1, Gradle 2.8 and my project min sdk vserion:14, target sdk version: 23. 
So, When I add vectorDrawables to configuration by documentation Google: Added VectorDrawable support library, I get following error:
Error:(13, 0) Could not find property 'vectorDrawables' on ProductFlavor_Decorated{name=main, dimension=null, minSdkVersion=ApiVersionImpl{mApiLevel=14, mCodename='null'}, targetSdkVersion=ApiVersionImpl{mApiLevel=23, mCodename='null'}, renderscriptTargetApi=null, renderscriptSupportModeEnabled=null, renderscriptNdkModeEnabled=null, versionCode=25, versionName=1.0.25, applicationId=com.smsoft.alibaba, testApplicationId=null, testInstrumentationRunner=null, testInstrumentationRunnerArguments={}, testHandleProfiling=null, testFunctionalTest=null, signingConfig=null, resConfig=null, mBuildConfigFields={}, mResValues={}, mProguardFiles=[], mConsumerProguardFiles=[], mManifestPlaceholders={}}.

this is my build.gradle file:
apply plugin: 'com.android.application'

android {
    compileSdkVersion 23
    buildToolsVersion ""23.0.2""

    defaultConfig {
        applicationId ""com.smsoft.alibaba""
        minSdkVersion 14
        targetSdkVersion 23
        versionCode 25
        versionName ""1.0.25""
        vectorDrawables.useSupportLibrary = true
    }
    buildTypes {
        release {
            minifyEnabled false
            proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro'
        }
    }
}

dependencies {
     compile fileTree(dir: 'libs', include: ['*.jar'])
     testCompile 'junit:junit:4.12'
     compile 'com.android.support:appcompat-v7:23.2.0'
     compile 'com.android.support:design:23.2.0'
     compile 'com.android.support:support-v4:23.2.0'
     compile 'com.android.support:cardview-v7:23.2.0'
}

Anybody know how to fix this problem ?
EDIT
Thanks to @Gabriele Mariotti to signal for my confused between gradle and gradle plugin. I'm confused when reading the addition of Compact Vector Drawables instructions.
",<android><android-studio><gradle><android-support-library><android-vectordrawable>,7,"android,android-studio,gradle,android-support-library,android-vectordrawable",['android studio 151 could not find property vectordrawables'],"['im using android studio 151 gradle 28 and my project min sdk vserion14 target sdk version 23 so when i add vectordrawables to configuration by documentation google added vectordrawable support library i get following error error13 0 could not find property vectordrawables on productflavordecoratednamemain dimensionnull minsdkversionapiversionimplmapilevel14 mcodenamenull targetsdkversionapiversionimplmapilevel23 mcodenamenull renderscripttargetapinull renderscriptsupportmodeenablednull renderscriptndkmodeenablednull versioncode25 versionname1025 applicationidcomsmsoftalibaba testapplicationidnull testinstrumentationrunnernull testinstrumentationrunnerarguments testhandleprofilingnull testfunctionaltestnull signingconfignull resconfignull mbuildconfigfields mresvalues mproguardfiles mconsumerproguardfiles mmanifestplaceholders', 'this is my buildgradle file apply plugin comandroidapplication android compilesdkversion 23 buildtoolsversion 2302 defaultconfig applicationid comsmsoftalibaba minsdkversion 14 targetsdkversion 23 versioncode 25 versionname 1025 vectordrawablesusesupportlibrary true buildtypes release minifyenabled false proguardfiles getdefaultproguardfileproguardandroidtxt proguardrulespro dependencies compile filetreedir libs include jar testcompile junitjunit412 compile comandroidsupportappcompatv72320 compile comandroidsupportdesign2320 compile comandroidsupportsupportv42320 compile comandroidsupportcardviewv72320 anybody know how to fix this problem ', 'edit thanks to gabriele mariotti to signal for my confused between gradle and gradle plugin', 'im confused when reading the addition of compact vector drawables instructions']"
AR with iOS: putting a light in the scene makes everything black?,"Ok, I am trying desperately to achieve this sort of warm lighting on my objects when added to my ARScene in Swift/Xcode - warm lighting and little glowing lights around:

To be clear, I do NOT want the objects I add to my scene to look like they belong in the surrounding room. I want them to stand out/ look warm and glow.All the tutorials on ARKit teach you how to mimic the lighting of the actual room.
Xcode has several lighting options, pulling from the surroundings gathered by the camera because with:
if let lightEstimate = session.currentFrame?.lightEstimate

I can print out the warmth, intensity, etc. And I also have these properties currently set to match the light of room:
sceneView.automaticallyUpdatesLighting = true
extension ARSCNView {

    func setup() { //SCENE SETUP
        antialiasingMode = .multisampling4X
        autoenablesDefaultLighting = true
        preferredFramesPerSecond = 60
        contentScaleFactor = 1.3

        if let camera = pointOfView?.camera {
            camera.wantsHDR = true
            camera.wantsExposureAdaptation = true
            camera.exposureOffset = -1
            camera.minimumExposure = -1
            camera.maximumExposure = 3
        }
    }
}

I have tried upping the emission on my object's textures and everything but nothing achieves the effect. Adding a light just turns the objects black/no color.
What is wrong here?
",<swift><xcode><augmented-reality><arkit><lighting>,5,"swift,xcode,augmented-reality,arkit,lighting",['ar with ios putting a light in the scene makes everything black'],"['ok i am trying desperately to achieve this sort of warm lighting on my objects when added to my arscene in swiftxcode warm lighting and little glowing lights around to be clear i do not want the objects i add to my scene to look like they belong in the surrounding room', 'i want them to stand out look warm and glowall the tutorials on arkit teach you how to mimic the lighting of the actual room', 'xcode has several lighting options pulling from the surroundings gathered by the camera because with if let lightestimate sessioncurrentframelightestimate i can print out the warmth intensity etc', 'and i also have these properties currently set to match the light of room sceneviewautomaticallyupdateslighting true extension arscnview func setup scene setup antialiasingmode multisampling4x autoenablesdefaultlighting true preferredframespersecond 60 contentscalefactor 13 if let camera pointofviewcamera camerawantshdr true camerawantsexposureadaptation true cameraexposureoffset 1 cameraminimumexposure 1 cameramaximumexposure 3 i have tried upping the emission on my objects textures and everything but nothing achieves the effect', 'adding a light just turns the objects blackno color', 'what is wrong here']"
ASP.NET Ajax Error: Sys.WebForms.PageRequestManagerParserErrorException,"My website has been giving me intermittent errors when trying to perform any Ajax activities.  The message I get is
Sys.WebForms.PageRequestManagerParserErrorException: The message received from the server could not be parsed. Common causes for this error are when the response is modified by calls to Response.Write(), response filters, HttpModules, or server trace is enabled.

Details: Error parsing near '

<!DOCTYPE html P'.

So its obviously some sort of server timeout or the server's just returning back mangled garbage.  This generally, unfortunately not always, happe
",<javascript><asp.net><.net><exception><ajax.net>,26,"javascript,asp.net,.net,exception,ajax.net",['aspnet ajax error syswebformspagerequestmanagerparsererrorexception'],"['my website has been giving me intermittent errors when trying to perform any ajax activities', 'the message i get is syswebformspagerequestmanagerparsererrorexception the message received from the server could not be parsed', 'common causes for this error are when the response is modified by calls to responsewrite response filters httpmodules or server trace is enabled', 'details error parsing near doctype html p', 'so its obviously some sort of server timeout or the servers just returning back mangled garbage', 'this generally unfortunately not always happe']"
Unlisted App in Stores,"Is it possible to publish an iOS App in App Store and Google Play Store, which is unlisted and can't be found by search? Only people, who have the link to the App in the Store can download it. Is this possible?
",<android><ios><google-play><app-store><app-store-connect>,7,"android,ios,google-play,app-store,app-store-connect",['unlisted app in stores'],"['is it possible to publish an ios app in app store and google play store which is unlisted and cant be found by search', 'only people who have the link to the app in the store can download it', 'is this possible']"
"How to store the active status of a Task, and maintain permanency of a List of these Tasks","I am trying to accurately learn the status of Tasks that are kicked off by a QueueBackgroundWorkerItem thread.  I can access the Task object and add them to a List of my TaskModels, and send that list object to my View.
My view only ever shows one one Task status, no matter how many times I click the QueueWorkItem link, and start a new task.  I'd like to figure out a couple of things:

How, in MVC, do I keep a live List of how many tasks I generated?  I assumed by sending the model to the view I would assure some permanency.  
Once I can do that, I assume I would be able to store the Task objects in my List.  However, even in this example below, I still don't seem to be able to know what the Status of the Task is at any given time (it seems I can only know what it is at the time of adding it to my list).

I am hoping someone has done something similar and can help with this.
Thanks!
-Jason
EDIT: The core requirements of this setup are:

I need to use a QueueBackgroundWorkerItem to run a long job even if the browser gets closed
I chose to embed a Task so I could learn the ongoing status of each job run.  I understand that with the QBWI, that running a task would be overkill.  But I could find no other way to know what the status of the QBWI is at any time.

CONTROLLER:
List<TaskModel> taskModelList = new List<TaskModel>();

public ActionResult QueueWorkItem()
{
    Task task;
    ViewBag.Message = ""State: "";
    String printPath = @""C:\Work\QueueBackgroundWorkerItemPractice\QueueBackgroundWorkerItemPractice\WorkerPrintFile"" + DateTime.Now.ToLongTimeString().ToString().Replace("":"", ""_"") + "".txt"";
    System.Web.Hosting.HostingEnvironment.QueueBackgroundWorkItem(cancellationToken =>
    {
        task = Task.Run(() =>
        {
            string filePath = printPath;
            string text = ""File line "";
            if (!System.IO.File.Exists(filePath))
            {
                using (var stream = System.IO.File.Create(filePath)) { }
            }
            TextWriter tw = new StreamWriter(printPath);

            for (int i = 0; i < 400; i++)
            {
                text = ""Line "" + i;

                tw.WriteLine(text);

                Thread.Sleep(200);
            }

            tw.Close();
        });

        var c = task.ContinueWith((antecedent) =>
        {

            taskModelList.Add(new TaskModel(task));

        });

    });

    return View(taskModelList);
}

VIEW:
@model List<QueueBackgroundWorkerItemPractice.Models.TaskModel>

@{
    ViewBag.Title = ""Queue Background Worker"";
}
<h2>@ViewBag.Title.</h2>
<h3>@ViewBag.Message<span id=""modelClass""></span></h3>

<p>Use this area to provide additional information.</p>

@{ 
    <ul>
        @foreach (var taskModel in Model)
        {
            <li>@taskModel.Status</li>
        }
    </ul>
}

EDIT, solution:
Following Raffaeu's advice, and the following compromises, I was able to find it as such:

We are only running one task at any given time.  I don't need a list
I don't truly need the status on-demand.  I only need to know when it's completed

I wanted to be able to leverage the Task ID to instantiate the task later from the ID.  That proved to involve more overhead than necessary.
Instead I found the feature Task.CompletedTask (available in .NET 4.6 and up).  This, used in async, allowed me to get the status of the Task when it is complete.  Voila.  Thanks to everyone for your suggestions.
The best part - this long-running task will complete whether I close the browser...or stop IIS.  Miraculous.
public ActionResult QueueWorkItem()
{
    System.Web.Hosting.HostingEnvironment.QueueBackgroundWorkItem(cancellationToken =>
    {
        task = Task.Run(async () =>
        {
            String printPath = @""C:..."";
            string filePath = printPath;
            string text = ""File line "";
            if (!System.IO.File.Exists(filePath))
            {
                using (var stream = System.IO.File.Create(filePath)) { }
            }
            TextWriter tw = new StreamWriter(printPath);

            for (int i = 0; i < 400; i++)
            {
                text = ""Line "" + i;

                tw.WriteLine(text);

                Thread.Sleep(200);
            }

            tw.Close();
            await Task.CompletedTask;
        });

        var c = task.ContinueWith((antecedent) =>
        {
            taskID = task.Id;
            status = task.Status.ToString();

            try
            {
                string connString = WebConfigurationManager.ConnectionStrings[""TaskContext""].ToString();
                sqlCommand.CommandText = ""INSERT INTO dbo.TaskTable (TaskId, Status) VALUES ("" + taskID + "", '"" + status + ""')"";
                conn.ConnectionString = connString;
                sqlCommand.Connection = conn;
                conn.Open();
                sqlCommand.ExecuteNonQuery();
            }
            catch (Exception ex)
            {
                String info = ex.Message + ex.ToString() + ex.StackTrace;

                throw new Exception(""SQL Issue"" + info);
            }
            finally
            {
                if (conn != null)
                {
                    conn.Close();
                    conn = null;
                }
                sqlCommand = null;
            }


        });

    });

    return View();
}

",<c#><asp.net><iis><task><session-variables>,7,"c#,asp.net,iis,task,session-variables",['how to store the active status of a task and maintain permanency of a list of these tasks'],"['i am trying to accurately learn the status of tasks that are kicked off by a queuebackgroundworkeritem thread', 'i can access the task object and add them to a list of my taskmodels and send that list object to my view', 'my view only ever shows one one task status no matter how many times i click the queueworkitem link and start a new task', 'id like to figure out a couple of things how in mvc do i keep a live list of how many tasks i generated', 'i assumed by sending the model to the view i would assure some permanency', 'once i can do that i assume i would be able to store the task objects in my list', 'however even in this example below i still dont seem to be able to know what the status of the task is at any given time it seems i can only know what it is at the time of adding it to my list', 'i am hoping someone has done something similar and can help with this', 'thanks', 'jason edit the core requirements of this setup are i need to use a queuebackgroundworkeritem to run a long job even if the browser gets closed i chose to embed a task so i could learn the ongoing status of each job run', 'i understand that with the qbwi that running a task would be overkill', 'but i could find no other way to know what the status of the qbwi is at any time', 'controller listtaskmodel taskmodellist new listtaskmodel public actionresult queueworkitem task task viewbagmessage state string printpath cworkqueuebackgroundworkeritempracticequeuebackgroundworkeritempracticeworkerprintfile datetimenowtolongtimestringtostringreplace txt systemwebhostinghostingenvironmentqueuebackgroundworkitemcancellationtoken task taskrun string filepath printpath string text file line if systemiofileexistsfilepath using var stream systemiofilecreatefilepath textwriter tw new streamwriterprintpath for int i 0 i 400 i text line i twwritelinetext threadsleep200 twclose var c taskcontinuewithantecedent taskmodellistaddnew taskmodeltask return viewtaskmodellist view model listqueuebackgroundworkeritempracticemodelstaskmodel viewbagtitle queue background worker h2viewbagtitleh2 h3viewbagmessagespan idmodelclassspanh3 puse this area to provide additional informationp ul foreach var taskmodel in model litaskmodelstatusli ul edit solution following raffaeus advice and the following compromises i was able to find it as such we are only running one task at any given time', 'i dont need a list i dont truly need the status ondemand', 'i only need to know when its completed i wanted to be able to leverage the task id to instantiate the task later from the id', 'that proved to involve more overhead than necessary', 'instead i found the feature taskcompletedtask available in net 46 and up', 'this used in async allowed me to get the status of the task when it is complete', 'voila', 'thanks to everyone for your suggestions', 'the best part this longrunning task will complete whether i close the browseror stop iis', 'miraculous', 'public actionresult queueworkitem systemwebhostinghostingenvironmentqueuebackgroundworkitemcancellationtoken task taskrunasync string printpath c string filepath printpath string text file line if systemiofileexistsfilepath using var stream systemiofilecreatefilepath textwriter tw new streamwriterprintpath for int i 0 i 400 i text line i twwritelinetext threadsleep200 twclose await taskcompletedtask var c taskcontinuewithantecedent taskid taskid status taskstatustostring try string connstring webconfigurationmanagerconnectionstringstaskcontexttostring sqlcommandcommandtext insert into dbotasktable taskid status values taskid status connconnectionstring connstring sqlcommandconnection conn connopen sqlcommandexecutenonquery catch exception ex string info exmessage extostring exstacktrace throw new exceptionsql issue info finally if conn null connclose conn null sqlcommand null return view ']"
selenium.common.exceptions.ElementClickInterceptedException: Message: element click intercepted: Element is not clickable with Selenium and Python,"I am currently working on a project which fills a form automatically. And the next button appears when the form is filled, that's why it gives me an error. 
I have tried:
WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH,""//input[@type='button' and @class='button']"")))
Next = driver.find_element_by_xpath(""//input[@type='button' and @class='button']"")
Next.click()

HTML:
<span class=""btn"">
    <input type=""button"" value=""Next"" class=""button"" payoneer=""Button"" data-controltovalidate=""PersonalDetails"" data-onfieldsvalidation=""ToggleNextButton"" data-onclick=""UpdateServerWithCurrentSection();"" id=""PersonalDetailsButton"">
     </input>
     <div class=""clearfix""></div>
</span>

ERROR:

selenium.common.exceptions.ElementClickInterceptedException: Message:
  element click intercepted: Element  is not clickable at point (203, 530).
  Other element would receive the click: ...   (Session info: chrome=76.0.3809.132)

",<python><selenium><xpath><css-selectors><webdriverwait>,23,"python,selenium,xpath,css-selectors,webdriverwait",['seleniumcommonexceptionselementclickinterceptedexception message element click intercepted element is not clickable with selenium and python'],"['i am currently working on a project which fills a form automatically', 'and the next button appears when the form is filled thats why it gives me an error', 'i have tried webdriverwaitdriver 10untilecelementtobeclickablebyxpathinputtypebutton and classbutton next driverfindelementbyxpathinputtypebutton and classbutton nextclick html span classbtn input typebutton valuenext classbutton payoneerbutton datacontroltovalidatepersonaldetails dataonfieldsvalidationtogglenextbutton dataonclickupdateserverwithcurrentsection idpersonaldetailsbutton input div classclearfixdiv span error seleniumcommonexceptionselementclickinterceptedexception message element click intercepted element is not clickable at point 203 530', 'other element would receive the click session info chrome7603809132']"
Mock authentication decorator in unittesting,"I wanted to mock validate_token decorator while writing unit test for one of view
#views.py
from third_part.module import vaidate_token
from setting import config
class myViews:
     @validate_token([config['issuer'], config['secret_key']])
     def get_data():
         #Do stuff
         return json.loads(data)

Here validate_token is a thirtd_party module to authorize request and the token is issued by third party so I don't want execute validate_token decorator for my tests 
below are my sample test code. 
test_views.py
@patch('views.validate_token', lambda x: x)
def test_get_data(self):
    endpoint = '/app/get_data'
    res = self.client.get(endpoint)
    assert res.status_code==200

I tried to mock while running tests
But its not working as expected, , its giving 401 error. 
how can I mock/patch decorator for tests
anything am missing here
Thanks in advance.
",<python><unit-testing><flask><mocking><pytest>,9,"python,unit-testing,flask,mocking,pytest",['mock authentication decorator in unittesting'],"['i wanted to mock validatetoken decorator while writing unit test for one of view viewspy from thirdpartmodule import vaidatetoken from setting import config class myviews validatetokenconfigissuer configsecretkey def getdata do stuff return jsonloadsdata here validatetoken is a thirtdparty module to authorize request and the token is issued by third party so i dont want execute validatetoken decorator for my tests below are my sample test code', 'testviewspy patchviewsvalidatetoken lambda x x def testgetdataself endpoint appgetdata res selfclientgetendpoint assert resstatuscode200 i tried to mock while running tests but its not working as expected its giving 401 error', 'how can i mockpatch decorator for tests anything am missing here thanks in advance']"
use draggable divs with jqueryUI sortable and bootstrap (cursor take distance from divs in col-xs-6),"I want to make a draggable divs with jquery UI and bootstrap like this fiddle but when I want to drag third divs at the end it takes distance from cursor.
$(function() {
    $( "".columns"" ).sortable({
    });
});

",<jquery><html><css><twitter-bootstrap><jquery-ui>,5,"jquery,html,css,twitter-bootstrap,jquery-ui",['use draggable divs with jqueryui sortable and bootstrap cursor take distance from divs in colxs6'],"['i want to make a draggable divs with jquery ui and bootstrap like this fiddle but when i want to drag third divs at the end it takes distance from cursor', 'function columns sortable ']"
"In hibernate how to programmatically set the isolation level of a transaction, or how to create two transactions with different isolation levels","I'm using hibernate 3.6 with MSSQL 2005, 2008, 2012.
I would like to set the isolation level of a transaction created by the session, but I can't find any information about in.
This is my code
   Session sess = factory.openSession();
   Transaction tx = null;
   try {
       tx = sess.beginTransaction();

       // do some work
       ...

       tx.commit();
   }
   catch (RuntimeException e) {
       if (tx != null) tx.rollback();
       throw e; // or display error message
   }
   finally {
       sess.close();
   }

I would like an to do something like that
   sess.beginTransaction(1|2|4|8);

Is that possible?
Thank you.
",<java><sql-server><hibernate><transactions><isolation-level>,7,"java,sql-server,hibernate,transactions,isolation-level",['in hibernate how to programmatically set the isolation level of a transaction or how to create two transactions with different isolation levels'],"['im using hibernate 36 with mssql 2005 2008 2012 i would like to set the isolation level of a transaction created by the session but i cant find any information about in', 'this is my code session sess factoryopensession transaction tx null try tx sessbegintransaction do some work txcommit catch runtimeexception e if tx null txrollback throw e or display error message finally sessclose i would like an to do something like that sessbegintransaction1248 is that possible', 'thank you']"
Android Gradle Plugin 3.5.1 databinding error with Kotiln Generic type,"I am in the middle of trying to modularize a library so tbh anything could be going on here. After updating from the Android Gradle Plugin 3.5.0 to 3.5.1, I now get a databinding error on a layout which uses my Resource.kt class. The class I believe was lifted straight out of the Google Github Browser sample (I can't get the latest commit of that to build at all for some reason). The error seems to be specifically with the generic data field T.
Resource.kt
data class Resource<out T>(val status: Status, val data: T?, val message: String?, val throwable: Throwable? = null) {
    companion object {
        fun <T> success(data: T?): Resource<T> {
            return Resource(SUCCESS, data, null)
        }

        fun <T> error(data: T?, msg: String, throwable: Throwable?): Resource<T> {
            return Resource(ERROR, data, msg, throwable)
        }

        fun <T> loading(data: T?): Resource<T> {
            return Resource(LOADING, data, null)
        }
    }
}

Layout xml:
<layout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:app=""http://schemas.android.com/apk/res-auto""
    xmlns:tools=""http://schemas.android.com/tools"">

    <data>

        <import type=""android.view.View"" />

        <import type=""core.sdk.data.remote.response.Resource"" />

        <import type=""core.sdk.data.remote.response.Status"" />

        <variable
            name=""resource""
            type=""Resource"" />

        <variable
            name=""progressText""
            type=""String"" />
    </data>

    <LinearLayout
        android:id=""@+id/circular_progress""
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:layout_gravity=""center""
        android:gravity=""center""
        android:orientation=""vertical""
        app:visibleGone=""@{resource.data == null}"">

        <androidx.core.widget.ContentLoadingProgressBar
            android:id=""@+id/progress_bar""
            style=""@style/Widget.AppCompat.ProgressBar""
            android:layout_width=""wrap_content""
            android:layout_height=""wrap_content""
            android:indeterminateTint=""@color/ll_secondary""
            android:indeterminateTintMode=""src_in""
            app:visibleGone=""@{resource.status == Status.LOADING}""
            tools:ignore=""UnusedAttribute"" />

        <TextView
            android:id=""@+id/progress_text_view""
            android:layout_width=""match_parent""
            android:layout_height=""wrap_content""
            android:gravity=""center_horizontal""
            android:text=""@{progressText}""
            android:textAppearance=""?attr/textAppearanceHeadline5""
            android:textColor=""@color/ll_secondary""
            android:textStyle=""italic""
            app:visibleGone=""@{resource.status == Status.LOADING}""
            tools:text=""loading..."" />
    </LinearLayout>

</layout>

Error:
LoadingStateBindingImpl.java:106: error: ';' expected
        ? resourceData = null;

I have incremental databinding and kapt on:
android.databinding.incremental=true
kapt.incremental.apt=true

Project is a fully Kotlin using Kotlin 1.3.50 with a jvm target of 1.8:
compileOptions {
    sourceCompatibility JavaVersion.VERSION_1_8
    targetCompatibility JavaVersion.VERSION_1_8
}

kotlinOptions {
    jvmTarget = ""1.8""
}

This error does not appear with AGP 3.5.0. Here is the same file with 3.5.0 and no error:

",<android><kotlin><android-gradle-plugin><android-databinding><android-studio-3.5.1>,5,"android,kotlin,android-gradle-plugin,android-databinding,android-studio-3.5.1",['android gradle plugin 351 databinding error with kotiln generic type'],"['i am in the middle of trying to modularize a library so tbh anything could be going on here', 'after updating from the android gradle plugin 350 to 351 i now get a databinding error on a layout which uses my resourcekt class', 'the class i believe was lifted straight out of the google github browser sample i cant get the latest commit of that to build at all for some reason', 'the error seems to be specifically with the generic data field t resourcekt data class resourceout tval status status val data t val message string val throwable throwable', ' null companion object fun t successdata t', ' resourcet return resourcesuccess data null fun t errordata t msg string throwable throwable', ' resourcet return resourceerror data msg throwable fun t loadingdata t', ' resourcet return resourceloading data null layout xml layout xmlnsandroid xmlnsapp xmlnstools data import typeandroidviewview import typecoresdkdataremoteresponseresource import typecoresdkdataremoteresponsestatus variable nameresource typeresource variable nameprogresstext typestring data linearlayout androidididcircularprogress androidlayoutwidthmatchparent androidlayoutheightmatchparent androidlayoutgravitycenter androidgravitycenter androidorientationvertical appvisiblegoneresourcedata null androidxcorewidgetcontentloadingprogressbar androidididprogressbar stylestylewidgetappcompatprogressbar androidlayoutwidthwrapcontent androidlayoutheightwrapcontent androidindeterminatetintcolorllsecondary androidindeterminatetintmodesrcin appvisiblegoneresourcestatus statusloading toolsignoreunusedattribute textview androidididprogresstextview androidlayoutwidthmatchparent androidlayoutheightwrapcontent androidgravitycenterhorizontal androidtextprogresstext androidtextappearanceattrtextappearanceheadline5 androidtextcolorcolorllsecondary androidtextstyleitalic appvisiblegoneresourcestatus statusloading toolstextloading linearlayout layout error loadingstatebindingimpljava106 error expected ', 'resourcedata null i have incremental databinding and kapt on androiddatabindingincrementaltrue kaptincrementalapttrue project is a fully kotlin using kotlin 1350 with a jvm target of 18 compileoptions sourcecompatibility javaversionversion18 targetcompatibility javaversionversion18 kotlinoptions jvmtarget 18 this error does not appear with agp 350 here is the same file with 350 and no error']"
What is the Jquery compatible version for Bootstrap 4.0.0,"Please suggest the compatible version of jquery to be used with Bootstrap version 4.0.0
Also just for knowledge,  list out the versions of bootstrap and Jquery which works to together 
Any suggestions or reference
Thanks
",<jquery><twitter-bootstrap><user-interface><jquery-ui><bootstrap-4>,9,"jquery,twitter-bootstrap,user-interface,jquery-ui,bootstrap-4",['what is the jquery compatible version for bootstrap 400'],['please suggest the compatible version of jquery to be used with bootstrap version 400 also just for knowledge list out the versions of bootstrap and jquery which works to together any suggestions or reference thanks']
How do I handle an infinite list of IO objects in Haskell?,"I'm writing a program that reads from a list of files.  The each file either contains a link to the next file or marks that it's the end of the chain.
Being new to Haskell, it seemed like the idiomatic way to handle this is is a lazy list of possible files to this end, I have
getFirstFile :: String -> DataFile
getNextFile :: Maybe DataFile -> Maybe DataFile

loadFiles :: String -> [Maybe DataFile]
loadFiles = iterate getNextFile . Just . getFirstFile

getFiles :: String -> [DataFile]
getFiles = map fromJust . takeWhile isJust . loadFiles

So far, so good.  The only problem is that, since getFirstFile and getNextFile both need to open files, I need their results to be in the IO monad.  This gives the modified form of
getFirstFile :: String -> IO DataFile
getNextFile :: Maybe DataFile -> IO (Maybe DataFile)

loadFiles :: String -> [IO Maybe DataFile]
loadFiles = iterate (getNextFile =<<) . Just . getFirstFile

getFiles :: String -> IO [DataFile]
getFiles = liftM (map fromJust . takeWhile isJust) . sequence . loadFiles

The problem with this is that, since iterate returns an infinite list, sequence becomes an infinite loop.  I'm not sure how to proceed from here.  Is there a lazier form of sequence that won't hit all of the list elements?  Should I be rejiggering the map and takeWhile to be operating inside the IO monad for each list element?  Or do I need to drop the whole infinite list process and write a recursive function to terminate the list manually?
",<haskell><io><monads><infinite-loop><lazy-evaluation>,8,"haskell,io,monads,infinite-loop,lazy-evaluation",['how do i handle an infinite list of io objects in haskell'],"['im writing a program that reads from a list of files', 'the each file either contains a link to the next file or marks that its the end of the chain', 'being new to haskell it seemed like the idiomatic way to handle this is is a lazy list of possible files to this end i have getfirstfile string datafile getnextfile maybe datafile maybe datafile loadfiles string maybe datafile loadfiles iterate getnextfile ', 'just ', 'getfirstfile getfiles string datafile getfiles map fromjust ', 'takewhile isjust ', 'loadfiles so far so good', 'the only problem is that since getfirstfile and getnextfile both need to open files i need their results to be in the io monad', 'this gives the modified form of getfirstfile string io datafile getnextfile maybe datafile io maybe datafile loadfiles string io maybe datafile loadfiles iterate getnextfile ', 'just ', 'getfirstfile getfiles string io datafile getfiles liftm map fromjust ', 'takewhile isjust ', 'sequence ', 'loadfiles the problem with this is that since iterate returns an infinite list sequence becomes an infinite loop', 'im not sure how to proceed from here', 'is there a lazier form of sequence that wont hit all of the list elements', 'should i be rejiggering the map and takewhile to be operating inside the io monad for each list element', 'or do i need to drop the whole infinite list process and write a recursive function to terminate the list manually']"
Best approach for SSO for Asp.Net application with Login from external application with multiple ADFS,"I have an already built Asp.Net application which is using Asp.Net membership provider.
There is a client web application which has its own login. Once logged in, the user gets some links. These links are directed to the application I have developed. Currently since these are two different applications hosted in two domains, there are two time login required.
What I am trying to achieve is have SSO and not have to login when the user is already logged in the client application. I have read through and seems its possible to have this done via a STS provider like ThinkTecture IdentityServer and utlising ADFS  at our end.
Is this the best approach and if yes, I couldn't find much of documentation with respect to what are the updates I need to ask from the main application team to have it SSO enabled. 
",<asp.net><single-sign-on><wif><claims-based-identity><federated-identity>,14,"asp.net,single-sign-on,wif,claims-based-identity,federated-identity",['best approach for sso for aspnet application with login from external application with multiple adfs'],"['i have an already built aspnet application which is using aspnet membership provider', 'there is a client web application which has its own login', 'once logged in the user gets some links', 'these links are directed to the application i have developed', 'currently since these are two different applications hosted in two domains there are two time login required', 'what i am trying to achieve is have sso and not have to login when the user is already logged in the client application', 'i have read through and seems its possible to have this done via a sts provider like thinktecture identityserver and utlising adfs at our end', 'is this the best approach and if yes i couldnt find much of documentation with respect to what are the updates i need to ask from the main application team to have it sso enabled']"
Race condition in JavaScript with compound assignment,"I'm not talking about complex race conditions involving the network or events. Rather, I seem to have found out that the += operator is not atomic in V8 (Chrome 58, or Node 8).
The code below aims to run two so-called threads in parallel. Each ""thread"" calls repeatedly a function that returns its number parameter after sleeping that many seconds. The results are summed up into an accumulator.


function sleep(ms) {
  return new Promise(resolve => setTimeout(resolve, ms));
}

// Return the passed number after sleeping that many seconds
async function n(c) {
  await sleep(c * 1000);
  console.log('End', c);
  return c;
}

let acc = 0;  // global

// Call n repeatedly and sum up results
async function nForever(c) {
  while (1) {
    console.log('Calling', c);
    acc += await n(c);  // += not atomic?!
    console.log('Acc', acc);
  }
}

(async function() {
  // parallel repeated calls
  nForever(1);
  nForever(5.3);  // .3 for sanity, to avoid overlap with 1 * 5
})();



The problem is that after ~5 seconds, I'd expect the accumulator to be 10.3 (5 times 1 + 1 times 5.3). However, it's 5.3!

",<javascript><node.js><multithreading><asynchronous><async-await>,10,"javascript,node.js,multithreading,asynchronous,async-await",['race condition in javascript with compound assignment'],"['im not talking about complex race conditions involving the network or events', 'rather i seem to have found out that the operator is not atomic in v8 chrome 58 or node 8', 'the code below aims to run two socalled threads in parallel', 'each thread calls repeatedly a function that returns its number parameter after sleeping that many seconds', 'the results are summed up into an accumulator', 'function sleepms return new promiseresolve settimeoutresolve ms return the passed number after sleeping that many seconds async function nc await sleepc 1000 consolelogend c return c let acc 0 global call n repeatedly and sum up results async function nforeverc while 1 consolelogcalling c acc await nc not atomic', 'consolelogacc acc async function parallel repeated calls nforever1 nforever53 3 for sanity to avoid overlap with 1 5 the problem is that after 5 seconds id expect the accumulator to be 103 5 times 1 1 times 53', 'however its 53']"
how to do horizontal scroll in ionic 3,"look at my  
I have 10 names in the ion-scroll but it is coming to the next line like a paragraph.
here is my .html code.
<ion-scroll scrollX=""true"" style=""width:100vw; height:50px"" >
        <ion-row class=""headerChip"">
          <div *ngFor=""let tabName of product_type; let idx = index"" [ngClass]=""showSelectedTabArray[idx].showSelectedTab ? 'headerChipGray' : 'headerChipGreen'"">
          <ion-chip  (click)=""changeData(tabName)"">
          <ion-label  >{{tabName.languagename}}</ion-label>
          <div></div>
          </ion-chip>
          </div>
        </ion-row>
      </ion-scroll>

here is my css
.headerChipGray{
    ion-chip.chip.chip-md{
        margin: 2px 2px 2px 2px;
        border-radius: 10px;
        border: 1px solid gray;
        background: white;
    }
    ion-chip.chip.chip-ios{
        margin: 2px 2px 2px 2px;
        border-radius: 10px;
        border: 1px solid gray;
        background: white;
    }
}

.headerChipGreen{

    ion-chip.chip.chip-md{
        margin: 2px 2px 2px 2px;
        border-radius: 10px;
        background: white;
        color: #A80C50;
        border: 1px solid #A80C50;
    }

    ion-chip.chip.chip-ios{
        margin: 2px 2px 2px 2px;
        border-radius: 10px;
        background: white;
        color: #A80C50;
        border: 1px solid #A80C50;
    }
}


this same piece of code used to work in ionic 2 after updating to ionic 3 i am facing this issue what i am missing ionic doc for ion-scroll

",<css><angular><scroll><ionic2><ionic3>,13,"css,angular,scroll,ionic2,ionic3",['how to do horizontal scroll in ionic 3'],"['look at my i have 10 names in the ionscroll but it is coming to the next line like a paragraph', 'here is my html code', 'ionscroll scrollxtrue stylewidth100vw height50px ionrow classheaderchip div ngforlet tabname of producttype let idx index ngclassshowselectedtabarrayidxshowselectedtab ', 'headerchipgray headerchipgreen ionchip clickchangedatatabname ionlabel tabnamelanguagenameionlabel divdiv ionchip div ionrow ionscroll here is my css headerchipgray ionchipchipchipmd margin 2px 2px 2px 2px borderradius 10px border 1px solid gray background white ionchipchipchipios margin 2px 2px 2px 2px borderradius 10px border 1px solid gray background white headerchipgreen ionchipchipchipmd margin 2px 2px 2px 2px borderradius 10px background white color a80c50 border 1px solid a80c50 ionchipchipchipios margin 2px 2px 2px 2px borderradius 10px background white color a80c50 border 1px solid a80c50 this same piece of code used to work in ionic 2 after updating to ionic 3 i am facing this issue what i am missing ionic doc for ionscroll']"
WebSocket connection to 'ws://localhost:4000/sockjs-node/612/2pdjfv15/websocket' failed: Connection closed before receiving a handshake response error,"I'M using Browser Sync with webpack-dev-server, And facing the issue while using browser sync..!! only form fill up is working, click, scroll is not working in browser sync, and there is no any compile time error occurring, But above things are not working..!! Here is my ""Webpack.dev.js"" file, So what is wrong over here..?
const helpers = require('./helpers');
const buildUtils = require('./build-utils');
const webpackMerge = require('webpack-merge'); 
const commonConfig = require('./webpack.common.js');

const LoaderOptionsPlugin = require('webpack/lib/LoaderOptionsPlugin');
const NamedModulesPlugin = require('webpack/lib/NamedModulesPlugin');
const EvalSourceMapDevToolPlugin = require('webpack/lib/EvalSourceMapDevToolPlugin');
const BrowserSyncPlugin = require('browser-sync-webpack-plugin');

module.exports = function (options) {
  const ENV = process.env.ENV = process.env.NODE_ENV = 'development';
  const HOST = process.env.HOST || 'localhost';
  const PORT = process.env.PORT || 3000;

  const METADATA = Object.assign({}, buildUtils.DEFAULT_METADATA, {
    host: HOST,
    port: PORT,
    ENV: ENV,
    HMR: helpers.hasProcessFlag('hot'),
    PUBLIC: process.env.PUBLIC_DEV || HOST + ':' + PORT
  });

  return webpackMerge(commonConfig({ env: ENV, metadata: METADATA  }), {

    output: {


      path: helpers.root('dist'),


      filename: '[name].bundle.js',


      sourceMapFilename: '[file].map',


      chunkFilename: '[id].chunk.js',

      library: 'ac_[name]',
      libraryTarget: 'var',
    },

    module: {

      rules: [


        {
          test: /\.css$/,
          use: ['style-loader', 'css-loader'],
          include: [helpers.root('src', 'styles')]
        },

        {
          test: /\.scss$/,
          use: ['style-loader', 'css-loader', 'sass-loader'],
          include: [helpers.root('src', 'styles')]
        },

      ]

    },

    plugins: [
      new EvalSourceMapDevToolPlugin({
        moduleFilenameTemplate: '[resource-path]',
        sourceRoot: 'webpack:///'
      }),


      new NamedModulesPlugin(),


      new LoaderOptionsPlugin({
        debug: true,
        options: { }
      }),

      new BrowserSyncPlugin({
        // browse to http://localhost:3000/ during development,
        host: 'localhost',
        port: 4000,
        proxy: 'http://localhost:3000'
      },
      {
        reload: false
      })
    ],

    devServer: {
      port: METADATA.port,
      host: METADATA.host,
      hot: METADATA.HMR,
      public: METADATA.PUBLIC,
      historyApiFallback: true,
      watchOptions: {

        ignored: /node_modules/
      },

      setup: function(app) {
        // For example, to define custom handlers for some paths:
        // app.get('/some/path', function(req, res) {
        //   res.json({ custom: 'response' });
        // });
      },
    },

    node: {
      global: true,
      crypto: 'empty',
      process: true,
      module: false,
      clearImmediate: false,
      setImmediate: false,
      fs: 'empty'
    }

  });
};

",<angular><webpack><websocket><webpack-dev-server><browser-sync>,26,"angular,webpack,websocket,webpack-dev-server,browser-sync",['websocket connection to wslocalhost4000sockjsnode6122pdjfv15websocket failed connection closed before receiving a handshake response error'],"['im using browser sync with webpackdevserver and facing the issue while using browser sync', 'only form fill up is working click scroll is not working in browser sync and there is no any compile time error occurring but above things are not working', 'here is my webpackdevjs file so what is wrong over here', 'const helpers requirehelpers const buildutils requirebuildutils const webpackmerge requirewebpackmerge const commonconfig requirewebpackcommonjs const loaderoptionsplugin requirewebpacklibloaderoptionsplugin const namedmodulesplugin requirewebpacklibnamedmodulesplugin const evalsourcemapdevtoolplugin requirewebpacklibevalsourcemapdevtoolplugin const browsersyncplugin requirebrowsersyncwebpackplugin moduleexports function options const env processenvenv processenvnodeenv development const host processenvhost localhost const port processenvport 3000 const metadata objectassign buildutilsdefaultmetadata host host port port env env hmr helpershasprocessflaghot public processenvpublicdev host port return webpackmergecommonconfig env env metadata metadata output path helpersrootdist filename namebundlejs sourcemapfilename filemap chunkfilename idchunkjs library acname librarytarget var module rules test css use styleloader cssloader include helpersrootsrc styles test scss use styleloader cssloader sassloader include helpersrootsrc styles plugins new evalsourcemapdevtoolplugin modulefilenametemplate resourcepath sourceroot webpack new namedmodulesplugin new loaderoptionsplugin debug true options new browsersyncplugin browse to during development host localhost port 4000 proxy reload false devserver port metadataport host metadatahost hot metadatahmr public metadatapublic historyapifallback true watchoptions ignored nodemodules setup functionapp for example to define custom handlers for some paths appgetsomepath functionreq res resjson custom response node global true crypto empty process true module false clearimmediate false setimmediate false fs empty ']"
How can I create an AI for tic tac toe in Python using ANN and genetic algorithm?,"I'm very interested in the field of machine learning and recently I got the idea for a project for the next few weeks. 
Basically I want to create an AI that can beat every human at Tic Tac Toe. The algorithm must be scalable for every n*n board size, and maybe even for other dimensions (for a 3D analogue of the game, for example). 
Also I don't want the algorithm to know anything of the game in advance: it must learn on its own. So no hardcoded ifs, and no supervisioned learning. 
My idea is to use an Artificial Neural Network for the main algorithm itself, and to train it through the use of a genetic algorithm. So I have to code only the rules of the game, and then each population, battling with itself, should learn from scratch. 
It's a big project, and I'm not an expert on this field, but I hope, with such an objective, to learn lots of things.

First of all, is that possible? I mean, is it possible to reach a good result within a reasonable amount of time?
Are there good libraries in Python that I can use for this project? And is Python a suitable language for this kind of project?

",<python><neural-network><artificial-intelligence><genetic-algorithm><tic-tac-toe>,6,"python,neural-network,artificial-intelligence,genetic-algorithm,tic-tac-toe",['how can i create an ai for tic tac toe in python using ann and genetic algorithm'],"['im very interested in the field of machine learning and recently i got the idea for a project for the next few weeks', 'basically i want to create an ai that can beat every human at tic tac toe', 'the algorithm must be scalable for every nn board size and maybe even for other dimensions for a 3d analogue of the game for example', 'also i dont want the algorithm to know anything of the game in advance it must learn on its own', 'so no hardcoded ifs and no supervisioned learning', 'my idea is to use an artificial neural network for the main algorithm itself and to train it through the use of a genetic algorithm', 'so i have to code only the rules of the game and then each population battling with itself should learn from scratch', 'its a big project and im not an expert on this field but i hope with such an objective to learn lots of things', 'first of all is that possible', 'i mean is it possible to reach a good result within a reasonable amount of time', 'are there good libraries in python that i can use for this project', 'and is python a suitable language for this kind of project']"
"Visual Studio 2015 target framework ""dotnet"" vs ""net452""","When creating a new Visual Studio 2015 class library (package) project, one is able to set multiple target frameworks.
What is the difference between dotnet and net452?
project.json:
""frameworks"": {
  ""dotnet"": { },
  ""net452"": {}
}

Project layout:

",<visual-studio><visual-studio-2015><asp.net-core><dnx><.net-4.6>,8,"visual-studio,visual-studio-2015,asp.net-core,dnx,.net-4.6",['visual studio 2015 target framework dotnet vs net452'],"['when creating a new visual studio 2015 class library package project one is able to set multiple target frameworks', 'what is the difference between dotnet and net452', 'projectjson frameworks dotnet net452 project layout']"
Removing the title from a QGroupBox,"Is it possible to completely remove the title from a QGroupBox? If you just give it an empty title, the label where the title would be still takes up space. It looks like this:

But I want it to look like this instead:

I tried the following things without success:

Setting the title font size to zero
Giving the title a size of zero in the stylesheet via setStyleSheet(""QGroupBox:title{ max-width: 0; max-height: 0; }"");
Moving the title inside the box via setStyleSheet(""QGroupBox:title{ subcontrol-position: center center;}"")

Note: You might say that a group box without title is a use case for QFrame. The problem with this is that I want to mix groups/frames with and without title, but the frame has a different visual style than the group box. So if you could tell me how to make QFrame look like QGroupBox that would solve my problems too.
",<c++><qt><qt5><qtstylesheets><qgroupbox>,12,"c++,qt,qt5,qtstylesheets,qgroupbox",['removing the title from a qgroupbox'],"['is it possible to completely remove the title from a qgroupbox', 'if you just give it an empty title the label where the title would be still takes up space', 'it looks like this but i want it to look like this instead i tried the following things without success setting the title font size to zero giving the title a size of zero in the stylesheet via setstylesheetqgroupboxtitle maxwidth 0 maxheight 0 moving the title inside the box via setstylesheetqgroupboxtitle subcontrolposition center center note you might say that a group box without title is a use case for qframe', 'the problem with this is that i want to mix groupsframes with and without title but the frame has a different visual style than the group box', 'so if you could tell me how to make qframe look like qgroupbox that would solve my problems too']"
Character in Switch-Statement C++,"Please help! I can't produce the output of my program. This is the condition:
Construct a program that gives a discount of 100 pesos if the shirt bought is XL and the the price is greater than 500; and a discount of 50 pesos if the shirt bought is L and the price is greater than 600.
#include <iostream>
using namespace std;


int main()
{
    int p;
    int s;

    cout << ""Input price: "";
    cin  >> p;
    cout << ""Input size: "";
    cin  >> s;

switch (s)
{
case 'XL': case 'xl':
    {
        if (p>500){
            cout << ""Total price: "" << p-100 << "" pesos."";
            break;
        }
        else if ((s=='XL' || s=='xl') && (p<500)){
            cout << ""Total price: "" << p << "" pesos."";
            break;
        }
    }
case 'L': case 'l':
    {
        if (p>600){
            cout << ""Total price: "" << p-50 << "" pesos."";
            break;
        }
        else if ((s=='XL' || s=='xl') && (p<600)){
            cout << ""Total price: "" << p << "" pesos."";
            break;
        }
    }
case 'M': case 'm':
    {
        cout << ""Total price: "" << p << "" pesos."";
        break;
    }
case 'S': case 's':
    {
        cout << ""Total price: "" << p << "" pesos."";
        break;
    }
}

return 0;

}
The output of the program:
Input price: 500
Input size: XL

Process returned 0 (0x0)   execution time : 5.750 s
Press any key to continue.

P.S. How can I remove the warning (multi-character character constant) in my program?
Thanks in advance!
",<c++><switch-statement><character><constants><output>,7,"c++,switch-statement,character,constants,output",['character in switchstatement c'],"['please help', 'i cant produce the output of my program', 'this is the condition construct a program that gives a discount of 100 pesos if the shirt bought is xl and the the price is greater than 500 and a discount of 50 pesos if the shirt bought is l and the price is greater than 600', 'include iostream using namespace std int main int p int s cout input price cin p cout input size cin s switch s case xl case xl if p500 cout total price p100 pesos', ' break else if sxl sxl p500 cout total price p pesos', ' break case l case l if p600 cout total price p50 pesos', ' break else if sxl sxl p600 cout total price p pesos', ' break case m case m cout total price p pesos', ' break case s case s cout total price p pesos', ' break return 0 the output of the program input price 500 input size xl process returned 0 0x0 execution time 5750 s press any key to continue', 'p', 'how can i remove the warning multicharacter character constant in my program', 'thanks in advance']"
Need advice on selecting a data access method,"I am in the early stages of planning a conversion of a large classic ASP database application to ASP.Net and I'm having trouble picking out which data access method to use.  I have played around with Linq To SQL, Dynamic Data, strongly typed datasets, Enterprise Library (Data Access Application Blocks), and a tiny bit with Entity Framework, but none of them have jumped out to me as ""the one"".  There are just too many choices - my head is swimming, help me choose!  
Perhaps it would help to give some background on the application that I am converting along with the priorities...

The back end is Microsoft SQL Server (2005 or later) and we are committed to that, so I don't need to worry about ever supporting a different database platform.
The database is very mature and contains a great deal of the business logic.  It is highly normalized and makes extensive use of stored procedures, triggers, and views.  I would rather not reinvent two wheels at the same time, so I'd like to make as few changes to the database as possible.  So, I need to choose a data access method that is flexible enough to let me work around any quirks in the database.
The application has many data entry forms and extensive searching and reporting capabilities (reports are another beast which I will tackle later).
The application needs to be flexible enough to deal with minor changes to the database structure.  The application (and database) may be installed at different sites where minor custom modifications are made to the database.  Ideally the application could identify the database extensions and react appropriately.  In other words, if I need to store an O/R mapping in the application, I need to be able to swap that out (or refresh it easily) when installing the application and database at a new site.
Rapid application development is critical.  Since the database is already done and the user interface is going to closely match the existing application, I'm hoping to find something where we can crank this out fairly quickly.  I am willing to sacrifice not using the absolute latest and greatest technology if it will save time in development.  In other words, if there is a steep learning curve to using something like Entity Framework, I'm fine with going something like strongly typed Datasets and a custom DAL if it will speed up the process.  
I am a total newbie to ASP.Net but am intimately familiar with Classic ASP, T-SQL and the old ADO (e.g. disconnected recordsets).  If any of the data access methods is better suited for someone coming from my background, I might lean in that direction.

Thanks for any advice that you can offer!
",<asp.net><linq-to-sql><entity-framework><dynamic-data><data-access-layer>,6,"asp.net,linq-to-sql,entity-framework,dynamic-data,data-access-layer",['need advice on selecting a data access method'],"['i am in the early stages of planning a conversion of a large classic asp database application to aspnet and im having trouble picking out which data access method to use', 'i have played around with linq to sql dynamic data strongly typed datasets enterprise library data access application blocks and a tiny bit with entity framework but none of them have jumped out to me as the one', 'there are just too many choices my head is swimming help me choose', 'perhaps it would help to give some background on the application that i am converting along with the priorities the back end is microsoft sql server 2005 or later and we are committed to that so i dont need to worry about ever supporting a different database platform', 'the database is very mature and contains a great deal of the business logic', 'it is highly normalized and makes extensive use of stored procedures triggers and views', 'i would rather not reinvent two wheels at the same time so id like to make as few changes to the database as possible', 'so i need to choose a data access method that is flexible enough to let me work around any quirks in the database', 'the application has many data entry forms and extensive searching and reporting capabilities reports are another beast which i will tackle later', 'the application needs to be flexible enough to deal with minor changes to the database structure', 'the application and database may be installed at different sites where minor custom modifications are made to the database', 'ideally the application could identify the database extensions and react appropriately', 'in other words if i need to store an or mapping in the application i need to be able to swap that out or refresh it easily when installing the application and database at a new site', 'rapid application development is critical', 'since the database is already done and the user interface is going to closely match the existing application im hoping to find something where we can crank this out fairly quickly', 'i am willing to sacrifice not using the absolute latest and greatest technology if it will save time in development', 'in other words if there is a steep learning curve to using something like entity framework im fine with going something like strongly typed datasets and a custom dal if it will speed up the process', 'i am a total newbie to aspnet but am intimately familiar with classic asp tsql and the old ado eg', 'disconnected recordsets', 'if any of the data access methods is better suited for someone coming from my background i might lean in that direction', 'thanks for any advice that you can offer']"
Why am I getting a ChromeProxyService error with Flutter Web and Chrome,"I'm using Flutter version 3.3.8 and Google Chrome version 107.0.5304.110.
I send an http request, and this is the error that I get:
ChromeProxyService: Failed to evaluate expression 'xhr': InternalError: Expression evaluation in async frames is not supported. No frame with index 30..
",<flutter><google-chrome><flutter-web><flutter-http><flutter-web-browser>,7,"flutter,google-chrome,flutter-web,flutter-http,flutter-web-browser",['why am i getting a chromeproxyservice error with flutter web and chrome'],"['im using flutter version 338 and google chrome version 10705304110 i send an http request and this is the error that i get chromeproxyservice failed to evaluate expression xhr internalerror expression evaluation in async frames is not supported', 'no frame with index 30']"
boost::asio io_service thread pool,"What's the proper usage of settings up a thread pool for io_service? These 2 statements from the documentation are throwing me off:
io_service::run

A normal exit from the run() function implies that the io_service object is stopped (the stopped() function returns true). Subsequent calls to run(), run_one(), poll() or poll_one() will return immediately unless there is a prior call to reset().

io_service::reset

This function must be called prior to any second or later set of invocations of the run(), run_one(), poll() or poll_one() functions when a previous invocation of these functions returned due to the io_service being stopped or running out of work.

Here's what I'm currently doing:
boost::thread_group     m_Threads;
boost::asio::io_service m_IoService;
boost::barrier          m_Barrier(numThreads);

for( unsigned int i = 0; i < numThreads; ++i )
{
    m_Threads.create_thread(
        [&]()
        {
            for(;;)
            {
                m_IoService.run();

                if( m_Barrier.wait() )  //  will only return true for 1 thread
                {
                    m_IoService.reset();
                }
                m_Barrier.wait();
            }
        });
}

m_IoService.stop();
m_Threads.interrupt_all();
m_Threads.join_all();

Everything seems to work fine if I just put m_IoService.run() in an infinite loop (which the documentation seems to indicate should not be the case). What's the correct way?
",<c++><networking><boost><boost-asio><c++11>,15,"c++,networking,boost,boost-asio,c++11",['boostasio ioservice thread pool'],"['whats the proper usage of settings up a thread pool for ioservice', 'these 2 statements from the documentation are throwing me off ioservicerun a normal exit from the run function implies that the ioservice object is stopped the stopped function returns true', 'subsequent calls to run runone poll or pollone will return immediately unless there is a prior call to reset', 'ioservicereset this function must be called prior to any second or later set of invocations of the run runone poll or pollone functions when a previous invocation of these functions returned due to the ioservice being stopped or running out of work', 'heres what im currently doing boostthreadgroup mthreads boostasioioservice mioservice boostbarrier mbarriernumthreads for unsigned int i 0 i numthreads i mthreadscreatethread for mioservicerun if mbarrierwait will only return true for 1 thread mioservicereset mbarrierwait mioservicestop mthreadsinterruptall mthreadsjoinall everything seems to work fine if i just put mioservicerun in an infinite loop which the documentation seems to indicate should not be the case', 'whats the correct way']"
How to take a subset of an object using an interface?,"Suppose I have this class and interface
class User {
    name: string;
    age: number;
    isAdmin: boolean;
}

interface IUser {
    name: string;
    age: number;
}

And then I get this json object from somewhere
const data = {
    name: ""John"",
    age: 25,
    isAdmin: true
}

I want to subset data using IUser and remove the isAdmin property like this
let user = subset<IUser>(data);
// user is now { name: ""John"", age: 25 }
// can safely insert user in the db

My question is how do I implement that function in TypeScript?
function subset<T>(obj: object) {
    // keep all properties of obj that are in T
    // keep, all optional properties in T
    // remove any properties out of T
}

",<oop><typescript><interface><typescript2.0><mass-assignment>,7,"oop,typescript,interface,typescript2.0,mass-assignment",['how to take a subset of an object using an interface'],"['suppose i have this class and interface class user name string age number isadmin boolean interface iuser name string age number and then i get this json object from somewhere const data name john age 25 isadmin true i want to subset data using iuser and remove the isadmin property like this let user subsetiuserdata user is now name john age 25 can safely insert user in the db my question is how do i implement that function in typescript', 'function subsettobj object keep all properties of obj that are in t keep all optional properties in t remove any properties out of t ']"
Are captureless lambdas structural types?,"P1907R1, accepted for C++20, introduced structural types, which are a valid types for non-type template parameter.
GCC and Clang both accepts the following snippet for C++2a:
template<auto v>
constexpr auto identity_v = v;

constexpr auto l1 = [](){};
constexpr auto l2 = identity_v<l1>; 

implying that the type of a captureless lambda is a structural type.
Question

Does a captureless lambda indeed fulfill the requirements for its type to to be a structural type?

",<c++><templates><lambda><language-lawyer><c++20>,8,"c++,templates,lambda,language-lawyer,c++20",['are captureless lambdas structural types'],"['p1907r1 accepted for c20 introduced structural types which are a valid types for nontype template parameter', 'gcc and clang both accepts the following snippet for c2a templateauto v constexpr auto identityv v constexpr auto l1 constexpr auto l2 identityvl1 implying that the type of a captureless lambda is a structural type', 'question does a captureless lambda indeed fulfill the requirements for its type to to be a structural type']"
How to close an issue with GitHub API,"I am trying to figure out how to close an issue through the Github API.
Specifically I'm trying to do it through pyGitHub and python, but knowing how to close an issue through the GitHub API would be enough to let me figure it out.
Can anyone point me in the right direction? I'm sure it's simple but I can't find it in the documentation
",<python><github><github-api><issue-tracking><pygithub>,6,"python,github,github-api,issue-tracking,pygithub",['how to close an issue with github api'],"['i am trying to figure out how to close an issue through the github api', 'specifically im trying to do it through pygithub and python but knowing how to close an issue through the github api would be enough to let me figure it out', 'can anyone point me in the right direction', 'im sure its simple but i cant find it in the documentation']"
WPF animating a StackPanel's width from 0 to Auto?,"I am trying to animate a StackPanel when its visibility changed to grow from a width of 0 to its automatic width, here is what I have at the moment:
<Trigger Property=""Visibility"" Value=""Visible"">
    <Setter Property=""Width"" Value=""0""></Setter>
    <Trigger.EnterActions>
        <BeginStoryboard>
            <Storyboard>
                <ObjectAnimationUsingKeyFrames Storyboard.TargetProperty=""Width"" Duration=""0:0:1"">
                    <DiscreteObjectKeyFrame KeyTime=""0"">
                        <DiscreteObjectKeyFrame.Value>
                            <System:Double>NaN</System:Double>
                        </DiscreteObjectKeyFrame.Value>
                    </DiscreteObjectKeyFrame>
                </ObjectAnimationUsingKeyFrames>
            </Storyboard>
        </BeginStoryboard>
    </Trigger.EnterActions>
</Trigger>

Can someone explain how I might achieve this animation? Is it maybe not possible in the way I am trying to do it?
Thanks,
alex.
",<.net><wpf><xaml><wpf-controls><wpf-4.0>,6,".net,wpf,xaml,wpf-controls,wpf-4.0",['wpf animating a stackpanels width from 0 to auto'],"['i am trying to animate a stackpanel when its visibility changed to grow from a width of 0 to its automatic width here is what i have at the moment trigger propertyvisibility valuevisible setter propertywidth value0setter triggerenteractions beginstoryboard storyboard objectanimationusingkeyframes storyboardtargetpropertywidth duration001 discreteobjectkeyframe keytime0 discreteobjectkeyframevalue systemdoublenansystemdouble discreteobjectkeyframevalue discreteobjectkeyframe objectanimationusingkeyframes storyboard beginstoryboard triggerenteractions trigger can someone explain how i might achieve this animation', 'is it maybe not possible in the way i am trying to do it', 'thanks alex']"
how profiling class method using IPython %lprun magic function,"How can I profile a method of an object called inside a function? I am using the %lprun magic in a jupyter notebook. Please see the following ex.py example file:
class foo():
    def __init__(self, a=0, n=1):
                self.a=a
                self.n=n

    def compute(self):
        result = 0
        for i in range(self.n):
            result += self.a
        return result 

def my_func():
    a = 1
    n = 1000
    my_foo = foo(a, n)
    result = my_foo.compute()
    print(result)

Then, from my jupyter notebook, i can profile my_func:
 from ex import my_func

 %lprun -f my_func my_func()

but I cannot profile my compute method:
from ex import my_func

%lprun -f my_foo.compute my_func()

Is what I want even possible? How would I have to fill the class method in the -f argument for it to work?
According to the documentation, ""cProfile only times explicit function calls, not special methods called because of syntax"", ... so it should work.
A (maybe) related question that I found is here.
",<python><class><ipython><profiling><jupyter-notebook>,14,"python,class,ipython,profiling,jupyter-notebook",['how profiling class method using ipython lprun magic function'],"['how can i profile a method of an object called inside a function', 'i am using the lprun magic in a jupyter notebook', 'please see the following expy example file class foo def initself a0 n1 selfaa selfnn def computeself result 0 for i in rangeselfn result selfa return result def myfunc a 1 n 1000 myfoo fooa n result myfoocompute printresult then from my jupyter notebook i can profile myfunc from ex import myfunc lprun f myfunc myfunc but i cannot profile my compute method from ex import myfunc lprun f myfoocompute myfunc is what i want even possible', 'how would i have to fill the class method in the f argument for it to work', 'according to the documentation cprofile only times explicit function calls not special methods called because of syntax so it should work', 'a maybe related question that i found is here']"
LSOpenURLsWithRole() errors when in a tmux session,"LSOpenURLsWithRole() failed with error -600 for the URL http://localhost:9000/.
This is the error I get when I try to launch my SimpleHTTPServer while in a tmux session. I'm a front-end web developer and I spend most of my time working with a SimpleHTTPServer, rather than Apache. The issue is that it errors out at the open command, because I have the habit of opening files and directories from the terminal directly (open dirname/, or open .) , and when i use this in tmux it gives me the same error.
I want to mention that I'm on a Macbook Air, running OSX 10.9 Mavericks.
This is the code of the function I use in my terminal to start the server:
# Start an HTTP server from a directory, optionally specifying the port
function server() {
    local port=""${1:-8000}""
    open ""http://localhost:${port}/""
    # Set the default Content-Type to `text/plain` instead of `application/octet-stream`
    # And serve everything as UTF-8 (although not technically correct, this doesn’t break anything for binary files)
    python -c $'import SimpleHTTPServer;\nmap = SimpleHTTPServer.SimpleHTTPRequestHandler.extensions_map;\nmap[""""] = ""text/plain"";\nfor key, value in map.items():\n\tmap[key] = value + "";charset=UTF-8"";\nSimpleHTTPServer.test();' ""$port"" 
}

Edit
The issue doesn't appear anymore so I have 3 possible solutions for this:
Highly unlikely:

changing from Python3 to Python 2.7.5 (OS X Default)

Most likely:

Apple released an update to Mavericks that fixes this issue
installing Command-Line tools in order to use Homebrew to build & install the latest version of VIM

",<python><macos><terminal><tmux><simplehttpserver>,5,"python,macos,terminal,tmux,simplehttpserver",['lsopenurlswithrole errors when in a tmux session'],"['lsopenurlswithrole failed with error 600 for the url this is the error i get when i try to launch my simplehttpserver while in a tmux session', 'im a frontend web developer and i spend most of my time working with a simplehttpserver rather than apache', 'the issue is that it errors out at the open command because i have the habit of opening files and directories from the terminal directly open dirname or open ', ' and when i use this in tmux it gives me the same error', 'i want to mention that im on a macbook air running osx 109 mavericks', 'this is the code of the function i use in my terminal to start the server start an http server from a directory optionally specifying the port function server local port18000 open set the default contenttype to textplain instead of applicationoctetstream and serve everything as utf8 although not technically correct this doesnt break anything for binary files python c import simplehttpservernmap simplehttpserversimplehttprequesthandlerextensionsmapnmap textplainnfor key value in mapitemsntmapkey value charsetutf8nsimplehttpservertest port edit the issue doesnt appear anymore so i have 3 possible solutions for this highly unlikely changing from python3 to python 275 os x default most likely apple released an update to mavericks that fixes this issue installing commandline tools in order to use homebrew to build install the latest version of vim']"
"Compiler bug, or non standard code? - Variadic template capture in lambda","I have the following C++11 code;
template<typename... T>
int g(T... t)
{
    return 0;
}

template<class... Args>
void f(Args... args)
{
    auto lm = [&, args...] { return g(args...); };
    lm();
}

int main()
{
    f(2, 5, 7);
}

I do believe that it's valid C++11, according to; Section 5.1.2.23 of the standard;

A capture followed by an ellipsis is a
  pack expansion (14.5.3). [ Example:
template<class... Args> void f(Args... args) {
    auto lm = [&, args...] { return g(args...); }; lm();
}

— end example ]

However while Clang++ compiles fine, G++ provides this error;
main.cpp: In function 'void f(Args ...)':
main.cpp:10:23: error: expected ',' before '...' token
     auto lm = [&, args...] { return g(args...); };
                   ^
main.cpp:10:23: error: expected identifier before '...' token
main.cpp:10:26: error: parameter packs not expanded with '...':
     auto lm = [&, args...] { return g(args...); };
                      ^
main.cpp:10:26: note:         'args'
main.cpp: In lambda function:
main.cpp:10:43: error: expansion pattern 'args' contains no argument packs
     auto lm = [&, args...] { return g(args...); };
                                       ^
main.cpp: In instantiation of 'struct f(Args ...) [with Args = {int, int, int}]::__lambda0':
main.cpp:10:49:   required from 'void f(Args ...) [with Args = {int, int, int}]'
main.cpp:16:14:   required from here
main.cpp:10:19: error: using invalid field 'f(Args ...)::__lambda0::__args'
     auto lm = [&, args...] { return g(args...); };
                   ^

So my question is simply, is this a compiler bug in G++?
",<c++><c++11><lambda><variadic-templates><compiler-bug>,5,"c++,c++11,lambda,variadic-templates,compiler-bug","['compiler bug or non standard code', ' variadic template capture in lambda']","['i have the following c11 code templatetypename t int gt t return 0 templateclass args void fargs args auto lm args return gargs lm int main f2 5 7 i do believe that its valid c11 according to section 51223 of the standard a capture followed by an ellipsis is a pack expansion 1453', ' example templateclass args void fargs args auto lm args return gargs lm end example however while clang compiles fine g provides this error maincpp in function void fargs maincpp1023 error expected before token auto lm args return gargs maincpp1023 error expected identifier before token maincpp1026 error parameter packs not expanded with auto lm args return gargs maincpp1026 note args maincpp in lambda function maincpp1043 error expansion pattern args contains no argument packs auto lm args return gargs maincpp in instantiation of struct fargs with args int int intlambda0 maincpp1049 required from void fargs with args int int int maincpp1614 required from here maincpp1019 error using invalid field fargs lambda0args auto lm args return gargs so my question is simply is this a compiler bug in g']"
AngularJS: How to show preload or loading until page is loaded completely?,"I've an image gallery site where I'm getting all images and image related data from the database as json format in my controller and then by using ng-repeat I'm binding them with the html. Now, data are loaded early but images are loaded late, so images are scattered. How to solve this. I don't want to use setTimeOut.
The sample code is as below:-
<!DOCTYPE html>
<html lang=""en"" class=""no-js"" ng-app=""cps"">
<body ng-controller=""CPSController"">
<div>
<li ng-repeat=""image in images"" class=""shown"">
                <a id=""{{image.imageid}}"" ng-click=""openimage(image.imageid)"">
                    <img idx=""id-thumb-{{$index}}"" ng-src=""/imagedisplay/{{image.imageid}}"" alt="""" style="""">
                    <div class=""meta_info"">
                        <h3>{{image.imagename}}.</h3>
                        <div class=""callto"">
                            <div class=""actions"">
                                <span><img src=""img/artist.svg"" alt="""">{{image.ownername}}</span>
                                <span><img src=""img/likes.svg"" alt="""">{{image.likes}}</span>
                                <span><img src=""img/views_small.svg"" alt="""">{{image.views}}</span>
                            </div>
                            <div class=""category"">
                                Art Category
                            </div>
                        </div>
                    </div>
                </a>
            </li>

</div>
</body>
</html>

<script>

    var cps = angular.module('cps', []);
    cps.controller('CPSController', function($scope, $http, $compile){
        $scope.products = [];
        $http.get(""/alldata/"").success(function(data){
             if(data != ""null"")
             {
               for(i=data.length-1; i>=0; i--){
                 $scope.products.push(data[i]);
                }
                $scope.sendOrder('views', 'likes', 'timestamp', 2);
              }else{
                //$('#noImages').show();
              }

           /*setTimeout(function(){
                $(""[idx^='id-thumb']"").show();
            });*/
        });
     });
</script>

",<javascript><html><css><angularjs><image-gallery>,11,"javascript,html,css,angularjs,image-gallery",['angularjs how to show preload or loading until page is loaded completely'],"['ive an image gallery site where im getting all images and image related data from the database as json format in my controller and then by using ngrepeat im binding them with the html', 'now data are loaded early but images are loaded late so images are scattered', 'how to solve this', 'i dont want to use settimeout', 'the sample code is as below doctype html html langen classnojs ngappcps body ngcontrollercpscontroller div li ngrepeatimage in images classshown a idimageimageid ngclickopenimageimageimageid img idxidthumbindex ngsrcimagedisplayimageimageid alt style div classmetainfo h3imageimagenameh3 div classcallto div classactions spanimg srcimgartistsvg altimageownernamespan spanimg srcimglikessvg altimagelikesspan spanimg srcimgviewssmallsvg altimageviewsspan div div classcategory art category div div div a li div body html script var cps angularmodulecps cpscontrollercpscontroller functionscope http compile scopeproducts httpgetalldatasuccessfunctiondata ifdata null foridatalength1 i0 i scopeproductspushdatai scopesendorderviews likes timestamp 2 else noimagesshow settimeoutfunction idxidthumbshow script']"
NLTK for Named Entity Recognition,"I am trying to use NLTK toolkit to get extract place, date and time from text messages. I just installed the toolkit on my machine and I wrote this quick snippet to test it out:
sentence = ""Let's meet tomorrow at 9 pm"";
tokens = nltk.word_tokenize(sentence)
pos_tags = nltk.pos_tag(tokens)
print nltk.ne_chunk(pos_tags, binary=True)

I was assuming that it will identify the date (tomorrow) and time (9 pm). But, surprisingly it failed to recognize that. I get the following result when I run my above code:
(S (GPE Let/NNP) 's/POS meet/NN tomorrow/NN at/IN 9/CD pm/NN)

Can someone help me understand if I am missing something or NLTK is just not mature enough to tag time and date properly. Thanks!
",<machine-learning><nlp><nltk><text-processing><named-entity-recognition>,27,"machine-learning,nlp,nltk,text-processing,named-entity-recognition",['nltk for named entity recognition'],"['i am trying to use nltk toolkit to get extract place date and time from text messages', 'i just installed the toolkit on my machine and i wrote this quick snippet to test it out sentence lets meet tomorrow at 9 pm tokens nltkwordtokenizesentence postags nltkpostagtokens print nltknechunkpostags binarytrue i was assuming that it will identify the date tomorrow and time 9 pm', 'but surprisingly it failed to recognize that', 'i get the following result when i run my above code s gpe letnnp spos meetnn tomorrownn atin 9cd pmnn can someone help me understand if i am missing something or nltk is just not mature enough to tag time and date properly', 'thanks']"
NewtonSoft.Json custom JsonConverter deserialize to DateTime not working,"I am trying to deserialize a Unix timestamp to a DateTime. In my case, I need to do much more checks before I can set a property to DateTime from a timestamp. If I use DateTime from Newtonsoft.Json it deserializes it to UTC time and I need to deserialize it to a specific timezone
The problem is that I am not able to get the correct time. It seems like my string to long parsing is failing. If I can get the long unix timestamp, I can get the rest of the logic working
I have a class named Alert
class Alert
{
    // Some properties

    [JsonConverter(typeof(UnixTimestampJsonConverter))]
    public DateTime Created { get; set; }

    // Some more properties
}

the class UnixTimestampJsonConverter is
class UnixTimestampJsonConverter : JsonConverter
{
    // Other override methods

    public override object ReadJson (JsonReader reader, Type objectType, 
        object existingValue, JsonSerializer serializer)
    {
        if (reader.TokenType == JsonToken.EndObject)
            return null;

        if (reader.TokenType == JsonToken.StartObject) {
            long instance = serializer.Deserialize<long> (reader);
            return TimeUtils.GetCustomDateTime (instance);
        }

        return null;
    }
}

Where TimeUtils.GetCustomDateTime (instance) takes the long unixtimestamp and converts it into DateTime object of specific timezone.
I am in a PCL library with Profile 78, so I have limited access to System.TimeZoneInfo and I am using PCL version of NodaTime for other timezone calculations.

In case anyone is interested, this is the project on Github - MBTA Sharp
",<c#><json><datetime><timezone><json.net>,5,"c#,json,datetime,timezone,json.net",['newtonsoftjson custom jsonconverter deserialize to datetime not working'],"['i am trying to deserialize a unix timestamp to a datetime', 'in my case i need to do much more checks before i can set a property to datetime from a timestamp', 'if i use datetime from newtonsoftjson it deserializes it to utc time and i need to deserialize it to a specific timezone the problem is that i am not able to get the correct time', 'it seems like my string to long parsing is failing', 'if i can get the long unix timestamp i can get the rest of the logic working i have a class named alert class alert some properties jsonconvertertypeofunixtimestampjsonconverter public datetime created get set some more properties the class unixtimestampjsonconverter is class unixtimestampjsonconverter jsonconverter other override methods public override object readjson jsonreader reader type objecttype object existingvalue jsonserializer serializer if readertokentype jsontokenendobject return null if readertokentype jsontokenstartobject long instance serializerdeserializelong reader return timeutilsgetcustomdatetime instance return null where timeutilsgetcustomdatetime instance takes the long unixtimestamp and converts it into datetime object of specific timezone', 'i am in a pcl library with profile 78 so i have limited access to systemtimezoneinfo and i am using pcl version of nodatime for other timezone calculations', 'in case anyone is interested this is the project on github mbta sharp']"
Different elements on this page appear to scroll at different speeds. How was this done?,"The effect i am refering to is visible at http://whyinteractive.com/showreel. The elements appear to scroll behind and in front of one another at different speeds creating some cool effects. How was this done?
",<javascript><jquery><css><scroll><pagespeed>,12,"javascript,jquery,css,scroll,pagespeed","['different elements on this page appear to scroll at different speeds', 'how was this done']","['the effect i am refering to is visible at the elements appear to scroll behind and in front of one another at different speeds creating some cool effects', 'how was this done']"
Vaadin - Iterate over components in a layout,"I'm working on a project in Vaadin 7. In that I need to parse over all the components in a Layout and find a component I need.

The above is the pictorial representation of my layout.
I'm dynamically creating the green coloured Vertical layout inside blue coloured Vertical layout. Since I'm creating them dynamically, I can't have any instance for those dynamically created things. But, I have unique ID's for all the components.
Now I need to find a Combobox using the Id. I donno how to parse in to the combobox from the Blue coloured vertical layout.
All I have is an instance of the blue coloured vertical layout and Id's for combobox.
And, I can have ID's for green and red layouts too if needed.
I need something like this, But stuck..
Iterator<Component> iterate = blueMainLayout.iterator();
Combobox cb;
while (iterate.hasNext()) {
Component c = (Component) iterate.next();
cb = (Combobox) blueMainLayout.....;
        if (cb.getId().equals(something.getId())) {
            // do my job
        }
    }

",<layout><dynamic><iterator><components><vaadin>,8,"layout,dynamic,iterator,components,vaadin",['vaadin iterate over components in a layout'],"['im working on a project in vaadin 7 in that i need to parse over all the components in a layout and find a component i need', 'the above is the pictorial representation of my layout', 'im dynamically creating the green coloured vertical layout inside blue coloured vertical layout', 'since im creating them dynamically i cant have any instance for those dynamically created things', 'but i have unique ids for all the components', 'now i need to find a combobox using the id', 'i donno how to parse in to the combobox from the blue coloured vertical layout', 'all i have is an instance of the blue coloured vertical layout and ids for combobox', 'and i can have ids for green and red layouts too if needed', 'i need something like this but stuck iteratorcomponent iterate bluemainlayoutiterator combobox cb while iteratehasnext component c component iteratenext cb combobox bluemainlayout if cbgetidequalssomethinggetid do my job ']"
Uploading Image to Firebase Storage and Database,"I want to put the download URL of images into my Firebase Database. I can upload the Image into storage but I can't figure out how to get the URL into my database with the rest of the ""post"".
@IBOutlet weak var titleText: UITextField!
@IBOutlet weak var authorText: UITextField!
@IBOutlet weak var mainText: UITextView!
@IBOutlet weak var dateText: UITextField!
@IBOutlet weak var myImageView: UIImageView!

var ref:FIRDatabaseReference?

override func viewDidLoad() {
    super.viewDidLoad()

    ref = FIRDatabase.database().reference()

}


override func didReceiveMemoryWarning() {
    super.didReceiveMemoryWarning()
}


@IBAction func uploadImage(_ sender: Any) {


       let image = UIImagePickerController()
    image.delegate = self
    image.sourceType = UIImagePickerControllerSourceType.photoLibrary

    image.allowsEditing = false

    self.present(image, animated: true)
    {
        //after its completed
    }
}


@objc(imagePickerController:didFinishPickingMediaWithInfo:) func imagePickerController(_ picker: UIImagePickerController, didFinishPickingMediaWithInfo info: [String : Any])
{
    if let image = info[UIImagePickerControllerOriginalImage] as? UIImage
    {
        myImageView.image = image

    }
    else
    {
        //error
    }

    self.dismiss(animated: true, completion: nil)

    let storageRef = FIRStorage.storage().reference().child(""myImage.png"")
    if let uploadData = UIImagePNGRepresentation(self.myImageView.image!){
        storageRef.put(uploadData, metadata: nil, completion:
            {
                (metadata, error) in
                if error != nil {
                    print(""error"")
                    return
                }

   print(metadata)

   //how do I put the download URL in the metadata into my database

        }  
        )
    }

}

@IBAction func addPost(_ sender: Any) {

    if self.titleText.text != """" && self.authorText.text != """" && self.mainText.text != """" && self.dateText.text != """"
    {

        ref?.child(""Posts"").childByAutoId().setValue([""Title"": titleText.text,""Article"": mainText.text, ""Author"": authorText.text, ""Date"": dateText.text, ""myImageURL"": myImageURL])

        //the myImageURL part is where I get an error

        self.performSegue(withIdentifier: ""post"", sender: self)

    }
    else{

        let alertController = UIAlertController(title: ""Oops!"", message: ""Field left blank"", preferredStyle: .alert)

        let defaultAction = UIAlertAction(title: ""Ok"", style: .cancel, handler: nil)
        alertController.addAction(defaultAction)

        self.present(alertController, animated: true, completion: nil)

        }
    }
}

",<swift><firebase><swift3><firebase-realtime-database><firebase-storage>,14,"swift,firebase,swift3,firebase-realtime-database,firebase-storage",['uploading image to firebase storage and database'],"['i want to put the download url of images into my firebase database', 'i can upload the image into storage but i cant figure out how to get the url into my database with the rest of the post', 'iboutlet weak var titletext uitextfield', 'iboutlet weak var authortext uitextfield', 'iboutlet weak var maintext uitextview', 'iboutlet weak var datetext uitextfield', 'iboutlet weak var myimageview uiimageview', 'var reffirdatabasereference', 'override func viewdidload superviewdidload ref firdatabasedatabasereference override func didreceivememorywarning superdidreceivememorywarning ibaction func uploadimage sender any let image uiimagepickercontroller imagedelegate self imagesourcetype uiimagepickercontrollersourcetypephotolibrary imageallowsediting false selfpresentimage animated true after its completed objcimagepickercontrollerdidfinishpickingmediawithinfo func imagepickercontroller picker uiimagepickercontroller didfinishpickingmediawithinfo info string any if let image infouiimagepickercontrolleroriginalimage as', 'uiimage myimageviewimage image else error selfdismissanimated true completion nil let storageref firstoragestoragereferencechildmyimagepng if let uploaddata uiimagepngrepresentationselfmyimageviewimage', ' storagerefputuploaddata metadata nil completion metadata error in if error nil printerror return printmetadata how do i put the download url in the metadata into my database ibaction func addpost sender any if selftitletexttext selfauthortexttext selfmaintexttext selfdatetexttext refchildpostschildbyautoidsetvaluetitle titletexttextarticle maintexttext author authortexttext date datetexttext myimageurl myimageurl the myimageurl part is where i get an error selfperformseguewithidentifier post sender self else let alertcontroller uialertcontrollertitle oops', ' message field left blank preferredstyle alert let defaultaction uialertactiontitle ok style cancel handler nil alertcontrolleraddactiondefaultaction selfpresentalertcontroller animated true completion nil ']"
How to disable worker log output from celery worker?,"I have a situation here. I have a celery task which uses python logger to log to a log file. However, When I run the celery workers, I can see the log messages on the screen. Its getting written to the log files but I also have loads of messages on my screen. 
The issue arises when I put celery in supervisord. I have set std_out path and std_err path but all the worker log messages are getting written to the std_err log file instead of std_out log file. This way I am unable to get the real error messages in the std_err plus the log messages are redundant as its anyway getting written to the application log file.
I tried setting the loglevel while starting celery workers but nothing seems to stop the workers from flushing the log messages to the screen which when run in supervisord, gets written to the std_err.
Here is my supervisor conf file
[program:celery_worker]
command=celery -A CeleryWorker worker --concurrency=4 -l error
directory=/home/swaroop/codebase/src
stdout_logfile=/home/swaroop/codebase/logs/clLogger.log
stderr_logfile=/home/swaroop/codebase/logs/clerrorLogger.log
autostart=true
autorestart=true

Anyone has any solution to this issue? Any technique to segregate the real celery error messages from the application log messages would be helpful.
",<python><logging><ubuntu-12.04><celery><supervisord>,6,"python,logging,ubuntu-12.04,celery,supervisord",['how to disable worker log output from celery worker'],"['i have a situation here', 'i have a celery task which uses python logger to log to a log file', 'however when i run the celery workers i can see the log messages on the screen', 'its getting written to the log files but i also have loads of messages on my screen', 'the issue arises when i put celery in supervisord', 'i have set stdout path and stderr path but all the worker log messages are getting written to the stderr log file instead of stdout log file', 'this way i am unable to get the real error messages in the stderr plus the log messages are redundant as its anyway getting written to the application log file', 'i tried setting the loglevel while starting celery workers but nothing seems to stop the workers from flushing the log messages to the screen which when run in supervisord gets written to the stderr', 'here is my supervisor conf file programceleryworker commandcelery a celeryworker worker concurrency4 l error directoryhomeswaroopcodebasesrc stdoutlogfilehomeswaroopcodebaselogsclloggerlog stderrlogfilehomeswaroopcodebaselogsclerrorloggerlog autostarttrue autorestarttrue anyone has any solution to this issue', 'any technique to segregate the real celery error messages from the application log messages would be helpful']"
Is it undefined behaviour if multiple operands in a compound expression modify the same object?,"I vaguely remember reading somewhere that it is undefined behaviour if multiple operands in a compound expression modify the same object.
I believe an example of this UB is shown in the code below however I've compiled on g++, clang++ and visual studio and all of them print out the same values and can't seem to produce unpredictable values in different compilers.
#include <iostream>

int a( int& lhs ) { lhs -= 4; return lhs; }
int b( int& lhs ) { lhs *= 7; return lhs; }
int c( int& lhs ) { lhs += 1; return lhs; }
int d( int& lhs ) { lhs += 2; return lhs; }
int e( int& lhs ) { lhs *= 3; return lhs; }

int main( int argc, char **argv )
{
    int i = 100;
    int j = ( b( i ) + c( i ) ) * e( i ) / a( i ) * d( i );

    std::cout << i << "", "" << j << std::endl;

    return 0;
}

Is this behaviour undefined or have I somehow conjured up a description of supposed UB that is not actually undefined?
I would be grateful if someone could post an example of this UB and maybe even point me to where in the C++ standard that it says it is UB.
",<c++><c++11><undefined-behavior><language-lawyer><unspecified-behavior>,27,"c++,c++11,undefined-behavior,language-lawyer,unspecified-behavior",['is it undefined behaviour if multiple operands in a compound expression modify the same object'],"['i vaguely remember reading somewhere that it is undefined behaviour if multiple operands in a compound expression modify the same object', 'i believe an example of this ub is shown in the code below however ive compiled on g clang and visual studio and all of them print out the same values and cant seem to produce unpredictable values in different compilers', 'include iostream int a int lhs lhs 4 return lhs int b int lhs lhs 7 return lhs int c int lhs lhs 1 return lhs int d int lhs lhs 2 return lhs int e int lhs lhs 3 return lhs int main int argc char argv int i 100 int j b i c i e i a i d i stdcout i j stdendl return 0 is this behaviour undefined or have i somehow conjured up a description of supposed ub that is not actually undefined', 'i would be grateful if someone could post an example of this ub and maybe even point me to where in the c standard that it says it is ub']"
Not able to get Azure Billing Account Id,"I need to get Usage Details at Billing Account Scope for that firstly I used this API but It returns an empty value. I used the Bearer Access token for hitting this API.Is anything other than this am I missed?
Postman Request attached as screenshot

",<azure><azure-active-directory><billing><azure-billing-api><cost-management>,6,"azure,azure-active-directory,billing,azure-billing-api,cost-management",['not able to get azure billing account id'],"['i need to get usage details at billing account scope for that firstly i used this api but it returns an empty value', 'i used the bearer access token for hitting this apiis anything other than this am i missed', 'postman request attached as screenshot']"
How do I set a custom font for the whole application?,"Is there any way to How to Apply global font [new custom font] to whole application in iphone objective-c.
I know that we can use below method to set font for each label
[self.titleLabel setFont:[UIFont fontWithName:@""FONOT_NAME"" size:FONT_SIZE]];

But I want to change for whole application.
Please help me if anyone know.
",<iphone><objective-c><ios><uiview><custom-font>,9,"iphone,objective-c,ios,uiview,custom-font",['how do i set a custom font for the whole application'],"['is there any way to how to apply global font new custom font to whole application in iphone objectivec i know that we can use below method to set font for each label selftitlelabel setfontuifont fontwithnamefonotname sizefontsize but i want to change for whole application', 'please help me if anyone know']"
Phusion Passenger Not Working on Apache,"UPDATE: When entering 'passenger-memory-stats' I'm showing:
---Passenger processes---
Processes: 0

How do I troubleshoot this? Why would passenger not be starting even though I added it in httpd.conf and restart apache?
I'm having trouble getting Phusion Passenger to Run Ruby on Rails on a server. I've followed all instructions at Phusion web site and installed passenger and modified and created Apache VirtualHost to point to the new directory and verified that all .conf files are being loaded successfully. Also httpd -M passenger_module is loaded. I also successfully ran Passenger Standalone and Rails server webrick on localhost and was able to verify that it works with curl.
But when I try to run my domain from the browser, I just get a 404 not found or an empty index file that I create in that folder specified by the DocumentRoot under VirtualHost (so I know it's loading .conf and going into the right directory) but it's not loading Rails Application....Can someone please point out what I'm doing wrong? Here are my settings and config:
ruby -v:
ruby 2.1.2p95

rails -v:
Rails 4.2.3

passenger -v:
Phusion Passenger version 5.0.15

httpd -v:
Apache/2.2.27 (Unix)

opearting system:
CentOS

uname -i: 
x86_64

httpd.conf:  
Include ""/usr/local/apache/conf/includes/mydomain.conf""
LoadModule passenger_module /usr/local/rvm/gems/ruby-2.1.2/gems/passenger-5.0.15/buildout/apache2/mod_passenger.so
<IfModule mod_passenger.c>
PassengerRoot /usr/local/rvm/gems/ruby-2.1.2/gems/passenger-5.0.15
PassengerDefaultRuby /usr/local/rvm/gems/ruby-2.1.2/wrappers/ruby
</IfModule>

/usr/local/apache/conf/includes/mydomain.conf:
<VirtualHost 208.79.235.241:80>
ServerName mydomain.com
DocumentRoot /home/clevert/public_html/rails_apps/mydomain.com/public
PassengerRuby /usr/local/rvm/gems/ruby-2.1.2/wrappers/ruby
<Directory /home/clevert/public_html/rails_apps/mydomain.com/public>
Allow from all
Options -MultiViews
</Directory>
</VirtualHost>

passenger-config about ruby-command:
Command: /usr/local/rvm/gems/ruby-2.1.2/wrappers/ruby

passenger-config validate-install:
Checking whether this Passenger install is in PATH... ✓
Checking whether there are no other Passenger installations... ✓
Checking whether Apache is installed... ✓
Checking whether the Passenger module is correctly configured in Apache... ✓
Everything looks good. :-)

",<ruby-on-rails><ruby><apache><passenger><phusion>,6,"ruby-on-rails,ruby,apache,passenger,phusion",['phusion passenger not working on apache'],"['update when entering passengermemorystats im showing passenger processes processes 0 how do i troubleshoot this', 'why would passenger not be starting even though i added it in httpdconf and restart apache', 'im having trouble getting phusion passenger to run ruby on rails on a server', 'ive followed all instructions at phusion web site and installed passenger and modified and created apache virtualhost to point to the new directory and verified that all conf files are being loaded successfully', 'also httpd m passengermodule is loaded', 'i also successfully ran passenger standalone and rails server webrick on localhost and was able to verify that it works with curl', 'but when i try to run my domain from the browser i just get a 404 not found or an empty index file that i create in that folder specified by the documentroot under virtualhost so i know its loading conf and going into the right directory but its not loading rails applicationcan someone please point out what im doing wrong', 'here are my settings and config ruby v ruby 212p95 rails v rails 423 passenger v phusion passenger version 5015 httpd v apache2227 unix opearting system centos uname i x8664 httpdconf include usrlocalapacheconfincludesmydomainconf loadmodule passengermodule usrlocalrvmgemsruby212gemspassenger5015buildoutapache2modpassengerso ifmodule modpassengerc passengerroot usrlocalrvmgemsruby212gemspassenger5015 passengerdefaultruby usrlocalrvmgemsruby212wrappersruby ifmodule usrlocalapacheconfincludesmydomainconf virtualhost 2087923524180 servername mydomaincom documentroot homeclevertpublichtmlrailsappsmydomaincompublic passengerruby usrlocalrvmgemsruby212wrappersruby directory homeclevertpublichtmlrailsappsmydomaincompublic allow from all options multiviews directory virtualhost passengerconfig about rubycommand command usrlocalrvmgemsruby212wrappersruby passengerconfig validateinstall checking whether this passenger install is in path checking whether there are no other passenger installations checking whether apache is installed checking whether the passenger module is correctly configured in apache everything looks good', '']"
How to calculate the mean of the top 10% in R,"My dataset contains multiple observations for different species. Each species has a different number of observations. Looking for a fast way in R to calculate the mean of the top 10% of values for a given variable for each species.
I figured out how to get a given number of values (i.e., the top 20 values).  
clim6 <-setDT(range)[order(species, clim6),.SD[1:20],by=species]
write.csv(Bioclimlo6, file = ""clim6.csv"")

I also know that there is a way to trim the dataset to generate a mean of the remaining dataset but I'm not sure how to trim only the bottom 90%. 
mean(x, trim = 0, na.rm = FALSE)

",<r><data.table><mean><quantile><percentile>,7,"r,data.table,mean,quantile,percentile",['how to calculate the mean of the top 10 in r'],"['my dataset contains multiple observations for different species', 'each species has a different number of observations', 'looking for a fast way in r to calculate the mean of the top 10 of values for a given variable for each species', 'i figured out how to get a given number of values ie the top 20 values', 'clim6 setdtrangeorderspecies clim6sd120byspecies writecsvbioclimlo6 file clim6csv i also know that there is a way to trim the dataset to generate a mean of the remaining dataset but im not sure how to trim only the bottom 90', 'meanx trim 0 narm false']"
How to add a mean line to a seaborn stripplot or swarmplot,"I have a rather simple strip plot with vertical data.
planets = sns.load_dataset(""planets"")
sns.stripplot(x=""method"", y=""distance"", data=planets, size=4, color="".7"")
plt.xticks(rotation=45, ha=""right"")
plt.show()

I want to plot the mean of each x-element (method) as a small horizontal bar similar to what you get with:
sns.boxplot(
    x=""method"",
    y=""distance"",
    data=planets,
    whis=[50, 50],
    showfliers=False,
    showbox=False,
    showcaps=False
)

But without the vertical lines (with whis=[50,50] just spots) for the first / third quartile and showing mean instead of median. Maybe there is a more elegant solution not involving a Boxplot.
",<python><matplotlib><seaborn><boxplot><swarmplot>,9,"python,matplotlib,seaborn,boxplot,swarmplot",['how to add a mean line to a seaborn stripplot or swarmplot'],"['i have a rather simple strip plot with vertical data', 'planets snsloaddatasetplanets snsstripplotxmethod ydistance dataplanets size4 color7 pltxticksrotation45 haright pltshow i want to plot the mean of each xelement method as a small horizontal bar similar to what you get with snsboxplot xmethod ydistance dataplanets whis50 50 showfliersfalse showboxfalse showcapsfalse but without the vertical lines with whis5050 just spots for the first third quartile and showing mean instead of median', 'maybe there is a more elegant solution not involving a boxplot']"
Metafunction to compute x^n and return the integer limit without overflow if not possible?,"Consider the following code:
template <std::intmax_t Base, std::intmax_t Exponent> 
struct integer_power_bounded
{
    static_assert(Exponent >= 0, 
                  ""Error in 'integer_power_bounded': 'Exponent >= 0' is false"");
    static constexpr std::intmax_t value = /* something */;
};

template <std::intmax_t Base> 
struct integer_power_bounded<Base, 0>
{
    static constexpr std::intmax_t value = 1;
};

Instead of /* something */, I would like to return std::numeric_limits<std::intmax_t>::min() or std::numeric_limits<std::intmax_t>::max() if Base^Exponent cannot be represented by a std::intmax_t. The difficult thing is to avoid overflows during computation because they create errors at compilation. 
How to do that (without boost) ?
",<c++><c++11><metaprogramming><template-meta-programming><integer-overflow>,8,"c++,c++11,metaprogramming,template-meta-programming,integer-overflow",['metafunction to compute xn and return the integer limit without overflow if not possible'],"['consider the following code template stdintmaxt base stdintmaxt exponent struct integerpowerbounded staticassertexponent 0 error in integerpowerbounded exponent 0 is false static constexpr stdintmaxt value something template stdintmaxt base struct integerpowerboundedbase 0 static constexpr stdintmaxt value 1 instead of something i would like to return stdnumericlimitsstdintmaxtmin or stdnumericlimitsstdintmaxtmax if baseexponent cannot be represented by a stdintmaxt', 'the difficult thing is to avoid overflows during computation because they create errors at compilation', 'how to do that without boost ']"
RxJava instead of AsyncTask?,"I came across several instances when people were trying to persuade me into using RxJava instead of Android's standard AsyncTask construct.
In my opinion RxJava offers a lot more features but loses in simplicity against AsyncTask.
Are there any use cases that suit one approach better than the other or even more general can RxJava even be considered superior?
",<java><android><concurrency><android-asynctask><rx-java>,15,"java,android,concurrency,android-asynctask,rx-java",['rxjava instead of asynctask'],"['i came across several instances when people were trying to persuade me into using rxjava instead of androids standard asynctask construct', 'in my opinion rxjava offers a lot more features but loses in simplicity against asynctask', 'are there any use cases that suit one approach better than the other or even more general can rxjava even be considered superior']"
Android - Confirm app exit with toast,"I'm new to Android development and I want it so when the user presses the back button on the main activity, a toast message appears with a ""confirm exit by pressing the back button again"" message. How would I do this? This is what I have so far:
@Override
public void onBackPressed() {
    // TODO Auto-generated method stub
    super.onBackPressed();
    Toast s = Toast.makeText(getBaseContext(), ""Press back again to exit"", Toast.LENGTH_LONG);
    s.show();
    wait();

    public boolean onBackPressed() {
        finish();    
    }
}

",<android><exit><toast><back><confirm>,10,"android,exit,toast,back,confirm",['android confirm app exit with toast'],"['im new to android development and i want it so when the user presses the back button on the main activity a toast message appears with a confirm exit by pressing the back button again message', 'how would i do this', 'this is what i have so far override public void onbackpressed todo autogenerated method stub superonbackpressed toast s toastmaketextgetbasecontext press back again to exit toastlengthlong sshow wait public boolean onbackpressed finish ']"
How to run VScode in sudo mode in WSL2?,"I was configuring the new Windows subsystem for Linux 2 developing environment. I have installed VSCode in Windows and WSL2 distribution of Ubuntu 18.04. I can open VSCode in Ubuntu(accessed through Windows Terminal) normally when logged as normal user, using command as follows:
simp1e@ZhuXian:/mnt/c/WINDOWS/system32$ code . 

But when I add sudo command in the front, the error occurs as follows:
simp1e@ZhuXian:/mnt/c/WINDOWS/system32$ sudo code .
sudo: code: command not found                                                                                                                                                           

At first, the problem remains after I switched to root user. Later I found that the PATH of root user didn't contain VSCode. So I add the VSCode path to /etc/environment. After that root user can open VSCode normally, but sudo code . still have the problem.
What should I do? Is this still related to the PATH?
",<ubuntu><visual-studio-code><sudo><windows-subsystem-for-linux><windows-terminal>,25,"ubuntu,visual-studio-code,sudo,windows-subsystem-for-linux,windows-terminal",['how to run vscode in sudo mode in wsl2'],"['i was configuring the new windows subsystem for linux 2 developing environment', 'i have installed vscode in windows and wsl2 distribution of ubuntu 1804 i can open vscode in ubuntuaccessed through windows terminal normally when logged as normal user using command as follows simp1ezhuxianmntcwindowssystem32 code ', 'but when i add sudo command in the front the error occurs as follows simp1ezhuxianmntcwindowssystem32 sudo code ', 'sudo code command not found at first the problem remains after i switched to root user', 'later i found that the path of root user didnt contain vscode', 'so i add the vscode path to etcenvironment', 'after that root user can open vscode normally but sudo code ', 'still have the problem', 'what should i do', 'is this still related to the path']"
boost::asio::ip::tcp::resolver::resolve() blocks forever,"I'm trying to create something similar as this code found at the boost.asio examples.
socket.h:
class some_class {
private:
    ...
        boost::asio::io_service io_service;
public:
        some_class() {
             /* This stuff isn't used in the example...
               ...but it doesn't change anything... */
             io_service.run();
        }
};

socket.cpp:
using boost::asio::ip::tcp;

bool some_class::connect(char* host, char* port) 
{
    printf(""Resolving hostname...\n"");

    /* Resolve hostname. */
    tcp::resolver resolver(io_service);
    tcp::resolver::query query(tcp::v4(), host, port);
    tcp::resolver::iterator iterator = resolver.resolve(query);

    printf(""Connecting to %s:%s... "", host, port);

    /* Connect to resolved hosts. */
    sock->connect(*iterator);

    return true;
}

g++ builds this without any errors, but the code never makes it past the resolver.resolve() call.

I've tried both ""127.0.0.1"" and ""localhost"" for host and ""80"" for port. (don't think it should matter, but apache2 is up and running)
When I ctrl+c out of my application, it obviously terminates but it does output the ""Connecting to string"" just before it does.
I am planning on building the example myself and seeing if the same problem occurs, and will definitely post the results here. Has anyone encountered this issue or knows what could possibly cause this behavior?
edit:
The example runs just fine... I have some debugging to do I suppose.
second edit:
I don't get it, the only thing that could be different is host/port.
Example uses char* argv[] and I'm using:
char host[] = ""localhost"";
char port[] = ""80"";

third edit:
it indeed seems to be blocking at connect, forgot to fflush(stdout). then it has to be a problem with the socket. going to do some more testing.
fourth edit:
stupid me, it wasn't blocking at all! I was just relying too much on console output.. 
",<c++><boost><g++><boost-asio><resolver>,5,"c++,boost,g++,boost-asio,resolver",['boostasioiptcpresolverresolve blocks forever'],"['im trying to create something similar as this code found at the boostasio examples', 'socketh class someclass private boostasioioservice ioservice public someclass this stuff isnt used in the example but it doesnt change anything ioservicerun socketcpp using boostasioiptcp bool someclassconnectchar host char port printfresolving hostnamen resolve hostname', ' tcpresolver resolverioservice tcpresolverquery querytcpv4 host port tcpresolveriterator iterator resolverresolvequery printfconnecting to ss host port connect to resolved hosts', ' sockconnectiterator return true g builds this without any errors but the code never makes it past the resolverresolve call', 'ive tried both 127001 and localhost for host and 80 for port', 'dont think it should matter but apache2 is up and running when i ctrlc out of my application it obviously terminates but it does output the connecting to string just before it does', 'i am planning on building the example myself and seeing if the same problem occurs and will definitely post the results here', 'has anyone encountered this issue or knows what could possibly cause this behavior', 'edit the example runs just fine i have some debugging to do i suppose', 'second edit i dont get it the only thing that could be different is hostport', 'example uses char argv and im using char host localhost char port 80 third edit it indeed seems to be blocking at connect forgot to fflushstdout', 'then it has to be a problem with the socket', 'going to do some more testing', 'fourth edit stupid me it wasnt blocking at all', 'i was just relying too much on console output']"
Solve this equation with fixed point iteration,"How can I solve this equation 

x3 + x - 1 = 0

using fixed point iteration?
Is there any fixed-point iteration code (especially in Python) I can find online?
",<python><equation><nonlinear-functions><numerical-analysis><fixed-point-iteration>,9,"python,equation,nonlinear-functions,numerical-analysis,fixed-point-iteration",['solve this equation with fixed point iteration'],"['how can i solve this equation x3 x 1 0 using fixed point iteration', 'is there any fixedpoint iteration code especially in python i can find online']"
Class Documentation Suggestions,"We are a Microsoft shop, concentrated on using C#. We have several projects, including websites, Windows services, and class libraries, that incorporate XML comments. 
I'm looking to generate MSDN-style HTML documentation for each project and deploy it to a centralized location that all of the developers can easily access. I also want to automate these steps so they can be run at regular intervals so I, and the other developers, don't need to worry about remembering to generate and deploy new documentation whenever a change is made. I've looked at Sandcastle and Doxygen and both look to be good options for generating the documentation that I want, but I need advice on a good way to automate the generation of it, like in a nightly job or something. 
Anyone out there doing something like this? I'm not sold on the end result being HTML; especially if there is a better idea.
EDIT:
I appreciate all of the good ideas. There are a couple of routes now that I can investigate, but I won't know which will work best until I get my hands dirty. The Sandcastle Help File Builder seems to offer me the best options for what I'm looking to do, so I'll give the nod to that suggestion. However, if I had more time to work on the XSLT and CSS solution to get the XML data looking just right, I'd pursue that suggestion first.
Thanks again everyone!
",<c#><doxygen><documentation-generation><sandcastle><xml-comments>,6,"c#,doxygen,documentation-generation,sandcastle,xml-comments",['class documentation suggestions'],"['we are a microsoft shop concentrated on using c', 'we have several projects including websites windows services and class libraries that incorporate xml comments', 'im looking to generate msdnstyle html documentation for each project and deploy it to a centralized location that all of the developers can easily access', 'i also want to automate these steps so they can be run at regular intervals so i and the other developers dont need to worry about remembering to generate and deploy new documentation whenever a change is made', 'ive looked at sandcastle and doxygen and both look to be good options for generating the documentation that i want but i need advice on a good way to automate the generation of it like in a nightly job or something', 'anyone out there doing something like this', 'im not sold on the end result being html especially if there is a better idea', 'edit i appreciate all of the good ideas', 'there are a couple of routes now that i can investigate but i wont know which will work best until i get my hands dirty', 'the sandcastle help file builder seems to offer me the best options for what im looking to do so ill give the nod to that suggestion', 'however if i had more time to work on the xslt and css solution to get the xml data looking just right id pursue that suggestion first', 'thanks again everyone']"
How do I indent the first line of a paragraph using HTML inline styling?,"I'm creating an HTML email and I do not want to use CSS styling in the head (for cross platform compatibility reasons). I need to set an indention for the first line of the paragraph using inline styling only. 
How would I do that?
",<html><email><html-email><inline><styling>,19,"html,email,html-email,inline,styling",['how do i indent the first line of a paragraph using html inline styling'],"['im creating an html email and i do not want to use css styling in the head for cross platform compatibility reasons', 'i need to set an indention for the first line of the paragraph using inline styling only', 'how would i do that']"
Visual Studio Development Server (2010) and NTLM authorization,"I'm using Visual Studio Development Server (Visual Basic 2010) and it works fine. Now I've enabled NTLM Authorization because I want to test the website using a different user account. Now when I try to access the website I always get the following error page:
Server Error in '/' Application.
HTTP Error 403 - Forbidden. 

Version Information: ASP.NET Development Server 10.0.0.0 
I'm using a test account which is a normal user within our domain. I've already set the access rights in my project folder to Full Access for this user but it does not help. Any further ideas?
Thanks!
",<asp.net><vb.net><visual-studio-2010><authentication><ntlm>,6,"asp.net,vb.net,visual-studio-2010,authentication,ntlm",['visual studio development server 2010 and ntlm authorization'],"['im using visual studio development server visual basic 2010 and it works fine', 'now ive enabled ntlm authorization because i want to test the website using a different user account', 'now when i try to access the website i always get the following error page server error in application', 'http error 403 forbidden', 'version information aspnet development server 10000 im using a test account which is a normal user within our domain', 'ive already set the access rights in my project folder to full access for this user but it does not help', 'any further ideas', 'thanks']"
iText: Reduce image quality (for reducing the resulting PDF size),"What is the best practice for reducing the size of JPEG images in a PDF file, newly created using iText? (My objective is a trade-off between image quality and file size.)
The images are created as follows:
Image image = new Image(ImageDataFactory.create(imagePath))

I would like to provide a scale factor, for instance 0.5, which halves the number of pixels in a row.
Say I generate a PDF with a single 3 MB image. I tried image.scale(0.5f, 0.5f), but the resulting PDF file is still roughly 3 MB. I expected it to become much smaller.
Thus I guess the source image, embedded in the PDF file, is not touched. But that is what I need: The total number of pixels in the entire PDF file stored on disk should be reduced.
What is the easiest/recommended way to achieve this?
",<java><pdf><itext><pdf-generation><itext7>,7,"java,pdf,itext,pdf-generation,itext7",['itext reduce image quality for reducing the resulting pdf size'],"['what is the best practice for reducing the size of jpeg images in a pdf file newly created using itext', 'my objective is a tradeoff between image quality and file size', 'the images are created as follows image image new imageimagedatafactorycreateimagepath i would like to provide a scale factor for instance 05 which halves the number of pixels in a row', 'say i generate a pdf with a single 3 mb image', 'i tried imagescale05f 05f but the resulting pdf file is still roughly 3 mb', 'i expected it to become much smaller', 'thus i guess the source image embedded in the pdf file is not touched', 'but that is what i need the total number of pixels in the entire pdf file stored on disk should be reduced', 'what is the easiestrecommended way to achieve this']"
"Git pull fatal: Out of memory, malloc failed","I've a repo on https://bitbucket.org/
A few days ago by a mistake big number of image files were pushed in the repo. then files were deleted via another push. After that repo worked OK, but today when I try to pull from the repo:
$ git pull
Password for 'https://repo@bitbucket.org': 
warning: no common commits
remote: Counting objects: 4635, done.
remote: Compressing objects: 100% (1710/1710), done.
fatal: Out of memory, malloc failed (tried to allocate 4266852665 bytes)
fatal: index-pack failed  

I've tried:

git config --global pack.windowMemory 1024m
$ git count-objects -v
count: 9
size: 48
in-pack: 4504
packs: 1
size-pack: 106822
prune-packable: 0
garbage: 0

No luck there, not sure what actions should i take next...
The size of the repo should be around 10-20m  of code. what actions should i take next?
UPDATE 1
i executed these commands:
$ git filter-branch --index-filter 'git rm --cached --ignore-unmatch public/images/*' HEAD
Rewrite a1c9fb8324a2d261aa745fc176ce2846d7a2bfd7 (288/288)
WARNING: Ref 'refs/heads/master' is unchanged

and
$ git push --force --all
Counting objects: 4513, done.
Compressing objects: 100% (1614/1614), done.
Writing objects: 100% (4513/4513), 104.20 MiB | 451 KiB/s, done.
Total 4513 (delta 2678), reused 4500 (delta 2671)
remote: bb/acl: ayermolenko is allowed. accepted payload.
To https://repo@bitbucket.org/repo.git
 + 203e824...ed003ce demo -> demo (forced update)
 + d59fd1b...a1c9fb8 master -> master (forced update)

Pull then works ok:
$ git pull
Already up-to-date.

But when I try to clone repo I get
~/www/clone$ git clone git@bitbucket.org:repo.git
Cloning into 'clone'...
remote: Counting objects: 5319, done.
remote: Compressing objects: 100% (1971/1971), done.
fatal: Out of memory, malloc failed (tried to allocate 4266852665 bytes)
fatal: index-pack failed

UPDATE 2
Sadly enough I didn't find all of the large files. Some are still left. So I asked support to kill all the logs of the repo
UPDATE 3
In the end I had to kill old & create a new repo.
",<git><memory><clone><bitbucket><git-clone>,11,"git,memory,clone,bitbucket,git-clone",['git pull fatal out of memory malloc failed'],"['ive a repo on a few days ago by a mistake big number of image files were pushed in the repo', 'then files were deleted via another push', 'after that repo worked ok but today when i try to pull from the repo git pull password for warning no common commits remote counting objects 4635 done', 'remote compressing objects 100 17101710 done', 'fatal out of memory malloc failed tried to allocate 4266852665 bytes fatal indexpack failed ive tried git config global packwindowmemory 1024m git countobjects v count 9 size 48 inpack 4504 packs 1 sizepack 106822 prunepackable 0 garbage 0 no luck there not sure what actions should i take next the size of the repo should be around 1020m of code', 'what actions should i take next', 'update 1 i executed these commands git filterbranch indexfilter git rm cached ignoreunmatch publicimages head rewrite a1c9fb8324a2d261aa745fc176ce2846d7a2bfd7 288288 warning ref refsheadsmaster is unchanged and git push force all counting objects 4513 done', 'compressing objects 100 16141614 done', 'writing objects 100 45134513 10420 mib 451 kibs done', 'total 4513 delta 2678 reused 4500 delta 2671 remote bbacl ayermolenko is allowed', 'accepted payload', 'to 203e824ed003ce demo demo forced update d59fd1ba1c9fb8 master master forced update pull then works ok git pull already uptodate', 'but when i try to clone repo i get wwwclone git clone gitbitbucketorgrepogit cloning into clone remote counting objects 5319 done', 'remote compressing objects 100 19711971 done', 'fatal out of memory malloc failed tried to allocate 4266852665 bytes fatal indexpack failed update 2 sadly enough i didnt find all of the large files', 'some are still left', 'so i asked support to kill all the logs of the repo update 3 in the end i had to kill old create a new repo']"
No peer certificate Exception - Volley and Android with self signed certificate,"I'm trying to make my app communicate with my server via https.
As I don't want to pay to get my server certificate signed by a trusted CA, the solution is to use a self signed certificate.
So, I've created my caconfig.cnf as follows:
[ ca ]
default_ca              = CA_default                    # The default ca section

[ CA_default ]
dir                     = ./demoCA                      # top dir
database                = $dir/index.txt                # index file.
new_certs_dir           = $dir/newcerts                 # new certs dir

certificate             = $dir/cacert.pem               # The CA cert
serial                  = $dir/serial                   # serial no file
private_key             = $dir/private/cakey.pem        # CA private key
RANDFILE                = $dir/private/.rand            # random number file

default_days            = 365                           # how long to certify for
default_crl_days        = 30                            # how long before next CRL
default_md              = md5                           # md to use
policy                  = policy_any                    # default policy
email_in_dn             = no                            # Don't add the email into cert DN
name_opt                = ca_default                    # Subject name display option
cert_opt                = ca_default                    # Certificate display option
copy_extensions         = none                          # Don't copy extensions from request

[ policy_any ]
countryName             = optional
stateOrProvinceName     = optional
organizationName        = optional
organizationalUnitName  = optional
commonName              = supplied
emailAddress            = optional

Then, I've created and signed my certificate using the following commands:
$ mkdir myCA myCA/private myCA/newcerts
$ echo ""01"" > myCA/serial
$ touch demoCA/index.txt

$ openssl genrsa -des3 -out myCA/private/cakey.pem 1024
$ openssl req -new -x509 -days 3650 -key myCA/private/cakey.pem -out myCA/cacert.pem

$ openssl req -sha1 -newkey rsa:2048 -keyout server-key.pem -out server-cert-req.pem -subj '/CN=myhost/' -nodes
$ openssl ca -config caconfig.cnf -in server-cert-req.pem -out server-cert.pem
$ openssl x509 -inform PEM -in cacert.pem -outform DER -out certificate.cer
$ rm server-cert-req.pem

In my nodejs server code, I'm creating the https server like this:
var express = require('express');
var https = require('https');

var PORT = 443;
var app = express();

app.get('/', function (req, res) {
    res.send(""Server is working"");
});

var httpsOptions = {
    key: fs.readFileSync('server-key.pem'),
    cert: fs.readFileSync('server-cert.pem')
};

https.createServer(httpsOptions, app).listen(PORT, function() {
    console.log('%s: Node server started on port %d ...', Date(Date.now() ), PORT);
});

In order to test if everything is correct, I've also created a node client script, which makes a request to my server. Here is the code for my node client:
var https = require('https');
var fs = require('fs');

var request = https.request({
    host: 'myhost',
    port: 443,
    path: '/',
    method: 'GET',
    rejectUnauthorized: true,

    // Once it is self signed, I'm using my server certificate (public key).
    ca: [fs.readFileSync('cacert.pem').toString()]
}, function(response) {
    response.on('data', function(data) {
        console.log(data.toString());
    });
});

request.on('error', function(err) {
    console.log(err);
})

request.end();

When I run my node client script, it works perfectly. On the other hand, the Android Volley Examples app, which I'm using to check how Volley works with https, is not working. Below, I'm describing all the steps I've followed in order to try to make it work.
I've created a .bks file using my certificate.cer file using the following command:
keytool -importcert -v -trustcacerts -file ""certificate.cer"" -alias IntermediateCA -keystore ""res/raw/my_keystore.bks"" -provider org.bouncycastle.jce.provider.BouncyCastleProvider -providerpath ""path_to_bouncycastle/bcprov-jdk16-146.jar"" -storetype BKS -storepass mysecret

Then, I've verified if the certificate was imported correctly into the .bks as follows:
keytool -list -keystore ""res/raw/my_keystore.bks"" -provider org.bouncycastle.jce.provider.BouncyCastleProvider -providerpath ""path_to_bouncycastle/bcprov-jdk16-146.jar"" -storetype BKS -storepass mysecret

And I got the following output, that means it's correct:
Keystore type: BKS
Keystore provider: BC

Your keystore contains 1 entry

imeto_alias, Oct 16, 2014, trustedCertEntry, 
Certificate fingerprint (SHA1): 03:DC:A1:6A:9B:1D:AD:59:A9:9B:1F:C2:43:7E:80:07:3B:B6:BE:CB

I've came across to this tutorial, and, as I'm using Volley, I've decided to follow it. So, below are the following changes I've made to the example project.
Got Volley from git clone https://android.googlesource.com/platform/frameworks/volley

Got Android Volley Examples project from git clone git://github.com/ogrebgr/android_volley_examples.git

Copied my_keystore.bks containing the self-signed public key in res/raw;

Opened Act_SsSslHttpClient in the examples project, found ""R.raw.test"" and replaced it with R.raw.my_keystore;

Found ""new SslHttpClient("" and replaced the default password ""test123″ with ""mysecret"";

Replaced ""44400"" with the HTTPS port of my server/virtualhost (""443""). (I could also remove this parameter since ""443"" is the default port;

Replaced ""https://tp.bolyartech.com:44400/https_test.html"" with my server URL.

Started the app, went to ""HTTPS with self-signed cert"", then ""Execute HTTPS request""

But, when I pressed the button, I got the following exception:
javax.net.ssl.SSLPeerUnverifiedException: No peer certificate

Below, is my JavaCode...
public class Act_SsSslHttpClient extends Activity {
    private TextView mTvResult;


    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.act__ss_ssl_http_client);

        mTvResult = (TextView) findViewById(R.id.tv_result);

        Button btnSimpleRequest = (Button) findViewById(R.id.btn_simple_request);
        btnSimpleRequest.setOnClickListener(new OnClickListener() {
            @Override
            public void onClick(View v) {

                // Replace R.raw.test with your keystore 
                InputStream keyStore = getResources().openRawResource(R.raw.my_keystore);


                // Usually getting the request queue shall be in singleton like in {@seeAct_SimpleRequest}
                // Current approach is used just for brevity
                RequestQueue queue = Volley.newRequestQueue(Act_SsSslHttpClient.this,
                                     new ExtHttpClientStack(new SslHttpClient(keyStore,
                                         ""mysecret"")));

                StringRequest myReq = new StringRequest(Method.GET,
                                                    ""https://myServerURL/"",
                                                    createMyReqSuccessListener(),
                                                    createMyReqErrorListener());

                queue.add(myReq);
            }
        });
    }

...

}

Does anybody know the solution?
Thank you.
",<android><node.js><https><android-volley><self-signed>,6,"android,node.js,https,android-volley,self-signed",['no peer certificate exception volley and android with self signed certificate'],"['im trying to make my app communicate with my server via https', 'as i dont want to pay to get my server certificate signed by a trusted ca the solution is to use a self signed certificate', 'so ive created my caconfigcnf as follows ca defaultca cadefault the default ca section cadefault dir democa top dir database dirindextxt index file', 'newcertsdir dirnewcerts new certs dir certificate dircacertpem the ca cert serial dirserial serial no file privatekey dirprivatecakeypem ca private key randfile dirprivaterand random number file defaultdays 365 how long to certify for defaultcrldays 30 how long before next crl defaultmd md5 md to use policy policyany default policy emailindn no dont add the email into cert dn nameopt cadefault subject name display option certopt cadefault certificate display option copyextensions none dont copy extensions from request policyany countryname optional stateorprovincename optional organizationname optional organizationalunitname optional commonname supplied emailaddress optional then ive created and signed my certificate using the following commands mkdir myca mycaprivate mycanewcerts echo 01 mycaserial touch democaindextxt openssl genrsa des3 out mycaprivatecakeypem 1024 openssl req new x509 days 3650 key mycaprivatecakeypem out mycacacertpem openssl req sha1 newkey rsa2048 keyout serverkeypem out servercertreqpem subj cnmyhost nodes openssl ca config caconfigcnf in servercertreqpem out servercertpem openssl x509 inform pem in cacertpem outform der out certificatecer rm servercertreqpem in my nodejs server code im creating the https server like this var express requireexpress var https requirehttps var port 443 var app express appget function req res ressendserver is working var httpsoptions key fsreadfilesyncserverkeypem cert fsreadfilesyncservercertpem httpscreateserverhttpsoptions applistenport function consolelogs node server started on port d datedatenow port in order to test if everything is correct ive also created a node client script which makes a request to my server', 'here is the code for my node client var https requirehttps var fs requirefs var request httpsrequest host myhost port 443 path method get rejectunauthorized true once it is self signed im using my server certificate public key', 'ca fsreadfilesynccacertpemtostring functionresponse responseondata functiondata consolelogdatatostring requestonerror functionerr consolelogerr requestend when i run my node client script it works perfectly', 'on the other hand the android volley examples app which im using to check how volley works with https is not working', 'below im describing all the steps ive followed in order to try to make it work', 'ive created a bks file using my certificatecer file using the following command keytool importcert v trustcacerts file certificatecer alias intermediateca keystore resrawmykeystorebks provider orgbouncycastlejceproviderbouncycastleprovider providerpath pathtobouncycastlebcprovjdk16146jar storetype bks storepass mysecret then ive verified if the certificate was imported correctly into the bks as follows keytool list keystore resrawmykeystorebks provider orgbouncycastlejceproviderbouncycastleprovider providerpath pathtobouncycastlebcprovjdk16146jar storetype bks storepass mysecret and i got the following output that means its correct keystore type bks keystore provider bc your keystore contains 1 entry imetoalias oct 16 2014 trustedcertentry certificate fingerprint sha1 03dca16a9b1dad59a99b1fc2437e80073bb6becb ive came across to this tutorial and as im using volley ive decided to follow it', 'so below are the following changes ive made to the example project', 'got volley from git clone got android volley examples project from git clone gitgithubcomogrebgrandroidvolleyexamplesgit copied mykeystorebks containing the selfsigned public key in resraw opened actsssslhttpclient in the examples project found rrawtest and replaced it with rrawmykeystore found new sslhttpclient and replaced the default password test123 with mysecret replaced 44400 with the https port of my servervirtualhost 443', 'i could also remove this parameter since 443 is the default port replaced with my server url', 'started the app went to https with selfsigned cert then execute https request but when i pressed the button i got the following exception javaxnetsslsslpeerunverifiedexception no peer certificate below is my javacode public class actsssslhttpclient extends activity private textview mtvresult override protected void oncreatebundle savedinstancestate superoncreatesavedinstancestate setcontentviewrlayoutactsssslhttpclient mtvresult textview findviewbyidridtvresult button btnsimplerequest button findviewbyidridbtnsimplerequest btnsimplerequestsetonclicklistenernew onclicklistener override public void onclickview v replace rrawtest with your keystore inputstream keystore getresourcesopenrawresourcerrawmykeystore usually getting the request queue shall be in singleton like in seeactsimplerequest current approach is used just for brevity requestqueue queue volleynewrequestqueueactsssslhttpclientthis new exthttpclientstacknew sslhttpclientkeystore mysecret stringrequest myreq new stringrequestmethodget createmyreqsuccesslistener createmyreqerrorlistener queueaddmyreq does anybody know the solution', 'thank you']"
"How to resolve ""Frame Load Interrupted"" error in UIWebView?","In an app I'm contracted to build, I'm pulling a list of YouTube videos and allowing them to be displayed in the app. However, when a user taps a cell in the YouTube view's navigation controller and the modal view with a UIWebView appears, the UIWebView returns the error ""Frame load interrupted.""
I've run it through the debugger dozens of times, and everything seems to go well until I initialize the NSURLRequest. When the modal view is displayed, here is the code that runs in the ViewController's -viewDidLoad method:
- (void)viewDidLoad
{
    [super viewDidLoad];
    _webView = [[UIWebView alloc] init];
    _webView.delegate = self;
    NSURLRequest *request = [[NSURLRequest alloc] initWithURL:_url];
    [_webView loadRequest:request];
}

However, when I pull up the debugger on the line [_webView loadRequest:request];, I see the following:

Does anyone know why the UIWebView is returning the error?
",<ios><iphone><objective-c><uiwebview><youtube>,17,"ios,iphone,objective-c,uiwebview,youtube",['how to resolve frame load interrupted error in uiwebview'],"['in an app im contracted to build im pulling a list of youtube videos and allowing them to be displayed in the app', 'however when a user taps a cell in the youtube views navigation controller and the modal view with a uiwebview appears the uiwebview returns the error frame load interrupted', 'ive run it through the debugger dozens of times and everything seems to go well until i initialize the nsurlrequest', 'when the modal view is displayed here is the code that runs in the viewcontrollers viewdidload method voidviewdidload super viewdidload webview uiwebview alloc init webviewdelegate self nsurlrequest request nsurlrequest alloc initwithurlurl webview loadrequestrequest however when i pull up the debugger on the line webview loadrequestrequest i see the following does anyone know why the uiwebview is returning the error']"
How can I call a static method on a variable class?,"I'm trying to make some kind of function that loads and instantiates a class from a given variable. Something like this:
<?php
function loadClass($class) {
  $sClassPath = SYSPATH.""/classes/{$class}.php"";
  if (file_exists($sClassPath)) {
    require_once($sClassPath);
    $class = $class::getInstance();
  }
}
?>

If I use it like this:
<?php
  loadClass('session');
?>

It should include and instantiate the session class.
BTW: the static getInstance function comes from this code:
<?php
  function getCallingClass() {
    $backtrace = debug_backtrace();
    $method    = $backtrace[1]['function'];
    $file      = file($backtrace[1]['file']);
    $line      = $file[($backtrace[1]['line'] - 1)];
    $class     = trim(preg_replace(""/^.+?([A-Za-z0-9_]*)::{$method}\(.*$/s"", ""\\1\\2"", $line));

    if(! class_exists($class)) {
      return false;
    } return $class;
  }

  class Core {

    protected static $instances = array();

    public static function getInstance() {
      $class = getCallingClass();

      if (!isset(self::$instances[$class])) {
        self::$instances[$class] = new $class();
      } return self::$instances[$class];
    }

  }

?>


The thing is that right now the way to use the functions in a class is this:
<?php
  $session = session::getInstance();
?>

But now I want to build that into a function so that I never again have to use that line of code.
I just say loadClass('session');
and than I can use $session->blablablafunction();
",<php><oop><class><function><instance>,43,"php,oop,class,function,instance",['how can i call a static method on a variable class'],"['im trying to make some kind of function that loads and instantiates a class from a given variable', 'something like this php function loadclassclass sclasspath syspath', 'classesclassphp if fileexistssclasspath requireoncesclasspath class classgetinstance if i use it like this php loadclasssession it should include and instantiate the session class', 'btw the static getinstance function comes from this code php function getcallingclass backtrace debugbacktrace method backtrace1function file filebacktrace1file line filebacktrace1line 1 class trimpregreplaceazaz09method', 's 12 line if', 'classexistsclass return false return class class core protected static instances array public static function getinstance class getcallingclass if issetselfinstancesclass selfinstancesclass new class return selfinstancesclass the thing is that right now the way to use the functions in a class is this php session sessiongetinstance but now i want to build that into a function so that i never again have to use that line of code', 'i just say loadclasssession and than i can use sessionblablablafunction']"
How to work with ellipsis in bootstrap responsive table,"In a responsive table text-overflow:ellipsis is not working when the data increases in the th (as the col-xs-2 width increases).    

Code below:


<link href=""https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css"" rel=""stylesheet"">

<div class=""table-responsive"">
  <table class=""table"">
    <thead>
      <tr>
        <th class=""col-xs-2"" style=""text-overflow: ellipsis;"">Lorem IpsumLorem IpsumLorem IpsumLorem IpsumLorem IpsumLorem IpsumLorem Ipsum</th>
        <th class=""col-xs-1"">Firstname</th>
        <th class=""col-xs-1""> Lastname</th>
        <th class=""col-xs-4"">Age</th>
        <th class=""col-xs-2"">City</th>
        <th class=""col-xs-2"">Country</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>1</td>
        <td>Anna</td>
        <td>Pitt</td>
        <td>35</td>
        <td>New York</td>
        <td>USA</td>
      </tr>
    </tbody>
  </table>
</div>



",<html><css><twitter-bootstrap><twitter-bootstrap-3><css-position>,33,"html,css,twitter-bootstrap,twitter-bootstrap-3,css-position",['how to work with ellipsis in bootstrap responsive table'],"['in a responsive table textoverflowellipsis is not working when the data increases in the th as the colxs2 width increases', 'code below link href relstylesheet div classtableresponsive table classtable thead tr th classcolxs2 styletextoverflow ellipsislorem ipsumlorem ipsumlorem ipsumlorem ipsumlorem ipsumlorem ipsumlorem ipsumth th classcolxs1firstnameth th classcolxs1 lastnameth th classcolxs4ageth th classcolxs2cityth th classcolxs2countryth tr thead tbody tr td1td tdannatd tdpitttd td35td tdnew yorktd tdusatd tr tbody table div']"
select(2) and ioctl(2) returning 0 while stdin has data,"I'm trying to detect whether there is data on stdin for me to read.
Specifically, I've turned off canonical mode using tcsetattr, so I can read one character at a time (blocking). I want to detect escape sequences like those produced by the arrow keys, but distinguish those from a lone escape key. Additionally, I want to know quickly which was entered; I'm assuming my terminal is reasonably quick and the rest of an escape sequence after the ^[ follows reasonably quickly.
Suppose I already know (e.g. using select(2)) that there's something to read on stdin. I read a character using getchar(), and it's a ^[, ASCII 27. Now I want to know whether there is more coming within a certain time interval, or this escape character is everything (which would indicate a hit of the escape key). Using select(2) for this doesn't seem to work, since (I noticed, and read elsewhere) the rest of the characters are already buffered, so select(2) has nothing to detect anymore. So I turned to ioctl(2) using FIONREAD, but that doesn't seem to work either.
Minimal (non-)working example:
#include <stdio.h>
#include <stdlib.h>
#include <termios.h>
#include <sys/select.h>
#include <sys/ioctl.h>
#include <assert.h>

struct termios tios_bak;

void initkeyboard(void){
    struct termios tios;
    tcgetattr(0,&tios_bak);
    tios=tios_bak;

    tios.c_lflag&=~ICANON;
    tios.c_cc[VMIN]=1; // Read one char at a time
    tios.c_cc[VTIME]=0; // No timeout on reading, make it a blocking read

    tcsetattr(0,TCSAFLUSH,&tios);
}

void endkeyboard(void){
    tcsetattr(0,TCSAFLUSH,&tios_bak);
}

int main(void){
    initkeyboard();
    atexit(endkeyboard);

    printf(""Press an arrow key or the escape key, or the escape key followed by something else.\n"");

    char c=getchar();
    if(c!=27){
        printf(""Please input an escape sequence or key\n"");
        exit(1);
    }

    // Now we use select(2) to determine whether there's anything more to read.
    // If it was a lone escape key, there won't be anything new in a while.
    fd_set rdset;
    FD_ZERO(&rdset);
    FD_SET(0,&rdset);
    struct timeval tv;
    tv.tv_sec=1; // Here we wait one second; this is just to illustrate. In a real environment
    tv.tv_usec=0; // I'd wait something like 100ms, since that's reasonable for a terminal.
    int ret=select(1,&rdset,NULL,NULL,&tv);

    assert(ret!=-1); // (Error checking basically omitted)
    if(ret==0){
        printf(""select(2) returned 0.\n"");
        int n;
        assert(ioctl(0,FIONREAD,&n)>=0);
        assert(n>=0);
        if(n==0){
            printf(""ioctl(2) gave 0; nothing to read: lone escape key\n"");
            // INSERT printf(""%c\n"",getchar()); HERE TO DEMONSTRATE THIS IS WRONG IN CASE OF ESCAPE SEQUENCE
        } else {
            c=getchar();
            printf(""ioctl(2) says %d bytes in read buffer (first char=%c)\n"",n,c);
        }
    } else {
        c=getchar();
        printf(""select(2) returned %d: there was more to read (first char=%c)\n"",ret,c);
    }
}

Sorry for the long code. What happens is the following:

When you just press the escape key, it successfully detects that.
When you press the escape key and then quickly some other key (like 'a'), the code successfully detects there's more to read, which is fine; specific detection of escape sequences is out of scope.
When you generate an escape sequence, e.g. by pressing an arrow key, both select(2) and ioctl(2) return there's nothing to read, while clearly there is; this can be easily checked by inserting printf(""%c\n"",getchar()); at the indicated location. That will print [ (in the case of an arrow key, at least).

Question: how to correctly detect input in case (3)?
",<c><macos><unix><select><ioctl>,5,"c,macos,unix,select,ioctl",['select2 and ioctl2 returning 0 while stdin has data'],"['im trying to detect whether there is data on stdin for me to read', 'specifically ive turned off canonical mode using tcsetattr so i can read one character at a time blocking', 'i want to detect escape sequences like those produced by the arrow keys but distinguish those from a lone escape key', 'additionally i want to know quickly which was entered im assuming my terminal is reasonably quick and the rest of an escape sequence after the follows reasonably quickly', 'suppose i already know eg', 'using select2 that theres something to read on stdin', 'i read a character using getchar and its a ascii 27 now i want to know whether there is more coming within a certain time interval or this escape character is everything which would indicate a hit of the escape key', 'using select2 for this doesnt seem to work since i noticed and read elsewhere the rest of the characters are already buffered so select2 has nothing to detect anymore', 'so i turned to ioctl2 using fionread but that doesnt seem to work either', 'minimal nonworking example include stdioh include stdlibh include termiosh include sysselecth include sysioctlh include asserth struct termios tiosbak void initkeyboardvoid struct termios tios tcgetattr0tiosbak tiostiosbak tiosclflagicanon tioscccvmin1 read one char at a time tioscccvtime0 no timeout on reading make it a blocking read tcsetattr0tcsaflushtios void endkeyboardvoid tcsetattr0tcsaflushtiosbak int mainvoid initkeyboard atexitendkeyboard printfpress an arrow key or the escape key or the escape key followed by something elsen char cgetchar ifc27 printfplease input an escape sequence or keyn exit1 now we use select2 to determine whether theres anything more to read', ' if it was a lone escape key there wont be anything new in a while', 'fdset rdset fdzerordset fdset0rdset struct timeval tv tvtvsec1 here we wait one second this is just to illustrate', 'in a real environment tvtvusec0 id wait something like 100ms since thats reasonable for a terminal', 'int retselect1rdsetnullnulltv assertret1 error checking basically omitted ifret0 printfselect2 returned 0n int n assertioctl0fionreadn0 assertn0 ifn0 printfioctl2 gave 0 nothing to read lone escape keyn insert printfcngetchar here to demonstrate this is wrong in case of escape sequence else cgetchar printfioctl2 says d bytes in read buffer first charcnnc else cgetchar printfselect2 returned d there was more to read first charcnretc sorry for the long code', 'what happens is the following when you just press the escape key it successfully detects that', 'when you press the escape key and then quickly some other key like a the code successfully detects theres more to read which is fine specific detection of escape sequences is out of scope', 'when you generate an escape sequence eg', 'by pressing an arrow key both select2 and ioctl2 return theres nothing to read while clearly there is this can be easily checked by inserting printfcngetchar at the indicated location', 'that will print in the case of an arrow key at least', 'question how to correctly detect input in case 3']"
Django to serve generated excel file,"I looked at the various questions similar to mine, but I could not find anything a fix for my problem.
In my code, I want to serve a freshly generated excel file residing in my app directory in a folder named files
excelFile = ExcelCreator.ExcelCreator(""test"")
excelFile.create()
response = HttpResponse(content_type='application/vnd.ms-excel')
response['Content-Disposition'] = 'attachment; filename=""test.xls""'
return response

So when I click on the button that run this part of the code, it sends to the user an empty file. By looking at my code, I can understand that behavior because I don't point to that file within my response...
I saw some people use the file wrapper (which I don't quite understand the use). So I did like that:
response = HttpResponse(FileWrapper(excelFile.file),content_type='application/vnd.ms-excel')

But then, I receive the error message from server : A server error occurred.  Please contact the administrator.
Thanks for helping me in my Django quest, I'm getting better with all of your precious advices!
",<django><excel><file><httpresponse><serve>,5,"django,excel,file,httpresponse,serve",['django to serve generated excel file'],"['i looked at the various questions similar to mine but i could not find anything a fix for my problem', 'in my code i want to serve a freshly generated excel file residing in my app directory in a folder named files excelfile excelcreatorexcelcreatortest excelfilecreate response httpresponsecontenttypeapplicationvndmsexcel responsecontentdisposition attachment filenametestxls return response so when i click on the button that run this part of the code it sends to the user an empty file', 'by looking at my code i can understand that behavior because i dont point to that file within my response i saw some people use the file wrapper which i dont quite understand the use', 'so i did like that response httpresponsefilewrapperexcelfilefilecontenttypeapplicationvndmsexcel but then i receive the error message from server a server error occurred', 'please contact the administrator', 'thanks for helping me in my django quest im getting better with all of your precious advices']"
"Unable to hide ""Chrome is being controlled by automated software"" infobar within Chrome v76","After updating Chrome to version 76, I cannot figure out how to hide the ""Chrome is being controlled by automated software..."" notification overriding some controls on the page.
The latest stable release of ChromeDriver is indeed 76.0.3809.68.
The following code worked with Chrome 75 and ChromeDriver 74.
var options = new ChromeOptions();
options.AddArgument(""--test-type"");
options.AddArgument(""--disable-extensions"");
options.AddArguments(""disable-infobars"");
options.AddArguments(""--disable-notifications"");
options.AddArguments(""enable-automation"");
options.AddArguments(""--disable-popup-blocking"");
options.AddArguments(""start-maximized"");
var driver = new ChromeDriver(driverLocation, options, ScriptTimeout);

",<c#><selenium><google-chrome><selenium-webdriver><selenium-chromedriver>,35,"c#,selenium,google-chrome,selenium-webdriver,selenium-chromedriver",['unable to hide chrome is being controlled by automated software infobar within chrome v76'],"['after updating chrome to version 76 i cannot figure out how to hide the chrome is being controlled by automated software notification overriding some controls on the page', 'the latest stable release of chromedriver is indeed 760380968 the following code worked with chrome 75 and chromedriver 74 var options new chromeoptions optionsaddargumenttesttype optionsaddargumentdisableextensions optionsaddargumentsdisableinfobars optionsaddargumentsdisablenotifications optionsaddargumentsenableautomation optionsaddargumentsdisablepopupblocking optionsaddargumentsstartmaximized var driver new chromedriverdriverlocation options scripttimeout']"
Why does iOS terminate my app even when I free lots of memory in response to memory warnings?,"I can't figure out why iOS is terminating my app (iPad, iOS 4) due to memory usage even after I free a ton of memory in response to low-memory warnings. For example, here's a typical termination scenario, with me logging memory usage every so often -- look at the ""app"" usage, the first KB value on each line:
...
2011-12-14 13:25:42.343 Oyster[211:707] Memory usage (KB): app 268256, delta 6472, used 366800/373940
2011-12-14 13:25:43.292 Oyster[211:707] Memory usage (KB): app 273900, delta 5644, used 372444/381024
2011-12-14 13:25:44.159 Oyster[211:707] Memory usage (KB): app 282920, delta 9020, used 381464/389116
2011-12-14 13:25:45.184 Oyster[211:707] Memory usage (KB): app 272140, delta -10780, used 370684/379432
2011-12-14 13:25:46.109 Oyster[211:707] Memory usage (KB): app 260412, delta -11728, used 358956/365900
2011-12-14 13:25:48.443 Oyster[211:707] Received memory warning. Level=2
2011-12-14 13:25:48.454 Oyster[211:707] Memory usage (KB): app 9172, delta -251240, used 107716/112548
(gdb)

You can see app memory usage increasing till it gets a memory warning. Then I correctly respond to the memory warning and free a bunch (250MB!) of memory. At that point my app is terminated and iOS goes to the iPad home screen.
The ""Memory usage"" logs here are displayed with my logMemoryUsage() function which is based on code from this answer.
For the record, I'm using SDWebImage to cache UIImages in memory, but as shown, it handles memory warnings by emptying its cache (rather large at this point). I realize I could tweak SDWebImage's caching to not fill all available memory and just wait for memory warnings, but that begs the following question...
Why is iOS terminating my app, even though I'm responding to memory warnings by happily freeing a ton of memory?
",<objective-c><ios><memory-management><terminate><sdwebimage>,8,"objective-c,ios,memory-management,terminate,sdwebimage",['why does ios terminate my app even when i free lots of memory in response to memory warnings'],"['i cant figure out why ios is terminating my app ipad ios 4 due to memory usage even after i free a ton of memory in response to lowmemory warnings', 'for example heres a typical termination scenario with me logging memory usage every so often look at the app usage the first kb value on each line 20111214 132542343 oyster211707 memory usage kb app 268256 delta 6472 used 366800373940 20111214 132543292 oyster211707 memory usage kb app 273900 delta 5644 used 372444381024 20111214 132544159 oyster211707 memory usage kb app 282920 delta 9020 used 381464389116 20111214 132545184 oyster211707 memory usage kb app 272140 delta 10780 used 370684379432 20111214 132546109 oyster211707 memory usage kb app 260412 delta 11728 used 358956365900 20111214 132548443 oyster211707 received memory warning', 'level2 20111214 132548454 oyster211707 memory usage kb app 9172 delta 251240 used 107716112548 gdb you can see app memory usage increasing till it gets a memory warning', 'then i correctly respond to the memory warning and free a bunch 250mb', 'of memory', 'at that point my app is terminated and ios goes to the ipad home screen', 'the memory usage logs here are displayed with my logmemoryusage function which is based on code from this answer', 'for the record im using sdwebimage to cache uiimages in memory but as shown it handles memory warnings by emptying its cache rather large at this point', 'i realize i could tweak sdwebimages caching to not fill all available memory and just wait for memory warnings but that begs the following question why is ios terminating my app even though im responding to memory warnings by happily freeing a ton of memory']"
Can you convert the output of php crypt() to valid MD5?,"I have some strings that have been encrypted using the PHP function crypt().
The outputs look something like this:
$1$Vf/.4.1.$CgCo33ebiHVuFhpwS.kMI0
$1$84..vD4.$Ps1PdaLWRoaiWDKCfjLyV1
$1$or1.RY4.$v3xo04v1yfB7JxDj1sC/J/

While I believe crypt() is using the MD5 algorithm, the outputs are not valid MD5 hashes.
Is there a way of converting the produced hashes into valid MD5 hashes (16-byte hex values)?

Update:
Thanks for the replies so answers so far.  I'm pretty sure the crypt function used is using some sort of MD5 algorithm.  What I'm looking to do is convert the ouput that I have into an MD5 hash that looks something like the following:
9e107d9d372bb6826bd81d3542a419d6  
e4d909c290d0fb1ca068ffaddf22cbd0  
d41d8cd98f00b204e9800998ecf8427e

(taken from Wikipedia)
Is there a way of converting from the hashes I have to ones like the above?
",<php><hash><cryptography><md5><crypt>,6,"php,hash,cryptography,md5,crypt",['can you convert the output of php crypt to valid md5'],"['i have some strings that have been encrypted using the php function crypt', 'the outputs look something like this 1vf41cgco33ebihvufhpwskmi0 184vd4ps1pdalwroaiwdkcfjlyv1 1or1ry4v3xo04v1yfb7jxdj1scj while i believe crypt is using the md5 algorithm the outputs are not valid md5 hashes', 'is there a way of converting the produced hashes into valid md5 hashes 16byte hex values', 'update thanks for the replies so answers so far', 'im pretty sure the crypt function used is using some sort of md5 algorithm', 'what im looking to do is convert the ouput that i have into an md5 hash that looks something like the following 9e107d9d372bb6826bd81d3542a419d6 e4d909c290d0fb1ca068ffaddf22cbd0 d41d8cd98f00b204e9800998ecf8427e taken from wikipedia is there a way of converting from the hashes i have to ones like the above']"
How to get current index in Array prototype map?,"I'm using Array.prototype.map.call to store in an array a bunch of node list objects:
function getListings() {
    return Array.prototype.map.call(document.querySelectorAll('li.g'), function(e) {
         return {
             rectangle: e.getBoundingClientRect();
         }
    }
}

However, I also want to store the order in which this elements appear in the DOM, and I don't know how to do that. 
I know that I'm storing this in an array, and the order would be the index of the array. For example:
var listings = getListings();
console.log(listings[0]); // rank #1
console.log(listings[1]); // rank #2
// etc...

but I'm inserting the json object in a database, and the easiest way to store the ""rank"" information is by creating a property ""rank"" in my object, but I don't know how to get the ""index"" of the current array. 
Something like:
function getListings() {
    return Array.prototype.map.call(document.querySelectorAll('li.g'), function(e) {
         return {
             rectangle: e.getBoundingClientRect(),
             rank: magicFunctionThatReturnsCurrentIndex() // <-- magic happens
         }
    }
}

Any help pointing me to the right direction will be greatly appreciated! Thanks
",<javascript><arrays><dom><prototypejs><prototype>,12,"javascript,arrays,dom,prototypejs,prototype",['how to get current index in array prototype map'],"['im using arrayprototypemapcall to store in an array a bunch of node list objects function getlistings return arrayprototypemapcalldocumentqueryselectoralllig functione return rectangle egetboundingclientrect however i also want to store the order in which this elements appear in the dom and i dont know how to do that', 'i know that im storing this in an array and the order would be the index of the array', 'for example var listings getlistings consoleloglistings0 rank 1 consoleloglistings1 rank 2 etc but im inserting the json object in a database and the easiest way to store the rank information is by creating a property rank in my object but i dont know how to get the index of the current array', 'something like function getlistings return arrayprototypemapcalldocumentqueryselectoralllig functione return rectangle egetboundingclientrect rank magicfunctionthatreturnscurrentindex magic happens any help pointing me to the right direction will be greatly appreciated', 'thanks']"
PowerMock will not work with JAXB Unmarshal,"I'm creating a test case wherein, I input xml and unmarshal it to procced with processing. I'm trying to use PowerMock and I keep getting
javax.xml.bind.UnmarshalException: unexpected element (uri:""http://www.xxxxxxx.org/xxxxx/xx/xx"", local:""Element""). Expected elements are <{}NotifRQ>,<{http://www.xxxxxxx.org/xxxxx/xx/xx}NotifRS>,etc
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.UnmarshallingContext.handleEvent(UnmarshallingContext.java:659)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.Loader.reportError(Loader.java:255)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.Loader.reportError(Loader.java:250)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.Loader.reportUnexpectedChildElement(Loader.java:117)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.UnmarshallingContext$DefaultRootLoader.childElement(UnmarshallingContext.java:1060)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.UnmarshallingContext._startElement(UnmarshallingContext.java:495)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.UnmarshallingContext.startElement(UnmarshallingContext.java:477)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.SAXConnector.startElement(SAXConnector.java:147)
    at org.apache.xerces.parsers.AbstractSAXParser.startElement(Unknown Source)
    at org.apache.xerces.impl.XMLNSDocumentScannerImpl.scanStartElement(Unknown Source)
    at org.apache.xerces.impl.XMLNSDocumentScannerImpl$NSContentDispatcher.scanRootElementHook(Unknown Source)
    at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl$FragmentContentDispatcher.dispatch(Unknown Source)
    at org.apache.xerces.impl.XMLDocumentFragmentScannerImpl.scanDocument(Unknown Source)
    at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
    at org.apache.xerces.parsers.XML11Configuration.parse(Unknown Source)
    at org.apache.xerces.parsers.XMLParser.parse(Unknown Source)
    at org.apache.xerces.parsers.AbstractSAXParser.parse(Unknown Source)
    at org.apache.xerces.jaxp.SAXParserImpl$JAXPSAXParser.parse(Unknown Source)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal0(UnmarshallerImpl.java:220)
    at com.sun.xml.internal.bind.v2.runtime.unmarshaller.UnmarshallerImpl.unmarshal(UnmarshallerImpl.java:192)
    at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:136)
    at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:141)
    at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:150)
    at javax.xml.bind.helpers.AbstractUnmarshallerImpl.unmarshal(AbstractUnmarshallerImpl.java:168)
    -------sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:88)
    at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:55)
    at java.lang.reflect.Method.invoke(Method.java:613)
    at org.junit.internal.runners.TestMethod.invoke(TestMethod.java:66)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:310)
    at org.junit.internal.runners.MethodRoadie$2.run(MethodRoadie.java:86)
    at org.junit.internal.runners.MethodRoadie.runBeforesThenTestThenAfters(MethodRoadie.java:94)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.executeTest(PowerMockJUnit44RunnerDelegateImpl.java:294)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit47RunnerDelegateImpl$PowerMockJUnit47MethodRunner.executeTestInSuper(PowerMockJUnit47RunnerDelegateImpl.java:127)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit47RunnerDelegateImpl$PowerMockJUnit47MethodRunner.executeTest(PowerMockJUnit47RunnerDelegateImpl.java:82)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$PowerMockJUnit44MethodRunner.runBeforesThenTestThenAfters(PowerMockJUnit44RunnerDelegateImpl.java:282)
    at org.junit.internal.runners.MethodRoadie.runTest(MethodRoadie.java:84)
    at org.junit.internal.runners.MethodRoadie.run(MethodRoadie.java:49)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.invokeTestMethod(PowerMockJUnit44RunnerDelegateImpl.java:207)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.runMethods(PowerMockJUnit44RunnerDelegateImpl.java:146)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl$1.run(PowerMockJUnit44RunnerDelegateImpl.java:120)
    at org.junit.internal.runners.ClassRoadie.runUnprotected(ClassRoadie.java:34)
    at org.junit.internal.runners.ClassRoadie.runProtected(ClassRoadie.java:44)
    at org.powermock.modules.junit4.internal.impl.PowerMockJUnit44RunnerDelegateImpl.run(PowerMockJUnit44RunnerDelegateImpl.java:122)
    at org.powermock.modules.junit4.common.internal.impl.JUnit4TestSuiteChunkerImpl.run(JUnit4TestSuiteChunkerImpl.java:106)
    at org.powermock.modules.junit4.common.internal.impl.AbstractCommonPowerMockRunner.run(AbstractCommonPowerMockRunner.java:53)
    at org.powermock.modules.junit4.PowerMockRunner.run(PowerMockRunner.java:59)
    at org.eclipse.jdt.internal.junit4.runner.JUnit4TestReference.run(JUnit4TestReference.java:49)
    at org.eclipse.jdt.internal.junit.runner.TestExecution.run(TestExecution.java:38)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:467)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.runTests(RemoteTestRunner.java:683)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.run(RemoteTestRunner.java:390)
    at org.eclipse.jdt.internal.junit.runner.RemoteTestRunner.main(RemoteTestRunner.java:197)

I unmarshal it in this Fashion:
JAXBContext jaxbContext = JAXBContext.newInstance(NotifRQ.class);
        Unmarshaller unmarshaller = jaxbContext.createUnmarshaller();
        NotifRQ notifRQ= (NotifRQ) unmarshaller.unmarshal(new File(""filename""));

",<java><xml><jaxb><junit4><powermock>,7,"java,xml,jaxb,junit4,powermock",['powermock will not work with jaxb unmarshal'],"['im creating a test case wherein i input xml and unmarshal it to procced with processing', 'im trying to use powermock and i keep getting javaxxmlbindunmarshalexception unexpected element uri localelement', 'expected elements are notifrq at comsunxmlinternalbindv2runtimeunmarshallerunmarshallingcontexthandleeventunmarshallingcontextjava659 at comsunxmlinternalbindv2runtimeunmarshallerloaderreporterrorloaderjava255 at comsunxmlinternalbindv2runtimeunmarshallerloaderreporterrorloaderjava250 at comsunxmlinternalbindv2runtimeunmarshallerloaderreportunexpectedchildelementloaderjava117 at comsunxmlinternalbindv2runtimeunmarshallerunmarshallingcontextdefaultrootloaderchildelementunmarshallingcontextjava1060 at comsunxmlinternalbindv2runtimeunmarshallerunmarshallingcontextstartelementunmarshallingcontextjava495 at comsunxmlinternalbindv2runtimeunmarshallerunmarshallingcontextstartelementunmarshallingcontextjava477 at comsunxmlinternalbindv2runtimeunmarshallersaxconnectorstartelementsaxconnectorjava147 at orgapachexercesparsersabstractsaxparserstartelementunknown source at orgapachexercesimplxmlnsdocumentscannerimplscanstartelementunknown source at orgapachexercesimplxmlnsdocumentscannerimplnscontentdispatcherscanrootelementhookunknown source at orgapachexercesimplxmldocumentfragmentscannerimplfragmentcontentdispatcherdispatchunknown source at orgapachexercesimplxmldocumentfragmentscannerimplscandocumentunknown source at orgapachexercesparsersxml11configurationparseunknown source at orgapachexercesparsersxml11configurationparseunknown source at orgapachexercesparsersxmlparserparseunknown source at orgapachexercesparsersabstractsaxparserparseunknown source at orgapachexercesjaxpsaxparserimpljaxpsaxparserparseunknown source at comsunxmlinternalbindv2runtimeunmarshallerunmarshallerimplunmarshal0unmarshallerimpljava220 at comsunxmlinternalbindv2runtimeunmarshallerunmarshallerimplunmarshalunmarshallerimpljava192 at javaxxmlbindhelpersabstractunmarshallerimplunmarshalabstractunmarshallerimpljava136 at javaxxmlbindhelpersabstractunmarshallerimplunmarshalabstractunmarshallerimpljava141 at javaxxmlbindhelpersabstractunmarshallerimplunmarshalabstractunmarshallerimpljava150 at javaxxmlbindhelpersabstractunmarshallerimplunmarshalabstractunmarshallerimpljava168 sunreflectnativemethodaccessorimplinvokenativemethodaccessorimpljava88 at sunreflectdelegatingmethodaccessorimplinvokedelegatingmethodaccessorimpljava55 at javalangreflectmethodinvokemethodjava613 at orgjunitinternalrunnerstestmethodinvoketestmethodjava66 at orgpowermockmodulesjunit4internalimplpowermockjunit44runnerdelegateimplpowermockjunit44methodrunnerruntestmethodpowermockjunit44runnerdelegateimpljava310 at orgjunitinternalrunnersmethodroadie2runmethodroadiejava86 at orgjunitinternalrunnersmethodroadierunbeforesthentestthenaftersmethodroadiejava94 at orgpowermockmodulesjunit4internalimplpowermockjunit44runnerdelegateimplpowermockjunit44methodrunnerexecutetestpowermockjunit44runnerdelegateimpljava294 at orgpowermockmodulesjunit4internalimplpowermockjunit47runnerdelegateimplpowermockjunit47methodrunnerexecutetestinsuperpowermockjunit47runnerdelegateimpljava127 at orgpowermockmodulesjunit4internalimplpowermockjunit47runnerdelegateimplpowermockjunit47methodrunnerexecutetestpowermockjunit47runnerdelegateimpljava82 at orgpowermockmodulesjunit4internalimplpowermockjunit44runnerdelegateimplpowermockjunit44methodrunnerrunbeforesthentestthenafterspowermockjunit44runnerdelegateimpljava282 at orgjunitinternalrunnersmethodroadieruntestmethodroadiejava84 at orgjunitinternalrunnersmethodroadierunmethodroadiejava49 at orgpowermockmodulesjunit4internalimplpowermockjunit44runnerdelegateimplinvoketestmethodpowermockjunit44runnerdelegateimpljava207 at orgpowermockmodulesjunit4internalimplpowermockjunit44runnerdelegateimplrunmethodspowermockjunit44runnerdelegateimpljava146 at orgpowermockmodulesjunit4internalimplpowermockjunit44runnerdelegateimpl1runpowermockjunit44runnerdelegateimpljava120 at orgjunitinternalrunnersclassroadierununprotectedclassroadiejava34 at orgjunitinternalrunnersclassroadierunprotectedclassroadiejava44 at orgpowermockmodulesjunit4internalimplpowermockjunit44runnerdelegateimplrunpowermockjunit44runnerdelegateimpljava122 at orgpowermockmodulesjunit4commoninternalimpljunit4testsuitechunkerimplrunjunit4testsuitechunkerimpljava106 at orgpowermockmodulesjunit4commoninternalimplabstractcommonpowermockrunnerrunabstractcommonpowermockrunnerjava53 at orgpowermockmodulesjunit4powermockrunnerrunpowermockrunnerjava59 at orgeclipsejdtinternaljunit4runnerjunit4testreferencerunjunit4testreferencejava49 at orgeclipsejdtinternaljunitrunnertestexecutionruntestexecutionjava38 at orgeclipsejdtinternaljunitrunnerremotetestrunnerruntestsremotetestrunnerjava467 at orgeclipsejdtinternaljunitrunnerremotetestrunnerruntestsremotetestrunnerjava683 at orgeclipsejdtinternaljunitrunnerremotetestrunnerrunremotetestrunnerjava390 at orgeclipsejdtinternaljunitrunnerremotetestrunnermainremotetestrunnerjava197 i unmarshal it in this fashion jaxbcontext jaxbcontext jaxbcontextnewinstancenotifrqclass unmarshaller unmarshaller jaxbcontextcreateunmarshaller notifrq notifrq notifrq unmarshallerunmarshalnew filefilename']"
How to make discrete Fourier transform (FFT) in numba.njit?,"Hello fellow programmers
I am trying to make a discrete Fourier transform in this minimal working example with the numba.njit decorator:
import numba
import numpy as np
import scipy
import scipy.fftpack

@numba.njit
def main():
    wave = [[[0.09254795,  0.10001078,  0.10744892, 0.07755555,  0.08506225, 0.09254795],
          [0.09907245,  0.10706145,  0.11502401,  0.08302302,  0.09105898, 0.09907245],
          [0.09565098,  0.10336405,  0.11105158,  0.08015589,  0.08791429, 0.09565098],
          [0.00181467,  0.001961,    0.00210684,  0.0015207,   0.00166789, 0.00181467]],
         [[-0.45816267, - 0.46058367, - 0.46289091, - 0.45298182, - 0.45562851, -0.45816267],
          [-0.49046506, - 0.49305676, - 0.49552669, - 0.48491893, - 0.48775223, -0.49046506],
          [-0.47352483, - 0.47602701, - 0.47841162, - 0.46817027, - 0.4709057, -0.47352483],
          [-0.00898358, - 0.00903105, - 0.00907629, - 0.008882, - 0.00893389, -0.00898358]],
         [[0.36561472,  0.36057289,  0.355442,  0.37542627,  0.37056626, 0.36561472],
          [0.39139261,  0.38599531,  0.38050268,  0.40189591,  0.39669325, 0.39139261],
          [0.37787385,  0.37266296,  0.36736003,  0.38801438,  0.38299141, 0.37787385],
          [0.00716892,  0.00707006,  0.00696945,  0.0073613,  0.00726601, 0.00716892]]]

    new_fft = scipy.fftpack.fft(wave)


if __name__ == '__main__':
    main()

Output:
C:\Users\Artur\Anaconda\python.exe C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py
Traceback (most recent call last):
  File ""C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py"", line 25, in <module>
    main()
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\dispatcher.py"", line 401, in _compile_for_args
    error_rewrite(e, 'typing')
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\dispatcher.py"", line 344, in error_rewrite
    reraise(type(e), e, None)
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\utils.py"", line 80, in reraise
    raise value.with_traceback(tb)
numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)
Unknown attribute 'fft' of type Module(<module 'scipy.fftpack' from 'C:\\Users\\Artur\\Anaconda\\lib\\site-packages\\scipy\\fftpack\\__init__.py'>)

File ""test2.py"", line 21:
def main():
    <source elided>

    new_fft = scipy.fftpack.fft(wave)
    ^

[1] During: typing of get attribute at C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py (21)

File ""test2.py"", line 21:
def main():
    <source elided>

    new_fft = scipy.fftpack.fft(wave)
    ^


Process finished with exit code 1

Unfortunately scipy.fftpack.fft seems to be a legacy function that is not supported by numba. So I searched for alternatives. I found two:
1.
scipy.fft(wave) which is the updated version of the above mentioned legacy function. It produces this error output:
C:\Users\Artur\Anaconda\python.exe C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py
Traceback (most recent call last):
  File ""C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py"", line 25, in <module>
    main()
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\dispatcher.py"", line 401, in _compile_for_args
    error_rewrite(e, 'typing')
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\dispatcher.py"", line 344, in error_rewrite
    reraise(type(e), e, None)
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\utils.py"", line 80, in reraise
    raise value.with_traceback(tb)
numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)
Invalid use of Module(<module 'scipy.fft' from 'C:\\Users\\Artur\\Anaconda\\lib\\site-packages\\scipy\\fft\\__init__.py'>) with parameters (list(list(list(float64))))
No type info available for Module(<module 'scipy.fft' from 'C:\\Users\\Artur\\Anaconda\\lib\\site-packages\\scipy\\fft\\__init__.py'>) as a callable.
[1] During: resolving callee type: Module(<module 'scipy.fft' from 'C:\\Users\\Artur\\Anaconda\\lib\\site-packages\\scipy\\fft\\__init__.py'>)
[2] During: typing of call at C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py (21)


File ""test2.py"", line 21:
def main():
    <source elided>

    new_fft = scipy.fft(wave)
    ^


Process finished with exit code 1

2.
np.fft.fft(wave) which seems to be supported but also produces an error:
C:\Users\Artur\Anaconda\python.exe C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py
Traceback (most recent call last):
  File ""C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py"", line 25, in <module>
    main()
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\dispatcher.py"", line 401, in _compile_for_args
    error_rewrite(e, 'typing')
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\dispatcher.py"", line 344, in error_rewrite
    reraise(type(e), e, None)
  File ""C:\Users\Artur\Anaconda\lib\site-packages\numba\core\utils.py"", line 80, in reraise
    raise value.with_traceback(tb)
numba.core.errors.TypingError: Failed in nopython mode pipeline (step: nopython frontend)
Unknown attribute 'fft' of type Module(<module 'numpy.fft' from 'C:\\Users\\Artur\\Anaconda\\lib\\site-packages\\numpy\\fft\\__init__.py'>)

File ""test2.py"", line 21:
def main():
    <source elided>

    new_fft = np.fft.fft(wave)
    ^

[1] During: typing of get attribute at C:/Users/Artur/Desktop/RL_framework/help_functions/test2.py (21)

File ""test2.py"", line 21:
def main():
    <source elided>

    new_fft = np.fft.fft(wave)
    ^


Process finished with exit code 1

Do you know a fft function, that works with the numba.njit decorator?
",<python><numpy><scipy><fft><numba>,8,"python,numpy,scipy,fft,numba",['how to make discrete fourier transform fft in numbanjit'],"['hello fellow programmers i am trying to make a discrete fourier transform in this minimal working example with the numbanjit decorator import numba import numpy as np import scipy import scipyfftpack numbanjit def main wave 009254795 010001078 010744892 007755555 008506225 009254795 009907245 010706145 011502401 008302302 009105898 009907245 009565098 010336405 011105158 008015589 008791429 009565098 000181467 0001961 000210684 00015207 000166789 000181467 045816267 046058367 046289091 045298182 045562851 045816267 049046506 049305676 049552669 048491893 048775223 049046506 047352483 047602701 047841162 046817027 04709057 047352483 000898358 000903105 000907629 0008882 000893389 000898358 036561472 036057289 0355442 037542627 037056626 036561472 039139261 038599531 038050268 040189591 039669325 039139261 037787385 037266296 036736003 038801438 038299141 037787385 000716892 000707006 000696945 00073613 000726601 000716892 newfft scipyfftpackfftwave if name main main output cusersarturanacondapythonexe cusersarturdesktoprlframeworkhelpfunctionstest2py traceback most recent call last file cusersarturdesktoprlframeworkhelpfunctionstest2py line 25 in module main file cusersarturanacondalibsitepackagesnumbacoredispatcherpy line 401 in compileforargs errorrewritee typing file cusersarturanacondalibsitepackagesnumbacoredispatcherpy line 344 in errorrewrite reraisetypee e none file cusersarturanacondalibsitepackagesnumbacoreutilspy line 80 in reraise raise valuewithtracebacktb numbacoreerrorstypingerror failed in nopython mode pipeline step nopython frontend unknown attribute fft of type modulemodule scipyfftpack from cusersarturanacondalibsitepackagesscipyfftpackinitpy file test2py line 21 def main source elided newfft scipyfftpackfftwave 1 during typing of get attribute at cusersarturdesktoprlframeworkhelpfunctionstest2py 21 file test2py line 21 def main source elided newfft scipyfftpackfftwave process finished with exit code 1 unfortunately scipyfftpackfft seems to be a legacy function that is not supported by numba', 'so i searched for alternatives', 'i found two 1 scipyfftwave which is the updated version of the above mentioned legacy function', 'it produces this error output cusersarturanacondapythonexe cusersarturdesktoprlframeworkhelpfunctionstest2py traceback most recent call last file cusersarturdesktoprlframeworkhelpfunctionstest2py line 25 in module main file cusersarturanacondalibsitepackagesnumbacoredispatcherpy line 401 in compileforargs errorrewritee typing file cusersarturanacondalibsitepackagesnumbacoredispatcherpy line 344 in errorrewrite reraisetypee e none file cusersarturanacondalibsitepackagesnumbacoreutilspy line 80 in reraise raise valuewithtracebacktb numbacoreerrorstypingerror failed in nopython mode pipeline step nopython frontend invalid use of modulemodule scipyfft from cusersarturanacondalibsitepackagesscipyfftinitpy with parameters listlistlistfloat64 no type info available for modulemodule scipyfft from cusersarturanacondalibsitepackagesscipyfftinitpy as a callable', '1 during resolving callee type modulemodule scipyfft from cusersarturanacondalibsitepackagesscipyfftinitpy 2 during typing of call at cusersarturdesktoprlframeworkhelpfunctionstest2py 21 file test2py line 21 def main source elided newfft scipyfftwave process finished with exit code 1 2 npfftfftwave which seems to be supported but also produces an error cusersarturanacondapythonexe cusersarturdesktoprlframeworkhelpfunctionstest2py traceback most recent call last file cusersarturdesktoprlframeworkhelpfunctionstest2py line 25 in module main file cusersarturanacondalibsitepackagesnumbacoredispatcherpy line 401 in compileforargs errorrewritee typing file cusersarturanacondalibsitepackagesnumbacoredispatcherpy line 344 in errorrewrite reraisetypee e none file cusersarturanacondalibsitepackagesnumbacoreutilspy line 80 in reraise raise valuewithtracebacktb numbacoreerrorstypingerror failed in nopython mode pipeline step nopython frontend unknown attribute fft of type modulemodule numpyfft from cusersarturanacondalibsitepackagesnumpyfftinitpy file test2py line 21 def main source elided newfft npfftfftwave 1 during typing of get attribute at cusersarturdesktoprlframeworkhelpfunctionstest2py 21 file test2py line 21 def main source elided newfft npfftfftwave process finished with exit code 1 do you know a fft function that works with the numbanjit decorator']"
AmCharts 4 Donut Graph - HyperLink for Custom URL,"I'm unable to get a hyperlink to this donut chart in amcharts4. I made it successfully using amcharts 3 but am not getting it in amcharts4.
Please let me know what I am doing wrong.
I also referred to another documentation but was unable to get help from it.
Here is my script:
am4core.ready(function() {

// Themes begin
am4core.useTheme(am4themes_animated);
// Themes end

var chart = am4core.create(""chartdiv"", am4charts.PieChart3D);
chart.hiddenState.properties.opacity = 0; // this creates initial fade-in

chart.data = [
  {
    country: ""India"",
    litres: 501.9,
    url:""amcharts.com/docs/v4/tutorials/clickable-links-in-tooltips/""
  },
  {
    country: ""Czech Republic"",
    litres: 301.9,
    url:""amcharts.com/docs/v4/tutorials/clickable-links-in-tooltips/""
  },
  {
    country: ""China"",
    litres: 201.1,
    url:""amcharts.com/docs/v4/tutorials/clickable-links-in-tooltips/""
  },
  {
    country: ""Germany"",
    litres: 165.8,
    url:""amcharts.com/docs/v4/tutorials/clickable-links-in-tooltips/""
  },
  {
    country: ""Australia"",
    litres: 139.9,
    url:""amcharts.com/docs/v4/tutorials/clickable-links-in-tooltips/""
  },
  {
    country: ""Japan"",
    litres: 128.3,
    url:""amcharts.com/docs/v4/tutorials/clickable-links-in-tooltips/""
  }
];


chart.innerRadius = am4core.percent(40);
chart.depth = 120;

chart.legend = new am4charts.Legend();

var series = chart.series.push(new am4charts.PieSeries3D());
series.dataFields.value = ""litres"";
series.dataFields.depthValue = ""litres"";
series.dataFields.category = ""country"";
series.slices.template.cornerRadius = 5;
series.colors.step = 3;
series.urlField= ""url"";
series.urlTarge= ""_blank""

}); // end am4core.ready()

Here is the HTML Part:
<div id=""chartdiv""></div>

And The Css
<style>
#chartdiv {
  width: 100%;
  height: 500px;
}

</style>

",<javascript><charts><hyperlink><amcharts><donut-chart>,6,"javascript,charts,hyperlink,amcharts,donut-chart",['amcharts 4 donut graph hyperlink for custom url'],"['im unable to get a hyperlink to this donut chart in amcharts4', 'i made it successfully using amcharts 3 but am not getting it in amcharts4', 'please let me know what i am doing wrong', 'i also referred to another documentation but was unable to get help from it', 'here is my script am4corereadyfunction themes begin am4coreusethemeam4themesanimated themes end var chart am4corecreatechartdiv am4chartspiechart3d charthiddenstatepropertiesopacity 0 this creates initial fadein chartdata country india litres 5019 urlamchartscomdocsv4tutorialsclickablelinksintooltips country czech republic litres 3019 urlamchartscomdocsv4tutorialsclickablelinksintooltips country china litres 2011 urlamchartscomdocsv4tutorialsclickablelinksintooltips country germany litres 1658 urlamchartscomdocsv4tutorialsclickablelinksintooltips country australia litres 1399 urlamchartscomdocsv4tutorialsclickablelinksintooltips country japan litres 1283 urlamchartscomdocsv4tutorialsclickablelinksintooltips chartinnerradius am4corepercent40 chartdepth 120 chartlegend new am4chartslegend var series chartseriespushnew am4chartspieseries3d seriesdatafieldsvalue litres seriesdatafieldsdepthvalue litres seriesdatafieldscategory country seriesslicestemplatecornerradius 5 seriescolorsstep 3 seriesurlfield url seriesurltarge blank end am4coreready here is the html part div idchartdivdiv and the css style chartdiv width 100 height 500px style']"
First Name Variations in a Database,"I am trying to determine what the best way is to find variations of a first name in a database.  For example, I search for Bill Smith.  I would like it return ""Bill Smith"", obviously, but I would also like it to return ""William Smith"", or ""Billy Smith"", or even ""Willy Smith"".  My initial thought was to build a first name hierarchy, but I do not know where I could obtain such data, if it even exists.
Since users can search the directory, I thought this would be a key feature.  For example, people I went to school with called me Joe, but I always go by Joseph now.  So, I was looking at doing a phonetic search on the last name, either with NYSIIS or Double Metaphone and then searching on the first name using this name heirarchy.  Is there a better way to do this - maybe some sort of graded relevance using a full text search on the full name instead of a two part search on the first and last name?  Part of me thinks that if I stored a name as a single value instead of multiple values, it might facilitate more search options at the expense of being able to address a user by the first name.
As far as platform, I am using SQL Server 2005 - however, I don't have a problem shifting some of the matching into the code; for example, pre-seeding the phonetic keys for a user, since they wouldn't change.
Any thoughts or guidance would be appreciated.  Countless searches have pretty much turned up empty.  Thanks!
Edit: It seems that there are two very distinct camps on the functionality and I am definitely sitting in the middle right now.  I could see the argument of a full-text search - most likely done with a lack of data normalization, and a multi-part approach that uses different criteria for different parts of the name.
The problem ultimately comes down to user intent.  The Bill / William example is a good one, because it shows the mutation of a first name based upon the formality of the usage.  I think that building a name hierarchy is the more accurate (and extensible) solution, but is going to be far more complex.  The fuzzy search approach is easier to implement at the expense of accuracy.  Is this a fair comparison?
Resolution: Upon doing some tests, I have determined to go with an approach where the initial registration will take a full name and I will split it out into multiple fields (forename, surname, middle, suffix, etc.).  Since I am sure that it won't be perfect, I will allow the user to edit the ""parts"", including adding a maiden or alternate name.  As far as searching goes, with either solution I am going to need to maintain what variations exists, either in a database table, or as a thesaurus.  Neither have an advantage over the other in this case.  I think it is going to come down to performance, and I will have to actually run some benchmarks to determine which is best.  Thank you, everyone, for your input!
",<sql><sql-server><algorithm><database-design><data-structures>,10,"sql,sql-server,algorithm,database-design,data-structures",['first name variations in a database'],"['i am trying to determine what the best way is to find variations of a first name in a database', 'for example i search for bill smith', 'i would like it return bill smith obviously but i would also like it to return william smith or billy smith or even willy smith', 'my initial thought was to build a first name hierarchy but i do not know where i could obtain such data if it even exists', 'since users can search the directory i thought this would be a key feature', 'for example people i went to school with called me joe but i always go by joseph now', 'so i was looking at doing a phonetic search on the last name either with nysiis or double metaphone and then searching on the first name using this name heirarchy', 'is there a better way to do this maybe some sort of graded relevance using a full text search on the full name instead of a two part search on the first and last name', 'part of me thinks that if i stored a name as a single value instead of multiple values it might facilitate more search options at the expense of being able to address a user by the first name', 'as far as platform i am using sql server 2005 however i dont have a problem shifting some of the matching into the code for example preseeding the phonetic keys for a user since they wouldnt change', 'any thoughts or guidance would be appreciated', 'countless searches have pretty much turned up empty', 'thanks', 'edit it seems that there are two very distinct camps on the functionality and i am definitely sitting in the middle right now', 'i could see the argument of a fulltext search most likely done with a lack of data normalization and a multipart approach that uses different criteria for different parts of the name', 'the problem ultimately comes down to user intent', 'the bill william example is a good one because it shows the mutation of a first name based upon the formality of the usage', 'i think that building a name hierarchy is the more accurate and extensible solution but is going to be far more complex', 'the fuzzy search approach is easier to implement at the expense of accuracy', 'is this a fair comparison', 'resolution upon doing some tests i have determined to go with an approach where the initial registration will take a full name and i will split it out into multiple fields forename surname middle suffix etc', 'since i am sure that it wont be perfect i will allow the user to edit the parts including adding a maiden or alternate name', 'as far as searching goes with either solution i am going to need to maintain what variations exists either in a database table or as a thesaurus', 'neither have an advantage over the other in this case', 'i think it is going to come down to performance and i will have to actually run some benchmarks to determine which is best', 'thank you everyone for your input']"
SSH into dynamic remote server and run a command - Laravel 5.8,"I'm using L 5.8 and I have a form with 3 inputs

Right now, I can SSH into a specific server with this package laravelcollective/remote"": ""~5.8. I required to pre configured IP, UN, PW in the config/remote.php like so :
'connections' => [
    'production' => [
        'host'      => '1.1.1.1',
        'username'  => 'code',
        'password'  => '8888',
        'key'       => '',
        'keytext'   => '',
        'keyphrase' => '',
        'agent'     => '',
        'timeout'   => 10,
    ],
],

Then, I can easily run any command(s) or even chain them
$commands = ['cd /home/code && ./runMe.sh'];
SSH::run($commands, function($line)
{
    echo $line.PHP_EOL;
});

Result
My portal will connect to that server and run that command successfully, and I've verified it.

Now
I need to read it from form inputs. Is it possible to use the same plugin and dynamically setting that file remote.php ?
or
Should I start looking into something else because this is a dead end ?
Please advise,
",<php><laravel><laravel-5><ssh><laravel-5.8>,5,"php,laravel,laravel-5,ssh,laravel-5.8",['ssh into dynamic remote server and run a command laravel 58'],"['im using l 58 and i have a form with 3 inputs right now i can ssh into a specific server with this package laravelcollectiveremote 58', 'i required to pre configured ip un pw in the configremotephp like so connections production host 1111 username code password 8888 key keytext keyphrase agent timeout 10 then i can easily run any commands or even chain them commands cd homecode runmesh sshruncommands functionline echo linephpeol result my portal will connect to that server and run that command successfully and ive verified it', 'now i need to read it from form inputs', 'is it possible to use the same plugin and dynamically setting that file remotephp ', 'or should i start looking into something else because this is a dead end ', 'please advise']"
Twitter OAuth Access Token Error: Request token missing,"I'm trying to run through a proof of concept social sign in flow with Twitter using Postman, following this guide: https://developer.twitter.com/en/docs/twitter-for-websites/log-in-with-twitter/guides/implementing-sign-in-with-twitter
I'm stuck on step 3: Converting the request token to an access token
I'm using Postman's built in Authorization for OAuth 1.0 and have provided values for my Consumer Key, Consumer Secret, Access Token, and Token Secret.
No matter what I try, the response from my POST to https://api.twitter.com/oauth/access_token is a 401:
Request token missing

I'm including my oauth_verifier from step 2 as x-www-form-urlencoded data.
My project is being developed with Laravel and Socialite. I've also tried using the getTokenCredentials method on the League\OAuth1\Client\Server\Server class and get the same Request token missing error.
My end goal is to use the userFromTokenAndSecret method provided by the Twitter Socialite driver to retrieve user profile data.
Has anyone encountered this error before?
",<laravel><twitter><postman><twitter-oauth><laravel-socialite>,6,"laravel,twitter,postman,twitter-oauth,laravel-socialite",['twitter oauth access token error request token missing'],"['im trying to run through a proof of concept social sign in flow with twitter using postman following this guide im stuck on step 3 converting the request token to an access token im using postmans built in authorization for oauth 10 and have provided values for my consumer key consumer secret access token and token secret', 'no matter what i try the response from my post to is a 401 request token missing im including my oauthverifier from step 2 as xwwwformurlencoded data', 'my project is being developed with laravel and socialite', 'ive also tried using the gettokencredentials method on the leagueoauth1clientserverserver class and get the same request token missing error', 'my end goal is to use the userfromtokenandsecret method provided by the twitter socialite driver to retrieve user profile data', 'has anyone encountered this error before']"
How to configure Serverless Cognito Lambda Triggers,"Using the Serverless framework to create a Cognito User Pool as well as several lambdas to be used for cognito events during TOPT SMS Authorization. Everything is created however the lambda functions are not registered with Cognito.
Relatively new to Serverless jut can't seem to get them to connect. Have tried pool names as others have tried to mark as already present at the end of creation the pool is there and the lambdas are there but there is no connection. 
Currently following another post tried changing user pool to CognitoUserPoolMyUserPool and then in lambda referencing it as MyUserPool. Have also tried just CognitoUserPool in both locations and neither work. 
Example serverless.yaml file:
service: cognito-authentication

frameworkVersion: "">=1.1.0 <2.0.0""

package:
  individually: false

plugins:
  - serverless-bundle 

custom:
  stage: ${opt:stage, self:provider.stage}
  poolName: ${self:custom.stage}-user-pool

provider:
  name: aws
  runtime: nodejs10.x
  stage: dev
  iamRoleStatements:
    - Effect: Allow
      Action:
        - sns:*
      Resource: 
        - ""*""

functions:

  preSignUp:
    handler: functions/pre-signup.main
    events:
      - cognitoUserPool:
        pool: MyUserPool
        trigger: PreSignUp

  defineAuthChallenge:
    handler: functions/define-auth-challenge.main
    events:
      - cognitoUserPool:
        pool: MyUserPool
        trigger: DefineAuthChallenge

  createAuthChallenge:
    handler: functions/create-auth-challenge.main
    events:
      - cognitoUserPool:
        pool: MyUserPool
        trigger: CreateAuthChallenge

  verifyAuthChallengeResponse:
    handler: functions/verify-auth-challenge-response.main
    events:
      - cognitoUserPool:
        pool: MyUserPool
        trigger: VerifyAuthChallengeResponse

resources:
  Resources:
    CognitoUserPoolMyUserPool:
      Type: ""AWS::Cognito::UserPool""
      Properties:
        # Generate a name based on the stage
        UserPoolName: ${self:custom.poolName}
        # Set phone_number as an alias
        UsernameAttributes:
          - phone_number
        Policies:
          PasswordPolicy:
            MinimumLength: 6
            RequireLowercase: False
            RequireNumbers: False
            RequireSymbols: False
            RequireUppercase: False

    CognitoUserPoolClient:
      Type: ""AWS::Cognito::UserPoolClient""
      Properties:
        # Generate an app client name based on the stage
        ClientName: ${self:custom.stage}-sms-auth-client
        UserPoolId:
          Ref: CognitoUserPoolMyUserPool
        ExplicitAuthFlows:
          - CUSTOM_AUTH_FLOW_ONLY
        GenerateSecret: false

Expectation is the User Pool is correctly created and configured to use the lambdas for triggered workflow execution.
",<amazon-web-services><aws-lambda><amazon-cognito><serverless-framework><eventtrigger>,6,"amazon-web-services,aws-lambda,amazon-cognito,serverless-framework,eventtrigger",['how to configure serverless cognito lambda triggers'],"['using the serverless framework to create a cognito user pool as well as several lambdas to be used for cognito events during topt sms authorization', 'everything is created however the lambda functions are not registered with cognito', 'relatively new to serverless jut cant seem to get them to connect', 'have tried pool names as others have tried to mark as already present at the end of creation the pool is there and the lambdas are there but there is no connection', 'currently following another post tried changing user pool to cognitouserpoolmyuserpool and then in lambda referencing it as myuserpool', 'have also tried just cognitouserpool in both locations and neither work', 'example serverlessyaml file service cognitoauthentication frameworkversion 110 200 package individually false plugins serverlessbundle custom stage optstage selfproviderstage poolname selfcustomstageuserpool provider name aws runtime nodejs10x stage dev iamrolestatements effect allow action sns resource functions presignup handler functionspresignupmain events cognitouserpool pool myuserpool trigger presignup defineauthchallenge handler functionsdefineauthchallengemain events cognitouserpool pool myuserpool trigger defineauthchallenge createauthchallenge handler functionscreateauthchallengemain events cognitouserpool pool myuserpool trigger createauthchallenge verifyauthchallengeresponse handler functionsverifyauthchallengeresponsemain events cognitouserpool pool myuserpool trigger verifyauthchallengeresponse resources resources cognitouserpoolmyuserpool type awscognitouserpool properties generate a name based on the stage userpoolname selfcustompoolname set phonenumber as an alias usernameattributes phonenumber policies passwordpolicy minimumlength 6 requirelowercase false requirenumbers false requiresymbols false requireuppercase false cognitouserpoolclient type awscognitouserpoolclient properties generate an app client name based on the stage clientname selfcustomstagesmsauthclient userpoolid ref cognitouserpoolmyuserpool explicitauthflows customauthflowonly generatesecret false expectation is the user pool is correctly created and configured to use the lambdas for triggered workflow execution']"
Put works in Postman but not AXIOS,"This is the weirdest thing in my MERN app. When I do a PUT from Postman to my api it works and updates my api and mongoDB. On the front-end it doesn't update the api even though console logs are showing the correct values and the url is the same? Any help or direction would be appreciated... been playing with it for days now.  
POSTMAN PROOF UPDATES WORK


The code for my axios is as follows:
handlePlayerSubmit(id, player) {
    console.log('This is the id: ' + id);
    console.log('This is the player: ' + player);

    let apiUrl = 'http://localhost:3001/api/teams';
    //sends the id and new author/text to our api
    axios.put(`${apiUrl}/${id}`, player).catch(err => {
      console.log(err);
    });

}
So I know it's firing due to the console logs... not sure why its not updating the api?
Also it's not console.logging an error.
NETWORK SCREEN SHOT IN DEV TOOLS

HEADERS FROM NETWORK TAB:


",<javascript><reactjs><api><axios><mern>,7,"javascript,reactjs,api,axios,mern",['put works in postman but not axios'],"['this is the weirdest thing in my mern app', 'when i do a put from postman to my api it works and updates my api and mongodb', 'on the frontend it doesnt update the api even though console logs are showing the correct values and the url is the same', 'any help or direction would be appreciated been playing with it for days now', 'postman proof updates work the code for my axios is as follows handleplayersubmitid player consolelogthis is the id id consolelogthis is the player player let apiurl sends the id and new authortext to our api axiosputapiurlid playercatcherr consolelogerr so i know its firing due to the console logs not sure why its not updating the api', 'also its not consolelogging an error', 'network screen shot in dev tools headers from network tab']"
Java - Scroll to specific text inside JTextArea,"I'm trying to implement a feature inside the current program that I'm writing and I wanna learn how to scroll down to specific text inside a JTextArea. For example, lets say I have the following:
JTextArea area = new JTextArea(someReallyLongString);

someReallyLongString would represent a paragraph, or a very large piece of text (in which the vertical scrollbar would be visible). And so what I am trying to do is scroll down to specific text within that text area. For example, lets say someReallyLongString contained the word ""the"" near the middle of the scrollbar (meaning this word is not visible), how would I scroll down to that specific text?
Thanks, any help would be greatly appreciating.
",<java><swing><text><jtextarea><caret>,10,"java,swing,text,jtextarea,caret",['java scroll to specific text inside jtextarea'],"['im trying to implement a feature inside the current program that im writing and i wanna learn how to scroll down to specific text inside a jtextarea', 'for example lets say i have the following jtextarea area new jtextareasomereallylongstring somereallylongstring would represent a paragraph or a very large piece of text in which the vertical scrollbar would be visible', 'and so what i am trying to do is scroll down to specific text within that text area', 'for example lets say somereallylongstring contained the word the near the middle of the scrollbar meaning this word is not visible how would i scroll down to that specific text', 'thanks any help would be greatly appreciating']"
Connect to SQL Server from CakePHP 3 on Ubuntu 12.04 LTS,"My setup was working on Windows but I recently switched to Ubuntu 12.04 LTS and now it won't connect. When I load a page where I need to talk to SQL Server, I get this error:

Database driver Cake\Database\Driver\Sqlserver cannot be used due to a
  missing PHP extension or unmet dependency

It is obvious that CakePHP can't find the SQL Server PDO driver.
I found many old tutorials to help me but I took the most recent (I want absolutely to be able to use PDO with my CakePHP website). This is the tutorial I followed.
Using the terminal, I can access the database with this command 
sqlcmd -S my.sql.server.com -U username

What do I need to do to connect to this sql server database from my ubuntu install with CakePHP 3.x?
",<php><sql-server><cakephp><pdo><cakephp-3.0>,5,"php,sql-server,cakephp,pdo,cakephp-3.0",['connect to sql server from cakephp 3 on ubuntu 1204 lts'],"['my setup was working on windows but i recently switched to ubuntu 1204 lts and now it wont connect', 'when i load a page where i need to talk to sql server i get this error database driver cakedatabasedriversqlserver cannot be used due to a missing php extension or unmet dependency it is obvious that cakephp cant find the sql server pdo driver', 'i found many old tutorials to help me but i took the most recent i want absolutely to be able to use pdo with my cakephp website', 'this is the tutorial i followed', 'using the terminal i can access the database with this command sqlcmd s mysqlservercom u username what do i need to do to connect to this sql server database from my ubuntu install with cakephp 3x']"
Contain image size with parent <div>,"I´ve been trying to keep my images next to each other on the same line, and just crop them to a smaller size if needed. Why doesn't object-fit work ? 
HTML:
<div class=""gallery"">
  <div class=""inner""><img src=""images/image1.jpg""></div>
  <div class=""inner""><img src=""images/image2.jpg""></div>
  <div class=""inner""><img src=""images/image3.jpg""></div>
</div>

CSS:
.gallery{
  width: 1000px;
  height: 300px;
  display: flex;
}

.inner{
   width: 333px;
   height: 300px;
}

.inner img{
   object-fit: contain;
}

",<html><css><image><flexbox><object-fit>,8,"html,css,image,flexbox,object-fit",['contain image size with parent div'],"['ive been trying to keep my images next to each other on the same line and just crop them to a smaller size if needed', 'why doesnt objectfit work ', 'html div classgallery div classinnerimg srcimagesimage1jpgdiv div classinnerimg srcimagesimage2jpgdiv div classinnerimg srcimagesimage3jpgdiv div css gallery width 1000px height 300px display flex inner width 333px height 300px inner img objectfit contain ']"
Breeze compatible JavaScript GUI frameworks,"While I already posted a similar question (Breeze compatible SPA building) and likely started something good going between IdeaBlade and Telerik as a consequence, I believe that Breeze deserves a lot wider recognition because of its unique approach to access Entity Framework on the server side. So, it seems pretty obvious to me that even notoriously complete JS frameworks like Sencha or Wakanda need to ensure to work with Breeze.
The current issues between KendoUI and Breeze are very clearly described in the post by Remco Blok at http://www.kendoui.com/blogs/teamblog/posts/13-02-21/breeze_js_and_the_kendo_ui_datasource.aspx. Stated succinctly the integration with Breeze should be made at the level of entities - not JSON data, which is the way almost everyone handles the transactions between a JS client and SQL server. 
Wakanda is a great example of a very rich development environment with elaborate GUI Builder, Debugger etc that unfortunately cannot be used with ""legacy data"" on the server side.
As far as I know, Breeze works just fine with Angular, but Angular needs AngularUI (http://angular-ui.github.io/) which in turn is not as complete as I would like it to be and has some JQuery dependencies that may cause collisions. Pretty soon, Breeze will work with KendoUI (AFAIK) - does anyone know about some other collection of JavaScript frameworks that all together would offer the level of ease that Visual Studio provides for Windows desktop applications creation? (after all, JavaScript applications are desktop application with the distribution problem solved in a very elegant fashion).
",<entity-framework><angularjs><extjs><breeze><wakanda>,6,"entity-framework,angularjs,extjs,breeze,wakanda",['breeze compatible javascript gui frameworks'],"['while i already posted a similar question breeze compatible spa building and likely started something good going between ideablade and telerik as a consequence i believe that breeze deserves a lot wider recognition because of its unique approach to access entity framework on the server side', 'so it seems pretty obvious to me that even notoriously complete js frameworks like sencha or wakanda need to ensure to work with breeze', 'the current issues between kendoui and breeze are very clearly described in the post by remco blok at stated succinctly the integration with breeze should be made at the level of entities not json data which is the way almost everyone handles the transactions between a js client and sql server', 'wakanda is a great example of a very rich development environment with elaborate gui builder debugger etc that unfortunately cannot be used with legacy data on the server side', 'as far as i know breeze works just fine with angular but angular needs angularui which in turn is not as complete as i would like it to be and has some jquery dependencies that may cause collisions', 'pretty soon breeze will work with kendoui afaik does anyone know about some other collection of javascript frameworks that all together would offer the level of ease that visual studio provides for windows desktop applications creation', 'after all javascript applications are desktop application with the distribution problem solved in a very elegant fashion']"
How to handle large files with NSData?,"I have a very large video and I need to chunk this video to upload it to Dropbox.
I tried to use NSData, but because this file is too large, my application always crashes, so I don't know what I can do now.
For smaller videos, I used this:
NSData(contentsOfURL: self.newAsset.URL)!.subdataWithRange(NSMakeRange(0, 10000000))

and I didn't have any problem with that, but when the video is too large I have an error:

Cannot allocate memory

So, what can I do to chunk the data of large videos?
",<ios><swift><nsdata><avurlasset><swiftydropbox>,5,"ios,swift,nsdata,avurlasset,swiftydropbox",['how to handle large files with nsdata'],"['i have a very large video and i need to chunk this video to upload it to dropbox', 'i tried to use nsdata but because this file is too large my application always crashes so i dont know what i can do now', 'for smaller videos i used this nsdatacontentsofurl selfnewasseturlsubdatawithrangensmakerange0 10000000 and i didnt have any problem with that but when the video is too large i have an error cannot allocate memory so what can i do to chunk the data of large videos']"
How to find out S3 Bucket last accessed time?,"I have a use-case where I need to find out last accessed time of the S3 bucket, but I am not able to find a way to do so. Though, we can get LastModifiedTime or LastUpdatedTime for the bucket, but I couldn't find any AWS API, which can give me the last accessed time for the AWS S3 Bucket. One way to do this is to parse through all the objects inside the buckets, but that's a very expensive operation to do, which I can't afford. 
Can somebody help me in getting the LastAccessedTime for the AWS S3 Bucket? I am using Python with boto3.
",<python-3.x><amazon-web-services><amazon-s3><boto><boto3>,8,"python-3.x,amazon-web-services,amazon-s3,boto,boto3",['how to find out s3 bucket last accessed time'],"['i have a usecase where i need to find out last accessed time of the s3 bucket but i am not able to find a way to do so', 'though we can get lastmodifiedtime or lastupdatedtime for the bucket but i couldnt find any aws api which can give me the last accessed time for the aws s3 bucket', 'one way to do this is to parse through all the objects inside the buckets but thats a very expensive operation to do which i cant afford', 'can somebody help me in getting the lastaccessedtime for the aws s3 bucket', 'i am using python with boto3']"
Python. AttributeError: 'NoneType' object has no attribute 'startswith',"Why is it this code won't work and give AttributeError?
internship = parser.find_all('a', attrs = {'title': lambda job: job.startswith('Internship')})

while this one works:
internship = parser.find_all('a', attrs = {'title': lambda job: job and job.startswith('Internship')})

This is the error that I got from the first code:
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""C:\Python27\lib\site-packages\bs4\element.py"", line 1299, in find_all
   return self._find_all(name, attrs, text, limit, generator, **kwargs)
  File ""C:\Python27\lib\site-packages\bs4\element.py"", line 549, in _find_all
   found = strainer.search(i)
  File ""C:\Python27\lib\site-packages\bs4\element.py"", line 1690, in search
   found = self.search_tag(markup)
  File ""C:\Python27\lib\site-packages\bs4\element.py"", line 1662, in search_tag
    if not self._matches(attr_value, match_against):
  File ""C:\Python27\lib\site-packages\bs4\element.py"", line 1722, in _matches
    return match_against(markup)
  File ""<stdin>"", line 1, in <lambda>
AttributeError: 'NoneType' object has no attribute 'startswith'

",<python-2.7><powershell><lambda><web-scraping><attributeerror>,7,"python-2.7,powershell,lambda,web-scraping,attributeerror","['python', 'attributeerror nonetype object has no attribute startswith']","['why is it this code wont work and give attributeerror', 'internship parserfindalla attrs title lambda job jobstartswithinternship while this one works internship parserfindalla attrs title lambda job job and jobstartswithinternship this is the error that i got from the first code traceback most recent call last file stdin line 1 in module file cpython27libsitepackagesbs4elementpy line 1299 in findall return selffindallname attrs text limit generator kwargs file cpython27libsitepackagesbs4elementpy line 549 in findall found strainersearchi file cpython27libsitepackagesbs4elementpy line 1690 in search found selfsearchtagmarkup file cpython27libsitepackagesbs4elementpy line 1662 in searchtag if not selfmatchesattrvalue matchagainst file cpython27libsitepackagesbs4elementpy line 1722 in matches return matchagainstmarkup file stdin line 1 in lambda attributeerror nonetype object has no attribute startswith']"
"Spring web flux WebClient : Connection rest by peers,#block terminated with an error.Error has been observed at the following site","i am using spring web flux, web client to call a rest api. i am getting the following error.
Oct 21 09:46:27 ql-hybrid-stg web.7d755d6967-5d7v8  Suppressed: java.lang.Exception: #block terminated with an error 
Oct 21 09:46:27 ql-hybrid-stg web.7d755d6967-5d7v8      at reactor.core.publisher.BlockingSingleSubscriber.blockingGet(BlockingSingleSubscriber.java:99) ~[reactor-core-3.3.2.RELEASE.jar!/:3.3.2.RELEASE] 
Oct 21 09:46:27 ql-hybrid-stg web.7d755d6967-5d7v8      ... 97 common frames omitted 
Oct 21 09:46:27 ql-hybrid-stg web.7d755d6967-5d7v8 Caused by: io.netty.channel.unix.Errors$NativeIoException: readAddress(..) failed: Connection reset by peer 
Oct 21 09:46:27 ql-hybrid-stg web.7d755d6967-5d7v8  Suppressed: reactor.core.publisher.FluxOnAssembly$OnAssemblyException:  
Oct 21 09:46:27 ql-hybrid-stg web.7d755d6967-5d7v8 Error has been observed at the following site(s): 
Oct 21 09:46:27 ql-hybrid-stg web.7d755d6967-5d7v8  |_ checkpoint ? Request to GET https://cc-qa.app/api/matches/list/?status=current&page=0&size=100 [DefaultWebClient] 

is the problem with my web client call or the api i am calling ?
i am confused as it showing many error like Connection rest by peers,#block terminated with an error.Error has been observed at the following site.
how to solve this ?
please find the code below
  @Bean
  public WebClient restClient() {

    String baseurl = env.getProperty(""base-url"");
    int memoryLimit = Integer.parseInt(env.getProperty(""webclient-buffer-size""));

    ExchangeStrategies exchangeStrategies =
        ExchangeStrategies.builder()
            .codecs(
                configurer -> configurer.defaultCodecs().maxInMemorySize(1024 * 1024 * memoryLimit))
            .build();
    return WebClient.builder()
        .exchangeStrategies(exchangeStrategies)
        .baseUrl(baseurl)
        .build();
  }

this the api call:
webClient
              .get()
              .uri(""/api/matches/list/?status=current&page=0&size=100"")
              .header(""authorization"", accessToken)
              .retrieve()
              .bodyToMono(InfoPayload.class)
              .block();

please help me to find the issue . thanks in advance
",<java><spring><spring-boot><webclient><spring-webflux>,5,"java,spring,spring-boot,webclient,spring-webflux",['spring web flux webclient connection rest by peersblock terminated with an errorerror has been observed at the following site'],"['i am using spring web flux web client to call a rest api', 'i am getting the following error', 'oct 21 094627 qlhybridstg web7d755d69675d7v8 suppressed javalangexception block terminated with an error oct 21 094627 qlhybridstg web7d755d69675d7v8 at reactorcorepublisherblockingsinglesubscriberblockinggetblockingsinglesubscriberjava99 reactorcore332releasejar332release oct 21 094627 qlhybridstg web7d755d69675d7v8 97 common frames omitted oct 21 094627 qlhybridstg web7d755d69675d7v8 caused by ionettychannelunixerrorsnativeioexception readaddress failed connection reset by peer oct 21 094627 qlhybridstg web7d755d69675d7v8 suppressed reactorcorepublisherfluxonassemblyonassemblyexception oct 21 094627 qlhybridstg web7d755d69675d7v8 error has been observed at the following sites oct 21 094627 qlhybridstg web7d755d69675d7v8 checkpoint ', 'request to get defaultwebclient is the problem with my web client call or the api i am calling ', 'i am confused as it showing many error like connection rest by peersblock terminated with an errorerror has been observed at the following site', 'how to solve this ', 'please find the code below bean public webclient restclient string baseurl envgetpropertybaseurl int memorylimit integerparseintenvgetpropertywebclientbuffersize exchangestrategies exchangestrategies exchangestrategiesbuilder codecs configurer configurerdefaultcodecsmaxinmemorysize1024 1024 memorylimit build return webclientbuilder exchangestrategiesexchangestrategies baseurlbaseurl build this the api call webclient get uriapimatchesliststatuscurrentpage0size100 headerauthorization accesstoken retrieve bodytomonoinfopayloadclass block please help me to find the issue ', 'thanks in advance']"
Only one SparkContext may be running in this JVM - [SPARK],"I'm trying to run the following code to get twitter information live:
import org.apache.spark._
import org.apache.spark.streaming._
import org.apache.spark.streaming.twitter._
import org.apache.spark.streaming.StreamingContext._
import twitter4j.auth.Authorization
import twitter4j.Status
import twitter4j.auth.AuthorizationFactory
import twitter4j.conf.ConfigurationBuilder
import org.apache.spark.streaming.api.java.JavaStreamingContext

import org.apache.spark.rdd.RDD
import org.apache.spark.SparkContext
import org.apache.spark.mllib.feature.HashingTF
import org.apache.spark.mllib.linalg.Vector
import org.apache.spark.SparkConf
import org.apache.spark.api.java.JavaSparkContext
import org.apache.spark.api.java.function.Function
import org.apache.spark.streaming.Duration
import org.apache.spark.streaming.api.java.JavaDStream
import org.apache.spark.streaming.api.java.JavaReceiverInputDStream

val consumerKey = ""xxx""
val consumerSecret = ""xxx""
val accessToken = ""xxx""
val accessTokenSecret = ""xxx""
val url = ""https://stream.twitter.com/1.1/statuses/filter.json""

val sparkConf = new SparkConf().setAppName(""Twitter Streaming"")
val sc = new SparkContext(sparkConf)

val documents: RDD[Seq[String]] = sc.textFile("""").map(_.split("" "").toSeq)


// Twitter Streaming
val ssc = new JavaStreamingContext(sc,Seconds(2))

val conf = new ConfigurationBuilder()
conf.setOAuthAccessToken(accessToken)
conf.setOAuthAccessTokenSecret(accessTokenSecret)
conf.setOAuthConsumerKey(consumerKey)
conf.setOAuthConsumerSecret(consumerSecret)
conf.setStreamBaseURL(url)
conf.setSiteStreamBaseURL(url)

val filter = Array(""Twitter"", ""Hadoop"", ""Big Data"")

val auth = AuthorizationFactory.getInstance(conf.build())
val tweets : JavaReceiverInputDStream[twitter4j.Status] = TwitterUtils.createStream(ssc, auth, filter)

val statuses = tweets.dstream.map(status => status.getText)
statuses.print()
ssc.start()

But when it arrives at this command: val sc = new SparkContext(sparkConf), the following error appears:

17/05/09 09:08:35 WARN SparkContext: Multiple running SparkContexts
  detected in the same JVM! org.apache.spark.SparkException: Only one
  SparkContext may be running in this JVM (see SPARK-2243). To ignore
  this error, set spark.driver.allowMultipleContexts = true.

I have tried to add the following parameters to the sparkConf value, but the error still appears:
val sparkConf = new SparkConf().setAppName(""Twitter Streaming"").setMaster(""local[4]"").set(""spark.driver.allowMultipleContexts"", ""true"")

If I ignore the error and continue running commands I get this other error:

17/05/09 09:15:44 WARN ReceiverSupervisorImpl: Restarting receiver
  with delay 2000 ms: Error receiving tweets 401:Authentication
  credentials (https://dev.twitter.com/pages/auth) were missing or
  incorrect. Ensure that you have set valid consumer key/secret, access
  token/secret, and the system clock is in sync. \n\n\nError 401 Unauthorized  
  HTTP ERROR: 401 Problem accessing
  '/1.1/statuses/filter.json'. Reason:Unauthorized
   

Any kind of contribution is appreciated. A greeting and have a good day.
",<java><apache-spark><twitter><stream><jvm>,9,"java,apache-spark,twitter,stream,jvm",['only one sparkcontext may be running in this jvm spark'],"['im trying to run the following code to get twitter information live import orgapachespark import orgapachesparkstreaming import orgapachesparkstreamingtwitter import orgapachesparkstreamingstreamingcontext import twitter4jauthauthorization import twitter4jstatus import twitter4jauthauthorizationfactory import twitter4jconfconfigurationbuilder import orgapachesparkstreamingapijavajavastreamingcontext import orgapachesparkrddrdd import orgapachesparksparkcontext import orgapachesparkmllibfeaturehashingtf import orgapachesparkmlliblinalgvector import orgapachesparksparkconf import orgapachesparkapijavajavasparkcontext import orgapachesparkapijavafunctionfunction import orgapachesparkstreamingduration import orgapachesparkstreamingapijavajavadstream import orgapachesparkstreamingapijavajavareceiverinputdstream val consumerkey xxx val consumersecret xxx val accesstoken xxx val accesstokensecret xxx val url val sparkconf new sparkconfsetappnametwitter streaming val sc new sparkcontextsparkconf val documents rddseqstring sctextfilemapsplit toseq twitter streaming val ssc new javastreamingcontextscseconds2 val conf new configurationbuilder confsetoauthaccesstokenaccesstoken confsetoauthaccesstokensecretaccesstokensecret confsetoauthconsumerkeyconsumerkey confsetoauthconsumersecretconsumersecret confsetstreambaseurlurl confsetsitestreambaseurlurl val filter arraytwitter hadoop big data val auth authorizationfactorygetinstanceconfbuild val tweets javareceiverinputdstreamtwitter4jstatus twitterutilscreatestreamssc auth filter val statuses tweetsdstreammapstatus statusgettext statusesprint sscstart but when it arrives at this command val sc new sparkcontextsparkconf the following error appears 170509 090835 warn sparkcontext multiple running sparkcontexts detected in the same jvm', 'orgapachesparksparkexception only one sparkcontext may be running in this jvm see spark2243', 'to ignore this error set sparkdriverallowmultiplecontexts true', 'i have tried to add the following parameters to the sparkconf value but the error still appears val sparkconf new sparkconfsetappnametwitter streamingsetmasterlocal4setsparkdriverallowmultiplecontexts true if i ignore the error and continue running commands i get this other error 170509 091544 warn receiversupervisorimpl restarting receiver with delay 2000 ms error receiving tweets 401authentication credentials were missing or incorrect', 'ensure that you have set valid consumer keysecret access tokensecret and the system clock is in sync', 'nnnerror 401 unauthorized http error 401 problem accessing 11statusesfilterjson', 'reasonunauthorized any kind of contribution is appreciated', 'a greeting and have a good day']"
Adding name attribute results in ID value becoming property of the document object in IE and Opera?,"Consider this HTML source code:
<form id=""foo1"" name=""x""> Form 1 </form>
<form id=""foo2""> Form 2 </form>

As you can see, we define two FORM elements.
In Chrome, Safari and Firefox, both document.foo1 and document.foo2 return undefined. 
However, in IE and Opera, document.foo1 returns a reference to the corresponding FORM element, whereas document.foo2 returns undefined.
Live demo: http://jsfiddle.net/zrmEm/2/
So, the first form does have its ID-named property in the document object, and the second form doesn't. And this difference is the result of adding the name attribute to the first form.
Now, where's the logic in that? Is this a known behavior?
",<javascript><html><internet-explorer><dom><opera>,5,"javascript,html,internet-explorer,dom,opera",['adding name attribute results in id value becoming property of the document object in ie and opera'],"['consider this html source code form idfoo1 namex form 1 form form idfoo2 form 2 form as you can see we define two form elements', 'in chrome safari and firefox both documentfoo1 and documentfoo2 return undefined', 'however in ie and opera documentfoo1 returns a reference to the corresponding form element whereas documentfoo2 returns undefined', 'live demo so the first form does have its idnamed property in the document object and the second form doesnt', 'and this difference is the result of adding the name attribute to the first form', 'now wheres the logic in that', 'is this a known behavior']"
Fast read C structure when it contains char array,"I have the following C structure
struct MyStruct {
    char chArray[96];
    __int64 offset;
    unsigned count;
}

I now have a bunch of files created in C with thousands of those structures. I need to read them using C# and speed is an issue.
I have done the following in C#
[StructLayout(LayoutKind.Sequential, CharSet = CharSet.Ansi, Size = 108)]
public struct PreIndexStruct {
    [MarshalAs(UnmanagedType.ByValTStr, SizeConst = 96)]
    public string Key;
    public long Offset;
    public int Count;
}

And then I read the data from the file using
using (BinaryReader br = new BinaryReader(
       new FileStream(pathToFile, FileMode.Open, FileAccess.Read, 
                      FileShare.Read, bufferSize))) 
{
    long length = br.BaseStream.Length;
    long position = 0;

    byte[] buff = new byte[structSize];
    GCHandle buffHandle = GCHandle.Alloc(buff, GCHandleType.Pinned);
    while (position < length) {
        br.Read(buff, 0, structSize);
        PreIndexStruct pis = (PreIndexStruct)Marshal.PtrToStructure(
            buffHandle.AddrOfPinnedObject(), typeof(PreIndexStruct));
        structures.Add(pis);

        position += structSize;
    }
    buffHandle.Free();
}

This works perfectly and I can retrieve the data just fine from the files.
I've read that I can speedup things if instead of using GCHandle.Alloc/Marshal.PtrToStructure I use C++/CLI or C# unsafe code. I found some examples but they only refer to structures without fixed sized arrays.
My question is, for my particular case, is there a faster way of doing things with C++/CLI or C# unsafe code?
EDIT
Additional performance info (I've used ANTS Performance Profiler 7.4):
66% of my CPU time is used by calls to Marshal.PtrToStructure.
Regarding I/O, only 6 out of 105ms are used to read from the file.
",<c#><performance><struct><c++-cli><unsafe>,8,"c#,performance,struct,c++-cli,unsafe",['fast read c structure when it contains char array'],"['i have the following c structure struct mystruct char charray96 int64 offset unsigned count i now have a bunch of files created in c with thousands of those structures', 'i need to read them using c and speed is an issue', 'i have done the following in c structlayoutlayoutkindsequential charset charsetansi size 108 public struct preindexstruct marshalasunmanagedtypebyvaltstr sizeconst 96 public string key public long offset public int count and then i read the data from the file using using binaryreader br new binaryreader new filestreampathtofile filemodeopen fileaccessread fileshareread buffersize long length brbasestreamlength long position 0 byte buff new bytestructsize gchandle buffhandle gchandleallocbuff gchandletypepinned while position length brreadbuff 0 structsize preindexstruct pis preindexstructmarshalptrtostructure buffhandleaddrofpinnedobject typeofpreindexstruct structuresaddpis position structsize buffhandlefree this works perfectly and i can retrieve the data just fine from the files', 'ive read that i can speedup things if instead of using gchandleallocmarshalptrtostructure i use ccli or c unsafe code', 'i found some examples but they only refer to structures without fixed sized arrays', 'my question is for my particular case is there a faster way of doing things with ccli or c unsafe code', 'edit additional performance info ive used ants performance profiler 74 66 of my cpu time is used by calls to marshalptrtostructure', 'regarding io only 6 out of 105ms are used to read from the file']"
secure cookies node.js + Heroku + CloudFlare,"I've looked at this answer and this answer but no dice. My problem is that when my app is accessed through https://appname.herokuapp.com, everything works fine. but when accessed through https://www.appname.com (which CloudFlare aliases to https://appname.herokuapp.com), it breaks down.
Specifically, when a user logs in, the authentication is processed correctly, but the user session cookie is not set properly. So when the logged-in user is forwarded to the next screen, the request gets rejected as unauthorized.
Right now I am doing this in express:
var mySession = session({
    key: ""sid"",
    secret: process.env.SESSIONS_SECRET,
    proxy: true,
    cookie: {
        maxAge: 86400000,
        secure: true,
    },
    store: rDBStore,
    resave: false,
    saveUninitialized: true,
    unset: 'destroy'
});

app.enable('trust proxy');
app.use(mySession);

Am I missing something in my node code, or in my CloudFlare settings?
",<node.js><cookies><heroku><https><cloudflare>,8,"node.js,cookies,heroku,https,cloudflare",['secure cookies nodejs heroku cloudflare'],"['ive looked at this answer and this answer but no dice', 'my problem is that when my app is accessed through everything works fine', 'but when accessed through which cloudflare aliases to it breaks down', 'specifically when a user logs in the authentication is processed correctly but the user session cookie is not set properly', 'so when the loggedin user is forwarded to the next screen the request gets rejected as unauthorized', 'right now i am doing this in express var mysession session key sid secret processenvsessionssecret proxy true cookie maxage 86400000 secure true store rdbstore resave false saveuninitialized true unset destroy appenabletrust proxy appusemysession am i missing something in my node code or in my cloudflare settings']"
Is tkwait wait_variable/wait_window/wait_visibility broken?,"I recently started to use tkwait casually and noticed that some functionality only works under special conditions. For example:
import tkinter as tk

def w(seconds):
    dummy = tk.Toplevel(root)
    dummy.title(seconds)
    dummy.after(seconds*1000, lambda x=dummy: x.destroy())
    dummy.wait_window(dummy)
    print(seconds)

root = tk.Tk()
for i in [5,2,10]:
    w(i)
root.mainloop()

The code above works just fine and as expected:

The for loop calls the function
The function runs and blocks the code for x seconds
The window gets destroyed and the for loop continues

But in a more event driven environment these tkwait calls gets tricky. The documentation states quote:

If an event handler invokes tkwait again, the nested call to tkwait
must complete before the outer call can complete.

Instead of an output of >>5 >>2 >>10 you will get >>10 >>2 >>5 because the nested call blocks the inner and the outer will block the inner. I suspect a nested event loop or an equivalent of the mainloop processes events in the normal fashion while waiting.
Am I doing something wrong by using this feature? Because if you think about it, nearly all tkinter dialog windows are using this feature and I've never read about this behavior before.
An event driven example might be:
import tkinter as tk

def w(seconds):
    dummy = tk.Toplevel(root)
    dummy.title(seconds)
    dummy.after(seconds*1000, lambda x=dummy: x.destroy())
    dummy.wait_window(dummy)
    print(seconds)

root = tk.Tk()
btn1 = tk.Button(
    root, command=lambda : w(5), text = '5 seconds')
btn2 = tk.Button(
    root, command=lambda : w(2), text = '2 seconds')
btn3 = tk.Button(
    root, command=lambda : w(10), text = '10 seconds')
btn1.pack()
btn2.pack()
btn3.pack()
root.mainloop()

As an additional problem that raises with wait_something is that it will prevent your process to finish if the wait_something never was released.
",<python><tkinter><tcl><wait><event-driven>,8,"python,tkinter,tcl,wait,event-driven",['is tkwait waitvariablewaitwindowwaitvisibility broken'],"['i recently started to use tkwait casually and noticed that some functionality only works under special conditions', 'for example import tkinter as tk def wseconds dummy tktoplevelroot dummytitleseconds dummyafterseconds1000 lambda xdummy xdestroy dummywaitwindowdummy printseconds root tktk for i in 5210 wi rootmainloop the code above works just fine and as expected the for loop calls the function the function runs and blocks the code for x seconds the window gets destroyed and the for loop continues but in a more event driven environment these tkwait calls gets tricky', 'the documentation states quote if an event handler invokes tkwait again the nested call to tkwait must complete before the outer call can complete', 'instead of an output of 5 2 10 you will get 10 2 5 because the nested call blocks the inner and the outer will block the inner', 'i suspect a nested event loop or an equivalent of the mainloop processes events in the normal fashion while waiting', 'am i doing something wrong by using this feature', 'because if you think about it nearly all tkinter dialog windows are using this feature and ive never read about this behavior before', 'an event driven example might be import tkinter as tk def wseconds dummy tktoplevelroot dummytitleseconds dummyafterseconds1000 lambda xdummy xdestroy dummywaitwindowdummy printseconds root tktk btn1 tkbutton root commandlambda w5 text 5 seconds btn2 tkbutton root commandlambda w2 text 2 seconds btn3 tkbutton root commandlambda w10 text 10 seconds btn1pack btn2pack btn3pack rootmainloop as an additional problem that raises with waitsomething is that it will prevent your process to finish if the waitsomething never was released']"
Can security for this username/password generator script be improved?,"Description
To manage the huge amount of my website logins, I wrote a bash script which takes

A string which, for me personally, identifies a certain account. Examples are mylogin@stackoverflow.com or thisWebsiteIVistedLately, but it can be possibly anything. It does not have to follow a certain pattern, it just should help me distinguish between different accounts I want to manage.
A master password.

The output is a combination of a username and a secure password for the account. I do not want to store any of the generated usernames/passwords, nor the master password. Therefore, similar to Honey Encryption, I want the script to generate a reasonable result for each input. If a bad guy entered a wrong master password, he would just get a different username/password combination, undistinguishable of the ""real"" one.
Here is the bash script I have come up with so far:
#!/bin/bash

# robust bash scripting
set -o errexit
set -o nounset
set -o pipefail

# external programs
OPENSSL=$(which openssl)
SED=$(which sed)
CUT=$(which cut)

# get identifier
read -s -p ""id = "" ID
echo """"

# read password
read -s -p ""pw = "" PW
echo """"

# generate username
printf ""%s"" ""$ID"" | { printf ""%s"" ""$PW"" | ""$OPENSSL"" enc -e -aes-256-cbc -pass stdin -salt -S ""0000000000000000"" -in /dev/fd/3; } 3<&0 | ""$OPENSSL"" dgst -sha512 -binary | ""$OPENSSL"" enc -base64 -A | ""$SED"" 's/[^a-zA-Z]//g' | ""$CUT"" -c -8

# generate password
printf ""%s"" ""$ID"" | { printf ""%s"" ""$PW"" | ""$OPENSSL"" enc -e -aes-256-cbc -pass stdin -salt -S ""1111111111111111"" -in /dev/fd/3; } 3<&0 | ""$OPENSSL"" dgst -sha512 -binary | ""$OPENSSL"" enc -base64 -A | ""$CUT"" -b -32

As you can see, username and password are generated by

Encrypting the identifier string with the given master password using AES,
hashing the result using SHA,
performing a base64 conversion, and
seding and cuting the output to reasonable formats for a username and password.

I tried to make any aspect as secure as possible. For identifier and password input, the bash internal read is used. Also, when the password is piped to openssl, the bash internal printf is used. Obviously, the used salts are just placeholders. In the final stage, these should be replaced by anyone using the script.
Example
Here is an example (assuming that above script was saved as myscript.sh:
$ ./myscript.sh
$ id = mylogin@stackoverflow.com
$ pw = 12345
$ CbAMaZar
$ XFTD9VRwQxFbU4tHKuiJvy5c18oJaDbg

The last two lines specify the generated username and password.
Now, assume someone knows anything about me, except for the master password (Kerckhoffs's principle). Here comes the bad guy:
$ ./myscript.sh
$ id = mylogin@stackoverflow.com
$ pw = 23456
$ MNLManDN
$ pczRREIy9+ag/0Y7jauAWpm5sllh5sjg

To check if this is correct, he would have to actually try the generated login.
Question
Now, my question is how the security of this script can be improved (in terms of cryptography as well as bash scripting). Of course, if the bad guy has root access or knows the master password, all is lost. This is why I do not plan to manage important accounts using this approach.
But if someone knows my correct username and password for an account (e.g. via SQL injection), there should be no (realistic) way to find my master password or any other account username/password combinations. Also, it should be impossible for any non-root user on the system to find out the generated username/password pairs or my master password.
So, to all security, cryptography, and programming gurus of SO: are there any security issues in the script above or can it be considered ""safe""?
",<linux><bash><security><cryptography><openssl>,5,"linux,bash,security,cryptography,openssl",['can security for this usernamepassword generator script be improved'],"['description to manage the huge amount of my website logins i wrote a bash script which takes a string which for me personally identifies a certain account', 'examples are myloginstackoverflowcom or thiswebsiteivistedlately but it can be possibly anything', 'it does not have to follow a certain pattern it just should help me distinguish between different accounts i want to manage', 'a master password', 'the output is a combination of a username and a secure password for the account', 'i do not want to store any of the generated usernamespasswords nor the master password', 'therefore similar to honey encryption i want the script to generate a reasonable result for each input', 'if a bad guy entered a wrong master password he would just get a different usernamepassword combination undistinguishable of the real one', 'here is the bash script i have come up with so far binbash robust bash scripting set o errexit set o nounset set o pipefail external programs opensslwhich openssl sedwhich sed cutwhich cut get identifier read s p id id echo read password read s p pw pw echo generate username printf s id printf s pw openssl enc e aes256cbc pass stdin salt s 0000000000000000 in devfd3 30 openssl dgst sha512 binary openssl enc base64 a sed sazazg cut c 8 generate password printf s id printf s pw openssl enc e aes256cbc pass stdin salt s 1111111111111111 in devfd3 30 openssl dgst sha512 binary openssl enc base64 a cut b 32 as you can see username and password are generated by encrypting the identifier string with the given master password using aes hashing the result using sha performing a base64 conversion and seding and cuting the output to reasonable formats for a username and password', 'i tried to make any aspect as secure as possible', 'for identifier and password input the bash internal read is used', 'also when the password is piped to openssl the bash internal printf is used', 'obviously the used salts are just placeholders', 'in the final stage these should be replaced by anyone using the script', 'example here is an example assuming that above script was saved as myscriptsh myscriptsh id myloginstackoverflowcom pw 12345 cbamazar xftd9vrwqxfbu4thkuijvy5c18ojadbg the last two lines specify the generated username and password', 'now assume someone knows anything about me except for the master password kerckhoffss principle', 'here comes the bad guy myscriptsh id myloginstackoverflowcom pw 23456 mnlmandn pczrreiy9ag0y7jauawpm5sllh5sjg to check if this is correct he would have to actually try the generated login', 'question now my question is how the security of this script can be improved in terms of cryptography as well as bash scripting', 'of course if the bad guy has root access or knows the master password all is lost', 'this is why i do not plan to manage important accounts using this approach', 'but if someone knows my correct username and password for an account eg', 'via sql injection there should be no realistic way to find my master password or any other account usernamepassword combinations', 'also it should be impossible for any nonroot user on the system to find out the generated usernamepassword pairs or my master password', 'so to all security cryptography and programming gurus of so are there any security issues in the script above or can it be considered safe']"
Why would HMAC SHA-1 return a different digest with the same input?,"I am trying to build a working encrypted signature for the Amazon S3 web service, writing a connection library using Objective C. 
I have run into HMAC SHA-1 digest problems with the ObjC code, so I'm putting that to the side and looking at existing, working Perl code, to try to troubleshoot digest creation.
I am testing HMAC SHA-1 digest output from the s3ls command of the Net::Amazon::S3 package and comparing that against the _encode subroutine that I pulled out and put into its own perl script:
#!/usr/bin/perl -w                                                                                                                                                                                    

use MIME::Base64 qw(encode_base64);
use Digest::HMAC_SHA1;
use String::Escape qw( printable unprintable );

sub _ascii_to_hex {
    (my $str = shift) =~ s/(.|\n)/sprintf(""%02lx"", ord $1)/eg;
    return $str;
}

sub _encode {
    my ( $aws_secret_access_key, $str ) = @_;
    print ""secret key hex: ""._ascii_to_hex($aws_secret_access_key).""\n"";
    my $hmac = Digest::HMAC_SHA1->new($aws_secret_access_key);
    $hmac->add($str);
    my $digest = $hmac->digest;
    print ""cleartext hex: ""._ascii_to_hex($str).""\n"";
    print ""digest hex: ""._ascii_to_hex($digest).""\n"";
    my $b64 = encode_base64( $digest, '' );
    print ""encoded: "".$b64.""\n"";
}

my $secret = ""abcd1234"";
my $cleartext = ""GET\n\n\nFri, 12 Dec 2008 10:08:51 GMT+00:00\n/"";
_encode($secret, $cleartext);

Here is sample output from this script:
$ ./testhmac.pl 
secret key hex: 6162636431323334
cleartext hex: 4745540a0a0a4672692c2031322044656320323030382031303a30383a353120474d542b30303a30300a2f
digest hex: 63308f9b8a198440d6d8685a3f3f70d0aab02f68
encoded: YzCPm4oZhEDW2GhaPz9w0KqwL2g=

What I am testing is that, if I input the same secret key and cleartext into the same _encode function of the Net::Amazon::S3 package, I should see the very same secret key, cleartext, and digest bytes.
Indeed, I get the same bytes for the secret key and cleartext.
But I get something different for the digest (and of course the base64 encoding), e.g.:
$ s3ls --access-key=foobar --secret-key=abcd1234
...
secret key hex: 6162636431323334
cleartext hex: 4745540a0a0a4672692c2031322044656320323030382031303a30383a353120474d542b30303a30300a2f
digest hex: c0da50050c451847de7ed055c5286de584527a22
encoded: wNpQBQxFGEfeftBVxSht5YRSeiI=

I have verified that the secret key and clear text are the same input to both scripts. The encoding subroutine is virtually identical in both scripts (except for an unused argument passed to the subroutine, which I remove from my custom version).
What would cause the HMAC SHA-1 digest to be computed differently in both cases, if the input bytes and _encode subroutine are the same?
(I have also verified the two scripts against the test cases at RFC 2201.)
",<perl><encryption><hmac><digest><sha1>,5,"perl,encryption,hmac,digest,sha1",['why would hmac sha1 return a different digest with the same input'],"['i am trying to build a working encrypted signature for the amazon s3 web service writing a connection library using objective c i have run into hmac sha1 digest problems with the objc code so im putting that to the side and looking at existing working perl code to try to troubleshoot digest creation', 'i am testing hmac sha1 digest output from the s3ls command of the netamazons3 package and comparing that against the encode subroutine that i pulled out and put into its own perl script usrbinperl w use mimebase64 qwencodebase64 use digesthmacsha1 use stringescape qw printable unprintable sub asciitohex my str shift snsprintf02lx ord 1eg return str sub encode my awssecretaccesskey str print secret key hex asciitohexawssecretaccesskey', 'n my hmac digesthmacsha1newawssecretaccesskey hmacaddstr my digest hmacdigest print cleartext hex asciitohexstr', 'n print digest hex asciitohexdigest', 'n my b64 encodebase64 digest print encoded b64', 'n my secret abcd1234 my cleartext getnnnfri 12 dec 2008 100851 gmt0000n encodesecret cleartext here is sample output from this script testhmacpl secret key hex 6162636431323334 cleartext hex 4745540a0a0a4672692c2031322044656320323030382031303a30383a353120474d542b30303a30300a2f digest hex 63308f9b8a198440d6d8685a3f3f70d0aab02f68 encoded yzcpm4ozhedw2ghapz9w0kqwl2g what i am testing is that if i input the same secret key and cleartext into the same encode function of the netamazons3 package i should see the very same secret key cleartext and digest bytes', 'indeed i get the same bytes for the secret key and cleartext', 'but i get something different for the digest and of course the base64 encoding eg', ' s3ls accesskeyfoobar secretkeyabcd1234 secret key hex 6162636431323334 cleartext hex 4745540a0a0a4672692c2031322044656320323030382031303a30383a353120474d542b30303a30300a2f digest hex c0da50050c451847de7ed055c5286de584527a22 encoded wnpqbqxfgefeftbvxsht5yrseii i have verified that the secret key and clear text are the same input to both scripts', 'the encoding subroutine is virtually identical in both scripts except for an unused argument passed to the subroutine which i remove from my custom version', 'what would cause the hmac sha1 digest to be computed differently in both cases if the input bytes and encode subroutine are the same', 'i have also verified the two scripts against the test cases at rfc 2201']"
How to do scalar testing with android?,"I'm not sure ""scalar testing"" is the correct term for it but I mean tests that aren't boolean ""fail or succeed"". The problem I'm working on is a chromatic tuner for android:
http://code.google.com/p/androidtuner/
And I want to test the algorithm by running a few wav files and processing the resulting pitch graph. The goal is to define the scalar test result as a normalized x-minus-y-squared-sum where x is the detected pitch and y is the expected pitch. So a perfect test run would be 0 but more realistically I'd like to tweak the algorithm and see if/how it improved on all the test cases.
Generally speaking - can a unit test result in a number and not a boolean? Does the android testing framework allow it? How should I integrate whichever solution with Eclipse?
My current idea is to just circumvent everything and use adb to fetch files generated after running each test. Though that's not too awesome.
",<java><android><algorithm><unit-testing><testing>,7,"java,android,algorithm,unit-testing,testing",['how to do scalar testing with android'],"['im not sure scalar testing is the correct term for it but i mean tests that arent boolean fail or succeed', 'the problem im working on is a chromatic tuner for android and i want to test the algorithm by running a few wav files and processing the resulting pitch graph', 'the goal is to define the scalar test result as a normalized xminusysquaredsum where x is the detected pitch and y is the expected pitch', 'so a perfect test run would be 0 but more realistically id like to tweak the algorithm and see ifhow it improved on all the test cases', 'generally speaking can a unit test result in a number and not a boolean', 'does the android testing framework allow it', 'how should i integrate whichever solution with eclipse', 'my current idea is to just circumvent everything and use adb to fetch files generated after running each test', 'though thats not too awesome']"
Cannot find module '@storybook/react' or its corresponding type declarations. On Heroku,"I'm having in issue when my app gets deployed on heroku with the next message.

My app is running on typescript/react that I want to deploy to Heroku. I am using storybook/react in my application.
This is my tsconfig.json file
{
  ""compilerOptions"": {
    ""target"": ""es5"",
    ""lib"": [
      ""dom"",
      ""dom.iterable"",
      ""esnext""
    ],
    ""allowJs"": true,
    ""skipLibCheck"": true,
    ""esModuleInterop"": true,
    ""downlevelIteration"": true,
    ""allowSyntheticDefaultImports"": true,
    ""strict"": true,
    ""forceConsistentCasingInFileNames"": true,
    ""noFallthroughCasesInSwitch"": true,
    ""module"": ""esnext"",
    ""moduleResolution"": ""node"",
    ""resolveJsonModule"": true,
    ""isolatedModules"": true,
    ""noEmit"": true,
    ""jsx"": ""react-jsx""
  },
  ""include"": [
    ""src/**/*""
  ]
}

The structure of my project is:
- public
- src
   - components
     - (In here I have all the imports to storybook)
  - connectors
  - hooks
  - layout
  - state
  - theme
  - utils

I have storybook/react in devDependencies:
 ""devDependencies"": {
    ""@storybook/addon-actions"": ""^6.3.1"",
    ""@storybook/addon-essentials"": ""^6.3.1"",
    ""@storybook/addon-links"": ""^6.3.1"",
    ""@storybook/node-logger"": ""^6.3.1"",
    ""@storybook/preset-create-react-app"": ""^3.1.6"",
    ""@storybook/react"": ""^6.3.8"",
    ""@types/node"": ""^16.7.13"",
    ""@types/react-router-dom"": ""^5.1.7"",
    ""colors"": ""^1.4.0"",
    ""create-react-component-folder"": ""^0.3.7"",
    ""husky"": ""^7.0.1"",
    ""prettier"": ""^2.3.2"",
    ""yargs"": ""^17.0.1""
  }

I also have this too in my dependencies object in package.json:
""@types/jest"": ""^26.0.23"",
""@types/react"": ""^17.0.11"",
""@types/react-dom"": ""^17.0.8"",

I don't know what I have wrong. The worst thing is that if I run the app locally it works but on Heroku it just breaks. Any idea of that this could be? Thanks!
",<reactjs><typescript><heroku><storybook><react-typescript>,7,"reactjs,typescript,heroku,storybook,react-typescript","['cannot find module storybookreact or its corresponding type declarations', 'on heroku']","['im having in issue when my app gets deployed on heroku with the next message', 'my app is running on typescriptreact that i want to deploy to heroku', 'i am using storybookreact in my application', 'this is my tsconfigjson file compileroptions target es5 lib dom domiterable esnext allowjs true skiplibcheck true esmoduleinterop true downleveliteration true allowsyntheticdefaultimports true strict true forceconsistentcasinginfilenames true nofallthroughcasesinswitch true module esnext moduleresolution node resolvejsonmodule true isolatedmodules true noemit true jsx reactjsx include src the structure of my project is public src components in here i have all the imports to storybook connectors hooks layout state theme utils i have storybookreact in devdependencies devdependencies storybookaddonactions 631 storybookaddonessentials 631 storybookaddonlinks 631 storybooknodelogger 631 storybookpresetcreatereactapp 316 storybookreact 638 typesnode 16713 typesreactrouterdom 517 colors 140 createreactcomponentfolder 037 husky 701 prettier 232 yargs 1701 i also have this too in my dependencies object in packagejson typesjest 26023 typesreact 17011 typesreactdom 1708 i dont know what i have wrong', 'the worst thing is that if i run the app locally it works but on heroku it just breaks', 'any idea of that this could be', 'thanks']"
Thin and Puma fail with similar issues - ERROR: Failed to build gem native extension on Mac with OpenSSL@1.1,"Describe the bug
I have tried to do a gem install puma and gem install thin and get an error.
I have a brand new Mac that I am setting up: MacOS Catalina 10.15.6 (19G73)
I have worked out that any version <= 4.2.1 works fine on my computer
I am using asdf version manager

Works: gem install puma -v '4.2.1'
Fails: gem install puma -v '4.3.0' or gem install pumad

Error for Puma
I have tried each of these commands to get this to work
gem install puma

gem install puma -v '4.3.0'  --  --with-ldflags=-L/usr/local/opt/openssl@1.1/lib  --with-cppflags=-I/usr/local/opt/openssl@1.1/include

gem install puma -v '4.3.0'  --  --with-ldflags=-L/usr/local/opt/openssl@1.1/lib  --with-cppflags=-I/usr/local/opt/openssl@1.1/include --with-opt-dir=/usr/local/opt/openssl@1.1

Building native extensions. This could take a while...
ERROR:  Error installing puma:
    ERROR: Failed to build gem native extension.

    current directory: /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/gems/puma-4.3.5/ext/puma_http11
/Users/myname/.asdf/installs/ruby/2.7.1/bin/ruby -I /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/site_ruby/2.7.0 -r ./siteconf20200806-17963-1cqtelz.rb extconf.rb
checking for BIO_read() in -lcrypto... yes
checking for SSL_CTX_new() in -lssl... yes
checking for openssl/bio.h... yes
checking for DTLS_method() in openssl/ssl.h... yes
checking for TLS_server_method() in openssl/ssl.h... yes
checking for SSL_CTX_set_min_proto_version in openssl/ssl.h... yes
creating Makefile

current directory: /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/gems/puma-4.3.5/ext/puma_http11
make ""DESTDIR="" clean

current directory: /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/gems/puma-4.3.5/ext/puma_http11
make ""DESTDIR=""
compiling http11_parser.c
ext/puma_http11/http11_parser.c:44:18: warning: unused variable 'puma_parser_en_main' [-Wunused-const-variable]
static const int puma_parser_en_main = 1;
                 ^
1 warning generated.
compiling io_buffer.c
compiling mini_ssl.c
mini_ssl.c:145:7: warning: unused variable 'min' [-Wunused-variable]
  int min, ssl_options;
      ^
mini_ssl.c:299:40: warning: function 'raise_error' could be declared with attribute 'noreturn' [-Wmissing-noreturn]
void raise_error(SSL* ssl, int result) {
                                       ^
2 warnings generated.
compiling puma_http11.c
puma_http11.c:203:22: error: implicitly declaring library function 'isspace' with type 'int (int)' [-Werror,-Wimplicit-function-declaration]
  while (vlen > 0 && isspace(value[vlen - 1])) vlen--;
                     ^
puma_http11.c:203:22: note: include the header <ctype.h> or explicitly provide a declaration for 'isspace'
1 error generated.
make: *** [puma_http11.o] Error 1

make failed, exit code 2

Gem files will remain installed in /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/gems/puma-4.3.5 for inspection.
Results logged to /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/extensions/x86_64-darwin-19/2.7.0/puma-4.3.5/gem_make.out

I saw on this thread that you need OpenSSL 1.1
OpenSSL@1.1
I reinstalled openssl
brew reinstall openssl@1.1
==> Downloading https://homebrew.bintray.com/bottles/openssl%401.1-1.1.1g.catalina.bottle.tar.gz
Already downloaded: /Users/myname/Library/Caches/Homebrew/downloads/d6b7a6d80c588c89e79f350ce3e05c95d31d804291cc120efcbb6c9478607a41--openssl@1.1-1.1.1g.catalina.bottle.tar.gz
==> Reinstalling openssl@1.1
==> Pouring openssl@1.1-1.1.1g.catalina.bottle.tar.gz
==> Caveats
A CA file has been bootstrapped using certificates from the system
keychain. To add additional certificates, place .pem files in
  /usr/local/etc/openssl@1.1/certs

and run
  /usr/local/opt/openssl@1.1/bin/c_rehash

openssl@1.1 is keg-only, which means it was not symlinked into /usr/local,
because macOS provides LibreSSL.

If you need to have openssl@1.1 first in your PATH run:
  echo 'export PATH=""/usr/local/opt/openssl@1.1/bin:$PATH""' >> ~/.zshrc

For compilers to find openssl@1.1 you may need to set:
  export LDFLAGS=""-L/usr/local/opt/openssl@1.1/lib""
  export CPPFLAGS=""-I/usr/local/opt/openssl@1.1/include""

For pkg-config to find openssl@1.1 you may need to set:
  export PKG_CONFIG_PATH=""/usr/local/opt/openssl@1.1/lib/pkgconfig""

I tested with these lines in .zshrc
export PATH=""/usr/local/opt/openssl@1.1/bin:$PATH""
export LDFLAGS=""-L/usr/local/opt/openssl@1.1/lib""
export CPPFLAGS=""-I/usr/local/opt/openssl@1.1/include""
export PKG_CONFIG_PATH=""/usr/local/opt/openssl@1.1/lib/pkgconfig""

Install for Thin
gem install thin
Building native extensions. This could take a while...
ERROR:  Error installing thin:
    ERROR: Failed to build gem native extension.

    current directory: /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/gems/thin-1.7.2/ext/thin_parser
/Users/myname/.asdf/installs/ruby/2.7.1/bin/ruby -I /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/site_ruby/2.7.0 -r ./siteconf20200806-18426-1lt7u04.rb extconf.rb
checking for main() in -lc... yes
creating Makefile

current directory: /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/gems/thin-1.7.2/ext/thin_parser
make ""DESTDIR="" clean

current directory: /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/gems/thin-1.7.2/ext/thin_parser
make ""DESTDIR=""
compiling parser.c
parser.c:31:18: warning: unused variable 'http_parser_en_main' [-Wunused-const-variable]
static const int http_parser_en_main = 1;
                 ^
1 warning generated.
compiling thin.c
thin.c:242:3: error: implicit declaration of function 'thin_http_parser_init' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
  thin_http_parser_init(hp);
  ^
thin.c:242:3: note: did you mean 'http_parser_init'?
./parser.h:41:5: note: 'http_parser_init' declared here
int http_parser_init(http_parser *parser);
    ^
thin.c:260:3: error: implicit declaration of function 'thin_http_parser_init' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
  thin_http_parser_init(http);
  ^
thin.c:277:3: error: implicit declaration of function 'thin_http_parser_init' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
  thin_http_parser_init(http);
  ^
thin.c:294:3: error: implicit declaration of function 'thin_http_parser_finish' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
  thin_http_parser_finish(http);
  ^
thin.c:294:3: note: did you mean 'Thin_HttpParser_finish'?
thin.c:290:7: note: 'Thin_HttpParser_finish' declared here
VALUE Thin_HttpParser_finish(VALUE self)
      ^
thin.c:296:10: error: implicit declaration of function 'thin_http_parser_is_finished' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
  return thin_http_parser_is_finished(http) ? Qtrue : Qfalse;
         ^
thin.c:334:5: error: implicit declaration of function 'thin_http_parser_execute' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
    thin_http_parser_execute(http, dptr, dlen, from);
    ^
thin.c:334:5: note: did you mean 'Thin_HttpParser_execute'?
thin.c:317:7: note: 'Thin_HttpParser_execute' declared here
VALUE Thin_HttpParser_execute(VALUE self, VALUE req_hash, VALUE data, VALUE start)
      ^
thin.c:338:8: error: implicit declaration of function 'thin_http_parser_has_error' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
    if(thin_http_parser_has_error(http)) {
       ^
thin.c:338:8: note: did you mean 'http_parser_has_error'?
./parser.h:44:5: note: 'http_parser_has_error' declared here
int http_parser_has_error(http_parser *parser);
    ^
thin.c:359:10: error: implicit declaration of function 'thin_http_parser_has_error' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
  return thin_http_parser_has_error(http) ? Qtrue : Qfalse;
         ^
thin.c:374:10: error: implicit declaration of function 'thin_http_parser_is_finished' is invalid in C99 [-Werror,-Wimplicit-function-declaration]
  return thin_http_parser_is_finished(http) ? Qtrue : Qfalse;
         ^
9 errors generated.
make: *** [thin.o] Error 1

make failed, exit code 2

Gem files will remain installed in /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/gems/thin-1.7.2 for inspection.
Results logged to /Users/myname/.asdf/installs/ruby/2.7.1/lib/ruby/gems/2.7.0/extensions/x86_64-darwin-19/2.7.0/thin-1.7.2/gem_make.out

",<ruby><macos><macos-catalina><puma><thin>,19,"ruby,macos,macos-catalina,puma,thin",['thin and puma fail with similar issues error failed to build gem native extension on mac with openssl11'],"['describe the bug i have tried to do a gem install puma and gem install thin and get an error', 'i have a brand new mac that i am setting up macos catalina 10156 19g73 i have worked out that any version 421 works fine on my computer i am using asdf version manager works gem install puma v 421 fails gem install puma v 430 or gem install pumad error for puma i have tried each of these commands to get this to work gem install puma gem install puma v 430 withldflagslusrlocaloptopenssl11lib withcppflagsiusrlocaloptopenssl11include gem install puma v 430 withldflagslusrlocaloptopenssl11lib withcppflagsiusrlocaloptopenssl11include withoptdirusrlocaloptopenssl11 building native extensions', 'this could take a while error error installing puma error failed to build gem native extension', 'current directory usersmynameasdfinstallsruby271librubygems270gemspuma435extpumahttp11 usersmynameasdfinstallsruby271binruby i usersmynameasdfinstallsruby271librubysiteruby270 r siteconf20200806179631cqtelzrb extconfrb checking for bioread in lcrypto yes checking for sslctxnew in lssl yes checking for opensslbioh yes checking for dtlsmethod in opensslsslh yes checking for tlsservermethod in opensslsslh yes checking for sslctxsetminprotoversion in opensslsslh yes creating makefile current directory usersmynameasdfinstallsruby271librubygems270gemspuma435extpumahttp11 make destdir clean current directory usersmynameasdfinstallsruby271librubygems270gemspuma435extpumahttp11 make destdir compiling http11parserc extpumahttp11http11parserc4418 warning unused variable pumaparserenmain wunusedconstvariable static const int pumaparserenmain 1 1 warning generated', 'compiling iobufferc compiling minisslc minisslc1457 warning unused variable min wunusedvariable int min ssloptions minisslc29940 warning function raiseerror could be declared with attribute noreturn wmissingnoreturn void raiseerrorssl ssl int result 2 warnings generated', 'compiling pumahttp11c pumahttp11c20322 error implicitly declaring library function isspace with type int int werrorwimplicitfunctiondeclaration while vlen 0 isspacevaluevlen 1 vlen pumahttp11c20322 note include the header ctypeh or explicitly provide a declaration for isspace 1 error generated', 'make pumahttp11o error 1 make failed exit code 2 gem files will remain installed in usersmynameasdfinstallsruby271librubygems270gemspuma435 for inspection', 'results logged to usersmynameasdfinstallsruby271librubygems270extensionsx8664darwin19270puma435gemmakeout i saw on this thread that you need openssl 11 openssl11 i reinstalled openssl brew reinstall openssl11 downloading already downloaded usersmynamelibrarycacheshomebrewdownloadsd6b7a6d80c588c89e79f350ce3e05c95d31d804291cc120efcbb6c9478607a41openssl11111gcatalinabottletargz reinstalling openssl11 pouring openssl11111gcatalinabottletargz caveats a ca file has been bootstrapped using certificates from the system keychain', 'to add additional certificates place pem files in usrlocaletcopenssl11certs and run usrlocaloptopenssl11bincrehash openssl11 is kegonly which means it was not symlinked into usrlocal because macos provides libressl', 'if you need to have openssl11 first in your path run echo export pathusrlocaloptopenssl11binpath zshrc for compilers to find openssl11 you may need to set export ldflagslusrlocaloptopenssl11lib export cppflagsiusrlocaloptopenssl11include for pkgconfig to find openssl11 you may need to set export pkgconfigpathusrlocaloptopenssl11libpkgconfig i tested with these lines in zshrc export pathusrlocaloptopenssl11binpath export ldflagslusrlocaloptopenssl11lib export cppflagsiusrlocaloptopenssl11include export pkgconfigpathusrlocaloptopenssl11libpkgconfig install for thin gem install thin building native extensions', 'this could take a while error error installing thin error failed to build gem native extension', 'current directory usersmynameasdfinstallsruby271librubygems270gemsthin172extthinparser usersmynameasdfinstallsruby271binruby i usersmynameasdfinstallsruby271librubysiteruby270 r siteconf20200806184261lt7u04rb extconfrb checking for main in lc yes creating makefile current directory usersmynameasdfinstallsruby271librubygems270gemsthin172extthinparser make destdir clean current directory usersmynameasdfinstallsruby271librubygems270gemsthin172extthinparser make destdir compiling parserc parserc3118 warning unused variable httpparserenmain wunusedconstvariable static const int httpparserenmain 1 1 warning generated', 'compiling thinc thinc2423 error implicit declaration of function thinhttpparserinit is invalid in c99 werrorwimplicitfunctiondeclaration thinhttpparserinithp thinc2423 note did you mean httpparserinit', 'parserh415 note httpparserinit declared here int httpparserinithttpparser parser thinc2603 error implicit declaration of function thinhttpparserinit is invalid in c99 werrorwimplicitfunctiondeclaration thinhttpparserinithttp thinc2773 error implicit declaration of function thinhttpparserinit is invalid in c99 werrorwimplicitfunctiondeclaration thinhttpparserinithttp thinc2943 error implicit declaration of function thinhttpparserfinish is invalid in c99 werrorwimplicitfunctiondeclaration thinhttpparserfinishhttp thinc2943 note did you mean thinhttpparserfinish', 'thinc2907 note thinhttpparserfinish declared here value thinhttpparserfinishvalue self thinc29610 error implicit declaration of function thinhttpparserisfinished is invalid in c99 werrorwimplicitfunctiondeclaration return thinhttpparserisfinishedhttp ', 'qtrue qfalse thinc3345 error implicit declaration of function thinhttpparserexecute is invalid in c99 werrorwimplicitfunctiondeclaration thinhttpparserexecutehttp dptr dlen from thinc3345 note did you mean thinhttpparserexecute', 'thinc3177 note thinhttpparserexecute declared here value thinhttpparserexecutevalue self value reqhash value data value start thinc3388 error implicit declaration of function thinhttpparserhaserror is invalid in c99 werrorwimplicitfunctiondeclaration ifthinhttpparserhaserrorhttp thinc3388 note did you mean httpparserhaserror', 'parserh445 note httpparserhaserror declared here int httpparserhaserrorhttpparser parser thinc35910 error implicit declaration of function thinhttpparserhaserror is invalid in c99 werrorwimplicitfunctiondeclaration return thinhttpparserhaserrorhttp ', 'qtrue qfalse thinc37410 error implicit declaration of function thinhttpparserisfinished is invalid in c99 werrorwimplicitfunctiondeclaration return thinhttpparserisfinishedhttp ', 'qtrue qfalse 9 errors generated', 'make thino error 1 make failed exit code 2 gem files will remain installed in usersmynameasdfinstallsruby271librubygems270gemsthin172 for inspection', 'results logged to usersmynameasdfinstallsruby271librubygems270extensionsx8664darwin19270thin172gemmakeout']"
How DateTime is validated in MVC Unobtrusive Validation?,"Using MVC4 with client-side & unobtrusive validation enabled, I'm trying to understand how the validation determine if an entered DateTime value is valid or not.
In my application this formatted date is valid: 01/31/2013,
while if I enter: 31/01/2013, I get:

The field [fieldId] must be a date

How does it determined what is a valid date?
",<asp.net-mvc><asp.net-mvc-3><asp.net-mvc-4><jquery-validate><unobtrusive-validation>,7,"asp.net-mvc,asp.net-mvc-3,asp.net-mvc-4,jquery-validate,unobtrusive-validation",['how datetime is validated in mvc unobtrusive validation'],"['using mvc4 with clientside unobtrusive validation enabled im trying to understand how the validation determine if an entered datetime value is valid or not', 'in my application this formatted date is valid 01312013 while if i enter 31012013 i get the field fieldid must be a date how does it determined what is a valid date']"
Encode wav to AAC on Android,"You can use MediaRecorder to record a stream directly to AAC but there doesn't seem to be a way to encode an existing PCM/WAV file to AAC. The ability to encode to AAC exists natively in Android and I'd like to use that. Is there no way to do it with a pre-existing audio file?
",<android><wav><encode><pcm><aac>,15,"android,wav,encode,pcm,aac",['encode wav to aac on android'],"['you can use mediarecorder to record a stream directly to aac but there doesnt seem to be a way to encode an existing pcmwav file to aac', 'the ability to encode to aac exists natively in android and id like to use that', 'is there no way to do it with a preexisting audio file']"
iOS: the background color of the header of my TableView is not changing anymore in iOS13,"My TableView's header is not displaying well in iOS13. No matter what color I put, it always displays a light gray now...
- (void)tableView:(UITableView *)tableView willDisplayHeaderView:(UIView *)view forSection:(NSInteger)section
{   //Section color & style

    UITableViewHeaderFooterView *v = (UITableViewHeaderFooterView *)view;

    v.backgroundView.alpha = 1;
    v.textLabel.textColor = sectionColor;
    v.textLabel.font = sectionFont;
    v.textLabel.numberOfLines = 1;
    v.textLabel.minimumScaleFactor = 0.5;
    v.textLabel.adjustsFontSizeToFitWidth = YES;
    v.backgroundView.backgroundColor = [UIColor blueColor];
} 

iOS12:

iOS13:

It is strange because when I put a stop in the debugger in step by step, it displays me the good image in iOS13, but not in the app:  

Any suggestions, thanks in advance ?  
",<ios><objective-c><uitableview><ios13><uibackgroundcolor>,7,"ios,objective-c,uitableview,ios13,uibackgroundcolor",['ios the background color of the header of my tableview is not changing anymore in ios13'],"['my tableviews header is not displaying well in ios13', 'no matter what color i put it always displays a light gray now voidtableviewuitableview tableview willdisplayheaderviewuiview view forsectionnsintegersection section color style uitableviewheaderfooterview v uitableviewheaderfooterview view vbackgroundviewalpha 1 vtextlabeltextcolor sectioncolor vtextlabelfont sectionfont vtextlabelnumberoflines 1 vtextlabelminimumscalefactor 05 vtextlabeladjustsfontsizetofitwidth yes vbackgroundviewbackgroundcolor uicolor bluecolor ios12 ios13 it is strange because when i put a stop in the debugger in step by step it displays me the good image in ios13 but not in the app any suggestions thanks in advance ']"
"Bazel: How do i use nodeJS_binary rule to do ""npm run start""","How do i use the nodejs_binary rule to do a standard npm run start. I am able to run a typical node project using this rule. However i want to run a the start script in package.json. So far i have the following below in my build file
load(""@build_bazel_rules_nodejs//:defs.bzl"", ""nodejs_binary"")

nodejs_binary(
    name = ""app"",
    data = ["":app_files""],
    node=""@nodejs//:bin/npm"",
    entry_point = ""workspace_name/src/server.js"",
    node_modules = ""@npm_deps//:node_modules"",
    args=[""start""]
)

This does not start the server..somehow npm command is not running properly. it indicates usage of the command in incomplete. 
I am currently able to do this within the WORKSPACE
bazel run @nodejs//:bin/yarn (runs yarn install and installs all node-modulse)
bazel run @nodejs//:bin/npm start (this starts the server)
In my package.json i have
{
  ""scripts"": {
    ""start"": ""babel-node src/server.js"",
   ...
  }
...
}

I do i get this to work with nodejs_binary rule and subsequently node_image
I changed from using npm to using yarn..workspace_name/src/server.js.. is called now but Then i had different set of problems, babel-node was not found. 
I modified the rule a bit. After careful study...I realise that there is a dependency on babel-node that is not satisfied at the time yarn run start is called. The following worked after i had run bazel run @nodejs//:bin/yarn before running the rule. 
nodejs_binary(
    name = ""app"",
    args = [""start""],
    data = [
        "":app_files"",
        ""@//:node_modules"",
    ],
    entry_point = ""workspace_name/src/server.js"",
    node = ""@nodejs//:bin/yarn"",
    node_modules = ""@npm_deps//:node_modules"",
)

It appears that ""@//:node_modules"" solves the babel-node dependency issue. So the rule above does not work on its own...it needs me to do bazel run @nodejs//:bin/yarn (more like npm/yarn install to make the node_modules, which contain babel-node dependecy available when npm/yarn start is run)
So my problem is that I do not want to have to manually run bazel run @nodejs//:bin/yarn before executing my rule. how do i do this.
I suppose it would work if i stopped depending on babel-node...but then i would have to change my code to not use es6 syntax (that is a hustle). Is there a way i can do this with a genrule? or something...
",<javascript><node.js><npm><bazel><npm-start>,5,"javascript,node.js,npm,bazel,npm-start",['bazel how do i use nodejsbinary rule to do npm run start'],"['how do i use the nodejsbinary rule to do a standard npm run start', 'i am able to run a typical node project using this rule', 'however i want to run a the start script in packagejson', 'so far i have the following below in my build file loadbuildbazelrulesnodejsdefsbzl nodejsbinary nodejsbinary name app data appfiles nodenodejsbinnpm entrypoint workspacenamesrcserverjs nodemodules npmdepsnodemodules argsstart this does not start the serversomehow npm command is not running properly', 'it indicates usage of the command in incomplete', 'i am currently able to do this within the workspace bazel run nodejsbinyarn runs yarn install and installs all nodemodulse bazel run nodejsbinnpm start this starts the server in my packagejson i have scripts start babelnode srcserverjs i do i get this to work with nodejsbinary rule and subsequently nodeimage i changed from using npm to using yarnworkspacenamesrcserverjs is called now but then i had different set of problems babelnode was not found', 'i modified the rule a bit', 'after careful studyi realise that there is a dependency on babelnode that is not satisfied at the time yarn run start is called', 'the following worked after i had run bazel run nodejsbinyarn before running the rule', 'nodejsbinary name app args start data appfiles nodemodules entrypoint workspacenamesrcserverjs node nodejsbinyarn nodemodules npmdepsnodemodules it appears that nodemodules solves the babelnode dependency issue', 'so the rule above does not work on its ownit needs me to do bazel run nodejsbinyarn more like npmyarn install to make the nodemodules which contain babelnode dependecy available when npmyarn start is run so my problem is that i do not want to have to manually run bazel run nodejsbinyarn before executing my rule', 'how do i do this', 'i suppose it would work if i stopped depending on babelnodebut then i would have to change my code to not use es6 syntax that is a hustle', 'is there a way i can do this with a genrule', 'or something']"
Remove border from IFrame,"How would I remove the border from an iframe embedded in my web app? An example of the iframe is:
<iframe src=""myURL"" width=""300"" height=""300"">Browser not compatible.</iframe>

I would like the transition from the content on my page to the contents of the iframe to be seamless, assuming the background colors are consistent. The target browser is IE6 only and unfortunately solutions for others will not help.
",<html><css><iframe><internet-explorer-6><noborder>,847,"html,css,iframe,internet-explorer-6,noborder",['remove border from iframe'],"['how would i remove the border from an iframe embedded in my web app', 'an example of the iframe is iframe srcmyurl width300 height300browser not compatibleiframe i would like the transition from the content on my page to the contents of the iframe to be seamless assuming the background colors are consistent', 'the target browser is ie6 only and unfortunately solutions for others will not help']"
.Net CompareExchange reordering,"Can the compiler or processor reorder the following instructions so that another Thread sees a == 0 and b == 1?
Assuming int a = 0, b = 0; somewhere.
System.Threading.Interlocked.CompareExchange<int>(ref a, 1, 0);
System.Threading.Interlocked.CompareExchange<int>(ref b, 1, 0);

",<c#><.net><multithreading><memory-fences><test-and-set>,7,"c#,.net,multithreading,memory-fences,test-and-set",['net compareexchange reordering'],"['can the compiler or processor reorder the following instructions so that another thread sees a 0 and b 1', 'assuming int a 0 b 0 somewhere', 'systemthreadinginterlockedcompareexchangeintref a 1 0 systemthreadinginterlockedcompareexchangeintref b 1 0']"
Shell script - Bump version automatically git,"I've the following command which I want to execute with one command via 'makefile' how can I do it ?
1. git tag -a v0.0.1 -m ""new release""
2. git push origin v0.0.1

Now I've created something for start
git:
    git add .
    git commit -m ""$m""
    git push origin master

Now I've two issue, how to resolve the version e.g.
Here is v0.0.1 but for each new release I need to bump it like first is 
v0.0.1 and the next release should be v0.0.2, can it be done somehow automatically (maybe have some counter...)? if not maybe add it as parameter to one command 

git tag -a v0.0.1 -m ""new release""
git push origin v0.0.1 

update
There is answer which looks good  with the following
git describe --tags --abbrev=0 | awk -F. '{$NF+=1; OFS="".""; print $0}'

but How should I combine it with ? 

git tag -a v0.0.1 -m ""new release""
git push origin v0.0.1 

update 2
When I try the following as suggest in Kevin answer I got error:
.PHONY: git
VERSION=git describe --tags --abbrev=0 | awk -F. '{$NF+=1; OFS="".""; print $0}'
git:
    git add .
    git commit -m ""$m""
    git push origin master
    git tag -a $(VERSION) -m ""new release""
    git push origin $(VERSION)

The error is: fatal: tag 'ERSION' already exists
it seems that the bump of not working and it somehow remove the v from version
I did another check, remove the repo and start it from scratch manually for the first release 0.0.1 now I did change in one file and run the script , the version should now be 0.0.2 if it success, but no Im getting error fatal: tag 'v0.0.1' already exists which explain that the bump is not working, any idea why ?
I guess it's related to this code  `'{$NF+=1; OFS="".""; print $0}'
",<linux><bash><git><shell><makefile>,6,"linux,bash,git,shell,makefile",['shell script bump version automatically git'],"['ive the following command which i want to execute with one command via makefile how can i do it ', '1 git tag a v001 m new release 2 git push origin v001 now ive created something for start git git add ', 'git commit m m git push origin master now ive two issue how to resolve the version eg', 'here is v001 but for each new release i need to bump it like first is v001 and the next release should be v002 can it be done somehow automatically maybe have some counter', 'if not maybe add it as parameter to one command git tag a v001 m new release git push origin v001 update there is answer which looks good with the following git describe tags abbrev0 awk f nf1 ofs', ' print 0 but how should i combine it with ', 'git tag a v001 m new release git push origin v001 update 2 when i try the following as suggest in kevin answer i got error phony git versiongit describe tags abbrev0 awk f nf1 ofs', ' print 0 git git add ', 'git commit m m git push origin master git tag a version m new release git push origin version the error is fatal tag ersion already exists it seems that the bump of not working and it somehow remove the v from version i did another check remove the repo and start it from scratch manually for the first release 001 now i did change in one file and run the script the version should now be 002 if it success but no im getting error fatal tag v001 already exists which explain that the bump is not working any idea why ', 'i guess its related to this code nf1 ofs', ' print 0']"
Codeigniter 3 Remove index.php Problems,"I have a little project that i developed for a client in codeigniter 2.1.4 and now, he insists to migrate to codeigniter 3 DEV version. I know that's not a good ideea but...
My problem is that i can't remove the index.php from the url.
This is my .htaccess file :
  Options +FollowSymLinks
  RewriteEngine on

  # Send request via index.php
  RewriteCond %{REQUEST_FILENAME} !-f
  RewriteCond %{REQUEST_FILENAME} !-d
  RewriteRule ^(.*)$ index.php?/$1 [L]

I have removed the index.php from the config.php file
No luck
I reinstalled the LAMP server (i'm on Ubuntu 12.04'), reconfigured I have other projects on my local server developed on Codeigniter 2.1.4 and Laravel 4 and they work just fine but this one it's killing me.
Thank you!
",<php><apache><.htaccess><codeigniter><mod-rewrite>,5,"php,apache,.htaccess,codeigniter,mod-rewrite",['codeigniter 3 remove indexphp problems'],"['i have a little project that i developed for a client in codeigniter 214 and now he insists to migrate to codeigniter 3 dev version', 'i know thats not a good ideea but my problem is that i cant remove the indexphp from the url', 'this is my htaccess file options followsymlinks rewriteengine on send request via indexphp rewritecond requestfilename f rewritecond requestfilename d rewriterule ', ' indexphp1 l i have removed the indexphp from the configphp file no luck i reinstalled the lamp server im on ubuntu 1204 reconfigured i have other projects on my local server developed on codeigniter 214 and laravel 4 and they work just fine but this one its killing me', 'thank you']"
"Calculating user, nice, sys, idle, iowait, irq and sirq from /proc/stat","/proc/stat shows ticks for user, nice, sys, idle, iowait, irq and sirq like this:
cpu  6214713 286 1216407 121074379 260283 253506 197368 0 0 0
How can I calculate the individual utilizations (in %) for user, nice etc with these values? Like the values that shows in 'top' or 'vmstat'.
",<python><c><linux><kernel><procfs>,9,"python,c,linux,kernel,procfs",['calculating user nice sys idle iowait irq and sirq from procstat'],"['procstat shows ticks for user nice sys idle iowait irq and sirq like this cpu 6214713 286 1216407 121074379 260283 253506 197368 0 0 0 how can i calculate the individual utilizations in for user nice etc with these values', 'like the values that shows in top or vmstat']"
How to use a boost::mutex as the mapped type in std::map?,"I would like to lock the keys/index in another map like this:
std::map<int, boost::mutex> pointCloudsMutexes_;
pointCloudsMutexes_[index].lock();

However, I am getting the following error:
/usr/include/c++/4.8/bits/stl_pair.h:113: error: no matching function for call to 'boost::mutex::mutex(const boost::mutex&)'
       : first(__a), second(__b) { }
                               ^

It seems to work with std::vector, but not with std::map. What am I doing wrong?
",<c++><boost><mutex><stdmap><boost-mutex>,5,"c++,boost,mutex,stdmap,boost-mutex",['how to use a boostmutex as the mapped type in stdmap'],"['i would like to lock the keysindex in another map like this stdmapint boostmutex pointcloudsmutexes pointcloudsmutexesindexlock however i am getting the following error usrincludec48bitsstlpairh113 error no matching function for call to boostmutexmutexconst boostmutex firsta secondb it seems to work with stdvector but not with stdmap', 'what am i doing wrong']"
C++: Is it safe to pass an argument like unique_ptr::get() to function,"Is is safe to pass a function parameter like getAName(getA().get())? getA() return a object unique_ptr<A>.
I test with the whole code below on VS 2010, it works. But I would like to make sure if it's c++ standard, is it safe with other c++ compilers? 
#include ""stdafx.h""
#include <memory>
#include <iostream>

using namespace std;

class A
{
public:
    A(){ cout<<""A()""<<endl;}
    ~A(){ cout<<""~A()""<<endl;}

    string name() { return ""A""; }
};

std::unique_ptr<A> getA()
{
    return std::unique_ptr<A>(new A());;
}

void getAName(A* a)
{
    if(a)
    {
        cout << a->name().c_str() << endl;
    }
}

int _tmain(int argc, _TCHAR* argv[])
{
    getAName(getA().get());
    return 0;
}

The outputs in console are:
A()
A
~()

Is it necessary to make code as below for safe for all compilers?
unique_ptr<A> a = getA();
getAName(a.get());

",<c++><c++11><stl><unique-ptr><temporary>,9,"c++,c++11,stl,unique-ptr,temporary",['c is it safe to pass an argument like uniqueptrget to function'],"['is is safe to pass a function parameter like getanamegetaget', 'geta return a object uniqueptra', 'i test with the whole code below on vs 2010 it works', 'but i would like to make sure if its c standard is it safe with other c compilers', 'include stdafxh include memory include iostream using namespace std class a public a coutaendl a coutaendl string name return a stduniqueptra geta return stduniqueptranew a void getanamea a ifa cout anamecstr endl int tmainint argc tchar argv getanamegetaget return 0 the outputs in console are a a is it necessary to make code as below for safe for all compilers', 'uniqueptra a geta getanameaget']"
"Facebook stops custom parameters (image,title,description) through FB.ui?","Today I check my site and this code not working:
<script>
...
    FB.ui({
            display: 'dialog',
            method: 'share_open_graph',
            action_type: 'og.likes',
            hashtag: '#Testing',
            action_properties: JSON.stringify({
                object: {
                    'og:image': img,
                    'og:image:secure_url': img,
                    'og:image:type': 'image/jpeg',
                    'og:image:width': w,
                    'og:image:height': h,
                    'og:image:alt': img,
                    'og:url': link,
                    'og:title': title,
                    'og:description': desc,
                    'fb:admins': fbadmin
                }
            })
        },
        function(response) {
            if (typeof response != 'undefined') {
                //Success
            } else {
                //Not Success;
            }
        });
</script>

With this code, from https://developers.facebook.com/docs/sharing/reference/share-dialog/ :
FB.ui({
  method: 'share',
  href: link,
}, function(response){});

Facebook sees and takes a picture of the link, but not the picture that I need share.
Apparently FB changed policy of sharing.
How to now I can customize paramateres for sharing? How to I can set custom image if this link has a lot of pictures?
Edited
Without og:url it worked again, but after click successfully shared content on facebook, redirected on board url, not on url that I need share.
",<jquery><facebook><parameters><sharing><fb.ui>,5,"jquery,facebook,parameters,sharing,fb.ui",['facebook stops custom parameters imagetitledescription through fbui'],"['today i check my site and this code not working script fbui display dialog method shareopengraph actiontype oglikes hashtag testing actionproperties jsonstringify object ogimage img ogimagesecureurl img ogimagetype imagejpeg ogimagewidth w ogimageheight h ogimagealt img ogurl link ogtitle title ogdescription desc fbadmins fbadmin functionresponse if typeof response undefined success else not success script with this code from fbui method share href link functionresponse facebook sees and takes a picture of the link but not the picture that i need share', 'apparently fb changed policy of sharing', 'how to now i can customize paramateres for sharing', 'how to i can set custom image if this link has a lot of pictures', 'edited without ogurl it worked again but after click successfully shared content on facebook redirected on board url not on url that i need share']"
"How to connect backend (python, flask) with frontend (html, css, javascript)","Info: for backend I'm using python with flask (for the moment it accepts http get methods) and for frontend I'm using html, css and javascript.
Problem: I'm trying to make a http request (first time I tried POST and then GET) but the browser did not allow me to do that: ""Access to XMLHttpRequest at 'localhost:5000/test' from origin 'null' has been blocked by CORS policy: Cross origin requests are only supported for protocol schemes: http, data, chrome, chrome-extension, https."".
What another choices do I have? (I would like some simple choices, it is just a homework).
I've tried to make http POST and GET request.
I've read that I cannot make http request from browser.
I've read that I need (for example) an apache server. - too complicated, I need something more simple.
I've tried: https://flask-cors.readthedocs.io/en/latest/
document.getElementById(""btn"").addEventListener('click', add);
function add()
{
    const url = ""localhost:5000/test"";
    const http = new XMLHttpRequest();
    http.open(""GET"", url);
    http.send();
    http.onreadystatechange=(e)=> {
        console.log(http.responseText)
    }
}

from flask import Flask
from flask_cors import CORS
from flask import request
from flask import jsonify
import json
import mysql.connector
import random
import string
import time

time.sleep(3)
app = Flask(__name__)

@app.route(""/test"")
def test():
    return ""It's working""


if __name__ == ""__main__"":
    app.run(host='0.0.0.0', port=5000)

I expect that in the browser console to be printed message: ""It's working"", but I get the error:
Access to XMLHttpRequest at 'localhost:5000/test' from origin 'null' has been blocked by CORS policy: Cross origin requests are only supported for protocol schemes: http, data, chrome, chrome-extension, https.
LE: Flask server is inside a docker container. Ports are mapped ""5000:5000'.
",<javascript><python><post><flask><get>,6,"javascript,python,post,flask,get",['how to connect backend python flask with frontend html css javascript'],"['info for backend im using python with flask for the moment it accepts http get methods and for frontend im using html css and javascript', 'problem im trying to make a http request first time i tried post and then get but the browser did not allow me to do that access to xmlhttprequest at localhost5000test from origin null has been blocked by cors policy cross origin requests are only supported for protocol schemes http data chrome chromeextension https', 'what another choices do i have', 'i would like some simple choices it is just a homework', 'ive tried to make http post and get request', 'ive read that i cannot make http request from browser', 'ive read that i need for example an apache server', ' too complicated i need something more simple', 'ive tried documentgetelementbyidbtnaddeventlistenerclick add function add const url localhost5000test const http new xmlhttprequest httpopenget url httpsend httponreadystatechangee consoleloghttpresponsetext from flask import flask from flaskcors import cors from flask import request from flask import jsonify import json import mysqlconnector import random import string import time timesleep3 app flaskname approutetest def test return its working if name main apprunhost0000 port5000 i expect that in the browser console to be printed message its working but i get the error access to xmlhttprequest at localhost5000test from origin null has been blocked by cors policy cross origin requests are only supported for protocol schemes http data chrome chromeextension https', 'le flask server is inside a docker container', 'ports are mapped 50005000']"
'str' object has no attribute 'META',"I am getting the error:

'str' object has no attribute 'META'

The Traceback highlights this bit of code:
return render('login.html', c)

Where that bit of code is in my views.py:
from django.shortcuts import render
from django.http import HttpResponseRedirect    # allows us to redirect the browser to a difference URL
from django.contrib import auth                 # checks username and password handles login and log outs
from django.core.context_processors import csrf # csrf - cross site request forgery. 

def login(request):
    c = {}
    c.update(csrf(request))
    return render('login.html', c)

This is what my template looks like:
{% extends ""base.html""%}

{% block content %}

    {% if form.errors %}
        <p class = 'error'>Sorry, that's not a valid username or password</p>
    {% endif %}

    <form action = '/accounts/auth/' method = 'post'> {% csrf_token %}
        <label for = 'username'>User name: </label>
        <input type = 'text' name = 'username' value = '' id = 'username'>
        <label for = 'password'>Password: </label>
        <input type = 'password' name = 'password' value = '' id = 'password'>

        <input type = 'submit' value = 'login'>
    </form>
{% endblock %}  

I assume I might be using render() incorrectly but in the docs I think I am putting in the correct parameters.
https://docs.djangoproject.com/en/dev/topics/http/shortcuts/
",<python><django><django-views><django-templates><render>,9,"python,django,django-views,django-templates,render",['str object has no attribute meta'],"['i am getting the error str object has no attribute meta the traceback highlights this bit of code return renderloginhtml c where that bit of code is in my viewspy from djangoshortcuts import render from djangohttp import httpresponseredirect allows us to redirect the browser to a difference url from djangocontrib import auth checks username and password handles login and log outs from djangocorecontextprocessors import csrf csrf cross site request forgery', 'def loginrequest c cupdatecsrfrequest return renderloginhtml c this is what my template looks like extends basehtml block content if formerrors p class errorsorry thats not a valid username or passwordp endif form action accountsauth method post csrftoken label for usernameuser name label input type text name username value id username label for passwordpassword label input type password name password value id password input type submit value login form endblock i assume i might be using render incorrectly but in the docs i think i am putting in the correct parameters']"
What are the differences between Generics in C# and Java... and Templates in C++?,"I mostly use Java and generics are relatively new. I keep reading that Java made the wrong decision or that .NET has better implementations etc. etc.
So, what are the main differences between C++, C#, Java in generics? Pros/cons of each?
",<c#><java><c++><generics><templates>,203,"c#,java,c++,generics,templates",['what are the differences between generics in c and java and templates in c'],"['i mostly use java and generics are relatively new', 'i keep reading that java made the wrong decision or that net has better implementations etc', 'etc', 'so what are the main differences between c c java in generics', 'proscons of each']"
calling init for multiple parent classes with super?,"
Possible Duplicate:
Can Super deal with multiple inheritance? 

Python inheritance? I have a class structure (below), and want the child class to call the __init__ of both parents. Is this possible to do in a 'super' way or is it just a terrible idea?
class Parent1(object):
    def __init__(self):
        self.var1 = 1

class Parent2(object):
    def _init__(self):
        self.var2 = 2

class Child(Parent1, Parent2):
    def __init__(self):
        ## call __init__ of Parent1
        ## call __init__ of Parent2
        ## super(Child, self).__init__()

",<python><multiple-inheritance><init><super><new-style-class>,23,"python,multiple-inheritance,init,super,new-style-class",['calling init for multiple parent classes with super'],"[' possible duplicate can super deal with multiple inheritance', 'python inheritance', 'i have a class structure below and want the child class to call the init of both parents', 'is this possible to do in a super way or is it just a terrible idea', 'class parent1object def initself selfvar1 1 class parent2object def initself selfvar2 2 class childparent1 parent2 def initself call init of parent1 call init of parent2 superchild selfinit']"
Flask + SQLAlchemy adjacency list backref error,"I have the following model:
class Category(db.Model):
    __tablename__ = 'categories'

    id = db.Column(db.Integer, primary_key=True)
    parent_id = db.Column(db.Integer, db.ForeignKey(id), nullable=True)
    level = db.Column(db.SmallInteger)
    name = db.Column(db.String(200))
    children = db.relationship('Category', backref=backref('parent', remote_side=id))

    def __repr__(self):
        return '<Category %r>' % (self.name)

This doesn't seem to work. I always get the following error:
NameError: name 'backref' is not defined

What am I doing wrong?
",<python><orm><flask><sqlalchemy><flask-sqlalchemy>,5,"python,orm,flask,sqlalchemy,flask-sqlalchemy",['flask sqlalchemy adjacency list backref error'],"['i have the following model class categorydbmodel tablename categories id dbcolumndbinteger primarykeytrue parentid dbcolumndbinteger dbforeignkeyid nullabletrue level dbcolumndbsmallinteger name dbcolumndbstring200 children dbrelationshipcategory backrefbackrefparent remotesideid def reprself return category r selfname this doesnt seem to work', 'i always get the following error nameerror name backref is not defined what am i doing wrong']"
generating two orthogonal vectors that are orthogonal to a particular direction,"What is the simplest and most efficient ways in numpy to generate two orthonormal vectors a and b such that the cross product of the two vectors equals another unit vector k, which is already known?
I know there are infinitely many such pairs, and it doesn't matter to me which pairs I get as long as the conditions axb=k and a.b=0 are satisfied. 
",<arrays><numpy><vector><orthogonal><cross-product>,17,"arrays,numpy,vector,orthogonal,cross-product",['generating two orthogonal vectors that are orthogonal to a particular direction'],"['what is the simplest and most efficient ways in numpy to generate two orthonormal vectors a and b such that the cross product of the two vectors equals another unit vector k which is already known', 'i know there are infinitely many such pairs and it doesnt matter to me which pairs i get as long as the conditions axbk and ab0 are satisfied']"
How new Identity Jump feature of Microsoft SQL Server 2012 handles the range of data type?,"I thought it was a bug but after reading this article http://www.codeproject.com/Tips/668042/SQL-Server-2012-Auto-Identity-Column-Value-Jump-Is, I found that it's a new feature of SQL Server 2012.
This feature increments your last identity column value by 1000(ints) for new rows(10000 for bigints) automatically.

I am still trying the solution given in the article but I don't have any problem if this jump happens at client side. Because I am showing hashed version of IDs to client. It's his own demand not mine.
But I am wondering what if the values of these identity columns goes more than the range of the data type (int or bigint)? How it handles the range and size of the column?
",<sql><sql-server><sql-server-2012><auto-increment><identity-column>,6,"sql,sql-server,sql-server-2012,auto-increment,identity-column",['how new identity jump feature of microsoft sql server 2012 handles the range of data type'],"['i thought it was a bug but after reading this article i found that its a new feature of sql server 2012 this feature increments your last identity column value by 1000ints for new rows10000 for bigints automatically', 'i am still trying the solution given in the article but i dont have any problem if this jump happens at client side', 'because i am showing hashed version of ids to client', 'its his own demand not mine', 'but i am wondering what if the values of these identity columns goes more than the range of the data type int or bigint', 'how it handles the range and size of the column']"
OutputCache VaryByContentEncodings gzip doesn't work,"I've set the OutputCache to include 'VaryByContentEncodings=""gzip""' in my ASP.net ASPX page. I want the page to serve different css files, a gzipped if the browser support it and the regular non compressed if the browser doesn't support compression.
Example:
<%@ OutputCache Duration=""320"" VaryByParam=""none"" VaryByContentEncodings=""gzip""  %>   

When I run the code I get the following error: 
The 'varybycontentencodings' attribute is not supported by the 'outputcache' directive in a page.
I don't know what's the problem and why it doesn't work. Second, do you think that by serving different gzip/non-compressed CSS I'm doing the right thing. Just note that the files are served from Amazon S3, so I can't rely on IIS or .NET engine to return the compressed files automatically. That's why I want to serve to separate cached version of the page.
In this it seems to be ok, but it doesn't work (using ASP.NET 4.5):
http://msdn.microsoft.com/en-us/library/system.web.httpcachevarybycontentencodings.aspx
Help would be greatly appreciated.
",<c#><asp.net><caching><encoding><outputcache>,9,"c#,asp.net,caching,encoding,outputcache",['outputcache varybycontentencodings gzip doesnt work'],"['ive set the outputcache to include varybycontentencodingsgzip in my aspnet aspx page', 'i want the page to serve different css files a gzipped if the browser support it and the regular non compressed if the browser doesnt support compression', 'example outputcache duration320 varybyparamnone varybycontentencodingsgzip when i run the code i get the following error the varybycontentencodings attribute is not supported by the outputcache directive in a page', 'i dont know whats the problem and why it doesnt work', 'second do you think that by serving different gzipnoncompressed css im doing the right thing', 'just note that the files are served from amazon s3 so i cant rely on iis or net engine to return the compressed files automatically', 'thats why i want to serve to separate cached version of the page', 'in this it seems to be ok but it doesnt work using aspnet 45 help would be greatly appreciated']"
"d3 US state map with markers, zooming transform issues","I've created a d3 map with US states, following this example:
http://bl.ocks.org/mbostock/4699541
and added markers following this SO question:
Put markers to a map generated with topoJSON and d3.js
The problem is that on zoom, the map markers stay in place.  I believe I need to translate them into a new position, but not sure how to make that happen.

var width = 900,
  height = 500,
  active = d3.select(null);

var projection = d3.geo.albersUsa()
  .scale(1000)
  .translate([width / 2, height / 2]);

var path = d3.geo.path()
  .projection(projection);

var svg = d3.select("".rebates"").append(""svg"")
  .attr(""width"", width)
  .attr(""height"", height);

svg.append(""rect"")
  .attr(""class"", ""background"")
  .attr(""width"", width)
  .attr(""height"", height)
  .on(""click"", reset);

var g = svg.append(""g"")
  .style(""stroke-width"", ""1.5px"");

d3.json(""/files/d3-geo/us.json"", function(error, us) {
  if (error) { throw error; }

  g.selectAll(""path"")
    .data(topojson.feature(us, us.objects.states).features)
    .enter().append(""path"")
    .attr(""d"", path)
    .attr(""class"", function(item) {
      return window.US_STATES[item.id].water_authorities > 0 ? 'avail' : 'unavail';
    })
    .on(""click"", clicked);

  g.append(""path"")
    .datum(topojson.mesh(us, us.objects.states, function(a, b) { return a !== b; }))
    .attr(""class"", ""mesh"")
    .attr(""d"", path);
});

d3.json('/files/coordinates.json', function(error, coords) {
  if (error) { throw error; }

  svg.selectAll("".mark"")
    .data(coords)
    .enter()
    .append(""image"")
    .attr('class','mark')
    .attr('width', 20)
    .attr('height', 20)
    .attr(""xlink:href"",'assets/gmap_red.png')
    .attr(""transform"", function(d) {
      return ""translate("" + projection([d[1],d[0]]) + "")"";
    });
});

function clicked(d) {
  if (active.node() === this) { return reset(); }
  if (window.US_STATES[d.id].water_authorities === 0) { return; }

  active.classed(""active"", false);
  active = d3.select(this).classed(""active"", true);

  var bounds = path.bounds(d),
    dx = bounds[1][0] - bounds[0][0],
    dy = bounds[1][1] - bounds[0][1],
    x = (bounds[0][0] + bounds[1][0]) / 2,
    y = (bounds[0][1] + bounds[1][1]) / 2,
    scale = .9 / Math.max(dx / width, dy / height),
    translate = [width / 2 - scale * x, height / 2 - scale * y];

  g.transition()
    .duration(750)
    .style(""stroke-width"", 1.5 / scale + ""px"")
    .attr(""transform"", ""translate("" + translate + "")scale("" + scale + "")"");
}

function reset() {
  active.classed(""active"", false);
  active = d3.select(null);

  rebatesTable.clear().draw();

  g.transition()
    .duration(750)
    .style(""stroke-width"", ""1.5px"")
    .attr(""transform"", """");
}

",<javascript><d3.js><mapping><geospatial><geo>,8,"javascript,d3.js,mapping,geospatial,geo",['d3 us state map with markers zooming transform issues'],"['ive created a d3 map with us states following this example and added markers following this so question put markers to a map generated with topojson and d3js the problem is that on zoom the map markers stay in place', 'i believe i need to translate them into a new position but not sure how to make that happen', 'var width 900 height 500 active d3selectnull var projection d3geoalbersusa scale1000 translatewidth 2 height 2 var path d3geopath projectionprojection var svg d3selectrebatesappendsvg attrwidth width attrheight height svgappendrect attrclass background attrwidth width attrheight height onclick reset var g svgappendg stylestrokewidth 15px d3jsonfilesd3geousjson functionerror us if error throw error gselectallpath datatopojsonfeatureus usobjectsstatesfeatures enterappendpath attrd path attrclass functionitem return windowusstatesitemidwaterauthorities 0 ', 'avail unavail onclick clicked gappendpath datumtopojsonmeshus usobjectsstates functiona b return a b attrclass mesh attrd path d3jsonfilescoordinatesjson functionerror coords if error throw error svgselectallmark datacoords enter appendimage attrclassmark attrwidth 20 attrheight 20 attrxlinkhrefassetsgmapredpng attrtransform functiond return translate projectiond1d0 function clickedd if activenode this return reset if windowusstatesdidwaterauthorities 0 return activeclassedactive false active d3selectthisclassedactive true var bounds pathboundsd dx bounds10 bounds00 dy bounds11 bounds01 x bounds00 bounds10 2 y bounds01 bounds11 2 scale 9 mathmaxdx width dy height translate width 2 scale x height 2 scale y gtransition duration750 stylestrokewidth 15 scale px attrtransform translate translate scale scale function reset activeclassedactive false active d3selectnull rebatestablecleardraw gtransition duration750 stylestrokewidth 15px attrtransform ']"
unable to allow static resources in spring security 3,"I am unable to allow static resources(like js,css,images) in spring security 3.Below is my config file.
<beans xmlns=""http://www.springframework.org/schema/beans""
    xmlns:security=""http://www.springframework.org/schema/security""
    xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
    xsi:schemaLocation=""http://www.springframework.org/schema/beans 
              http://www.springframework.org/schema/beans/spring-beans-3.1.xsd
              http://www.springframework.org/schema/security 
              http://www.springframework.org/schema/security/spring-security-3.1.xsd"">



    <bean id=""authenticationEntryPoint""
        class=""org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint"">
        <property name=""loginFormUrl"" value=""/login.htm"" />
    </bean>

    <security:http security=""none"" pattern=""/js/ajaxScript.js""/>   
    <security:http security=""none"" pattern=""/js/commonScript.js""/>  

    <bean class=""org.springframework.security.web.access.expression.DefaultWebSecurityExpressionHandler"" />

    <security:http auto-config=""false"" entry-point-ref=""authenticationEntryPoint"" disable-url-rewriting=""true"" use-expressions=""true"">

        <security:custom-filter position=""FORM_LOGIN_FILTER""
            ref=""customAuthenticationProcessingFilter"" />

<!--        <security:intercept-url pattern=""/js/jquery.min.js"" access=""isAuthenticated()"" /> -->
<!--        <security:intercept-url pattern=""/js/**/**"" access=""permitAll"" />  -->
        <security:intercept-url pattern=""/displayAdminPage.htm"" access=""hasRole('ROLE_ADMIN')"" />
        <security:access-denied-handler ref=""accessDeniedHandler"" />

    </security:http>

    <security:authentication-manager alias=""authenticationManager"">
       <security:authentication-provider user-service-ref=""customUserDetailService"">
       </security:authentication-provider>
    </security:authentication-manager> 

    <bean id=""customUserDetailService"" class=""com.qait.cdl.services.impl.UserSecurityServiceImpl"">
        <property name=""userDao"" ref=""userDao""/>
       </bean>

    <bean id=""customAuthenticationProcessingFilter""
        class=""com.qait.cdl.services.impl.CustomAuthenticationProcessingFilter"">
        <property name=""authenticationManager"" ref=""authenticationManager"" />
    </bean>

    <bean id=""accessDeniedHandler""
        class=""org.springframework.security.web.access.AccessDeniedHandlerImpl"">
        <property name=""errorPage"" value=""/WEB-INF/jsp/customLoginForm/denied.jsp"" />
    </bean>
</beans> 

I don't know where I am wrong?I want all js,images,css must be bypass by spring security.JS files are present in webapp/js and webapp/js/commonScript folder.Images are present in webapp/images folder.
Below is my web.xml
<?xml version=""1.0"" encoding=""UTF-8""?>
<web-app xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
    xmlns=""http://java.sun.com/xml/ns/javaee"" xmlns:web=""http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd""
    xsi:schemaLocation=""http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd""
    id=""WebApp_ID"" version=""2.5"">
    <display-name>cdl</display-name>
    <servlet>
        <servlet-name>dispatcher</servlet-name>
        <servlet-class>org.springframework.web.servlet.DispatcherServlet</servlet-class>
        <load-on-startup>1</load-on-startup>
    </servlet>
    <servlet-mapping>
        <servlet-name>dispatcher</servlet-name>
        <url-pattern>/</url-pattern>
    </servlet-mapping>

    <servlet>
        <servlet-name>startUpServlet</servlet-name>
        <servlet-class>com.qait.cdl.commons.startup.StartUpServlet</servlet-class>
        <load-on-startup>2</load-on-startup>
    </servlet>
    <servlet-mapping>
        <servlet-name>startUpServlet</servlet-name>
        <url-pattern>/startUpServlet.htm</url-pattern>
    </servlet-mapping>

    <welcome-file-list>
        <welcome-file>redirect.jsp</welcome-file>
    </welcome-file-list>

    <context-param>
        <param-name>CDL_ENV</param-name>
        <param-value>staging</param-value>
    </context-param>

    <listener>
        <listener-class>com.qait.cdl.commons.startup.CdlContextListner</listener-class>
    </listener>

    <!-- Session timeout -->
    <session-config>
        <session-timeout>600</session-timeout>
    </session-config>

    <filter>
        <filter-name>springSecurityFilterChain</filter-name>
        <filter-class>org.springframework.web.filter.DelegatingFilterProxy</filter-class>
    </filter>

    <filter-mapping>
        <filter-name>springSecurityFilterChain</filter-name>
        <url-pattern>/*</url-pattern>
    </filter-mapping>

    <listener>
        <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
    </listener>

    <context-param>
     <param-name>contextConfigLocation</param-name>
     <param-value>
     WEB-INF/applicationContext.xml
<!--      WEB-INF/SpringSecurityConfig.xml -->
     WEB-INF/dispatcher-servlet.xml
     </param-value>
    </context-param>

</web-app>

",<javascript><css><image><spring-mvc><spring-security>,5,"javascript,css,image,spring-mvc,spring-security",['unable to allow static resources in spring security 3'],"['i am unable to allow static resourceslike jscssimages in spring security 3below is my config file', 'beans xmlns xmlnssecurity xmlnsxsi xsischemalocation bean idauthenticationentrypoint classorgspringframeworksecuritywebauthenticationloginurlauthenticationentrypoint property nameloginformurl valueloginhtm bean securityhttp securitynone patternjsajaxscriptjs securityhttp securitynone patternjscommonscriptjs bean classorgspringframeworksecuritywebaccessexpressiondefaultwebsecurityexpressionhandler securityhttp autoconfigfalse entrypointrefauthenticationentrypoint disableurlrewritingtrue useexpressionstrue securitycustomfilter positionformloginfilter refcustomauthenticationprocessingfilter securityintercepturl patternjsjqueryminjs accessisauthenticated securityintercepturl patternjs accesspermitall securityintercepturl patterndisplayadminpagehtm accesshasroleroleadmin securityaccessdeniedhandler refaccessdeniedhandler securityhttp securityauthenticationmanager aliasauthenticationmanager securityauthenticationprovider userservicerefcustomuserdetailservice securityauthenticationprovider securityauthenticationmanager bean idcustomuserdetailservice classcomqaitcdlservicesimplusersecurityserviceimpl property nameuserdao refuserdao bean bean idcustomauthenticationprocessingfilter classcomqaitcdlservicesimplcustomauthenticationprocessingfilter property nameauthenticationmanager refauthenticationmanager bean bean idaccessdeniedhandler classorgspringframeworksecuritywebaccessaccessdeniedhandlerimpl property nameerrorpage valuewebinfjspcustomloginformdeniedjsp bean beans i dont know where i am wrongi want all jsimagescss must be bypass by spring securityjs files are present in webappjs and webappjscommonscript folderimages are present in webappimages folder', 'below is my webxml xml version10 encodingutf8 webapp xmlnsxsi xmlns xmlnsweb xsischemalocation idwebappid version25 displaynamecdldisplayname servlet servletnamedispatcherservletname servletclassorgspringframeworkwebservletdispatcherservletservletclass loadonstartup1loadonstartup servlet servletmapping servletnamedispatcherservletname urlpatternurlpattern servletmapping servlet servletnamestartupservletservletname servletclasscomqaitcdlcommonsstartupstartupservletservletclass loadonstartup2loadonstartup servlet servletmapping servletnamestartupservletservletname urlpatternstartupservlethtmurlpattern servletmapping welcomefilelist welcomefileredirectjspwelcomefile welcomefilelist contextparam paramnamecdlenvparamname paramvaluestagingparamvalue contextparam listener listenerclasscomqaitcdlcommonsstartupcdlcontextlistnerlistenerclass listener session timeout sessionconfig sessiontimeout600sessiontimeout sessionconfig filter filternamespringsecurityfilterchainfiltername filterclassorgspringframeworkwebfilterdelegatingfilterproxyfilterclass filter filtermapping filternamespringsecurityfilterchainfiltername urlpatternurlpattern filtermapping listener listenerclassorgspringframeworkwebcontextcontextloaderlistenerlistenerclass listener contextparam paramnamecontextconfiglocationparamname paramvalue webinfapplicationcontextxml webinfspringsecurityconfigxml webinfdispatcherservletxml paramvalue contextparam webapp']"
Autoscroll down angularjs,"Hi I'm creating a chat app with angularjs that autoscrolls down when a user messages another user.  I'm not sure how to implement this as my chat window is a fixed ul element.  I'm thinking I will need to implement a directive to do this (inboxmsg-scroll on the ul element)
Any help? thanks.
HTML
<ul class=""chatting-window"" inboxmsg-scroll>
    <li data-ng-repeat=""messageinfo in messages"">
        <div class=""message-date"">
            {{messageinfo[0]}}
        </div>
    </li>
</ul>

",<javascript><jquery><angularjs><angularjs-directive><autoscroll>,9,"javascript,jquery,angularjs,angularjs-directive,autoscroll",['autoscroll down angularjs'],"['hi im creating a chat app with angularjs that autoscrolls down when a user messages another user', 'im not sure how to implement this as my chat window is a fixed ul element', 'im thinking i will need to implement a directive to do this inboxmsgscroll on the ul element any help', 'thanks', 'html ul classchattingwindow inboxmsgscroll li datangrepeatmessageinfo in messages div classmessagedate messageinfo0 div li ul']"
Animate a CALayer's bounds w/redraws,"I am wondering how one might animate a CALayer's bounds so, on each bounds change, the layer calls drawInContext:.  I've tried the 2 following methods on my CALayer subclass:

Setting needsDisplayOnBoundsChange to YES
Returning YES for the + (BOOL)needsDisplayForKey:(NSString*)key for the bounds key

Neither work.  CALayer seems determined to use the layer's original contents and simply scale them according to contentsGravity (which, I assume, is for performance.)  Is their a workaround for this or am I missing something obvious?
EDIT: And, incidentally, I noticed that my custom CALayer subclass is not calling initWithLayer: to create a presentationLayer - weird.
Thanks in advance, 
Sam
",<iphone><objective-c><core-animation><calayer><bounds>,17,"iphone,objective-c,core-animation,calayer,bounds",['animate a calayers bounds wredraws'],"['i am wondering how one might animate a calayers bounds so on each bounds change the layer calls drawincontext', 'ive tried the 2 following methods on my calayer subclass setting needsdisplayonboundschange to yes returning yes for the boolneedsdisplayforkeynsstringkey for the bounds key neither work', 'calayer seems determined to use the layers original contents and simply scale them according to contentsgravity which i assume is for performance', 'is their a workaround for this or am i missing something obvious', 'edit and incidentally i noticed that my custom calayer subclass is not calling initwithlayer to create a presentationlayer weird', 'thanks in advance sam']"
Android databinding: cannot find ...BindingImpl in generated databinding file,"I am trying to databind a viewmodel using the example project android-sunflower. The current issue is that when I am trying to build the project I get the error error: cannot find symbol symbol:   class FragmentShopBindingImpl
  location: package {{packageName}}.databinding in the class DataBindinMapperImpl
I'm not really sure what I am missing here, since I added everything from the example project. The class FragmentShopBindingImpl does not get generated, or shouldn't it? Since I cannot see any occurence of a class ending with 'Impl' in the android sunflower example
My code: 
override fun onCreateView(
        inflater: LayoutInflater, container: ViewGroup?,
        savedInstanceState: Bundle?
    ): View? {

        val factory = InjectorUtils.provideShopViewModelFactory(context!!)
        val shopViewModel = ViewModelProviders.of(this, factory)
            .get(ShopViewModel::class.java)

        val binding = DataBindingUtil.inflate<FragmentShopBinding>(
            inflater, R.layout.fragment_shop, container, false).apply {
            viewModel = shopViewModel
            lifecycleOwner = this@ShopFragment
        }

        return binding.root
    }

Layout: 
<?xml version=""1.0"" encoding=""utf-8""?>
<layout xmlns:android=""http://schemas.android.com/apk/res/android""
    xmlns:tools=""http://schemas.android.com/tools"">

    <data>
        <variable
            name=""viewModel""
            type=""{{packageName}}.viewmodel.ShopViewModel"" />
    </data>

    <LinearLayout
        android:layout_width=""match_parent""
        android:layout_height=""match_parent""
        android:orientation=""vertical""
        tools:context="".fragments.ShopFragment"">

        <TextView
            android:text=""@{viewModel}""
            android:layout_width=""match_parent""
            android:layout_height=""match_parent"" />

    </LinearLayout>
</layout>

Image of generated file (ignore the {{packageName}}:

",<android><kotlin><data-binding><android-databinding><android-jetpack>,11,"android,kotlin,data-binding,android-databinding,android-jetpack",['android databinding cannot find bindingimpl in generated databinding file'],"['i am trying to databind a viewmodel using the example project androidsunflower', 'the current issue is that when i am trying to build the project i get the error error cannot find symbol symbol class fragmentshopbindingimpl location package packagenamedatabinding in the class databindinmapperimpl im not really sure what i am missing here since i added everything from the example project', 'the class fragmentshopbindingimpl does not get generated or shouldnt it', 'since i cannot see any occurence of a class ending with impl in the android sunflower example my code override fun oncreateview inflater layoutinflater container viewgroup savedinstancestate bundle', ' view', ' val factory injectorutilsprovideshopviewmodelfactorycontext', 'val shopviewmodel viewmodelprovidersofthis factory getshopviewmodelclassjava val binding databindingutilinflatefragmentshopbinding inflater rlayoutfragmentshop container falseapply viewmodel shopviewmodel lifecycleowner thisshopfragment return bindingroot layout xml version10 encodingutf8 layout xmlnsandroid xmlnstools data variable nameviewmodel typepackagenameviewmodelshopviewmodel data linearlayout androidlayoutwidthmatchparent androidlayoutheightmatchparent androidorientationvertical toolscontextfragmentsshopfragment textview androidtextviewmodel androidlayoutwidthmatchparent androidlayoutheightmatchparent linearlayout layout image of generated file ignore the packagename']"
How to use nuxtjs/auth-next module with Nuxt3?,"Just trying to add authentication to my NuxtJs 3 app folloging nuxt/auth configuration docs,  but still get an error during app start:

// nuxt.config.js

export default defineNuxtConfig({
    auth: {
        // ...
    },
    modules: [
        // '@nuxtjs/axios',
        '@nuxtjs/auth-next'
    ],
})

Received same error for @nuxtjs/axios but I just commented it out since its official documentation indicates to switch to $fetch API.
Cannot figure out where the error is
",<vue.js><authentication><nuxt.js><nuxtjs3><nuxt-module>,8,"vue.js,authentication,nuxt.js,nuxtjs3,nuxt-module",['how to use nuxtjsauthnext module with nuxt3'],"['just trying to add authentication to my nuxtjs 3 app folloging nuxtauth configuration docs but still get an error during app start nuxtconfigjs export default definenuxtconfig auth modules nuxtjsaxios nuxtjsauthnext received same error for nuxtjsaxios but i just commented it out since its official documentation indicates to switch to fetch api', 'cannot figure out where the error is']"
ln complains about no such file or directory,"I'm new in shell programming on macosx and have a little problem. I've written the following shell script:
#!/bin/sh

function createlink {
source_file=$1

target_file=""~/$source_file""

if [[ -f $target_file ]]; then
    rm $target_file
fi

ln $source_file $target_file
}

createlink "".netrc""

When I'm executing this script I get the message ln: ~/.netrc: No such file or directory and I don't know why this happened! Do you see the error? Thanks!
",<bash><macos><shell><variable-expansion><tilde-expansion>,6,"bash,macos,shell,variable-expansion,tilde-expansion",['ln complains about no such file or directory'],"['im new in shell programming on macosx and have a little problem', 'ive written the following shell script binsh function createlink sourcefile1 targetfilesourcefile if f targetfile then rm targetfile fi ln sourcefile targetfile createlink netrc when im executing this script i get the message ln netrc no such file or directory and i dont know why this happened', 'do you see the error', 'thanks']"
Move only files recursively from multiple directories into one directory with mv,"I currently have ~40k RAW images that are in a nested directory structure. (Some folders have as many as 100 subfolders filled with files.) I would like to move them all into one master directory, with no subfolders. How could this be accomplished using mv? I know the -r switch will copy recursively, but this copies folders as well, and I do not wish to have subdirectories in the master folder. 
",<bash><unix><gnu><directory><mv>,8,"bash,unix,gnu,directory,mv",['move only files recursively from multiple directories into one directory with mv'],"['i currently have 40k raw images that are in a nested directory structure', 'some folders have as many as 100 subfolders filled with files', 'i would like to move them all into one master directory with no subfolders', 'how could this be accomplished using mv', 'i know the r switch will copy recursively but this copies folders as well and i do not wish to have subdirectories in the master folder']"
How can I populate textbox through VBA in MS Access?,"I have a table RR_info which hold following fields RR_ID, HR_ID, No_of_Beds, Room_Category. Now i want that through VBA code with Form_load event I should populate textboxes for all these table fields. For this I wrote a query which get certain records according to hotel_id as a criteria but code is not working.
Private Sub Form_Load()
Dim SQL As String
Dim db As Database
Dim rs As DAO.Recordset

SQL = ""select * from RR_info where hr_id = "" & Forms![hhrrr]![List38] & "";""
Set db = CurrentDb
Set rs = db.OpenRecordset(SQL)

Me.RR_ID.Text = rs!RR_ID
Me.HR_ID.Text = rs!HR_ID
Me.Room_No.Text = rs![Room No]
Me.No_of_Beds.text = rs!No_of_Beds
Me.Room_Category.text = rs!Room_Category

Set rs = Nothing
Set db = Nothing

End Sub


This is the Picture of Table in which I want to add table data according to criteria through VBA.
",<ms-access><ms-access-2007><vba><ms-access-2010><ms-access-2003>,7,"ms-access,ms-access-2007,vba,ms-access-2010,ms-access-2003",['how can i populate textbox through vba in ms access'],"['i have a table rrinfo which hold following fields rrid hrid noofbeds roomcategory', 'now i want that through vba code with formload event i should populate textboxes for all these table fields', 'for this i wrote a query which get certain records according to hotelid as a criteria but code is not working', 'private sub formload dim sql as string dim db as database dim rs as daorecordset sql select from rrinfo where hrid formshhrrr', 'list38 set db currentdb set rs dbopenrecordsetsql merridtext rsrrid mehridtext rshrid meroomnotext rs', 'room no menoofbedstext rsnoofbeds meroomcategorytext rsroomcategory set rs nothing set db nothing end sub this is the picture of table in which i want to add table data according to criteria through vba']"
"How to best insert 350,000 rows with ADO.Net","I have a csv file with 350,000 rows, each row has about 150 columns.
What would be the best way to insert these rows into SQL Server using ADO.Net?
The way I've usually done it is to create the SQL statement manually.  I was wondering if there is any way I can code it to simply insert the entire datatable into SQL Server?  Or some short-cut like this.
By the way I already tried doing this with SSIS, but there are a few data clean-up issues which I can handle with C# but not so easily with SSIS.  The data started as XML, but I changed it to CSV for simplicity.
",<c#><.net><ado.net><csv><etl>,6,"c#,.net,ado.net,csv,etl",['how to best insert 350000 rows with adonet'],"['i have a csv file with 350000 rows each row has about 150 columns', 'what would be the best way to insert these rows into sql server using adonet', 'the way ive usually done it is to create the sql statement manually', 'i was wondering if there is any way i can code it to simply insert the entire datatable into sql server', 'or some shortcut like this', 'by the way i already tried doing this with ssis but there are a few data cleanup issues which i can handle with c but not so easily with ssis', 'the data started as xml but i changed it to csv for simplicity']"
OpenCV: solvePnP detection problems,"I've got problem with precise detection of markers using OpenCV.
I've recorded video presenting that issue: http://youtu.be/IeSSW4MdyfU
As you see I'm markers that I'm detecting are slightly moved at some camera angles. I've read on the web that this may be camera calibration problems, so I'll tell you guys how I'm calibrating camera, and maybe you'd be able to tell me what am I doing wrong?
At the beginnig I'm collecting data from various images, and storing calibration corners in _imagePoints vector like this
std::vector<cv::Point2f> corners;
_imageSize = cvSize(image->size().width, image->size().height);

bool found = cv::findChessboardCorners(*image, _patternSize, corners);

if (found) {
    cv::Mat *gray_image = new cv::Mat(image->size().height, image->size().width, CV_8UC1);
    cv::cvtColor(*image, *gray_image, CV_RGB2GRAY);

    cv::cornerSubPix(*gray_image, corners, cvSize(11, 11), cvSize(-1, -1), cvTermCriteria(CV_TERMCRIT_EPS+ CV_TERMCRIT_ITER, 30, 0.1));

    cv::drawChessboardCorners(*image, _patternSize, corners, found);
}

_imagePoints->push_back(_corners);

Than, after collecting enough data I'm calculating camera matrix and coefficients with this code:
std::vector< std::vector<cv::Point3f> > *objectPoints = new std::vector< std::vector< cv::Point3f> >();

for (unsigned long i = 0; i < _imagePoints->size(); i++) {
    std::vector<cv::Point2f> currentImagePoints = _imagePoints->at(i);
    std::vector<cv::Point3f> currentObjectPoints;

    for (int j = 0; j < currentImagePoints.size(); j++) {
        cv::Point3f newPoint = cv::Point3f(j % _patternSize.width, j / _patternSize.width, 0);

        currentObjectPoints.push_back(newPoint);
    }

    objectPoints->push_back(currentObjectPoints);
}

std::vector<cv::Mat> rvecs, tvecs;

static CGSize size = CGSizeMake(_imageSize.width, _imageSize.height);
cv::Mat cameraMatrix = [_userDefaultsManager cameraMatrixwithCurrentResolution:size]; // previously detected matrix
cv::Mat coeffs = _userDefaultsManager.distCoeffs; // previously detected coeffs
cv::calibrateCamera(*objectPoints, *_imagePoints, _imageSize, cameraMatrix, coeffs, rvecs, tvecs);

Results are like you've seen in the video.
What am I doing wrong? is that an issue in the code? How much images should I use to perform calibration (right now I'm trying to obtain 20-30 images before end of calibration).
Should I use images that containg wrongly detected chessboard corners, like this:

or should I use only properly detected chessboards like these:


I've been experimenting with circles grid instead of of chessboards, but results were much worse that now.
In case of questions how I'm detecting marker: I'm using solvepnp function:
solvePnP(modelPoints, imagePoints, [_arEngine currentCameraMatrix], _userDefaultsManager.distCoeffs, rvec, tvec);

with modelPoints specified like this:
    markerPoints3D.push_back(cv::Point3d(-kMarkerRealSize / 2.0f, -kMarkerRealSize / 2.0f, 0));
    markerPoints3D.push_back(cv::Point3d(kMarkerRealSize / 2.0f, -kMarkerRealSize / 2.0f, 0));
    markerPoints3D.push_back(cv::Point3d(kMarkerRealSize / 2.0f, kMarkerRealSize / 2.0f, 0));
    markerPoints3D.push_back(cv::Point3d(-kMarkerRealSize / 2.0f, kMarkerRealSize / 2.0f, 0));

and imagePoints are coordinates of marker corners in processing image (I'm using custom algorithm to do that)
",<ios><opencv><camera><markers><camera-calibration>,20,"ios,opencv,camera,markers,camera-calibration",['opencv solvepnp detection problems'],"['ive got problem with precise detection of markers using opencv', 'ive recorded video presenting that issue as you see im markers that im detecting are slightly moved at some camera angles', 'ive read on the web that this may be camera calibration problems so ill tell you guys how im calibrating camera and maybe youd be able to tell me what am i doing wrong', 'at the beginnig im collecting data from various images and storing calibration corners in imagepoints vector like this stdvectorcvpoint2f corners imagesize cvsizeimagesizewidth imagesizeheight bool found cvfindchessboardcornersimage patternsize corners if found cvmat grayimage new cvmatimagesizeheight imagesizewidth cv8uc1 cvcvtcolorimage grayimage cvrgb2gray cvcornersubpixgrayimage corners cvsize11 11 cvsize1 1 cvtermcriteriacvtermcriteps cvtermcrititer 30 01 cvdrawchessboardcornersimage patternsize corners found imagepointspushbackcorners than after collecting enough data im calculating camera matrix and coefficients with this code stdvector stdvectorcvpoint3f objectpoints new stdvector stdvector cvpoint3f for unsigned long i 0 i imagepointssize i stdvectorcvpoint2f currentimagepoints imagepointsati stdvectorcvpoint3f currentobjectpoints for int j 0 j currentimagepointssize j cvpoint3f newpoint cvpoint3fj patternsizewidth j patternsizewidth 0 currentobjectpointspushbacknewpoint objectpointspushbackcurrentobjectpoints stdvectorcvmat rvecs tvecs static cgsize size cgsizemakeimagesizewidth imagesizeheight cvmat cameramatrix userdefaultsmanager cameramatrixwithcurrentresolutionsize previously detected matrix cvmat coeffs userdefaultsmanagerdistcoeffs previously detected coeffs cvcalibratecameraobjectpoints imagepoints imagesize cameramatrix coeffs rvecs tvecs results are like youve seen in the video', 'what am i doing wrong', 'is that an issue in the code', 'how much images should i use to perform calibration right now im trying to obtain 2030 images before end of calibration', 'should i use images that containg wrongly detected chessboard corners like this or should i use only properly detected chessboards like these ive been experimenting with circles grid instead of of chessboards but results were much worse that now', 'in case of questions how im detecting marker im using solvepnp function solvepnpmodelpoints imagepoints arengine currentcameramatrix userdefaultsmanagerdistcoeffs rvec tvec with modelpoints specified like this markerpoints3dpushbackcvpoint3dkmarkerrealsize 20f kmarkerrealsize 20f 0 markerpoints3dpushbackcvpoint3dkmarkerrealsize 20f kmarkerrealsize 20f 0 markerpoints3dpushbackcvpoint3dkmarkerrealsize 20f kmarkerrealsize 20f 0 markerpoints3dpushbackcvpoint3dkmarkerrealsize 20f kmarkerrealsize 20f 0 and imagepoints are coordinates of marker corners in processing image im using custom algorithm to do that']"
How to generate unique id in Dart,"I write websocket chat.
How to generate unique id for user?
now i use this code:
id = new DateTime.now().millisecondsSinceEpoch;

is there any more neat solution?
",<unique><dart><identity><uuid><uniqueidentifier>,141,"unique,dart,identity,uuid,uniqueidentifier",['how to generate unique id in dart'],"['i write websocket chat', 'how to generate unique id for user', 'now i use this code id new datetimenowmillisecondssinceepoch is there any more neat solution']"
"How to launch tests in Chrome with the console docked at the bottom, not the right?","Whenever I launch Karma on Chrome a new Chrome window pops up. When I bring up the console on this Chrome Window the console comes up attached to the right side. I prefer the console attached to the bottom so I always bring it down - its kind of annoying.
How can I get Karma to launch Chrome with the console docked at the bottom?
",<javascript><google-chrome><google-chrome-devtools><karma-runner><karma-jasmine>,7,"javascript,google-chrome,google-chrome-devtools,karma-runner,karma-jasmine",['how to launch tests in chrome with the console docked at the bottom not the right'],"['whenever i launch karma on chrome a new chrome window pops up', 'when i bring up the console on this chrome window the console comes up attached to the right side', 'i prefer the console attached to the bottom so i always bring it down its kind of annoying', 'how can i get karma to launch chrome with the console docked at the bottom']"
JEditorPane.getPreferredSize not always working in Java 9?,"This question is about different behaviour of JEditorPane in Java 8 and Java 9. I’d like to know if others have experienced the same, whether it could be a bug in Java 9, and if possible have your input to how to handle it in Java 9.
Context: In our (age-old) code base we are using a subclass of JTable, and for rendering multi-line HTML in one of the columns we are using a subclass of JEditorPane. We are using JEditorPane.getPreferredSize() for determining the height of the content and using it for setting the height of the table row. It’s been working well for many years. It doesn’t work in Java 9; the rows are displayed just 10 pixels high. Seen both on Windows and Mac.
I should like to show you two code examples. If the first and shorter one suffices for you, feel free to skip the second and longer one.
MCVE:
JEditorPane pane = new JEditorPane(""text/html"", """");

pane.setText(""<html>One line</html>"");
System.out.println(pane.getPreferredSize());
pane.setText(""<html>Line one<br />Line 2<br />Third line<br />Line four</html>"");
System.out.println(pane.getPreferredSize());

Output in Java 8 (1.8.0_131):
java.awt.Dimension[width=48,height=15]
java.awt.Dimension[width=57,height=60]

And on Java 9 (jdk-9.0.4):
java.awt.Dimension[width=49,height=15]
java.awt.Dimension[width=58,height=0]

In Java 9 the first time I set the text, the preferred height reflects it. Every subsequent time it doesn’t.
I have searched to see if I could find any information on a bug that might account for this, did not find anything relevant.
Question: Is this intended (change of) behaviour? Is it a bug??
Longer example
public class TestJEditorPaneAsRenderer extends JFrame {

    public TestJEditorPaneAsRenderer() {
        super(""Test JEditorPane"");
        
        MyRenderer renderer = new MyRenderer();
        
        String html2 = ""<html>one/2<br />two/2</html>"";
        String html4 = ""<html>one of four<br />two of four<br />""
                + ""three of four<br />four of four</html>"";
        JTable table = new JTable(new String[][] { { html2 }, { html4 } },
                                  new String[] { ""Dummy col title"" }) {
            @Override
            public TableCellRenderer getDefaultRenderer(Class<?> colType) {
                return renderer;
            }
        };
        
        add(table);
        setSize(100, 150);
        setDefaultCloseOperation(EXIT_ON_CLOSE);
    }
    
    public static void main(String[] args) {
        System.out.println(System.getProperty(""java.version""));
        new TestJEditorPaneAsRenderer().setVisible(true);
    }

}

class MyRenderer extends JEditorPane implements TableCellRenderer {

    public MyRenderer() {
        super(""text/html"", """");
    }
    
    @Override
    public Component getTableCellRendererComponent(
            JTable table, Object value, boolean selected, boolean hasFocus, int row, int col) {
        setText(value.toString());
        Dimension preferredSize = getPreferredSize();
        System.out.format(""Row %d preferred size %s%n"",row, preferredSize);
        if (preferredSize.height > 0 && table.getRowHeight(row) != preferredSize.height) {
            table.setRowHeight(row, preferredSize.height);
        }
        return this;
    }
    
}

Result on Java 8 is as expected:

Output from Java 8:
1.8.0_131
Row 0 preferred size java.awt.Dimension[width=32,height=30]
Row 1 preferred size java.awt.Dimension[width=72,height=60]
Row 0 preferred size java.awt.Dimension[width=32,height=30]
Row 1 preferred size java.awt.Dimension[width=72,height=60]

On Java 9 the second row is not shown high enough so most of the lines are hidden:

Output from Java 9:
9.0.4
Row 0 preferred size java.awt.Dimension[width=33,height=30]
Row 1 preferred size java.awt.Dimension[width=73,height=0]
Row 0 preferred size java.awt.Dimension[width=33,height=0]
Row 1 preferred size java.awt.Dimension[width=73,height=0]

A possible fix is if I create a new renderer component each time by changing the body of getDefaultRenderer() to:
return new MyRenderer();

Now the table looks good as on Java 8. If necessary I suppose we could live with a similar fix in our production code, but it seems quite a waste. Especially if it’s only necessary until the behaviour change is reverted in a coming Java version. I’d be grateful for your suggestions here.
",<java><swing><java-9><jeditorpane><preferredsize>,10,"java,swing,java-9,jeditorpane,preferredsize",['jeditorpanegetpreferredsize not always working in java 9'],"['this question is about different behaviour of jeditorpane in java 8 and java 9 id like to know if others have experienced the same whether it could be a bug in java 9 and if possible have your input to how to handle it in java 9 context in our ageold code base we are using a subclass of jtable and for rendering multiline html in one of the columns we are using a subclass of jeditorpane', 'we are using jeditorpanegetpreferredsize for determining the height of the content and using it for setting the height of the table row', 'its been working well for many years', 'it doesnt work in java 9 the rows are displayed just 10 pixels high', 'seen both on windows and mac', 'i should like to show you two code examples', 'if the first and shorter one suffices for you feel free to skip the second and longer one', 'mcve jeditorpane pane new jeditorpanetexthtml panesettexthtmlone linehtml systemoutprintlnpanegetpreferredsize panesettexthtmlline onebr line 2br third linebr line fourhtml systemoutprintlnpanegetpreferredsize output in java 8 180131 javaawtdimensionwidth48height15 javaawtdimensionwidth57height60 and on java 9 jdk904 javaawtdimensionwidth49height15 javaawtdimensionwidth58height0 in java 9 the first time i set the text the preferred height reflects it', 'every subsequent time it doesnt', 'i have searched to see if i could find any information on a bug that might account for this did not find anything relevant', 'question is this intended change of behaviour', 'is it a bug', 'longer example public class testjeditorpaneasrenderer extends jframe public testjeditorpaneasrenderer supertest jeditorpane myrenderer renderer new myrenderer string html2 htmlone2br two2html string html4 htmlone of fourbr two of fourbr three of fourbr four of fourhtml jtable table new jtablenew string html2 html4 new string dummy col title override public tablecellrenderer getdefaultrendererclass coltype return renderer addtable setsize100 150 setdefaultcloseoperationexitonclose public static void mainstring args systemoutprintlnsystemgetpropertyjavaversion new testjeditorpaneasrenderersetvisibletrue class myrenderer extends jeditorpane implements tablecellrenderer public myrenderer supertexthtml override public component gettablecellrenderercomponent jtable table object value boolean selected boolean hasfocus int row int col settextvaluetostring dimension preferredsize getpreferredsize systemoutformatrow d preferred size snrow preferredsize if preferredsizeheight 0 tablegetrowheightrow preferredsizeheight tablesetrowheightrow preferredsizeheight return this result on java 8 is as expected output from java 8 180131 row 0 preferred size javaawtdimensionwidth32height30 row 1 preferred size javaawtdimensionwidth72height60 row 0 preferred size javaawtdimensionwidth32height30 row 1 preferred size javaawtdimensionwidth72height60 on java 9 the second row is not shown high enough so most of the lines are hidden output from java 9 904 row 0 preferred size javaawtdimensionwidth33height30 row 1 preferred size javaawtdimensionwidth73height0 row 0 preferred size javaawtdimensionwidth33height0 row 1 preferred size javaawtdimensionwidth73height0 a possible fix is if i create a new renderer component each time by changing the body of getdefaultrenderer to return new myrenderer now the table looks good as on java 8 if necessary i suppose we could live with a similar fix in our production code but it seems quite a waste', 'especially if its only necessary until the behaviour change is reverted in a coming java version', 'id be grateful for your suggestions here']"
What is the fastest way to convert float to int on x86,"What is the fastest way you know to convert a floating-point number to an int on an x86 CPU.  Preferrably in C or assembly (that can be in-lined in C) for any combination of the following:

32/64/80-bit float -> 32/64-bit integer

I'm looking for some technique that is faster than to just let the compiler do it.
",<c><optimization><x86><floating-point><assembly>,26,"c,optimization,x86,floating-point,assembly",['what is the fastest way to convert float to int on x86'],"['what is the fastest way you know to convert a floatingpoint number to an int on an x86 cpu', 'preferrably in c or assembly that can be inlined in c for any combination of the following 326480bit float 3264bit integer im looking for some technique that is faster than to just let the compiler do it']"
How to get list of all columns from a parquet file using s3 select?,"I have a parquet file stored in S3 bucket. I want to get the list of all columns of the parquet file. I am using s3 select but it just give me list of all rows wihtout any column headers. 
Is there anyway to get all column names from this parquet file without downloading it completely? Since parquet file can be very large, I would not want to download the entire parquet file which is why I am using s3 select to pick first few rows using 
select * from S3Object LIMIT 10

I tried to fetch column names explicitly by doing 
SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'S3Object'

but it would not work as AWS S3 doesn't support this yet.
Is there any other way to achieve the same?
",<java><sql><amazon-s3><parquet><amazon-s3-select>,6,"java,sql,amazon-s3,parquet,amazon-s3-select",['how to get list of all columns from a parquet file using s3 select'],"['i have a parquet file stored in s3 bucket', 'i want to get the list of all columns of the parquet file', 'i am using s3 select but it just give me list of all rows wihtout any column headers', 'is there anyway to get all column names from this parquet file without downloading it completely', 'since parquet file can be very large i would not want to download the entire parquet file which is why i am using s3 select to pick first few rows using select from s3object limit 10 i tried to fetch column names explicitly by doing select columnname from informationschemacolumns where tablename s3object but it would not work as aws s3 doesnt support this yet', 'is there any other way to achieve the same']"
JOptionPane and scroll function,"I want to JList a lot of results in a JOptionPane, however, I'm not sure how to add in a scroll function should there be too many results. How would I add a scroll bar to a JOptionPane? Any help would be great.
Thanks.
",<java><swing><jscrollpane><jlist><joptionpane>,11,"java,swing,jscrollpane,jlist,joptionpane",['joptionpane and scroll function'],"['i want to jlist a lot of results in a joptionpane however im not sure how to add in a scroll function should there be too many results', 'how would i add a scroll bar to a joptionpane', 'any help would be great', 'thanks']"
Building and running Monodevelop solution in OS X Terminal,"I'd like to build and run a Monodevelop solution from the OS X Terminal. What are the appropriate tools/commands to do this?
I tried running mdtools build from the directory containing MySolution.sln. This results in -bash: mdtools: command not found. Where can I download and install mdtools? (if this is the right way to go). 
I built the solution from the IDE. Then I tried to run it from bin/Debug with mySolution.exe. This resulted in the error message -bash: mySolution.exe: command not found (even though ls shows it exists).
",<c#><macos><command-line><terminal><monodevelop>,8,"c#,macos,command-line,terminal,monodevelop",['building and running monodevelop solution in os x terminal'],"['id like to build and run a monodevelop solution from the os x terminal', 'what are the appropriate toolscommands to do this', 'i tried running mdtools build from the directory containing mysolutionsln', 'this results in bash mdtools command not found', 'where can i download and install mdtools', 'if this is the right way to go', 'i built the solution from the ide', 'then i tried to run it from bindebug with mysolutionexe', 'this resulted in the error message bash mysolutionexe command not found even though ls shows it exists']"
Using my own corpus for category classification in Python NLTK,"I'm a NTLK/Python beginner and managed to load my own corpus using CategorizedPlaintextCorpusReader but how do I actually train and use the data for classification of text?
>>> from nltk.corpus.reader import CategorizedPlaintextCorpusReader
>>> reader = CategorizedPlaintextCorpusReader('/ebs/category', r'.*\.txt', cat_pattern=r'(.*)\.txt')
>>> len(reader.categories())
234

",<python><nlp><machine-learning><nltk><corpus>,7,"python,nlp,machine-learning,nltk,corpus",['using my own corpus for category classification in python nltk'],"['im a ntlkpython beginner and managed to load my own corpus using categorizedplaintextcorpusreader but how do i actually train and use the data for classification of text', ' from nltkcorpusreader import categorizedplaintextcorpusreader reader categorizedplaintextcorpusreaderebscategory r', 'txt catpatternr', 'txt lenreadercategories 234']"
Symfony2: Doctrine does not load related entities in many-to-many relation,"I have a many-to-many-relation, and when I load an entity that is on one side this relation, I expect to see as its property the ArrayCollection of related entities on another side. However, this does not happen - the ArrayCollection loaded has no elements in it, while in the database I can see the related entries. What could be the reason?
Here is my code:
One side of the relation, ConsolidatedReport class:
/**
 * @var ArrayCollection
 *
 * @ORM\ManyToMany(targetEntity=""P24\Response"",  inversedBy=""consolidatedReports"")
 * @ORM\JoinTable(name=""con_rprt_responses"")
 */
private $responses;

Another side of the relation, Response class:
/**
 * @var ArrayCollection
 *
 * @ORM\ManyToMany(targetEntity=""P24\ConsolidatedReport\ConsolidatedReport"", mappedBy=""responses"")
 */
private $consolidatedReports;

Here is the function I run to get an instance of ConsolidatedReport. This function sits inside a service that is being called from container:  
/**
 * Picks the consolidated report with given id.
 *
 * @param string $id
 *
 * @return ConsolidatedReport
 *
 * @throws NonExistentConsolidatedReportException if the survey doesn't exist
 */
public function pick($id)
{
    $report = $this->repository->findOneBy(array('id' => $id));

    if (!$report) {
        throw new NonExistentConsolidatedReportException($id);
    }

    return $report;
}'

In the database, there is ""con_rprt_responses"" table with two columns ""consolidated_reports_id"" and ""response_id"". However, in profiler I do not see any queries to that table.
What could go wrong here?
UPDATE:
Please see my answer to this question below, that worked for me.
",<php><symfony><doctrine-orm><annotations><many-to-many>,12,"php,symfony,doctrine-orm,annotations,many-to-many",['symfony2 doctrine does not load related entities in manytomany relation'],"['i have a manytomanyrelation and when i load an entity that is on one side this relation i expect to see as its property the arraycollection of related entities on another side', 'however this does not happen the arraycollection loaded has no elements in it while in the database i can see the related entries', 'what could be the reason', 'here is my code one side of the relation consolidatedreport class var arraycollection ormmanytomanytargetentityp24response inversedbyconsolidatedreports ormjointablenameconrprtresponses private responses another side of the relation response class var arraycollection ormmanytomanytargetentityp24consolidatedreportconsolidatedreport mappedbyresponses private consolidatedreports here is the function i run to get an instance of consolidatedreport', 'this function sits inside a service that is being called from container picks the consolidated report with given id', ' param string id return consolidatedreport throws nonexistentconsolidatedreportexception if the survey doesnt exist public function pickid report thisrepositoryfindonebyarrayid id if report throw new nonexistentconsolidatedreportexceptionid return report in the database there is conrprtresponses table with two columns consolidatedreportsid and responseid', 'however in profiler i do not see any queries to that table', 'what could go wrong here', 'update please see my answer to this question below that worked for me']"
Laravel: Nesting query join results in a sub array,"NOTE Please do not suggest using Eloquent, this is specifically for the Laravel query builder.
For performance reasons we are using Query Builder to retrieve results from a table:
DB::table('posts')->get();

If we then want to join a relation onto that query:
DB:table('posts')
    ->leftJoin('comments', 'posts.id', '=', 'comments.post_id')
    ->get();

The results are merged into the array of each post:
[
    'id'                => 1,
    'title'             => 'My Blog Post',
    'content'           => '<h1>This is a post</h1><p>hello world</p>',
    'post_author'       => 'Billy',
    'comment'           => 'This is a comment',
    'comment_author'    => 'Andrew',
]

How can we have the joined results placed into a nested array? Such as:
[
    'id'                => 1,
    'title'             => 'My Blog Post',
    'content'           => '<h1>This is a post</h1><p>hello world</p>',
    'post_author'       => 'Billy',
    'comment'           => [
        'id'                => 22,
        'comment'           => 'This is a comment',
        'comment_author'    => 'Andrew',            
    ],
]

",<php><mysql><arrays><laravel><laravel-5>,6,"php,mysql,arrays,laravel,laravel-5",['laravel nesting query join results in a sub array'],"['note please do not suggest using eloquent this is specifically for the laravel query builder', 'for performance reasons we are using query builder to retrieve results from a table dbtablepostsget if we then want to join a relation onto that query dbtableposts leftjoincomments postsid commentspostid get the results are merged into the array of each post id 1 title my blog post content h1this is a posth1phello worldp postauthor billy comment this is a comment commentauthor andrew how can we have the joined results placed into a nested array', 'such as id 1 title my blog post content h1this is a posth1phello worldp postauthor billy comment id 22 comment this is a comment commentauthor andrew ']"
Directory-tree listing in Python,"How do I get a list of all files (and directories) in a given directory in Python?
",<python><file><directory><subdirectory><directory-tree>,609,"python,file,directory,subdirectory,directory-tree",['directorytree listing in python'],['how do i get a list of all files and directories in a given directory in python']
Get actual width and height of a component,"We're facing a fairly scary issue in JavaScript that none of us seems to be quite capable of resolving: 
How do we get the width and height of a DOM element, including children, entire box model etc. without the component actually being displayed on the page?
Remember: I'm looking for suggestions. Even answers which don't answer the question fully (or don't quite fit with the specified parameters) might, and probably will, be helpful.
Main goal: I'm adding HTML elements into the page via Javascript - HTML elements with sizes and styles from a database. Problem is that they misbehave, usually bad aligment, one element is larger than another due to padding/margin whatever, and so I need to check their actual size to fix these issues.
The resulting application is going to be a, as BigMacAttack has described it in the comments, a 'tightly knit mosaic of 3rd-party HTML controls' would pretty much be spot-on. It needs to look a lot like full-fledged desktop application, and HTML seems to hate the idea with passion. Not that I blame it.
Anyway, here's some example code:
JavaScript:
function exampleElement(caption, content) {
    this.caption = caption;
    this.content = content;
    this.rootElement = document.createElement(""div"");
}

exampleElement.prototype.constructElement = function() {
    var otherElement = document.createElement(""p"");
    this.rootElement.className = ""exampleElement"";
    this.rootElement.textContent = this.caption; 
    otherElement.className = ""exampleP"";
    otherElement.textContent = this.content;
    this.rootElement.appendChild(otherElement);
    /*I need to know size of the otherElement here*/
    /*here goes code adding stuff into rootElement*/
};

window.onload = function() {
    var ex = new exampleElement(""Hello"", ""Here's text"");
    ex.constructElement();
    document.body.appendChild(ex.rootElement);
};

CSS:
.exampleElement {
    padding: 5px;
    margin: 6px;
}

.exampleElement .exampleP {
    padding: 20px;
    margin: 6px;
}

A fiddle
Now, we need our page to dynamically react to size of the window and to contents of individual components, that's why it's important to be able to get size of an object before even displaying it. It's also important that creation of an object is clearly separated into three phases:

creation via new
construction of DOM tree (constructElement)
addition into the document (either directly into body or into another DOM tree)

It's important that we know sizes of individual elements during the construction phase.
So far we've tried measuring it via jQuery, DOM width and height attributes, but none of that works with DOM object not being directly displayed on page. Another approach I have tried were several functions adding the object into document.body, getting width and height, and then immediately removing it - however, since our CSS files are very specific, this is unreliable unless you insert the entire rootElement, which will be a terrible performance and memory hog as our components get fairly complex.
I suppose an approach of dropping .CSS files completely and defining styles directly trough JS would solve at least part of our predicament, but there has to be a better way.
Starting bounty to get more ideas and suggestions. Just shoot people, even if answer is not entirely within the boundaries of the question (how would/did you do it etc.) - the goal I'm trying to achieve is for my JS generated HTML controls to properly fit together.
",<javascript><jquery><html><css><dom>,17,"javascript,jquery,html,css,dom",['get actual width and height of a component'],"['were facing a fairly scary issue in javascript that none of us seems to be quite capable of resolving how do we get the width and height of a dom element including children entire box model etc', 'without the component actually being displayed on the page', 'remember im looking for suggestions', 'even answers which dont answer the question fully or dont quite fit with the specified parameters might and probably will be helpful', 'main goal im adding html elements into the page via javascript html elements with sizes and styles from a database', 'problem is that they misbehave usually bad aligment one element is larger than another due to paddingmargin whatever and so i need to check their actual size to fix these issues', 'the resulting application is going to be a as bigmacattack has described it in the comments a tightly knit mosaic of 3rdparty html controls would pretty much be spoton', 'it needs to look a lot like fullfledged desktop application and html seems to hate the idea with passion', 'not that i blame it', 'anyway heres some example code javascript function exampleelementcaption content thiscaption caption thiscontent content thisrootelement documentcreateelementdiv exampleelementprototypeconstructelement function var otherelement documentcreateelementp thisrootelementclassname exampleelement thisrootelementtextcontent thiscaption otherelementclassname examplep otherelementtextcontent thiscontent thisrootelementappendchildotherelement i need to know size of the otherelement here here goes code adding stuff into rootelement windowonload function var ex new exampleelementhello heres text exconstructelement documentbodyappendchildexrootelement css exampleelement padding 5px margin 6px exampleelement examplep padding 20px margin 6px a fiddle now we need our page to dynamically react to size of the window and to contents of individual components thats why its important to be able to get size of an object before even displaying it', 'its also important that creation of an object is clearly separated into three phases creation via new construction of dom tree constructelement addition into the document either directly into body or into another dom tree its important that we know sizes of individual elements during the construction phase', 'so far weve tried measuring it via jquery dom width and height attributes but none of that works with dom object not being directly displayed on page', 'another approach i have tried were several functions adding the object into documentbody getting width and height and then immediately removing it however since our css files are very specific this is unreliable unless you insert the entire rootelement which will be a terrible performance and memory hog as our components get fairly complex', 'i suppose an approach of dropping css files completely and defining styles directly trough js would solve at least part of our predicament but there has to be a better way', 'starting bounty to get more ideas and suggestions', 'just shoot people even if answer is not entirely within the boundaries of the question how woulddid you do it etc', ' the goal im trying to achieve is for my js generated html controls to properly fit together']"
MalformedJsonException: Use JsonReader.setLenient(true) to accept malformed JSON at line 1 column 1 path,"Trying to send info in JSON format using Retrofit, but it enters into Retrofit's onFailure method and throws the following error:
com.google.gson.stream.MalformedJsonException: Use JsonReader.setLenient(true) to accept malformed JSON at line 1 column 1 path $

So far I have tried to solve it by using the answers from the following links:
1) MalformedJsonException with Retrofit API?
2) Use JsonReader.setLenient(true) to accept malformed JSON at line 1 column 1 path $
Here is my code:
Retrofit interface:
public interface ServerApi {
    @POST(""/register/test"")
    Call<User> createAccount(@Body User user);
}

MainActivity with connection stuff:
public class MainActivity extends AppCompatActivity {

    @Override
    protected void onCreate(@Nullable Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_main);

        User user= new User(""myemail@mail.ru"",""vercode100"");
        sendNetworkRequest(user);
    }

    private void sendNetworkRequest(User user){

        //create Retrofit instance
        Retrofit.Builder builder= new Retrofit.Builder()
                .baseUrl(""http://localhost:8080"")
                .addConverterFactory(GsonConverterFactory.create());

        Retrofit retrofit= builder.build();

        //Get client and call object for the request
        ServerApi client= retrofit.create(ServerApi.class);
        Call<User> call= client.createAccount(user);

        call.enqueue(new Callback<User>() {
            @Override
            public void onResponse(Call<User> call, Response<User> response) {
            }

            @Override
            public void onFailure(Call<User> call, Throwable t) {
            }
        });

    }
}

User class:
public class User {
    private String email;
    private String verificationCode;

    public User(String email, String verificationCode) {
        this.email = email;
        this.verificationCode = verificationCode;
    }

}

The server side expects JSON like this:
{
    ""email"" : ""user.email"",
    ""verificationCode"" : ""123456""
}

I know that there are some common questions in stackoverflow, but neither of them fully solves my problem.
",<android><json><gson><retrofit><retrofit2>,6,"android,json,gson,retrofit,retrofit2",['malformedjsonexception use jsonreadersetlenienttrue to accept malformed json at line 1 column 1 path'],"['trying to send info in json format using retrofit but it enters into retrofits onfailure method and throws the following error comgooglegsonstreammalformedjsonexception use jsonreadersetlenienttrue to accept malformed json at line 1 column 1 path so far i have tried to solve it by using the answers from the following links 1 malformedjsonexception with retrofit api', '2 use jsonreadersetlenienttrue to accept malformed json at line 1 column 1 path here is my code retrofit interface public interface serverapi postregistertest calluser createaccountbody user user mainactivity with connection stuff public class mainactivity extends appcompatactivity override protected void oncreatenullable bundle savedinstancestate superoncreatesavedinstancestate setcontentviewrlayoutactivitymain user user new usermyemailmailruvercode100 sendnetworkrequestuser private void sendnetworkrequestuser user create retrofit instance retrofitbuilder builder new retrofitbuilder baseurl addconverterfactorygsonconverterfactorycreate retrofit retrofit builderbuild get client and call object for the request serverapi client retrofitcreateserverapiclass calluser call clientcreateaccountuser callenqueuenew callbackuser override public void onresponsecalluser call responseuser response override public void onfailurecalluser call throwable t user class public class user private string email private string verificationcode public userstring email string verificationcode thisemail email thisverificationcode verificationcode the server side expects json like this email useremail verificationcode 123456 i know that there are some common questions in stackoverflow but neither of them fully solves my problem']"
fill sequence of datetimes,"I have a data.frame consisting of IDs, DateTimes and Values. For each ID I want to expand the DateTimes so that there is one every hour between the min and max. The ID and Value columns should be filled with their respective values (i.e. not NA). There will never be case where there are multiple unique Value values for each ID. For example the new data.frame should have 4 rows with ID == 1 and 5 rows with ID == 2 (9 rows total). What is simplest way to do this?
I commonly work with dplyr so will accept both base or dplyr/tidyverse methods
library(dplyr)
library(lubridate)

dt <- Sys.time() %>% floor_date('hours')
df <- data.frame(ID = c(1, 1, 2, 2), 
                 DateTime = c(dt, dt + hours(3), dt + hours(6), dt + hours(9)),
                 Value = c(3, 3, 4, 4))

the expected output is:
output <- data.frame(ID = c(1, 1, 1, 1, 2, 2, 2, 2), 
                     DateTime = c(dt, dt + hours(1), dt + hours(2), dt + hours(3), 
                                  dt + hours(6), dt + hours(7), dt + hours(8), dt + hours(9)),
                     Value = c(3, 3, 3, 3, 4, 4, 4, 4))

  ID            DateTime Value
1  1 2018-03-27 19:00:00     3
2  1 2018-03-27 20:00:00     3
3  1 2018-03-27 21:00:00     3
4  1 2018-03-27 22:00:00     3
5  2 2018-03-28 01:00:00     4
6  2 2018-03-28 02:00:00     4
7  2 2018-03-28 03:00:00     4
8  2 2018-03-28 04:00:00     4

",<r><dplyr><lubridate><posixct><seq>,5,"r,dplyr,lubridate,posixct,seq",['fill sequence of datetimes'],"['i have a dataframe consisting of ids datetimes and values', 'for each id i want to expand the datetimes so that there is one every hour between the min and max', 'the id and value columns should be filled with their respective values ie', 'not na', 'there will never be case where there are multiple unique value values for each id', 'for example the new dataframe should have 4 rows with id 1 and 5 rows with id 2 9 rows total', 'what is simplest way to do this', 'i commonly work with dplyr so will accept both base or dplyrtidyverse methods librarydplyr librarylubridate dt systime floordatehours df dataframeid c1 1 2 2 datetime cdt dt hours3 dt hours6 dt hours9 value c3 3 4 4 the expected output is output dataframeid c1 1 1 1 2 2 2 2 datetime cdt dt hours1 dt hours2 dt hours3 dt hours6 dt hours7 dt hours8 dt hours9 value c3 3 3 3 4 4 4 4 id datetime value 1 1 20180327 190000 3 2 1 20180327 200000 3 3 1 20180327 210000 3 4 1 20180327 220000 3 5 2 20180328 010000 4 6 2 20180328 020000 4 7 2 20180328 030000 4 8 2 20180328 040000 4']"
rtsp stream capturing,"I'm looking for some universal way to dump rtsp stream. I want to figure out, that some rtsp stream is working well and server is sending some watchable video.
openRTSP
At first, google recommends me openRTSP tool. 
 openRTSP -4 ${stream_link} > ${output_file}

But output video file dumped by that tool is not really correct. Video decoder (ffdec) returns many errors like ""Failed to decode video packet"" and ""[h264] no frame!"", which don't suit me. 
ffmpeg
Then I've tried to dump rtsp stream with ffmpeg tool. 
ffmpeg -loglevel debug -i ""${stream_link}"" -s 640x480 -vcodec copy -acodec copy -y ${output_file}

But streaming process was interrupted often by error:
Application provided invalid, non monotonically increasing dts to muxer in stream 0: 730672 >= 730672
av_interleaved_write_frame(): Invalid argument

I'm trying to use --fflags igndts but ffmpeg doesn't ignore these errors. It doesn't make any sense, because that error actually means that audio and video streams are sending asynchronously. The worst thing is that dumped file, resulted by that interrupted dump, is not correct too. Ffdec return some error:
ERROR [mov,mp4,m4a,3gp,3g2,mj2] moov atom not found
ERROR [ffdec] av_open_input_file: Operation not permitted

After a nice cup of googling I've found, that it's really old ffmpeg's muxer bug. 
mplayer
Than I've tried to use mplayer with LIVE_555 lib.
mplayer -noframedrop -dumpfile ${output_file} -dumpstream ${stream_link}

But I've got some errors too.
Stream not seekable!
Core dumped ;)

Question
I think I'm doing something wrong. It's sounds really ridiculous, that there is no way to save rtsp stream in correct and playable video-file.
Maybe there are some another tools which can help with that task? Actually, I will be grateful for any advice for all kind of libs and languages. But that process should be automatic and have cli.
Refinements
Something about 50% experiments I've done on the localhost with vlc-streamer that emulates rtsp-broadcaster. Here is a manual which I try to follow.
I have really fresh and latest ffmpeg with x264 support, that I've installed by that useful thread.
",<video><ffmpeg><video-streaming><rtsp><mplayer>,24,"video,ffmpeg,video-streaming,rtsp,mplayer",['rtsp stream capturing'],"['im looking for some universal way to dump rtsp stream', 'i want to figure out that some rtsp stream is working well and server is sending some watchable video', 'openrtsp at first google recommends me openrtsp tool', 'openrtsp 4 streamlink outputfile but output video file dumped by that tool is not really correct', 'video decoder ffdec returns many errors like failed to decode video packet and h264 no frame', ' which dont suit me', 'ffmpeg then ive tried to dump rtsp stream with ffmpeg tool', 'ffmpeg loglevel debug i streamlink s 640x480 vcodec copy acodec copy y outputfile but streaming process was interrupted often by error application provided invalid non monotonically increasing dts to muxer in stream 0 730672 730672 avinterleavedwriteframe invalid argument im trying to use fflags igndts but ffmpeg doesnt ignore these errors', 'it doesnt make any sense because that error actually means that audio and video streams are sending asynchronously', 'the worst thing is that dumped file resulted by that interrupted dump is not correct too', 'ffdec return some error error movmp4m4a3gp3g2mj2 moov atom not found error ffdec avopeninputfile operation not permitted after a nice cup of googling ive found that its really old ffmpegs muxer bug', 'mplayer than ive tried to use mplayer with live555 lib', 'mplayer noframedrop dumpfile outputfile dumpstream streamlink but ive got some errors too', 'stream not seekable', 'core dumped question i think im doing something wrong', 'its sounds really ridiculous that there is no way to save rtsp stream in correct and playable videofile', 'maybe there are some another tools which can help with that task', 'actually i will be grateful for any advice for all kind of libs and languages', 'but that process should be automatic and have cli', 'refinements something about 50 experiments ive done on the localhost with vlcstreamer that emulates rtspbroadcaster', 'here is a manual which i try to follow', 'i have really fresh and latest ffmpeg with x264 support that ive installed by that useful thread']"
OpenCV - Object matching using SURF descriptors and BruteForceMatcher,"I have a question about objects matching with OpenCV.
I'm useing SURF algorithm implemented in opencv 2.3 to first detect features on each image, and then extracting the descriptors of these features.
The problem in matching using Brute Force Matcher, I don't know how I judge that the two images are matched or not that's as when I'm using two different images there are lines between descriptors in the two images!
These outputs of my code, either the two images -I compare with them - are similar or different, the result image indicate that the two images are matched. 
The question is: How can I distinguish between the two images?
True matching: 

False matching!! : 

My code:   
Mat image1, outImg1, image2, outImg2;

// vector of keypoints
vector<KeyPoint> keypoints1, keypoints2;

// Read input images
image1 = imread(""C://Google-Logo.jpg"",0);
image2 = imread(""C://Alex_Eng.jpg"",0);

SurfFeatureDetector surf(2500);
surf.detect(image1, keypoints1);
surf.detect(image2, keypoints2);
drawKeypoints(image1, keypoints1, outImg1, Scalar(255,255,255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);
drawKeypoints(image2, keypoints2, outImg2, Scalar(255,255,255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS);

namedWindow(""SURF detector img1"");
imshow(""SURF detector img1"", outImg1);

namedWindow(""SURF detector img2"");
imshow(""SURF detector img2"", outImg2);

SurfDescriptorExtractor surfDesc;
Mat descriptors1, descriptors2;
surfDesc.compute(image1, keypoints1, descriptors1);
surfDesc.compute(image2, keypoints2, descriptors2);

BruteForceMatcher<L2<float>> matcher;
vector<DMatch> matches;
matcher.match(descriptors1,descriptors2, matches);

nth_element(matches.begin(), matches.begin()+24, matches.end());
matches.erase(matches.begin()+25, matches.end());

Mat imageMatches;
drawMatches(image1, keypoints1, image2, keypoints2, matches, imageMatches, Scalar(255,255,255));

namedWindow(""Matched"");
imshow(""Matched"", imageMatches);

cv::waitKey();
return 0;

",<c++><opencv><computer-vision><surf><object-detection>,19,"c++,opencv,computer-vision,surf,object-detection",['opencv object matching using surf descriptors and bruteforcematcher'],"['i have a question about objects matching with opencv', 'im useing surf algorithm implemented in opencv 23 to first detect features on each image and then extracting the descriptors of these features', 'the problem in matching using brute force matcher i dont know how i judge that the two images are matched or not thats as when im using two different images there are lines between descriptors in the two images', 'these outputs of my code either the two images i compare with them are similar or different the result image indicate that the two images are matched', 'the question is how can i distinguish between the two images', 'true matching false matching', ' my code mat image1 outimg1 image2 outimg2 vector of keypoints vectorkeypoint keypoints1 keypoints2 read input images image1 imreadcgooglelogojpg0 image2 imreadcalexengjpg0 surffeaturedetector surf2500 surfdetectimage1 keypoints1 surfdetectimage2 keypoints2 drawkeypointsimage1 keypoints1 outimg1 scalar255255255 drawmatchesflagsdrawrichkeypoints drawkeypointsimage2 keypoints2 outimg2 scalar255255255 drawmatchesflagsdrawrichkeypoints namedwindowsurf detector img1 imshowsurf detector img1 outimg1 namedwindowsurf detector img2 imshowsurf detector img2 outimg2 surfdescriptorextractor surfdesc mat descriptors1 descriptors2 surfdesccomputeimage1 keypoints1 descriptors1 surfdesccomputeimage2 keypoints2 descriptors2 bruteforcematcherl2float matcher vectordmatch matches matchermatchdescriptors1descriptors2 matches nthelementmatchesbegin matchesbegin24 matchesend matcheserasematchesbegin25 matchesend mat imagematches drawmatchesimage1 keypoints1 image2 keypoints2 matches imagematches scalar255255255 namedwindowmatched imshowmatched imagematches cvwaitkey return 0']"
New Line Issue when copying data from SQL Server 2012 to Excel,"I recently upgraded to SQL2012 and am using Management Studio. One of my columns in the database has a CHAR(13) + CHAR(10) stored in it. 
When I was using SQL Server 2008, this would copy and paste completely fine into Excel. Now, however, copying and pasting the same data creates a new line/ carriage return in the data I have in Excel.
Is there a setting I missed in SQL2012 that will resolve this issue? I don't want to simply REPLACE(CHAR(13) + CHAR(10)) on every single database selection, as I would have to go from using SELECT * to defining each individual column.
",<sql><sql-server-2008><excel><copy-paste><sql-server-2012>,71,"sql,sql-server-2008,excel,copy-paste,sql-server-2012",['new line issue when copying data from sql server 2012 to excel'],"['i recently upgraded to sql2012 and am using management studio', 'one of my columns in the database has a char13 char10 stored in it', 'when i was using sql server 2008 this would copy and paste completely fine into excel', 'now however copying and pasting the same data creates a new line carriage return in the data i have in excel', 'is there a setting i missed in sql2012 that will resolve this issue', 'i dont want to simply replacechar13 char10 on every single database selection as i would have to go from using select to defining each individual column']"
NSTabView comes with duplicate buttons in Interface Builder?,"If I drag a Tab View Controller to the storyboard of an OS X application, the tab view buttons seem to misbehave. Can you help me understand what's going on?
Here's an minimal example of a fresh project, where I simply replaced the default empty View Controller with a new Tab View Controller:

The highlighted Tab View is shown as No Shadow Tab View by default, which means that the Tab View's style is Tabless in the Attributes Inspector.
There are also two Tab View Items below the Tab View in the Scene's list.
If I build & run, the result looks like this:

The tab controls are visible, but the tab view has no bezel. It seems like the tab buttons that are displayed are actually the two extra Tab View Items, not the native buttons of the Tab View itself.
If I change the Tab View's style to Top Tabs instead of the default Tabless, I get a bezel, but duplicate tab buttons:

And if I change it to Tabless With Bezel, the bezel is below the tab buttons, instead of properly sitting midway under the buttons:

I can't figure this out. Why are there two sets of tab buttons to start with (with the ""real"" one hidden by default)? The two extra Tab View Items seem to be completely redundant, but they can't be deleted.
Is there a way to have a tab bar with a proper bezel when using Interface Builder and a Tab View Controller? 
",<xcode><macos><cocoa><interface-builder><nstabviewcontroller>,6,"xcode,macos,cocoa,interface-builder,nstabviewcontroller",['nstabview comes with duplicate buttons in interface builder'],"['if i drag a tab view controller to the storyboard of an os x application the tab view buttons seem to misbehave', 'can you help me understand whats going on', 'heres an minimal example of a fresh project where i simply replaced the default empty view controller with a new tab view controller the highlighted tab view is shown as no shadow tab view by default which means that the tab views style is tabless in the attributes inspector', 'there are also two tab view items below the tab view in the scenes list', 'if i build run the result looks like this the tab controls are visible but the tab view has no bezel', 'it seems like the tab buttons that are displayed are actually the two extra tab view items not the native buttons of the tab view itself', 'if i change the tab views style to top tabs instead of the default tabless i get a bezel but duplicate tab buttons and if i change it to tabless with bezel the bezel is below the tab buttons instead of properly sitting midway under the buttons i cant figure this out', 'why are there two sets of tab buttons to start with with the real one hidden by default', 'the two extra tab view items seem to be completely redundant but they cant be deleted', 'is there a way to have a tab bar with a proper bezel when using interface builder and a tab view controller']"
Configure TSA in Xml Signature in C#,"I am trying to sign an XML file in C# using Signature Class library by Microsoft.
What I have done is like this-
using System;
using System.Collections.Generic;
using System.Linq;
using System.Net;
using System.Security.Cryptography;
using System.Security.Cryptography.X509Certificates;
using System.Security.Cryptography.Xml;
using System.Text;
using System.Threading.Tasks;
using System.Windows;
using System.Xml;
using XMLSigner.Model;
using DataObject = System.Security.Cryptography.Xml.DataObject;

internal static XmlDocument GetSignedXMLDocument(XmlDocument xmlDocument, X509Certificate2 certificate, long procedureSerial = -1, string reason = """")
{
    //Check if local time is OK
    if(!Ntp.CheckIfLocalTimeIsOk()) {
        MessageBox.Show(""PC Time is need to be updated before sign !"");
        return null;    //Last Sign Not Verified
    }
    //Then sign the xml
    try
    {
        //MessageBox.Show(certificate.Subject);
        SignedXml signedXml = new SignedXml(xmlDocument);
        signedXml.SigningKey = certificate.PrivateKey;

        // Create a reference to be signed
        Reference reference = new Reference();
        /////////////////////
        reference.Uri = """";//""#"" + procedureSerial;
        //reference.Type = reason;
        //reference.Id = DateTime.UtcNow.Ticks.ToString();
        reference.Id = Base64EncodedCurrentTime();
        //reference.TransformChain = ;
        /////////////////////
        // Add an enveloped transformation to the reference.            
        XmlDsigEnvelopedSignatureTransform env = new XmlDsigEnvelopedSignatureTransform(true);
        reference.AddTransform(env);

        // Add the reference to the SignedXml object.
        signedXml.AddReference(reference);

        //canonicalize
        XmlDsigC14NTransform c14t = new XmlDsigC14NTransform();
        reference.AddTransform(c14t);

        KeyInfo keyInfo = new KeyInfo();
        KeyInfoX509Data keyInfoData = new KeyInfoX509Data(certificate);
        KeyInfoName kin = new KeyInfoName();
        //kin.Value = ""Public key of certificate"";
        kin.Value = certificate.FriendlyName;

        RSA rsa = (RSA)certificate.PublicKey.Key;
        RSAKeyValue rkv = new RSAKeyValue(rsa);
        keyInfo.AddClause(rkv);

        keyInfo.AddClause(kin);
        keyInfo.AddClause(keyInfoData);
        signedXml.KeyInfo = keyInfo;

        //////////////////////////////////////////Add Other Data as we need////
        // Add the data object to the signature.
        //CreateMetaDataObject(""Name"", GetNetworkTime());
        signedXml.AddObject(CreateMetaDataObject(procedureSerial, reason));
        ///////////////////////////////////////////////////////////////////////
        // Compute the signature.
        signedXml.ComputeSignature();

        // Get the XML representation of the signature and save 
        // it to an XmlElement object.
        XmlElement xmlDigitalSignature = signedXml.GetXml();

        xmlDocument.DocumentElement.AppendChild(
                xmlDocument.ImportNode(xmlDigitalSignature, true)
            );
        /////////////////////
    } catch (Exception exception) {
        MessageBox.Show(""Internal System Error during sign"");
        throw exception;
    }
    return xmlDocument;
}

And it is working completely fine. But I have an issue with this code. I have to use TSA Server for the stored time in the XML Signature, but the time is set from local PC, to avoid this issue, I have checked time manually from Ntp.CheckIfLocalTimeIsOk() function defined in here. But I like to have the time come from a TSA link like-

http://ca.signfiles.com/TSAServer.aspx
http://timestamp.globalsign.com/scripts/timstamp.dll
https://timestamp.geotrust.com/tsa

Is it possible to configure TSA in XmlSignature in C#?
",<c#><asp.net><xml><digital-signature><xml-signature>,6,"c#,asp.net,xml,digital-signature,xml-signature",['configure tsa in xml signature in c'],"['i am trying to sign an xml file in c using signature class library by microsoft', 'what i have done is like this using system using systemcollectionsgeneric using systemlinq using systemnet using systemsecuritycryptography using systemsecuritycryptographyx509certificates using systemsecuritycryptographyxml using systemtext using systemthreadingtasks using systemwindows using systemxml using xmlsignermodel using dataobject systemsecuritycryptographyxmldataobject internal static xmldocument getsignedxmldocumentxmldocument xmldocument x509certificate2 certificate long procedureserial 1 string reason check if local time is ok ifntpcheckiflocaltimeisok messageboxshowpc time is need to be updated before sign ', ' return null last sign not verified then sign the xml try messageboxshowcertificatesubject signedxml signedxml new signedxmlxmldocument signedxmlsigningkey certificateprivatekey create a reference to be signed reference reference new reference referenceuri procedureserial referencetype reason referenceid datetimeutcnowtickstostring referenceid base64encodedcurrenttime referencetransformchain add an enveloped transformation to the reference', 'xmldsigenvelopedsignaturetransform env new xmldsigenvelopedsignaturetransformtrue referenceaddtransformenv add the reference to the signedxml object', 'signedxmladdreferencereference canonicalize xmldsigc14ntransform c14t new xmldsigc14ntransform referenceaddtransformc14t keyinfo keyinfo new keyinfo keyinfox509data keyinfodata new keyinfox509datacertificate keyinfoname kin new keyinfoname kinvalue public key of certificate kinvalue certificatefriendlyname rsa rsa rsacertificatepublickeykey rsakeyvalue rkv new rsakeyvaluersa keyinfoaddclauserkv keyinfoaddclausekin keyinfoaddclausekeyinfodata signedxmlkeyinfo keyinfo add other data as we need add the data object to the signature', 'createmetadataobjectname getnetworktime signedxmladdobjectcreatemetadataobjectprocedureserial reason compute the signature', 'signedxmlcomputesignature get the xml representation of the signature and save it to an xmlelement object', 'xmlelement xmldigitalsignature signedxmlgetxml xmldocumentdocumentelementappendchild xmldocumentimportnodexmldigitalsignature true catch exception exception messageboxshowinternal system error during sign throw exception return xmldocument and it is working completely fine', 'but i have an issue with this code', 'i have to use tsa server for the stored time in the xml signature but the time is set from local pc to avoid this issue i have checked time manually from ntpcheckiflocaltimeisok function defined in here', 'but i like to have the time come from a tsa link like is it possible to configure tsa in xmlsignature in c']"
How to easily parse csv file to use in node.js sequelize database migration strategy?,"I've got the migration strategy via sequelize-cli set up and running so the table can be constructed properly. It works using sequelize db:migrate and it creates the table just fine. And sequelize db:migrate:undo will delete the table. 
I've also included code (per the SE comment here) to insert a couple of records. That works too. Here's the code for all that:


'use strict';

module.exports = {
  up: function(queryInterface, DataTypes, done) {
    return queryInterface.createTable('survey', {
      id: {
        type: DataTypes.INTEGER,
        primaryKey: true,
        autoIncrement: true
      },
      state: {
        type: DataTypes.TEXT
      },
      age: {
        type: DataTypes.INTEGER
      },
      race: {
        type: DataTypes.TEXT
      },
      gender: {
        type: DataTypes.TEXT
      },
      education: {
        type: DataTypes.TEXT
      },
      q1: {
        type: DataTypes.INTEGER
      },
      q2: {
        type: DataTypes.INTEGER
      },
      .
      .
      .
      q24: {
        type: DataTypes.INTEGER
      },
      q25: {
        type: DataTypes.INTEGER
      }
    }).then(function() {
      queryInterface.sequelize.query(""INSERT INTO survey (state, age, race, gender, q1, q7, q24) VALUES ('Texas', 42, 'white', 'female', 5, 4, 3), ('Louisiana', 19, 'hispanic', 'male', 1, 2,5)"");
      done();
    });
  },

  down: function(queryInterface, Sequelize) {
    return queryInterface.dropTable('survey');
  }
};



But I have a CSV file with over 3000 records that needs to be used as the seed data. It's in the db folder and called survey.csv. I also have a seeders folder that I think was created automatically by a sequelize init or sequelize migration:create. It's currently empty. 
I could use the concatenate function in Excel to create the ordered n-tuples of data to insert and just paste those 3000 lines into promise part of up, but that seems ridiculous. 
I found this reply for a similar question, but in Rails:

You need the CSV library. From the docs:
arr_of_arrs = CSV.read(""path/to/file.csv"")
This will give you a 2D array which you can process as you like. CSV 
  similar to IO.read, but with a few extras such as header parsing.

It looks like there's a handful (or more) csv node packages, but golly, they're so complicated (like the simply-named csv). 
Is there a simpler csv parser (like the one for Rails) that I can use to facilitate the dumping of the csv into the database? Or another method that doesn't require a bazillion lines of superfluous code copied from a spreadsheet?
",<mysql><node.js><csv><database-migration><sequelize-cli>,5,"mysql,node.js,csv,database-migration,sequelize-cli",['how to easily parse csv file to use in nodejs sequelize database migration strategy'],"['ive got the migration strategy via sequelizecli set up and running so the table can be constructed properly', 'it works using sequelize dbmigrate and it creates the table just fine', 'and sequelize dbmigrateundo will delete the table', 'ive also included code per the se comment here to insert a couple of records', 'that works too', 'heres the code for all that use strict moduleexports up functionqueryinterface datatypes done return queryinterfacecreatetablesurvey id type datatypesinteger primarykey true autoincrement true state type datatypestext age type datatypesinteger race type datatypestext gender type datatypestext education type datatypestext q1 type datatypesinteger q2 type datatypesinteger ', '', '', 'q24 type datatypesinteger q25 type datatypesinteger thenfunction queryinterfacesequelizequeryinsert into survey state age race gender q1 q7 q24 values texas 42 white female 5 4 3 louisiana 19 hispanic male 1 25 done down functionqueryinterface sequelize return queryinterfacedroptablesurvey but i have a csv file with over 3000 records that needs to be used as the seed data', 'its in the db folder and called surveycsv', 'i also have a seeders folder that i think was created automatically by a sequelize init or sequelize migrationcreate', 'its currently empty', 'i could use the concatenate function in excel to create the ordered ntuples of data to insert and just paste those 3000 lines into promise part of up but that seems ridiculous', 'i found this reply for a similar question but in rails you need the csv library', 'from the docs arrofarrs csvreadpathtofilecsv this will give you a 2d array which you can process as you like', 'csv similar to ioread but with a few extras such as header parsing', 'it looks like theres a handful or more csv node packages but golly theyre so complicated like the simplynamed csv', 'is there a simpler csv parser like the one for rails that i can use to facilitate the dumping of the csv into the database', 'or another method that doesnt require a bazillion lines of superfluous code copied from a spreadsheet']"
Mockito incorrect argument matcher after Jenkins core upgrade,"We have Jenkins shared library project with some unit-tests that utilize Mockito.
After an upgrade of Jenkins-core from version 2.325 to 2.326 tests start failing on the following line:
class DSLMock {

  DSLMock() {

    this.mock = mock(DSL.class)

->  when(mock.invokeMethod(eq(""error""), any())).then(new Answer<String>() {
      @Override
      String answer(InvocationOnMock invocationOnMock) throws Throwable {
        throw new AbortException((String) invocationOnMock.getArguments()[1][0])
      }
    })
...

with error:

org.mockito.exceptions.misusing.InvalidUseOfMatchersException: 
Misplaced or misused argument matcher detected here:
-> at com.devops.jenkins.testing.DSLMock.<init>(DSLMock.groovy:66)
-> at com.devops.jenkins.testing.DSLMock.<init>(DSLMock.groovy:66)
You cannot use argument matchers outside of verification or stubbing.
Examples of correct usage of argument matchers:
    when(mock.get(anyInt())).thenReturn(null);
    doThrow(new RuntimeException()).when(mock).someVoidMethod(anyObject());
    verify(mock).someMethod(contains(""foo""))
This message may appear after an NullPointerException if the last matcher is returning an object 
like any() but the stubbed method signature expect a primitive argument, in this case,
use primitive alternatives.
    when(mock.get(any())); // bad use, will raise NPE
    when(mock.get(anyInt())); // correct usage use
Also, this error might show up because you use argument matchers with methods that cannot be mocked.
Following methods *cannot* be stubbed/verified: final/private/equals()/hashCode().
Mocking methods declared on non-public parent classes is not supported.

I've tried to replace any() with methods like anyString() and just value like """" but still got same error.
Also I've tried different stub syntax like
doAnswer(new Answer...).when(mock).invokeMethod(eq(""error""), any())

In changelog https://www.jenkins.io/changelog-old/#v2.326 I see Groovy patch version has been upgraded:

Upgrade Groovy from 2.4.12 to 2.4.21

I wonder if that would cause the issue. Other dependencies versions are not changed:
<groovy.version>2.4.12</groovy.version>
<junit-jupiter.version>5.8.1</junit-jupiter.version>
<mockito.core.version>3.3.3</mockito.core.version>

",<java><jenkins><groovy><mockito><matcher>,5,"java,jenkins,groovy,mockito,matcher",['mockito incorrect argument matcher after jenkins core upgrade'],"['we have jenkins shared library project with some unittests that utilize mockito', 'after an upgrade of jenkinscore from version 2325 to 2326 tests start failing on the following line class dslmock dslmock thismock mockdslclass whenmockinvokemethodeqerror anythennew answerstring override string answerinvocationonmock invocationonmock throws throwable throw new abortexceptionstring invocationonmockgetarguments10 with error orgmockitoexceptionsmisusinginvaliduseofmatchersexception misplaced or misused argument matcher detected here at comdevopsjenkinstestingdslmockinitdslmockgroovy66 at comdevopsjenkinstestingdslmockinitdslmockgroovy66 you cannot use argument matchers outside of verification or stubbing', 'examples of correct usage of argument matchers whenmockgetanyintthenreturnnull dothrownew runtimeexceptionwhenmocksomevoidmethodanyobject verifymocksomemethodcontainsfoo this message may appear after an nullpointerexception if the last matcher is returning an object like any but the stubbed method signature expect a primitive argument in this case use primitive alternatives', 'whenmockgetany bad use will raise npe whenmockgetanyint correct usage use also this error might show up because you use argument matchers with methods that cannot be mocked', 'following methods cannot be stubbedverified finalprivateequalshashcode', 'mocking methods declared on nonpublic parent classes is not supported', 'ive tried to replace any with methods like anystring and just value like but still got same error', 'also ive tried different stub syntax like doanswernew answerwhenmockinvokemethodeqerror any in changelog i see groovy patch version has been upgraded upgrade groovy from 2412 to 2421 i wonder if that would cause the issue', 'other dependencies versions are not changed groovyversion2412groovyversion junitjupiterversion581junitjupiterversion mockitocoreversion333mockitocoreversion']"
Changing keyboard type for html textarea on iPad,"I'm writing a web application for iPad.
I know it's possible to change the type of keyboard displayed when an html input field is selected using:
Text: <input type=""text"" />
Telephone: <input type=""tel"" /> 
URL: <input type=""url"" /> 
Email: <input type=""email"" /> 
Zip Code: <input type=""text"" pattern=""[0-9]*"" />

the problem is that I have to use textarea instead of input. Is it possible to obtain the same result?
If not : is there any way to change the keyboard label for the ENTER key. At the moment the default label is ""Return"" and I would like to have ""Send"" (since it's a chat app).
thanks a lot!
",<ios><forms><input><keyboard><textarea>,8,"ios,forms,input,keyboard,textarea",['changing keyboard type for html textarea on ipad'],"['im writing a web application for ipad', 'i know its possible to change the type of keyboard displayed when an html input field is selected using text input typetext telephone input typetel url input typeurl email input typeemail zip code input typetext pattern09 the problem is that i have to use textarea instead of input', 'is it possible to obtain the same result', 'if not is there any way to change the keyboard label for the enter key', 'at the moment the default label is return and i would like to have send since its a chat app', 'thanks a lot']"
How can I send a managed object to native function to use it?,"How can I send a managed object to native function to use it?
void managed_function()
{
  Object^ obj = gcnew Object();

  void* ptr = obj ??? // How to convert Managed object to void*?

  unmanaged_function(ptr);
}

// The parameter type should be void* and I can not change the type.
// This function is native but it uses managed object. Because type of ptr could not be 
// Object^ I called it ""Unmanaged Function"".
void unmanaged_function(void* ptr)
{
  Object^ obj = ptr ??? // How to convert void* to Managed object?

  obj->SomeManagedMethods();
}

",<.net><c++-cli><unmanaged><managed><mixed-mode>,7,".net,c++-cli,unmanaged,managed,mixed-mode",['how can i send a managed object to native function to use it'],"['how can i send a managed object to native function to use it', 'void managedfunction object obj gcnew object void ptr obj ', '', ' how to convert managed object to void', 'unmanagedfunctionptr the parameter type should be void and i can not change the type', ' this function is native but it uses managed object', 'because type of ptr could not be object i called it unmanaged function', 'void unmanagedfunctionvoid ptr object obj ptr ', '', ' how to convert void to managed object', 'objsomemanagedmethods ']"
Asp.Net Core 3 Identity - Custom Claims not present in JWT from browser,"Asp.Net Core 3.0
I am using the ASP.NET Core web application with Angular and Authentication (Individual User Accounts) template (from Visual Studio 2019).
My intention is to add some Custom Claims in the generated JWT and use them in browser.
In order to do that, I have extended the UserClaimsPrincipalFactory
public class MyCustomClaimsInjector : UserClaimsPrincipalFactory<ApplicationUser>
{
    public MyCustomClaimsFactory(UserManager<ApplicationUser> userManager, IOptions<IdentityOptions> optionsAccessor) : base(userManager, optionsAccessor)
    {
    }

    protected override async Task<ClaimsIdentity> GenerateClaimsAsync(ApplicationUser user)
    {
        var id = await base.GenerateClaimsAsync(user);
        id.AddClaim(new Claim(""my_claim1"", ""AdditionalClaim1""));
        id.AddClaim(new Claim(""my_claim2"", ""AdditionalClaim2""));
        return id;
    }
}

As well, I have registered the extension in the Startup.cs 
    public void ConfigureServices(IServiceCollection services)
    {
        services.AddDbContext<ApplicationDbContext>(options => options.UseSqlServer(Configuration.GetConnectionString(""DefaultConnection"")));

        services.AddDefaultIdentity<ApplicationUser>()
            .AddEntityFrameworkStores<ApplicationDbContext>()
            .AddClaimsPrincipalFactory<MyCustomClaimsFactory>();


        services.AddIdentityServer()
            .AddApiAuthorization<ApplicationUser, ApplicationDbContext>();

        services.AddAuthentication()
            .AddIdentityServerJwt();
        services.AddControllersWithViews();
        services.AddRazorPages();
        // In production, the Angular files will be served from this directory
        services.AddSpaStaticFiles(configuration =>
        {
            configuration.RootPath = ""ClientApp/dist"";
        });
    }

During Sign In phase, started from the SPA client, the debugger passes through MyCustomClaimsFactory and adds the claims to the ClaimsIdentity in the GenerateClaimsAsync method. 
But, I find strange why the JWT received in browser does not contain the Claims added by the MyCustomClaimsFactory. 
Is my expectation to see the Custom Claim in the JWT in browser OK ?
Can anyone suggest the direction to dig in... Why the claims isn't present in the JWT ? 
Decoded JWT is:

The SPA app:

",<c#><authentication><jwt><asp.net-core-identity><asp.net-core-3.0>,5,"c#,authentication,jwt,asp.net-core-identity,asp.net-core-3.0",['aspnet core 3 identity custom claims not present in jwt from browser'],"['aspnet core 30 i am using the aspnet core web application with angular and authentication individual user accounts template from visual studio 2019', 'my intention is to add some custom claims in the generated jwt and use them in browser', 'in order to do that i have extended the userclaimsprincipalfactory public class mycustomclaimsinjector userclaimsprincipalfactoryapplicationuser public mycustomclaimsfactoryusermanagerapplicationuser usermanager ioptionsidentityoptions optionsaccessor baseusermanager optionsaccessor protected override async taskclaimsidentity generateclaimsasyncapplicationuser user var id await basegenerateclaimsasyncuser idaddclaimnew claimmyclaim1 additionalclaim1 idaddclaimnew claimmyclaim2 additionalclaim2 return id as well i have registered the extension in the startupcs public void configureservicesiservicecollection services servicesadddbcontextapplicationdbcontextoptions optionsusesqlserverconfigurationgetconnectionstringdefaultconnection servicesadddefaultidentityapplicationuser addentityframeworkstoresapplicationdbcontext addclaimsprincipalfactorymycustomclaimsfactory servicesaddidentityserver addapiauthorizationapplicationuser applicationdbcontext servicesaddauthentication addidentityserverjwt servicesaddcontrollerswithviews servicesaddrazorpages in production the angular files will be served from this directory servicesaddspastaticfilesconfiguration configurationrootpath clientappdist during sign in phase started from the spa client the debugger passes through mycustomclaimsfactory and adds the claims to the claimsidentity in the generateclaimsasync method', 'but i find strange why the jwt received in browser does not contain the claims added by the mycustomclaimsfactory', 'is my expectation to see the custom claim in the jwt in browser ok ', 'can anyone suggest the direction to dig in why the claims isnt present in the jwt ', 'decoded jwt is the spa app']"
How to make framework in CocoaPods that has multiple targets?,"I write a framework and I like to divide framework to small separate submodules (targets). Apple provides a cool description for thing I want to achieve with CocoaPods:

Targets are the basic building blocks of a package. A target can define a module or a test suite.
  Targets can depend on other targets in this package, and on products in packages which this package depends on.

I could easily do it with Swift Package Manager:
    targets: [
        .target(name: ""Network""),
        .target(name: ""Service"", dependencies: [""Network""])
    ],

I could use import Network in a Service target and it's cool because they are separate modules, logic is clear.
How to achieve it in CocoaPods and Carthage (I write a framework, not the final application)?
What I've tried:
Subspec
I tried to use subspecs:
  s.subspec 'Service' do |ss|
    ss.dependency 'MyFramework/Network'
    ss.source_files = 'Sources/Service/**/*.swift'
  end

  s.subspec 'Network' do |ss|
    ss.source_files = 'Sources/Network/**/*.swift'
  end

It doesn't work as I want because CocoaPods just merges all files into one framework (just divides it to separate folders), so:

I receive namespace collisions.
Fatal error when I try to import Network inside Service because there is no Network target after pod install. So I can't use one that framework with Swift Package Manager. CocoaPods just merges everything to one target MyFramework as I mentioned before.

Separate repos/pods
It's the solution but it's very hard to maintain multiple separate git repositories and make separate commit and pushes. I want to keep everything in a one repo.
",<ios><swift><cocoapods><carthage><swift-package-manager>,18,"ios,swift,cocoapods,carthage,swift-package-manager",['how to make framework in cocoapods that has multiple targets'],"['i write a framework and i like to divide framework to small separate submodules targets', 'apple provides a cool description for thing i want to achieve with cocoapods targets are the basic building blocks of a package', 'a target can define a module or a test suite', 'targets can depend on other targets in this package and on products in packages which this package depends on', 'i could easily do it with swift package manager targets targetname network targetname service dependencies network i could use import network in a service target and its cool because they are separate modules logic is clear', 'how to achieve it in cocoapods and carthage i write a framework not the final application', 'what ive tried subspec i tried to use subspecs ssubspec service do ss ssdependency myframeworknetwork sssourcefiles sourcesserviceswift end ssubspec network do ss sssourcefiles sourcesnetworkswift end it doesnt work as i want because cocoapods just merges all files into one framework just divides it to separate folders so i receive namespace collisions', 'fatal error when i try to import network inside service because there is no network target after pod install', 'so i cant use one that framework with swift package manager', 'cocoapods just merges everything to one target myframework as i mentioned before', 'separate repospods its the solution but its very hard to maintain multiple separate git repositories and make separate commit and pushes', 'i want to keep everything in a one repo']"
Cropping with drawImage not working in Safari,"I'm working on some simple image manipulation functions with canvas.
The user uploads an image, is able to rotate and crop it and then clicks ok.
The image is then split in half with each half drawn mirrored to two canvas elements, like this:
Original
Mirrored
It all works great in Chrome, Firefox, IE and Android devices.
Safari won't play nice though. All the image manipulation works fine except the split function. It does draw to one of the canvas elements, but the other is just black. I've tried changing the drawImage code around, but I just can't get it to work.
Here's the function:
function splitImage(canvas, context, image, isLeftSide) {
  canvas.width = img.width;
  canvas.height = img.height;
  context.save();
  if(isLeftSide) {
    context.drawImage(
      image, 
      image.width / 2,
      0, 
      image.width, 
      image.height, 
      canvas.width / 2, 
      0, 
      canvas.width, 
      canvas.height
    );
    context.scale(-1, 1);
    context.drawImage(
      image, 
      image.width / 2, 
      0, 
      image.width, 
      image.height, 
      -canvas.width / 2, 
      0, 
      canvas.width, 
      canvas.height
    );
  } else {
    context.drawImage(
      image, 
      0, 
      0, 
      image.width / 2, 
      image.height, 
      0, 
      0, 
      canvas.width / 2, 
      canvas.height
    );
    context.scale(-1, 1);
    context.drawImage(
      image, 
      0, 
      0, 
      image.width / 2, 
      image.height, 
      -canvas.width, 
      0, 
      canvas.width / 2, 
      canvas.height
    );
  }
  context.restore();
  download(canvas);
}

To be exact, it's the drawImage operations inside the if(isLeftSide) that doesn't work in Safari.
Any ideas?
Edit:
It doesn't seem to work on iOS devices either.
I've read that Safari and iOS devices might run out of memory when working with large images.
To counteract this (and reduce some lag) I've added a resize function. The image is resized to a maximum of 800 px width and 800 px height if necessary, keeping the aspect ratio intact. This is done before any other image manipulation, but hasn't made any difference.
The resize function:
function resizeImage() {
  var size = 800;
  if(imgTemp.width > size && imgTemp.width >= imgTemp.height) {
    imgTemp.height = (imgTemp.height / imgTemp.width) * size;
    imgTemp.width = size;
  } else if (imgTemp.height > size && imgTemp.height > imgTemp.width) {
    imgTemp.width = (imgTemp.width / imgTemp.height) * size;
    imgTemp.height = size;
  }
}

",<javascript><jquery><canvas><safari><image-manipulation>,12,"javascript,jquery,canvas,safari,image-manipulation",['cropping with drawimage not working in safari'],"['im working on some simple image manipulation functions with canvas', 'the user uploads an image is able to rotate and crop it and then clicks ok the image is then split in half with each half drawn mirrored to two canvas elements like this original mirrored it all works great in chrome firefox ie and android devices', 'safari wont play nice though', 'all the image manipulation works fine except the split function', 'it does draw to one of the canvas elements but the other is just black', 'ive tried changing the drawimage code around but i just cant get it to work', 'heres the function function splitimagecanvas context image isleftside canvaswidth imgwidth canvasheight imgheight contextsave ifisleftside contextdrawimage image imagewidth 2 0 imagewidth imageheight canvaswidth 2 0 canvaswidth canvasheight contextscale1 1 contextdrawimage image imagewidth 2 0 imagewidth imageheight canvaswidth 2 0 canvaswidth canvasheight else contextdrawimage image 0 0 imagewidth 2 imageheight 0 0 canvaswidth 2 canvasheight contextscale1 1 contextdrawimage image 0 0 imagewidth 2 imageheight canvaswidth 0 canvaswidth 2 canvasheight contextrestore downloadcanvas to be exact its the drawimage operations inside the ifisleftside that doesnt work in safari', 'any ideas', 'edit it doesnt seem to work on ios devices either', 'ive read that safari and ios devices might run out of memory when working with large images', 'to counteract this and reduce some lag ive added a resize function', 'the image is resized to a maximum of 800 px width and 800 px height if necessary keeping the aspect ratio intact', 'this is done before any other image manipulation but hasnt made any difference', 'the resize function function resizeimage var size 800 ifimgtempwidth size imgtempwidth imgtempheight imgtempheight imgtempheight imgtempwidth size imgtempwidth size else if imgtempheight size imgtempheight imgtempwidth imgtempwidth imgtempwidth imgtempheight size imgtempheight size ']"
"UITextView alignment, caret goes left","I'm using a UITextView where I want the text to be centered. However, this doesn't work fully. When adding a new line at the end of another line that is not the last line, or pressing on an empty line, the caret positions itself to the left of the textview, and when you start typing it usually jumps to the center. But sometimes it stays left-aligned and the text itself gets left aligned as well.
Creating the UITextView and setting the alignment programmatically or via the storyboard does not seem to matter.
You can test it for yourself easily by adding a UITextView and setting the alignment to centered or right aligned, as that seems to have the same problem.
A gif to illustrate the problem: https://i.stack.imgur.com/aZxrK.gif
",<ios><iphone><textview><alignment><uitextview>,7,"ios,iphone,textview,alignment,uitextview",['uitextview alignment caret goes left'],"['im using a uitextview where i want the text to be centered', 'however this doesnt work fully', 'when adding a new line at the end of another line that is not the last line or pressing on an empty line the caret positions itself to the left of the textview and when you start typing it usually jumps to the center', 'but sometimes it stays leftaligned and the text itself gets left aligned as well', 'creating the uitextview and setting the alignment programmatically or via the storyboard does not seem to matter', 'you can test it for yourself easily by adding a uitextview and setting the alignment to centered or right aligned as that seems to have the same problem', 'a gif to illustrate the problem']"
"Is {1, 2} a value? If yes, what is its type? If no, why can it be assigned to an initializer list?","#include <initializer_list>

using namespace std;

template<class T>
void f(initializer_list<T>)
{}

int main()
{
    typeid(1);           // OK
    typeid(int);         // OK
    typeid(decltype(1)); // OK

    f({1, 2}); // OK

    typeid({1, 2});           // error
    decltype({1, 2}) v;       // error
    typeid(decltype({1, 2})); // error
}

Is {1, 2} a value? 
If yes, why is typeid({1, 2}); not legal?
If no, why can it be assigned to an initializer_list object?
",<c++><c++11><types><type-conversion><initializer-list>,6,"c++,c++11,types,type-conversion,initializer-list","['is 1 2 a value', 'if yes what is its type', 'if no why can it be assigned to an initializer list']","['include initializerlist using namespace std templateclass t void finitializerlistt int main typeid1 ok typeidint ok typeiddecltype1 ok f1 2 ok typeid1 2 error decltype1 2 v error typeiddecltype1 2 error is 1 2 a value', 'if yes why is typeid1 2 not legal', 'if no why can it be assigned to an initializerlist object']"
Unit testing EF Core using in-memory database with an eager-loaded function,"I am writing unit tests for my my Web API and cannot get the test to pass except by  removing the include (eager-loading from the method). I am using the in-memory database to provide the dbcontext and can't figure out why it is returning no data. Thanks in advance for any help or constructive criticism
This is the method I am trying to test.
Note: it passes the test if I comment out the .include statements.
    public async Task<LibraryAsset> GetAsset(int assetId)
    {
        var asset = await _context.LibraryAssets
            .Include(p => p.Photo)
            .Include(p => p.Category)
            .Include(a => a.AssetType)
            .Include(s => s.Status)
            .Include(s => s.Author)
            .FirstOrDefaultAsync(x => x.Id == assetId);

        return asset;
    }

This is the base DbContext using the inMemory DB:
    public DataContext GetDbContext()
    {
        var builder = new DbContextOptionsBuilder<DataContext>();

        if (useSqlite)
        {
            // Use Sqlite DB.
            builder.UseSqlite(""DataSource=:memory:"", x => { });
        }
        else
        {
            // Use In-Memory DB.
            builder.UseInMemoryDatabase(Guid.NewGuid().ToString());
        }

        var DataContext = new DataContext(builder.Options);

        if (useSqlite)
        {
            // SQLite needs to open connection to the DB.
            // Not required for in-memory-database and MS SQL.
            DataContext.Database.OpenConnection();
        }

        DataContext.Database.EnsureCreated();

        return DataContext;
    }

This is the test:
    [Fact]
    public async void GetAssetById_ExistingAsset_ReturnAsset()
    {
        using (var context = GetDbContext())
        {
            ILogger<LibraryAssetService> logger = new 
            NullLogger<LibraryAssetService>();

            var service = new LibraryAssetService(context, _logger);

            var asset = new LibraryAsset
            {
                Id = 40,
                NumberOfCopies = 20,
                Title = """",
                Year = 1992,
                Status = new Status { Id = 1 },
                AssetType = new AssetType { Id = 1 },
                Author = new Author { Id = 1 },
                Category = new Category { Id = 2 },
                Photo = new AssetPhoto { Id = 1 }
            };

            context.LibraryAssets.Attach(asset);

            context.Add(asset);
            context.SaveChanges();

            var actual = await service.GetAsset(40);
            Assert.Equal(40, actual.Id);
        }
    }

This is my first time writing unit tests and I am basically learning as I go. Please feel free to point out any other mistakes that you may have noticed as well.
",<c#><unit-testing><asp.net-core><entity-framework-core><xunit>,6,"c#,unit-testing,asp.net-core,entity-framework-core,xunit",['unit testing ef core using inmemory database with an eagerloaded function'],"['i am writing unit tests for my my web api and cannot get the test to pass except by removing the include eagerloading from the method', 'i am using the inmemory database to provide the dbcontext and cant figure out why it is returning no data', 'thanks in advance for any help or constructive criticism this is the method i am trying to test', 'note it passes the test if i comment out the include statements', 'public async tasklibraryasset getassetint assetid var asset await contextlibraryassets includep pphoto includep pcategory includea aassettype includes sstatus includes sauthor firstordefaultasyncx xid assetid return asset this is the base dbcontext using the inmemory db public datacontext getdbcontext var builder new dbcontextoptionsbuilderdatacontext if usesqlite use sqlite db', 'builderusesqlitedatasourcememory x else use inmemory db', 'builderuseinmemorydatabaseguidnewguidtostring var datacontext new datacontextbuilderoptions if usesqlite sqlite needs to open connection to the db', ' not required for inmemorydatabase and ms sql', 'datacontextdatabaseopenconnection datacontextdatabaseensurecreated return datacontext this is the test fact public async void getassetbyidexistingassetreturnasset using var context getdbcontext iloggerlibraryassetservice logger new nullloggerlibraryassetservice var service new libraryassetservicecontext logger var asset new libraryasset id 40 numberofcopies 20 title year 1992 status new status id 1 assettype new assettype id 1 author new author id 1 category new category id 2 photo new assetphoto id 1 contextlibraryassetsattachasset contextaddasset contextsavechanges var actual await servicegetasset40 assertequal40 actualid this is my first time writing unit tests and i am basically learning as i go', 'please feel free to point out any other mistakes that you may have noticed as well']"
Return lazy iterator that depends on data allocated within the function,"I am new to Rust and reading The Rust Programming Language, and in the Error Handling section there is a ""case study"" describing a program to read data from a CSV file using the csv and rustc-serialize libraries (using getopts for argument parsing).
The author writes a function search that steps through the rows of the csv file using a csv::Reader object and collect those entries whose 'city' field match a specified value into a vector and returns it. I've taken a slightly different approach than the author, but this should not affect my question. My (working) function looks like this:
extern crate csv;
extern crate rustc_serialize;

use std::path::Path;
use std::fs::File;

fn search<P>(data_path: P, city: &str) -> Vec<DataRow>
    where P: AsRef<Path>
{
    let file = File::open(data_path).expect(""Opening file failed!"");
    let mut reader = csv::Reader::from_reader(file).has_headers(true);

    reader.decode()
          .map(|row| row.expect(""Failed decoding row""))
          .filter(|row: &DataRow| row.city == city)
          .collect()
}

where the DataRow type is just a record,
#[derive(Debug, RustcDecodable)]
struct DataRow {
    country: String,
    city: String,
    accent_city: String,
    region: String,
    population: Option<u64>,
    latitude: Option<f64>,
    longitude: Option<f64>
}

Now, the author poses, as the dreaded ""exercise to the reader"", the problem of modifying this function to return an iterator instead of a vector (eliminating the call to collect). My question is: How can this be done at all, and what are the most concise and idiomatic ways of doing it?

A simple attempt that i think gets the type signature right is
fn search_iter<'a,P>(data_path: P, city: &'a str)
    -> Box<Iterator<Item=DataRow> + 'a>
    where P: AsRef<Path>
{
    let file = File::open(data_path).expect(""Opening file failed!"");
    let mut reader = csv::Reader::from_reader(file).has_headers(true);

    Box::new(reader.decode()
                   .map(|row| row.expect(""Failed decoding row""))
                   .filter(|row: &DataRow| row.city == city))
}

I return a trait object of type Box<Iterator<Item=DataRow> + 'a> so as not to have to expose the internal Filter type, and where the lifetime 'a is introduced just to avoid having to make a local clone of city. But this fails to compile because reader does not live long enough; it's allocated on the stack and so is deallocated when the function returns.
I guess this means that reader has to be allocated on the heap (i.e. boxed) from the beginning, or somehow moved off the stack before the function ends. If I were returning a closure, this is exactly the problem that would be solved by making it a move closure. But I don't know how to do something similar when I'm not returning a function. I've tried defining a custom iterator type containing the needed data, but I couldn't get it to work, and it kept getting uglier and more contrived (don't make too much of this code, I'm only including it to show the general direction of my attempts):
fn search_iter<'a,P>(data_path: P, city: &'a str)
    -> Box<Iterator<Item=DataRow> + 'a>
    where P: AsRef<Path>
{
    struct ResultIter<'a> {
        reader: csv::Reader<File>,
        wrapped_iterator: Option<Box<Iterator<Item=DataRow> + 'a>>
    }

    impl<'a> Iterator for ResultIter<'a> {
        type Item = DataRow;

        fn next(&mut self) -> Option<DataRow>
        { self.wrapped_iterator.unwrap().next() }
    }

    let file = File::open(data_path).expect(""Opening file failed!"");

    // Incrementally initialise
    let mut result_iter = ResultIter {
        reader: csv::Reader::from_reader(file).has_headers(true),
        wrapped_iterator: None // Uninitialised
    };
    result_iter.wrapped_iterator =
        Some(Box::new(result_iter.reader
                                 .decode()
                                 .map(|row| row.expect(""Failed decoding row""))
                                 .filter(|&row: &DataRow| row.city == city)));

    Box::new(result_iter)
}

This question seems to concern the same problem, but the author of the answer solves it by making the concerned data static, which I don't think is an alternative for this question.
I am using Rust 1.10.0, the current stable version from the Arch Linux package rust.
",<iterator><rust><heap-memory><allocation><lifetime>,11,"iterator,rust,heap-memory,allocation,lifetime",['return lazy iterator that depends on data allocated within the function'],"['i am new to rust and reading the rust programming language and in the error handling section there is a case study describing a program to read data from a csv file using the csv and rustcserialize libraries using getopts for argument parsing', 'the author writes a function search that steps through the rows of the csv file using a csvreader object and collect those entries whose city field match a specified value into a vector and returns it', 'ive taken a slightly different approach than the author but this should not affect my question', 'my working function looks like this extern crate csv extern crate rustcserialize use stdpathpath use stdfsfile fn searchpdatapath p city str vecdatarow where p asrefpath let file fileopendatapathexpectopening file failed', ' let mut reader csvreaderfromreaderfilehasheaderstrue readerdecode maprow rowexpectfailed decoding row filterrow datarow rowcity city collect where the datarow type is just a record derivedebug rustcdecodable struct datarow country string city string accentcity string region string population optionu64 latitude optionf64 longitude optionf64 now the author poses as the dreaded exercise to the reader the problem of modifying this function to return an iterator instead of a vector eliminating the call to collect', 'my question is how can this be done at all and what are the most concise and idiomatic ways of doing it', 'a simple attempt that i think gets the type signature right is fn searchiterapdatapath p city a str boxiteratoritemdatarow a where p asrefpath let file fileopendatapathexpectopening file failed', ' let mut reader csvreaderfromreaderfilehasheaderstrue boxnewreaderdecode maprow rowexpectfailed decoding row filterrow datarow rowcity city i return a trait object of type boxiteratoritemdatarow a so as not to have to expose the internal filter type and where the lifetime a is introduced just to avoid having to make a local clone of city', 'but this fails to compile because reader does not live long enough its allocated on the stack and so is deallocated when the function returns', 'i guess this means that reader has to be allocated on the heap ie', 'boxed from the beginning or somehow moved off the stack before the function ends', 'if i were returning a closure this is exactly the problem that would be solved by making it a move closure', 'but i dont know how to do something similar when im not returning a function', 'ive tried defining a custom iterator type containing the needed data but i couldnt get it to work and it kept getting uglier and more contrived dont make too much of this code im only including it to show the general direction of my attempts fn searchiterapdatapath p city a str boxiteratoritemdatarow a where p asrefpath struct resultitera reader csvreaderfile wrappediterator optionboxiteratoritemdatarow a impla iterator for resultitera type item datarow fn nextmut self optiondatarow selfwrappediteratorunwrapnext let file fileopendatapathexpectopening file failed', ' incrementally initialise let mut resultiter resultiter reader csvreaderfromreaderfilehasheaderstrue wrappediterator none uninitialised resultiterwrappediterator someboxnewresultiterreader decode maprow rowexpectfailed decoding row filterrow datarow rowcity city boxnewresultiter this question seems to concern the same problem but the author of the answer solves it by making the concerned data static which i dont think is an alternative for this question', 'i am using rust 1100 the current stable version from the arch linux package rust']"
On Debian 11 (Bullseye) /proc/self/cgroup inside a docker container does not show docker infos,"I recently updated from Debian 10 (Buster) to 11 (Bullseye) and since then my Jenkins setup inside Docker is not working anymore, as Jenkins tries to find out if it is running in a docker container by checking /proc/self/cgroup.
Normally /proc/self/cgroup inside a docker container would look something like this:
12:rdma:/
11:perf_event:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
10:freezer:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
9:memory:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
8:cpuset:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
7:devices:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
6:net_cls,net_prio:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
5:hugetlb:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
4:pids:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
3:cpu,cpuacct:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
2:blkio:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
1:name=systemd:/docker/a2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81
0::/system.slice/containerd.service

but since I updated to Debian 11 it looks pretty small:
0::/

As Jenkins is not recognizing anymore that it is running inside a docker container itself, it starts other build containers with the wrong arguments.
Question
The simple question would be: Is this a bug?
But the real question might be what am I doing wrong? I cannot find anyone else with this problem, so it might be a misconfiguration or anything similar.
I reinstalled Docker, removed any configuration and I even tried downgrading Docker to 20.10.6 as this is the last version I know was working under Debian 10, but none of that changed anything.
I don't have a clue on how to approach this problem any further. It already took me a full day to find out that the problem was not Jenkins itself (nearly got crazy reading Jenkins logs). I am hitting bedrock right now, so any help and any input is really appreciated!

Jenkins stuff
For those interested in the Jenkins part, here Jenkins checks if it is running inside a container:
https://github.com/jenkinsci/docker-workflow-plugin/blob/b174d46226ef1095903f2e789355a3b216b46dda/src/main/java/org/jenkinsci/plugins/docker/workflow/client/DockerClient.java#L347
Jenkins thinking it is not running inside a container will log something like this:
Jenkins does not seem to be running inside a container
$ docker run -t -d -u 0:0
-w /var/jenkins_home/workspace/myrepo_master
-v /var/jenkins_home/workspace/myrepo_master:/var/jenkins_home/workspace/myrepo_master:rw,z
-v /var/jenkins_home/workspace/myrepo_master@tmp:/var/jenkins_home/workspace/myrepo_master@tmp:rw,z
-e ******** ... my-awesome-build-container cat

And thus mounting /var/jenkins_home from the host system, where Jenkins has no access to from inside its container.
While the log output on Debian 10 (and Ubuntu 20.04) looks something like this:
Jenkins seems to be running inside container 7814083762a1bed51dec2f468c6ee07c978a0b6377e347c3ed7dc23393feac11
$ docker run -t -d -u 0:0
-w /var/jenkins_home/workspace/myrepo_master
--volumes-from 7814083762a1bed51dec2f468c6ee07c978a0b6377e347c3ed7dc23393feac11
-e ******** ... my-awesome-build-container cat

and starting the build container with the correct volume using --volumes-from.
Edit: The Jenkins plugin is now fixed since version 528.v7c193a_0b_e67c by PR#280: https://github.com/jenkinsci/docker-workflow-plugin/pull/280
",<linux><docker><jenkins><debian><cgroups>,8,"linux,docker,jenkins,debian,cgroups",['on debian 11 bullseye procselfcgroup inside a docker container does not show docker infos'],"['i recently updated from debian 10 buster to 11 bullseye and since then my jenkins setup inside docker is not working anymore as jenkins tries to find out if it is running in a docker container by checking procselfcgroup', 'normally procselfcgroup inside a docker container would look something like this 12rdma 11perfeventdockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 10freezerdockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 9memorydockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 8cpusetdockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 7devicesdockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 6netclsnetpriodockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 5hugetlbdockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 4pidsdockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 3cpucpuacctdockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 2blkiodockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 1namesystemddockera2ffe0e97ac22657a2a023ad628e9df837c38a03b1ebc904d3f6d644eb1a1a81 0systemslicecontainerdservice but since i updated to debian 11 it looks pretty small 0 as jenkins is not recognizing anymore that it is running inside a docker container itself it starts other build containers with the wrong arguments', 'question the simple question would be is this a bug', 'but the real question might be what am i doing wrong', 'i cannot find anyone else with this problem so it might be a misconfiguration or anything similar', 'i reinstalled docker removed any configuration and i even tried downgrading docker to 20106 as this is the last version i know was working under debian 10 but none of that changed anything', 'i dont have a clue on how to approach this problem any further', 'it already took me a full day to find out that the problem was not jenkins itself nearly got crazy reading jenkins logs', 'i am hitting bedrock right now so any help and any input is really appreciated', 'jenkins stuff for those interested in the jenkins part here jenkins checks if it is running inside a container jenkins thinking it is not running inside a container will log something like this jenkins does not seem to be running inside a container docker run t d u 00 w varjenkinshomeworkspacemyrepomaster v varjenkinshomeworkspacemyrepomastervarjenkinshomeworkspacemyrepomasterrwz v varjenkinshomeworkspacemyrepomastertmpvarjenkinshomeworkspacemyrepomastertmprwz e myawesomebuildcontainer cat and thus mounting varjenkinshome from the host system where jenkins has no access to from inside its container', 'while the log output on debian 10 and ubuntu 2004 looks something like this jenkins seems to be running inside container 7814083762a1bed51dec2f468c6ee07c978a0b6377e347c3ed7dc23393feac11 docker run t d u 00 w varjenkinshomeworkspacemyrepomaster volumesfrom 7814083762a1bed51dec2f468c6ee07c978a0b6377e347c3ed7dc23393feac11 e myawesomebuildcontainer cat and starting the build container with the correct volume using volumesfrom', 'edit the jenkins plugin is now fixed since version 528v7c193a0be67c by pr280']"
How to exclude certain requireJS files from uglifying/optimizing,"I have a working requirejs project that is using grunt for building and deployment. If using no optimization at all, the build is working without problems and I get one big js file to deploy it on production.
The problem I have is, that I have some external frameworks (like angularJS) where I already have a minimized/optimized version of it and don't want to optimize it again. 
Currently without optimization I include the minified version of this framework via a seperate path config in my gruntfile. Whereas in my normal main.js I have the non-minified version for development.
Now I want to use the optimizer to optimize my own code, but to NOT optimize the external frameworks. But the external frameworks should be included in the resulting big javascript file. Basically I want to tell the optimizer that he should use the original file in some cases. 
Can I do it something like this? 
I only have found a global exclude option, so that some modules are not included in the resulting optimized js at all. 
This is my grunt configuration:
requirejs: {
            compile: {
                options: {
                    baseUrl: ""<%= pkg.folders.jsSource %>"",
                    name: ""../external-libs/almond-0.1.1"",
                    include: ""main"",
                    mainConfigFile: ""<%= pkg.folders.jsSource %>/main.js"",
                    out: ""<%= pkg.folders.build + pkg.name + '-' + pkg.version %>/js/main.js"",
                    //logLevel: 0,
                    optimize: ""uglify2"",
                    //optimize: ""none"",
                    paths: {
                        'angular':'../external-libs/min/angular-1.0.4',
                        'jquery':'../external-libs/min/jquery-1.7.2',
                        'jquery.mobile':'../external-libs/min/jquery.mobile-1.2.0',
                        'adapter': '../external-libs/min/jquery-mobile-angular-adapter-1.2.0',
                        'moment': '../external-libs/moment-1.6.2.min',
                        'iscroll': '../external-libs/min/iscroll-4.2.5',
                        'iscrollview': '../external-libs/min/jquery.mobile.iscrollview-1.2.6',
                        'add2Home': '../external-libs/min/add2home',
                        'config/config': ""config/<%=configDatei%>""
                    }
                }
            }
        },

And this is the relevant part of the main.js: 
require.config({
        paths:{
            'angular':'../external-libs/angular-1.0.4',
            'jquery':'../external-libs/jquery-1.7.2',
            'jquery.mobile':'../external-libs/jquery.mobile-1.2.0',
            'adapter': '../external-libs/jquery-mobile-angular-adapter-1.2.0',
            'moment': '../external-libs/moment-1.6.2.min',
            'iscroll': '../external-libs/iscroll-4.2.5',
            'iscrollview': '../external-libs/jquery.mobile.iscrollview-1.2.6',
            'add2Home': '../external-libs/add2home'
        },
        shim:{
            'angular':{ deps:['jquery'], exports:'angular' },
            'iscroll':{ deps:['jquery'], exports:'iscroll' },
            'iscrollview':{ deps:['jquery.mobile', 'iscroll'], exports:'iscrollview' }
        }
    });

Thanks for any help. 
",<requirejs><require><gruntjs><uglifyjs><uglifyjs2>,27,"requirejs,require,gruntjs,uglifyjs,uglifyjs2",['how to exclude certain requirejs files from uglifyingoptimizing'],"['i have a working requirejs project that is using grunt for building and deployment', 'if using no optimization at all the build is working without problems and i get one big js file to deploy it on production', 'the problem i have is that i have some external frameworks like angularjs where i already have a minimizedoptimized version of it and dont want to optimize it again', 'currently without optimization i include the minified version of this framework via a seperate path config in my gruntfile', 'whereas in my normal mainjs i have the nonminified version for development', 'now i want to use the optimizer to optimize my own code but to not optimize the external frameworks', 'but the external frameworks should be included in the resulting big javascript file', 'basically i want to tell the optimizer that he should use the original file in some cases', 'can i do it something like this', 'i only have found a global exclude option so that some modules are not included in the resulting optimized js at all', 'this is my grunt configuration requirejs compile options baseurl pkgfoldersjssource name externallibsalmond011 include main mainconfigfile pkgfoldersjssource mainjs out pkgfoldersbuild pkgname pkgversion jsmainjs loglevel 0 optimize uglify2 optimize none paths angularexternallibsminangular104 jqueryexternallibsminjquery172 jquerymobileexternallibsminjquerymobile120 adapter externallibsminjquerymobileangularadapter120 moment externallibsmoment162min iscroll externallibsminiscroll425 iscrollview externallibsminjquerymobileiscrollview126 add2home externallibsminadd2home configconfig configconfigdatei and this is the relevant part of the mainjs requireconfig paths angularexternallibsangular104 jqueryexternallibsjquery172 jquerymobileexternallibsjquerymobile120 adapter externallibsjquerymobileangularadapter120 moment externallibsmoment162min iscroll externallibsiscroll425 iscrollview externallibsjquerymobileiscrollview126 add2home externallibsadd2home shim angular depsjquery exportsangular iscroll depsjquery exportsiscroll iscrollview depsjquerymobile iscroll exportsiscrollview thanks for any help']"
"jQuery widget has no method ""extend""","I'm working on a Wordpress site which contains a number of jQuery and jQuery UI-dependent plugins. Everything seemed to be working fine, but when we moved over the entire site to the new domain name, I started seeing the following error in the Chrome console:
Uncaught TypeError: Object function (b,c,d){var e=b.split(""."")[0],f;b=b.split(""."")[1],f=e+""-""+b,d||(d=c,c=a.Widget),a.expr["":""][f]=function(c){return!!a.data(c,b)},a[e]=a[e]||{},a[e][b]=function(a,b){arguments.length&&this._createWidget(a,b)};var g=new c;g.options=a.extend(!0,{},g.options),a[e][b].prototype=a.extend(!0,g,{namespace:e,widgetName:b,widgetEventPrefix:a[e][b].prototype.widgetEventPrefix||b,widgetBaseClass:f},d),a.widget.bridge(b,a[e][b])} has no method 'extend'
Here is the line in jQuery UI 1.9.3 that seems to be causing this:
this.options = $.widget.extend( {},
this.options,
this._getCreateOptions(),
options );

I can't seem to get past this at all, no matter what I tried to do. I'm using the proper method (or so I've read) to add scripts by using wp_enqueue_script() and setting jquery as a dependency of jquery-ui, and looking at the HTML, jQuery is indeed loading before jQuery UI.
If anyone has any idea of what might be happening I would really appreciate it, this is driving me nuts.
",<javascript><jquery><wordpress><jquery-ui><typeerror>,8,"javascript,jquery,wordpress,jquery-ui,typeerror",['jquery widget has no method extend'],"['im working on a wordpress site which contains a number of jquery and jquery uidependent plugins', 'everything seemed to be working fine but when we moved over the entire site to the new domain name i started seeing the following error in the chrome console uncaught typeerror object function bcdvar ebsplit0fbbsplit1febddccawidgetaexprffunctioncreturn', 'adatacbaeaeaebfunctionabargumentslengththiscreatewidgetabvar gnew cgoptionsaextend0goptionsaebprototypeaextend0gnamespaceewidgetnamebwidgeteventprefixaebprototypewidgeteventprefixbwidgetbaseclassfdawidgetbridgebaeb has no method extend here is the line in jquery ui 193 that seems to be causing this thisoptions widgetextend thisoptions thisgetcreateoptions options i cant seem to get past this at all no matter what i tried to do', 'im using the proper method or so ive read to add scripts by using wpenqueuescript and setting jquery as a dependency of jqueryui and looking at the html jquery is indeed loading before jquery ui', 'if anyone has any idea of what might be happening i would really appreciate it this is driving me nuts']"
How to unit test Promise catch() method behavior with async/await in Jest?,"Say I have this simple React component:
class Greeting extends React.Component {
    constructor() {
        fetch(""https://api.domain.com/getName"")
            .then((response) => {
                return response.text();
            })
            .then((name) => {
                this.setState({
                    name: name
                });
            })
            .catch(() => {
                this.setState({
                    name: ""<unknown>""
                });
            });
    }

    render() {
        return <h1>Hello, {this.state.name}</h1>;
    }
}

Given the answers below and bit more of research on the subject, I've come up with this final solution to test the resolve() case:
test.only(""greeting name is 'John Doe'"", async () => {
    const fetchPromise = Promise.resolve({
        text: () => Promise.resolve(""John Doe"")
    });

    global.fetch = () => fetchPromise;

    const app = await shallow(<Application />);

    expect(app.state(""name"")).toEqual(""John Doe"");
});

Which is working fine. My problem is now testing the catch() case. The following didn't work as I expected it to work:
test.only(""greeting name is 'John Doe'"", async () => {
    const fetchPromise = Promise.reject(undefined);

    global.fetch = () => fetchPromise;

    const app = await shallow(<Application />);

    expect(app.state(""name"")).toEqual(""<unknown>"");
});

The assertion fails, name is empty:
expect(received).toEqual(expected)

Expected value to equal:
    ""<unknown>""
Received:
    """"

    at tests/components/Application.spec.tsx:51:53
    at process._tickCallback (internal/process/next_tick.js:103:7)

What am I missing?
",<reactjs><unit-testing><async-await><jestjs><es6-promise>,9,"reactjs,unit-testing,async-await,jestjs,es6-promise",['how to unit test promise catch method behavior with asyncawait in jest'],"['say i have this simple react component class greeting extends reactcomponent constructor fetch thenresponse return responsetext thenname thissetstate name name catch thissetstate name unknown render return h1hello thisstatenameh1 given the answers below and bit more of research on the subject ive come up with this final solution to test the resolve case testonlygreeting name is john doe async const fetchpromise promiseresolve text promiseresolvejohn doe globalfetch fetchpromise const app await shallowapplication expectappstatenametoequaljohn doe which is working fine', 'my problem is now testing the catch case', 'the following didnt work as i expected it to work testonlygreeting name is john doe async const fetchpromise promiserejectundefined globalfetch fetchpromise const app await shallowapplication expectappstatenametoequalunknown the assertion fails name is empty expectreceivedtoequalexpected expected value to equal unknown received at testscomponentsapplicationspectsx5153 at processtickcallback internalprocessnexttickjs1037 what am i missing']"
ASP.NET aspxerrorpath in URL,"I have a site where I use CustomErrors in the web.config to specify a custom error page, and that's working just fine.  The custom 404 page is also specified in the IIS configuration (because if it's not, I don't get my custom 404 page).
But I have some logic that kicks in if a user gets a 404 that looks at their requested URL and make a navigation suggestion, if appropriate.  This logic relies on the aspxerrorpath value.  On my development PC, the aspxerrorpath is correctly appended to the URL, like so:
http://localhost:3092/FileNotFound.aspx?aspxerrorpath=/badpage.aspx, but on my test site, there's no aspxerrorpath appended to the URL, so all of my custom logic is bypassed and my suggestions don't work.  I'm not sure if this is an IIS config issue or something else.  The web server is Windows Server 2008 with IIS 7.
Any thoughts?
Many Thanks.
",<.net><asp.net><iis><.net-3.5><iis-7>,17,".net,asp.net,iis,.net-3.5,iis-7",['aspnet aspxerrorpath in url'],"['i have a site where i use customerrors in the webconfig to specify a custom error page and thats working just fine', 'the custom 404 page is also specified in the iis configuration because if its not i dont get my custom 404 page', 'but i have some logic that kicks in if a user gets a 404 that looks at their requested url and make a navigation suggestion if appropriate', 'this logic relies on the aspxerrorpath value', 'on my development pc the aspxerrorpath is correctly appended to the url like so but on my test site theres no aspxerrorpath appended to the url so all of my custom logic is bypassed and my suggestions dont work', 'im not sure if this is an iis config issue or something else', 'the web server is windows server 2008 with iis 7 any thoughts', 'many thanks']"
Is there an upside down caret character?,"I have to maintain a large number of classic ASP pages, many of which have tabular data with no sort capabilities at all. Whatever order the original developer used in the database query is what you're stuck with.
I want to to tack on some basic sorting to a bunch of these pages, and I'm doing it all client side with javascript. I already have the basic script done to sort a given table on a given column in a given direction, and it works well as long as the table is limited by certain conventions we follow here.
What I want to do for the UI is just indicate sort direction with the caret character ( ^ ) and ... what?  Is there a special character that is the direct opposite of a caret?  The letter v won't quite cut it.  Alternatively, is there another character pairing I can use?
",<html><sorting><user-interface><character-encoding><character>,335,"html,sorting,user-interface,character-encoding,character",['is there an upside down caret character'],"['i have to maintain a large number of classic asp pages many of which have tabular data with no sort capabilities at all', 'whatever order the original developer used in the database query is what youre stuck with', 'i want to to tack on some basic sorting to a bunch of these pages and im doing it all client side with javascript', 'i already have the basic script done to sort a given table on a given column in a given direction and it works well as long as the table is limited by certain conventions we follow here', 'what i want to do for the ui is just indicate sort direction with the caret character and what', 'is there a special character that is the direct opposite of a caret', 'the letter v wont quite cut it', 'alternatively is there another character pairing i can use']"
Android Studio layout previews for Listview + Gridview,"Is there a way to get Android Studio's layout preview screen to populate a GridView or ListView with placeholder views of the actual runtime layout? 
In other words, I don't want to see a grid of ""Item 1/ Sub Item 1"" views, I want to be able to set @layout/foo somewhere and have it show up in there.
",<android><android-layout><listview><gridview><android-studio>,18,"android,android-layout,listview,gridview,android-studio",['android studio layout previews for listview gridview'],"['is there a way to get android studios layout preview screen to populate a gridview or listview with placeholder views of the actual runtime layout', 'in other words i dont want to see a grid of item 1 sub item 1 views i want to be able to set layoutfoo somewhere and have it show up in there']"
Run php function on button click,"I want to run a php function on button click. for eg :
<input type=""button"" name=""test"" id=""test"" value=""RUN""  onclick=""<?php echo testfun(); ?>"" /><br/>

<?php

function testfun()
{
   echo ""Your test function on button click is working"";
}

?>

My question is that when I do this I don't get the expected output I was looking for. Please give me the best solution for this to run a php function on button click whether it is a simple button or submit.
",<php><function><button><onclick><submit-button>,15,"php,function,button,onclick,submit-button",['run php function on button click'],"['i want to run a php function on button click', 'for eg input typebutton nametest idtest valuerun onclickphp echo testfun br php function testfun echo your test function on button click is working my question is that when i do this i dont get the expected output i was looking for', 'please give me the best solution for this to run a php function on button click whether it is a simple button or submit']"
Can't Truncate Table Befor Seeding,"I want to truncate my user table befor seed.i do like this :
DatabaseSeeder.php :
 <?php

 use Illuminate\Database\Seeder;
 use Illuminate\Support\Facades\DB;

 class DatabaseSeeder extends Seeder
 {
     public function run()
     {
         App\User::truncate();

         factory(App\User::class,1)->create();
     }
 }

Then run php artisan db:seed and have error:
In Connection.php line 664:

  SQLSTATE[42000]: Syntax error or access violation: 1701 Cannot truncate a table referenced in a foreign key constra
  int (`mr_musicer`.`dislikes`, CONSTRAINT `dislikes_user_id_foreign` FOREIGN KEY (`user_id`) REFERENCES `mr_musicer`
  .`users` (`id`)) (SQL: truncate `users`)


In Connection.php line 458:

  SQLSTATE[42000]: Syntax error or access violation: 1701 Cannot truncate a table referenced in a foreign key constra
  int (`mr_musicer`.`dislikes`, CONSTRAINT `dislikes_user_id_foreign` FOREIGN KEY (`user_id`) REFERENCES `mr_musicer`
  .`users` (`id`))

I want to now why i can't truncate my user table!
",<php><laravel><laravel-5><eloquent><lumen>,8,"php,laravel,laravel-5,eloquent,lumen",['cant truncate table befor seeding'],['i want to truncate my user table befor seedi do like this databaseseederphp php use illuminatedatabaseseeder use illuminatesupportfacadesdb class databaseseeder extends seeder public function run appusertruncate factoryappuserclass1create then run php artisan dbseed and have error in connectionphp line 664 sqlstate42000 syntax error or access violation 1701 cannot truncate a table referenced in a foreign key constra int mrmusicerdislikes constraint dislikesuseridforeign foreign key userid references mrmusicer users id sql truncate users in connectionphp line 458 sqlstate42000 syntax error or access violation 1701 cannot truncate a table referenced in a foreign key constra int mrmusicerdislikes constraint dislikesuseridforeign foreign key userid references mrmusicer users id i want to now why i cant truncate my user table']
How can i solve ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1` when using Huggingface's TrainArguments?,"I'm using the transformers library in Google colab, and
When i am using TrainingArguments from transformers library i'm getting Import error with this  code:
from transformers import TrainingArguments

training_args = TrainingArguments(
    output_dir = ""/content/our-model"",
    learning_rate=2e-5,
    per_device_train_batch_size= 64,
    per_device_eval_batch_size = 16,
    num_train_epochs = 2,
    weight_decay = 0.01,
    evaluation_strategy = ""epoch"",
    save_strategy = ""epoch"",
    load_best_model_at_end = True,
    push_to_hub = False
)

This is the error i'm getting:
<ipython-input-28-0518ea5ff407> in <cell line: 2>()
      1 from transformers import TrainingArguments
----> 2 training_args = TrainingArguments(
      3     output_dir = ""/content/our-model"",
      4     learning_rate=2e-5,
      5     per_device_train_batch_size= 64,

4 frames
/usr/local/lib/python3.10/dist-packages/transformers/training_args.py in _setup_devices(self)
   1670         if not is_sagemaker_mp_enabled():
   1671             if not is_accelerate_available(min_version=""0.20.1""):
-> 1672                 raise ImportError(
   1673                     ""Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U`""
   1674                 )

ImportError: Using the `Trainer` with `PyTorch` requires `accelerate>=0.20.1`: Please run `pip install transformers[torch]` or `pip install accelerate -U 

I already tried pip install for 0.20.1 version of accelerate and pip install transformers[torch]
and both didn't worked.
",<python><nlp><importerror><huggingface-transformers><huggingface>,12,"python,nlp,importerror,huggingface-transformers,huggingface",['how can i solve importerror using the trainer with pytorch requires accelerate0201 when using huggingfaces trainarguments'],['im using the transformers library in google colab and when i am using trainingarguments from transformers library im getting import error with this code from transformers import trainingarguments trainingargs trainingarguments outputdir contentourmodel learningrate2e5 perdevicetrainbatchsize 64 perdeviceevalbatchsize 16 numtrainepochs 2 weightdecay 001 evaluationstrategy epoch savestrategy epoch loadbestmodelatend true pushtohub false this is the error im getting ipythoninput280518ea5ff407 in cell line 2 1 from transformers import trainingarguments 2 trainingargs trainingarguments 3 outputdir contentourmodel 4 learningrate2e5 5 perdevicetrainbatchsize 64 4 frames usrlocallibpython310distpackagestransformerstrainingargspy in setupdevicesself 1670 if not issagemakermpenabled 1671 if not isaccelerateavailableminversion0201 1672 raise importerror 1673 using the trainer with pytorch requires accelerate0201 please run pip install transformerstorch or pip install accelerate u 1674 importerror using the trainer with pytorch requires accelerate0201 please run pip install transformerstorch or pip install accelerate u i already tried pip install for 0201 version of accelerate and pip install transformerstorch and both didnt worked']
Breakpoint-induced interactive debugging of Python with IPython,"Say I have an IPython session, from which I call some script:
> run my_script.py

Is there a way to induce a breakpoint in my_script.py from which I can inspect my workspace from IPython?
I remember reading that in previous versions of IPython one could do:
from IPython.Debugger import Tracer;     

def my_function():
    x = 5
    Tracer()
    print 5;

but the submodule Debugger does not seem to be available anymore. 
Assuming that I have an IPython session open already: how can I stop my program a location of my choice and inspect my workspace with IPython?
In general, I would prefer solutions that do not require me to pre-specify line numbers, since I would like to possibly have more than one such call to Tracer() above and not have to keep track of the line numbers where they are.
",<python><debugging><ipython><breakpoints><ipdb>,40,"python,debugging,ipython,breakpoints,ipdb",['breakpointinduced interactive debugging of python with ipython'],"['say i have an ipython session from which i call some script run myscriptpy is there a way to induce a breakpoint in myscriptpy from which i can inspect my workspace from ipython', 'i remember reading that in previous versions of ipython one could do from ipythondebugger import tracer def myfunction x 5 tracer print 5 but the submodule debugger does not seem to be available anymore', 'assuming that i have an ipython session open already how can i stop my program a location of my choice and inspect my workspace with ipython', 'in general i would prefer solutions that do not require me to prespecify line numbers since i would like to possibly have more than one such call to tracer above and not have to keep track of the line numbers where they are']"
AdMob mediation (Android and iOS) : how to force a network to test it?,"I am implementing AdMob mediation with several third party networks. I would like to test that the mediation with each of these networks is well implemented (ads well displayed). 
I would like to force the display of an ad from a defined network to test its implementation, and then switch quickly to another network.
One way to do that should be to change the bids in the AdMob mediation interface. For example put 100$ on the network I want to test and 0.1 $ on the other ones. 
But the problem is it seems that there is some delay before the changes are taken into account and even after a long delay, it seems that I do not have 100% of ads from the network at 100$.
How can I force a network (any test mode ?) in a manner that I will have immediately ads from this networks on 100% of the requests ? It could be test ads from this network.
Thanks !
",<android><ios><admob><mopub><inmobi>,12,"android,ios,admob,mopub,inmobi",['admob mediation android and ios how to force a network to test it'],"['i am implementing admob mediation with several third party networks', 'i would like to test that the mediation with each of these networks is well implemented ads well displayed', 'i would like to force the display of an ad from a defined network to test its implementation and then switch quickly to another network', 'one way to do that should be to change the bids in the admob mediation interface', 'for example put 100 on the network i want to test and 01 on the other ones', 'but the problem is it seems that there is some delay before the changes are taken into account and even after a long delay it seems that i do not have 100 of ads from the network at 100', 'how can i force a network any test mode ', 'in a manner that i will have immediately ads from this networks on 100 of the requests ', 'it could be test ads from this network', 'thanks ']"
"Logic first, WCF security later?","I'm working on a WCF service that will be communicating over net.tcp to n instances of a client app (that is being developed by another programmer in my office). 
At the moment I am using net.tcp without any security as I felt setting this up at this stage wasn't necessary, at least not until we are closer to rolling out.
During the development of a WCF application, is there any harm in using a standard binding (net.tcp in my case) without security, then once the business logic has been completed, implement all the security requirements? Are there any things I need to be aware of that may not function after the implementation of security?
",<c#><xml><wcf><security><wcf-binding>,5,"c#,xml,wcf,security,wcf-binding",['logic first wcf security later'],"['im working on a wcf service that will be communicating over nettcp to n instances of a client app that is being developed by another programmer in my office', 'at the moment i am using nettcp without any security as i felt setting this up at this stage wasnt necessary at least not until we are closer to rolling out', 'during the development of a wcf application is there any harm in using a standard binding nettcp in my case without security then once the business logic has been completed implement all the security requirements', 'are there any things i need to be aware of that may not function after the implementation of security']"
Configure SQL Server connection pool on Tomcat,"I've been trying to configure a connection pool for a SQL Server 2012 database. I currently have Informix and Oracle pools configured and working, only SQL Server is giving me a headache. This is how my resource on Context.xml looks so far:
<Resource name=""jdbc/sqlserv""
    auth=""Container""
    factory=""org.apache.tomcat.dbcp.dbcp.BasicDataSourceFactory""
    driverClass=""com.microsoft.sqlserver.jdbc.SQLServerDriver""
    type=""javax.sql.DataSource""
    maxActive=""50""
    maxIdle=""10""
    maxWait=""15000""
    username=""username""
    password=""password""
    url=""jdbc:sqlserver://127.0.0.1:1433;databaseName=SQLDB;""
    removeAbandoned=""true""
    removeAbandonedTimeout=""30""
    logAbandoned=""true"" /> 

That's using sqljdbc4 driver, of course. We already tried using jtds-1.3.0 with the driverClass=""net.sourceforge.jtds.jdbc.Driver"", but no go. All the resource-refs are also being correctly configured. Whenever I try to create a new connection using that Resource, it fails.
For comparison's sake, here's how our Informix and Oracle resources look like:
<Resource name=""jdbc/infmx""
    auth=""Container""
    type=""javax.sql.DataSource""
    factory=""org.apache.tomcat.dbcp.dbcp.BasicDataSourceFactory""
    maxActive=""50""
    maxIdle=""10""
    maxWait=""15000""
    username=""username""
    password=""password""
    driverClassName=""com.informix.jdbc.IfxDriver""
    url=""jdbc:informix-sqli://localhost:30091/infmx:informixserver=ol_infmx_soc""
    removeAbandoned=""true""
    removeAbandonedTimeout=""30""
    logAbandoned=""true""/>

<Resource name=""jdbc/orcl""
    auth=""Container""
    type=""oracle.jdbc.pool.OracleDataSource""
    driverClassName=""oracle.jdbc.driver.OracleDriver""
    factory=""oracle.jdbc.pool.OracleDataSourceFactory""
    url=""jdbc:oracle:thin:@127.0.0.1:1521:orcl""
    user=""username""
    password=""password""
    maxActive=""50""
    maxIdle=""10""
    maxWait=""15000"" /> 

So My question is: How can I correctly configure a connection pool for SQL Server 2012 on my tomcat context? I've searched high and low, attempted everything I've found, but nothing worked.
Thanks in advance.
[edit] Here's the stack trace: http://pastebin.com/w3rZSERs
[edit-2] It seems the problem is that Tomcat can't find the driver on his lib folder. We're pretty sure it's there, but we don't know to be sure of that. This happens with both sqljdbc4 and jtds-1.3.0. We're following every guideline we can find, but the problem persists.
",<java><sql-server><tomcat><tomcat7><connection-pooling>,5,"java,sql-server,tomcat,tomcat7,connection-pooling",['configure sql server connection pool on tomcat'],"['ive been trying to configure a connection pool for a sql server 2012 database', 'i currently have informix and oracle pools configured and working only sql server is giving me a headache', 'this is how my resource on contextxml looks so far resource namejdbcsqlserv authcontainer factoryorgapachetomcatdbcpdbcpbasicdatasourcefactory driverclasscommicrosoftsqlserverjdbcsqlserverdriver typejavaxsqldatasource maxactive50 maxidle10 maxwait15000 usernameusername passwordpassword urljdbcsqlserver1270011433databasenamesqldb removeabandonedtrue removeabandonedtimeout30 logabandonedtrue thats using sqljdbc4 driver of course', 'we already tried using jtds130 with the driverclassnetsourceforgejtdsjdbcdriver but no go', 'all the resourcerefs are also being correctly configured', 'whenever i try to create a new connection using that resource it fails', 'for comparisons sake heres how our informix and oracle resources look like resource namejdbcinfmx authcontainer typejavaxsqldatasource factoryorgapachetomcatdbcpdbcpbasicdatasourcefactory maxactive50 maxidle10 maxwait15000 usernameusername passwordpassword driverclassnamecominformixjdbcifxdriver urljdbcinformixsqlilocalhost30091infmxinformixserverolinfmxsoc removeabandonedtrue removeabandonedtimeout30 logabandonedtrue resource namejdbcorcl authcontainer typeoraclejdbcpooloracledatasource driverclassnameoraclejdbcdriveroracledriver factoryoraclejdbcpooloracledatasourcefactory urljdbcoraclethin1270011521orcl userusername passwordpassword maxactive50 maxidle10 maxwait15000 so my question is how can i correctly configure a connection pool for sql server 2012 on my tomcat context', 'ive searched high and low attempted everything ive found but nothing worked', 'thanks in advance', 'edit heres the stack trace edit2 it seems the problem is that tomcat cant find the driver on his lib folder', 'were pretty sure its there but we dont know to be sure of that', 'this happens with both sqljdbc4 and jtds130', 'were following every guideline we can find but the problem persists']"
GET query missing: Implementing GraphQL Using Apollo On an Express Server,"I'm following the tutorial here: Implementing GraphQL Using Apollo On an Express Server and I'm getting the error GET query missing in the browser at http://localhost:7700/graphql.
First I typed all the code myself. When I encountered the error, I downloaded the code from GitHub: kimobrian/GraphQL-Express: An Express Server implemented using GraphQL to eliminate the possibility that I had made a mistake. However, I'm still getting the same error.
I presume it is better to provide the link to the repo rather than paste the code here because I'm using the same code from the repo. Also, I am not sure which file might contain the problem.
$ npm start

> tutorial-server@1.0.0 start kimobrian/GraphQL-Express.git
> nodemon ./server.js --exec babel-node -e js

[nodemon] 1.18.9
[nodemon] to restart at any time, enter `rs`
[nodemon] watching: *.*
[nodemon] starting `babel-node ./server.js`
GraphQL Server is now running on http://localhost:7700

The error is GET query missing in the browser at http://localhost:7700/graphql. It's the same in Firefox and Chromium.
Update: The only question I find with relevant information is here: nodejs with Graphql. The suggested solution is  
server.use('/graphiql', graphiqlExpress({
  endpointURL: '/graphql',
}));

However, that's exactly the code I have already (from the tutorial). Here is my entire server.js:
import express from 'express';
import cors from 'cors';

import {
    graphqlExpress,
    graphiqlExpress,
} from 'graphql-server-express';

import bodyParser from 'body-parser';

import { schema } from './src/schema';

const PORT = 7700;
const server = express();
server.use('*', cors({ origin: 'http://localhost:7800' }));

server.use('/graphql', bodyParser.json(), graphqlExpress({
    schema
}));

server.use('/graphiql', graphiqlExpress({
    endpointURL: '/graphql'
}));

server.listen(PORT, () =>
    console.log(`GraphQL Server is now running on http://localhost:${PORT}`)
);

",<node.js><express><graphql><apollo><apollo-server>,6,"node.js,express,graphql,apollo,apollo-server",['get query missing implementing graphql using apollo on an express server'],"['im following the tutorial here implementing graphql using apollo on an express server and im getting the error get query missing in the browser at first i typed all the code myself', 'when i encountered the error i downloaded the code from github kimobriangraphqlexpress an express server implemented using graphql to eliminate the possibility that i had made a mistake', 'however im still getting the same error', 'i presume it is better to provide the link to the repo rather than paste the code here because im using the same code from the repo', 'also i am not sure which file might contain the problem', ' npm start tutorialserver100 start kimobriangraphqlexpressgit nodemon serverjs exec babelnode e js nodemon 1189 nodemon to restart at any time enter rs nodemon watching ', ' nodemon starting babelnode serverjs graphql server is now running on the error is get query missing in the browser at its the same in firefox and chromium', 'update the only question i find with relevant information is here nodejs with graphql', 'the suggested solution is serverusegraphiql graphiqlexpress endpointurl graphql however thats exactly the code i have already from the tutorial', 'here is my entire serverjs import express from express import cors from cors import graphqlexpress graphiqlexpress from graphqlserverexpress import bodyparser from bodyparser import schema from srcschema const port 7700 const server express serveruse cors origin serverusegraphql bodyparserjson graphqlexpress schema serverusegraphiql graphiqlexpress endpointurl graphql serverlistenport consoleloggraphql server is now running on ']"
how to handle the import hell in react?,"I’m running my react app via Node. Is there a way to easily handle this import hell?
I’m running
./node_modules/.bin/babel-node --presets react,es2015 server/server.js

as npm start. And server.js is a simple Express Server that serves a ReactDOMServer.renderToString(<MyApp />)
Some of my react components have something like this:
import GenericTemplate from ""../../templates/GenericTemplate/GenericTemplate"";
import Footer from ""../../organisms/Footer/Footer"";
import Header from ""../../organisms/Header/Header"";
import Hero from ""../../organisms/Hero/Hero"";
import MainMenu from ""../../organisms/MainMenu/MainMenu"";
import TodoList from ""../../organisms/TodoList/TodoList"";

this is prone to error, one changement like directory name would result in manually entering every file to update this.
do you have any idea how I can fix this. Ideally I would have something like this:
import { Footer, Header, Hero, MainMenu, TodoList } from ""myComponents""

is that possible? How?
Thank you!
",<javascript><node.js><reactjs><import><require>,8,"javascript,node.js,reactjs,import,require",['how to handle the import hell in react'],"['im running my react app via node', 'is there a way to easily handle this import hell', 'im running nodemodulesbinbabelnode presets reactes2015 serverserverjs as npm start', 'and serverjs is a simple express server that serves a reactdomserverrendertostringmyapp some of my react components have something like this import generictemplate from templatesgenerictemplategenerictemplate import footer from organismsfooterfooter import header from organismsheaderheader import hero from organismsherohero import mainmenu from organismsmainmenumainmenu import todolist from organismstodolisttodolist this is prone to error one changement like directory name would result in manually entering every file to update this', 'do you have any idea how i can fix this', 'ideally i would have something like this import footer header hero mainmenu todolist from mycomponents is that possible', 'thank you']"
How to debug a DLL project using QtCreator?,"I have written a non-Qt C DLL compiled with mingw using the QtCreator IDE.
When I inject the DLL into a process, the DLL causes that process to crash at a certain line of code. I found this line to be the culprit through the use of OutputDebugString. I know how to fix the line and the DLL works when that line is modified. However, for the purpose of learning how to use a debugger, I have left the line broken and unmodified.
How would I use the QtCreator debugger to find that same exact line is causing the problem? When QtCreator is set to compile in debug mode, pressing F5 results in the following dialog because there is no EXE:

",<c++><c><qt><dll><qt-creator>,6,"c++,c,qt,dll,qt-creator",['how to debug a dll project using qtcreator'],"['i have written a nonqt c dll compiled with mingw using the qtcreator ide', 'when i inject the dll into a process the dll causes that process to crash at a certain line of code', 'i found this line to be the culprit through the use of outputdebugstring', 'i know how to fix the line and the dll works when that line is modified', 'however for the purpose of learning how to use a debugger i have left the line broken and unmodified', 'how would i use the qtcreator debugger to find that same exact line is causing the problem', 'when qtcreator is set to compile in debug mode pressing f5 results in the following dialog because there is no exe']"
"Is ""'"" identical to ""\'"" as per the C/C++ standard?","int main()
{
    char* str1 = ""Tom's cat"";
    char* str2 = ""Tom\'s cat"";
}

The code can be compiled with VS 2015.
I just wonder: 
Are both of the two ways compliant to the C and/or the C++ standard?
",<c++><c><escaping><standards><language-specifications>,5,"c++,c,escaping,standards,language-specifications",['is identical to as per the cc standard'],['int main char str1 toms cat char str2 toms cat the code can be compiled with vs 2015 i just wonder are both of the two ways compliant to the c andor the c standard']
Error on sending AT+CWJAP_DEF commands to ESP8266,"I am trying to send AT commands to ESP8266 to get connected with internet with the Wifi.
When I am sending AT and AT+RST command on serial monitor then I am getting OK and ready response which seems perfect.
Then I am sending AT+CWLAP to get list of available wifi networks which is also executing correctly.
AT+CWLAP

+CWLAP:(3,""Moto"",-42,""a4:70:d6:7a:fa:6c"",1,25,0)
+CWLAP:(4,""PRANJAL"",-95,""1c:a5:32:3d:f5:c4"",1,-16,0)
+CWLAP:(2,""VIHAN"",-94,""c8:3a:35:2f:1d:81"",1,-21,0)
+CWLAP:(3,""Tenda"",-93,""c8:3a:35:20:a9:b1"",9,-4,0)

OK

Then I sent AT+CWMODE? which is also perfect.
AT+CWMODE?

+CWMODE:1

OK

Now I am trying to connect ESP8266 with above listed Wifi with this command, it is sending an ERROR on serial monitor.

AT+CWJAP_DEF=""Moto"",""reset1234""

Error
⸮=IRe""Moto"",""reset1234""

ERROR

Can anyone suggest me what could be the reason of this issue ?
#include ""SoftwareSerial.h""

SoftwareSerial esp8266(2, 3); // RX, TX

void setup()
{
  Serial.begin(9600); // serial port used for debugging
  esp8266.begin(9600);  // your ESP's baud rate might be different
}

void loop()
{
  if(esp8266.available())  // check if the ESP is sending a message
  {
    while(esp8266.available())
    {
      char c = esp8266.read();  // read the next character.

      Serial.write(c);  // writes data to the serial monitor
    }
  }

  if(Serial.available())
  {
    delay(10);  // wait to let all the input command in the serial buffer

    // read the input command in a string
    String cmd = """";
    while(Serial.available())
    {
      cmd += (char)Serial.read();
    }
    // send to the esp8266
    esp8266.println(cmd); 
  }
}


",<arduino><arduino-uno><at-command><esp8266><arduino-esp8266>,6,"arduino,arduino-uno,at-command,esp8266,arduino-esp8266",['error on sending atcwjapdef commands to esp8266'],"['i am trying to send at commands to esp8266 to get connected with internet with the wifi', 'when i am sending at and atrst command on serial monitor then i am getting ok and ready response which seems perfect', 'then i am sending atcwlap to get list of available wifi networks which is also executing correctly', 'atcwlap cwlap3moto42a470d67afa6c1250 cwlap4pranjal951ca5323df5c41160 cwlap2vihan94c83a352f1d811210 cwlap3tenda93c83a3520a9b1940 ok then i sent atcwmode', 'which is also perfect', 'atcwmode', 'cwmode1 ok now i am trying to connect esp8266 with above listed wifi with this command it is sending an error on serial monitor', 'atcwjapdefmotoreset1234 error iremotoreset1234 error can anyone suggest me what could be the reason of this issue ', 'include softwareserialh softwareserial esp82662 3 rx tx void setup serialbegin9600 serial port used for debugging esp8266begin9600 your esps baud rate might be different void loop ifesp8266available check if the esp is sending a message whileesp8266available char c esp8266read read the next character', 'serialwritec writes data to the serial monitor ifserialavailable delay10 wait to let all the input command in the serial buffer read the input command in a string string cmd whileserialavailable cmd charserialread send to the esp8266 esp8266printlncmd ']"
XMPP4r - Unable to Retrieve Offline Messages,"I am trying to get openfire multi user group chat history using ruby xmpp4r library with openfire server. I am able to frame the request but I am not getting the server reply. 
Below is the discovery request 
iqr = Iq.new(:get,""example.com"")
iqr.add_namespace(""http://jabber.org/protocol/disco#info"")
client.send(iqr)

and this is the request that is framed
<iq to='example.com' type='get' xmlns='http://jabber.org/protocol/disco#info'/>

but I am not getting a server reply. I followed XEP-0160 and XEP-0013.
What am I missing here?

Does openfire provide room chat history? Is there an api for that?
Any help is deeply appreciated. And I dont understand openfire much so any information on it is very much appreciated.
",<ruby-on-rails><ruby><xmpp><openfire><xmpp4r>,8,"ruby-on-rails,ruby,xmpp,openfire,xmpp4r",['xmpp4r unable to retrieve offline messages'],"['i am trying to get openfire multi user group chat history using ruby xmpp4r library with openfire server', 'i am able to frame the request but i am not getting the server reply', 'below is the discovery request iqr iqnewgetexamplecom iqraddnamespace clientsendiqr and this is the request that is framed iq toexamplecom typeget xmlns but i am not getting a server reply', 'i followed xep0160 and xep0013', 'what am i missing here', 'does openfire provide room chat history', 'is there an api for that', 'any help is deeply appreciated', 'and i dont understand openfire much so any information on it is very much appreciated']"
Why does this gRPC call from the Google Secret Manager API hang when run by Apache?,"In short:
I have a Django application being served up by Apache on a Google Compute Engine VM.
I want to access a secret from Google Secret Manager in my Python code (when the Django app is initialising).
When I do 'python manage.py runserver', the secret is successfully retrieved. However, when I get Apache to run my application, it hangs when it sends a request to the secret manager.
Too much detail:
I followed the answer to this question GCP VM Instance is not able to access secrets from Secret Manager despite of appropriate Roles. I have created a service account (not the default), and have given it the 'cloud-platform' scope. I also gave it the 'Secret Manager Admin' role in the web console.
After initially running into trouble, I downloaded the a json key for the service account from the web console, and set the GOOGLE_APPLICATION_CREDENTIALS env-var to point to it.
When I run the django server directly on the VM, everything works fine. When I let Apache run the application, I can see from the logs that the service account credential json is loaded successfully.
However, when I make my first API call, via google.cloud.secretmanager.SecretManagerServiceClient.list_secret_versions , the application hangs. I don't even get a 500 error in my browser, just an eternal loading icon. I traced the execution as far as:
grpc._channel._UnaryUnaryMultiCallable._blocking, line 926 : 'call = self._channel.segregated_call(...'
It never gets past that line. I couldn't figure out where that call goes so I couldnt inspect it any further than that.
Thoughts
I don't understand GCP service accounts / API access very well. I can't understand why this difference is occurring between the django dev server and apache, given that they're both using the same service account credentials from json. I'm also surprised that the application just hangs in the google library rather than throwing an exception. There's even a timeout option when sending a request, but changing this doesn't make any difference.
I wonder if it's somehow related to the fact that I'm running the django server under my own account, but apache is using whatever user account it uses?
Update
I tried changing the user/group that apache runs as to match my own. No change.
I enabled logging for gRPC itself. There is a clear difference between when I run with apache vs the django dev server.
On Django:
secure_channel_create.cc:178] grpc_secure_channel_create(creds=0x17cfda0, target=secretmanager.googleapis.com:443, args=0x7fe254620f20, reserved=(nil))
init.cc:167]                grpc_init(void)
client_channel.cc:1099]     chand=0x2299b88: creating client_channel for channel stack 0x2299b18
...
timer_manager.cc:188]       sleep for a 1001 milliseconds
...
client_channel.cc:1879]     chand=0x2299b88 calld=0x229e440: created call
...
call.cc:1980]               grpc_call_start_batch(call=0x229daa0, ops=0x20cfe70, nops=6, tag=0x7fe25463c680, reserved=(nil))
call.cc:1573]               ops[0]: SEND_INITIAL_METADATA...
call.cc:1573]               ops[1]: SEND_MESSAGE ptr=0x21f7a20
...
So, a channel is created, then a call is created, and then we see gRPC start to execute the operations for that call (as far as I read it).
On Apache:

secure_channel_create.cc:178] grpc_secure_channel_create(creds=0x7fd5bc850f70, target=secretmanager.googleapis.com:443, args=0x7fd583065c50, reserved=(nil))
init.cc:167]                grpc_init(void)
client_channel.cc:1099]     chand=0x7fd5bca91bb8: creating client_channel for channel stack 0x7fd5bca91b48
...
timer_manager.cc:188]       sleep for a 1001 milliseconds
...
timer_manager.cc:188]       sleep for a 1001 milliseconds
...

So, we a channel is created... and then nothing. No call, no operations. So the python code is sitting there waiting for gRPC to make this call, which it never does.
",<python><django><apache><google-cloud-platform><google-secret-manager>,5,"python,django,apache,google-cloud-platform,google-secret-manager",['why does this grpc call from the google secret manager api hang when run by apache'],"['in short i have a django application being served up by apache on a google compute engine vm', 'i want to access a secret from google secret manager in my python code when the django app is initialising', 'when i do python managepy runserver the secret is successfully retrieved', 'however when i get apache to run my application it hangs when it sends a request to the secret manager', 'too much detail i followed the answer to this question gcp vm instance is not able to access secrets from secret manager despite of appropriate roles', 'i have created a service account not the default and have given it the cloudplatform scope', 'i also gave it the secret manager admin role in the web console', 'after initially running into trouble i downloaded the a json key for the service account from the web console and set the googleapplicationcredentials envvar to point to it', 'when i run the django server directly on the vm everything works fine', 'when i let apache run the application i can see from the logs that the service account credential json is loaded successfully', 'however when i make my first api call via googlecloudsecretmanagersecretmanagerserviceclientlistsecretversions the application hangs', 'i dont even get a 500 error in my browser just an eternal loading icon', 'i traced the execution as far as grpcchannelunaryunarymulticallableblocking line 926 call selfchannelsegregatedcall it never gets past that line', 'i couldnt figure out where that call goes so i couldnt inspect it any further than that', 'thoughts i dont understand gcp service accounts api access very well', 'i cant understand why this difference is occurring between the django dev server and apache given that theyre both using the same service account credentials from json', 'im also surprised that the application just hangs in the google library rather than throwing an exception', 'theres even a timeout option when sending a request but changing this doesnt make any difference', 'i wonder if its somehow related to the fact that im running the django server under my own account but apache is using whatever user account it uses', 'update i tried changing the usergroup that apache runs as to match my own', 'no change', 'i enabled logging for grpc itself', 'there is a clear difference between when i run with apache vs the django dev server', 'on django securechannelcreatecc178 grpcsecurechannelcreatecreds0x17cfda0 targetsecretmanagergoogleapiscom443 args0x7fe254620f20 reservednil initcc167 grpcinitvoid clientchannelcc1099 chand0x2299b88 creating clientchannel for channel stack 0x2299b18 timermanagercc188 sleep for a 1001 milliseconds clientchannelcc1879 chand0x2299b88 calld0x229e440 created call callcc1980 grpccallstartbatchcall0x229daa0 ops0x20cfe70 nops6 tag0x7fe25463c680 reservednil callcc1573 ops0 sendinitialmetadata callcc1573 ops1 sendmessage ptr0x21f7a20 so a channel is created then a call is created and then we see grpc start to execute the operations for that call as far as i read it', 'on apache securechannelcreatecc178 grpcsecurechannelcreatecreds0x7fd5bc850f70 targetsecretmanagergoogleapiscom443 args0x7fd583065c50 reservednil initcc167 grpcinitvoid clientchannelcc1099 chand0x7fd5bca91bb8 creating clientchannel for channel stack 0x7fd5bca91b48 timermanagercc188 sleep for a 1001 milliseconds timermanagercc188 sleep for a 1001 milliseconds so we a channel is created and then nothing', 'no call no operations', 'so the python code is sitting there waiting for grpc to make this call which it never does']"
PHP build/integration tools: Do you use them?,"After reading the ""Modern PHP workflow"" article in the November 2008 edition of php|architect magazine which 
discussed unit testing (phpUnit), build tools (Phing) and continuous integration (Xinc), I'm inspired the learn more about some of the tooling available for PHP, especially Phing.
In the past I've often handled deployment to a production server by running the live site as a subversion working copy and simply running an ""svn update"" on the production box to deploy the latest version of the code.  
Do you use build tools for PHP code?  What advantages you you believe they offer over deploying direct from subversion?  What should I look out for, or what gotchas might I face?
",<php><build><continuous-integration><phing><xinc>,19,"php,build,continuous-integration,phing,xinc",['php buildintegration tools do you use them'],"['after reading the modern php workflow article in the november 2008 edition of phparchitect magazine which discussed unit testing phpunit build tools phing and continuous integration xinc im inspired the learn more about some of the tooling available for php especially phing', 'in the past ive often handled deployment to a production server by running the live site as a subversion working copy and simply running an svn update on the production box to deploy the latest version of the code', 'do you use build tools for php code', 'what advantages you you believe they offer over deploying direct from subversion', 'what should i look out for or what gotchas might i face']"
Create SQL Server DB from DataSet,"I read xsd and xml file in DataSet, now I want create db from this DataSet
foreach (DataTable dt in temp.Tables) {
    foreach (DataColumn dc in dt.Columns) {
        //example for one column
        SqlCommand createtable = new SqlCommand(
            ""create table "" + dt.TableName + "" ("" 
            + dc.ColumnName + ""  varchar(max))"", conn);
        createtable.ExecuteNonQuery();
    }
}

But I have some problem, when I create db table I need column type and size from XSD (in example use varchar(max)). How to fix this?
For example in xsd I have 
<xs:restriction base=""xs:string"">
<xs:maxLength value=""36""/>
<xs:minLength value=""1""/>
</xs:restriction>

or
<xs:restriction base=""xs:string"">
<xs:maxLength value=""40""/>
</xs:restriction>

or
<xs:restriction base=""xs:decimal"">
<xs:totalDigits value=""19""/>
<xs:fractionDigits value=""2""/>
</xs:restriction>

In the end I need script to create db tables with size of columns (like in xsd)
UPD: Maybe use XmlSchemaSet to parse XSD?
",<c#><sql><sql-server><xml><dataset>,5,"c#,sql,sql-server,xml,dataset",['create sql server db from dataset'],"['i read xsd and xml file in dataset now i want create db from this dataset foreach datatable dt in temptables foreach datacolumn dc in dtcolumns example for one column sqlcommand createtable new sqlcommand create table dttablename dccolumnname varcharmax conn createtableexecutenonquery but i have some problem when i create db table i need column type and size from xsd in example use varcharmax', 'how to fix this', 'for example in xsd i have xsrestriction basexsstring xsmaxlength value36 xsminlength value1 xsrestriction or xsrestriction basexsstring xsmaxlength value40 xsrestriction or xsrestriction basexsdecimal xstotaldigits value19 xsfractiondigits value2 xsrestriction in the end i need script to create db tables with size of columns like in xsd upd maybe use xmlschemaset to parse xsd']"
DFT matrix in python,"What's the easiest way to get the DFT matrix for 2-d DFT in python? I could not find such function in numpy.fft. Thanks!
",<python><numpy><scipy><fft><dft>,25,"python,numpy,scipy,fft,dft",['dft matrix in python'],"['whats the easiest way to get the dft matrix for 2d dft in python', 'i could not find such function in numpyfft', 'thanks']"
Template parse errors when overriding DataTable component of primeNg,"I want to override the template of the DataTable component of primeng and this is how my code looks like:
my-datatable.component.ts
import { Component, OnInit, ElementRef, Renderer2, ChangeDetectorRef } from '@angular/core';
import { DataTable, DomHandler } from 'primeng/primeng';
import { ObjectUtils } from '../../../../node_modules/primeng/components/utils/ObjectUtils'
import { ColumnHeaders } from '../../../../node_modules/primeng/components/datatable/datatable'

@Component({
  selector: 'my-datatable',
  templateUrl: './my-datatable.component.html',
  styleUrls: ['./my-datatable.component.scss']    
})
export class MyDatatableComponent extends DataTable {

    constructor(el: ElementRef, domHandler: DomHandler, renderer: Renderer2, changeDetector: ChangeDetectorRef, objectUtils: ObjectUtils) { 
        super(el, domHandler, renderer, changeDetector, objectUtils);
        console.log('MyDatatableComponent');
    }

}

my-datatable.component.html, this file has the same template as of the base component. Idea was to first run and then make modifications


<div [ngStyle]=""style"" [class]=""styleClass"" [style.width]=""containerWidth"" [ngClass]=""{'ui-datatable ui-widget':true,'ui-datatable-reflow':responsive,'ui-datatable-stacked':stacked,'ui-datatable-resizable':resizableColumns,'ui-datatable-scrollable':scrollable}"">
  <div class=""ui-datatable-loading ui-widget-overlay"" *ngIf=""loading""></div>
  <div class=""ui-datatable-loading-content"" *ngIf=""loading"">
    <i class=""fa fa-circle-o-notch fa-spin fa-2x""></i>
  </div>
  <div class=""ui-datatable-header ui-widget-header"" *ngIf=""header"">
    <ng-content select=""p-header""></ng-content>
  </div>
  <p-paginator [rows]=""rows"" [first]=""first"" [totalRecords]=""totalRecords"" [pageLinkSize]=""pageLinks"" styleClass=""ui-paginator-bottom"" (onPageChange)=""paginate($event)"" [rowsPerPageOptions]=""rowsPerPageOptions"" *ngIf=""paginator && paginatorPosition!='bottom' || paginatorPosition =='both'""></p-paginator>
  <div class=""ui-datatable-tablewrapper"" *ngIf=""!scrollable"">
    <table [class]=""tableStyleClass"" [ngStyle]=""tableStyle"">
      <thead class=""ui-datatable-thead"">
        <tr *ngIf=""!headerColumnGroup"" class=""ui-state-default"" [pColumnHeaders]=""columns""></tr>
        <ng-template [ngIf]=""headerColumnGroup"">
          <tr *ngFor=""let headerRow of headerColumnGroup.rows"" class=""ui-state-default"" [pColumnHeaders]=""headerRow.columns""></tr>
        </ng-template>
      </thead>
      <tfoot *ngIf=""hasFooter()"" class=""ui-datatable-tfoot"">
        <tr *ngIf=""!footerColumnGroup"" class=""ui-state-default"" [pColumnFooters]=""columns""></tr>
        <ng-template [ngIf]=""footerColumnGroup"">
          <tr *ngFor=""let footerRow of footerColumnGroup.rows"" class=""ui-state-default"" [pColumnFooters]=""footerRow.columns""></tr>
        </ng-template>
      </tfoot>
      <tbody [ngClass]=""{'ui-datatable-data ui-widget-content': true, 'ui-datatable-hoverable-rows': (rowHover||selectionMode)}"" [pTableBody]=""columns""></tbody>
    </table>
  </div>

  <ng-template [ngIf]=""scrollable"">
    <div class=""ui-datatable-scrollable-wrapper ui-helper-clearfix"" [ngClass]=""{'max-height':scrollHeight}"">
      <div *ngIf=""frozenColumns"" [pScrollableView]=""frozenColumns"" frozen=""true"" [ngStyle]=""{'width':this.frozenWidth}"" class=""ui-datatable-scrollable-view ui-datatable-frozen-view""></div>
      <div [pScrollableView]=""scrollableColumns"" [ngStyle]=""{'width':this.unfrozenWidth, 'left': this.frozenWidth}"" class=""ui-datatable-scrollable-view"" [virtualScroll]=""virtualScroll"" (onVirtualScroll)=""onVirtualScroll($event)"" [ngClass]=""{'ui-datatable-unfrozen-view': frozenColumns}""></div>
    </div>
  </ng-template>

  <p-paginator [rows]=""rows"" [first]=""first"" [totalRecords]=""totalRecords"" [pageLinkSize]=""pageLinks"" styleClass=""ui-paginator-bottom"" [alwaysShow]=""alwaysShowPaginator"" (onPageChange)=""paginate($event)"" [rowsPerPageOptions]=""rowsPerPageOptions"" *ngIf=""paginator && paginatorPosition!='top' || paginatorPosition =='both'""></p-paginator>
  <div class=""ui-datatable-footer ui-widget-header"" *ngIf=""footer"">
    <ng-content select=""p-footer""></ng-content>
  </div>

  <div class=""ui-column-resizer-helper ui-state-highlight"" style=""display:none""></div>
  <span class=""fa fa-arrow-down ui-datatable-reorder-indicator-up"" style=""position: absolute; display: none;""></span>
  <span class=""fa fa-arrow-up ui-datatable-reorder-indicator-down"" style=""position: absolute; display: none;""></span>
</div>



Also I have added this new component in the declarations array in the app.module.ts file. So, I know that it is being included, which is the reason why I am getting a parse error.
The errors which I encounter in the console is:
Unhandled Promise rejection: Template parse errors:
Can't bind to 'pColumnHeaders' since it isn't a known property of 'tr'. (""ass=""ui-datatable-thead"">
                  <tr *ngIf=""!headerColumnGroup"" class=""ui-state-default"" [ERROR ->][pColumnHeaders]=""columns""></tr>
                  <ng-template [ngIf]=""headerColumnGroup"">
         ""): ng:///AppModule/CsxDatatableComponent.html@14:74
Can't bind to 'pColumnHeaders' since it isn't a known property of 'tr'. (""                      <tr *ngFor=""let headerRow of headerColumnGroup.rows"" class=""ui-state-default"" [ERROR ->][pColumnHeaders]=""headerRow.columns""></tr>
                  </ng-template>
              </thead>
""): ng:///AppModule/CsxDatatableComponent.html@16:100
Can't bind to 'pColumnFooters' since it isn't a known property of 'tr'. (""ass=""ui-datatable-tfoot"">
                  <tr *ngIf=""!footerColumnGroup"" class=""ui-state-default"" [ERROR ->][pColumnFooters]=""columns""></tr>
                  <ng-template [ngIf]=""footerColumnGroup"">
         ""): ng:///AppModule/CsxDatatableComponent.html@20:74
Can't bind to 'pColumnFooters' since it isn't a known property of 'tr'. (""                      <tr *ngFor=""let footerRow of footerColumnGroup.rows"" class=""ui-state-default"" [ERROR ->][pColumnFooters]=""footerRow.columns""></tr>
                  </ng-template>
              </tfoot>
""): ng:///AppModule/CsxDatatableComponent.html@22:100
Can't bind to 'pTableBody' since it isn't a known property of 'tbody'. (""datatable-data ui-widget-content': true, 'ui-datatable-hoverable-rows': (rowHover||selectionMode)}"" [ERROR ->][pTableBody]=""columns""></tbody>
          </table>
      </div>
""): ng:///AppModule/CsxDatatableComponent.html@25:137
Can't bind to 'pScrollableView' since it isn't a known property of 'div'. (""-helper-clearfix"" [ngClass]=""{'max-height':scrollHeight}"">
              <div *ngIf=""frozenColumns"" [ERROR ->][pScrollableView]=""frozenColumns"" frozen=""true"" 
                  [ngStyle]=""{'width':this.frozenWid""): ng:///AppModule/CsxDatatableComponent.html@31:41
Can't bind to 'pScrollableView' since it isn't a known property of 'div'. (""ozenWidth}"" class=""ui-datatable-scrollable-view ui-datatable-frozen-view""></div>
              <div [ERROR ->][pScrollableView]=""scrollableColumns"" [ngStyle]=""{'width':this.unfrozenWidth, 'left': this.frozenWidt""): ng:///AppModule/CsxDatatableComponent.html@33:19
Can't bind to 'virtualScroll' since it isn't a known property of 'div'. (""is.unfrozenWidth, 'left': this.frozenWidth}""
                  class=""ui-datatable-scrollable-view"" [ERROR ->][virtualScroll]=""virtualScroll"" (onVirtualScroll)=""onVirtualScroll($event)""
                  [ngClas""): ng:///AppModule/CsxDatatableComponent.html@34:55 ; Zone: <root> ; Task: Promise.then ;

pColumnHeaders, pColumnFooters are all components which are already exported via the DataTableModule. I am unable to figure out how to make these parsing errors go away, I am sure I am missing something.
Any help is much appreciated.
Update: 
This is how my app.module.ts looks. I have the DataTableModule, BrowserModule and FormsModule imported. I am able to use the standard primeNg datatable component on my views, just not able to override it.
app.module.ts
import { BrowserModule } from '@angular/platform-browser';
import { BrowserAnimationsModule } from '@angular/platform-browser/animations';
import { NgModule } from '@angular/core';
import { FormsModule } from '@angular/forms';
import { HttpModule } from '@angular/http';

/* PRIME NG */
import { 
          AutoCompleteModule,
          PanelMenuModule, 
          MenuItem, 
          MenubarModule, 
          OverlayPanelModule, 
          TabViewModule, 
          ButtonModule, 
          CodeHighlighterModule,
          DropdownModule,
          DialogModule, 
          MultiSelectModule ,
          InputTextModule,
          TooltipModule,
          CheckboxModule,
          SplitButtonModule,
          RadioButtonModule,
          MessagesModule,
          ConfirmDialogModule,
          ConfirmationService,
          AccordionModule,
          PanelModule,
          FieldsetModule,
          CalendarModule,
          DataTableModule,
          MenuModule,
          BreadcrumbModule,
          TreeModule,
          DomHandler,
          ChartModule
        } from 'primeng/primeng';
import { ObjectUtils } from '../../node_modules/primeng/components/utils/ObjectUtils';


/* APP-SPECIFIC */
import { WindowRef } from './windowref';
import { routing } from './app.routing';
import { MyDatatableComponent } from './components/my-datatable.component';


@NgModule({
  declarations: [ 
    DatatableComponent,   
    ChartsGraphsComponent,
    CsxDatatableComponent
  ],
  imports: [
    BrowserModule,
    FormsModule,
    HttpModule,
    routing,
    AutoCompleteModule,
    BrowserAnimationsModule,
    PanelMenuModule,
    MenubarModule,
    OverlayPanelModule, 
    TabViewModule,
    ButtonModule,
    CodeHighlighterModule,
    DropdownModule,
    MultiSelectModule,
    DialogModule,
    InputTextModule,
    TooltipModule,
    CheckboxModule,
    SplitButtonModule,
    RadioButtonModule,
    MessagesModule,
    ConfirmDialogModule,
    AccordionModule,
    PanelModule,
    FieldsetModule,
    CalendarModule,
    DataTableModule,
    MenuModule,
    BreadcrumbModule,
    TreeModule,
    ChartModule
  ],
  providers: [
    DomHandler,
    ObjectUtils
  ],
  bootstrap: [AppComponent]
})
export class AppModule { }

",<angularjs><angularjs-directive><angular2-template><angular2-directives><primeng>,7,"angularjs,angularjs-directive,angular2-template,angular2-directives,primeng",['template parse errors when overriding datatable component of primeng'],"['i want to override the template of the datatable component of primeng and this is how my code looks like mydatatablecomponentts import component oninit elementref renderer2 changedetectorref from angularcore import datatable domhandler from primengprimeng import objectutils from nodemodulesprimengcomponentsutilsobjectutils import columnheaders from nodemodulesprimengcomponentsdatatabledatatable component selector mydatatable templateurl mydatatablecomponenthtml styleurls mydatatablecomponentscss export class mydatatablecomponent extends datatable constructorel elementref domhandler domhandler renderer renderer2 changedetector changedetectorref objectutils objectutils superel domhandler renderer changedetector objectutils consolelogmydatatablecomponent mydatatablecomponenthtml this file has the same template as of the base component', 'idea was to first run and then make modifications div ngstylestyle classstyleclass stylewidthcontainerwidth ngclassuidatatable uiwidgettrueuidatatablereflowresponsiveuidatatablestackedstackeduidatatableresizableresizablecolumnsuidatatablescrollablescrollable div classuidatatableloading uiwidgetoverlay ngifloadingdiv div classuidatatableloadingcontent ngifloading i classfa facircleonotch faspin fa2xi div div classuidatatableheader uiwidgetheader ngifheader ngcontent selectpheaderngcontent div ppaginator rowsrows firstfirst totalrecordstotalrecords pagelinksizepagelinks styleclassuipaginatorbottom onpagechangepaginateevent rowsperpageoptionsrowsperpageoptions ngifpaginator paginatorpositionbottom paginatorposition bothppaginator div classuidatatabletablewrapper ngifscrollable table classtablestyleclass ngstyletablestyle thead classuidatatablethead tr ngifheadercolumngroup classuistatedefault pcolumnheaderscolumnstr ngtemplate ngifheadercolumngroup tr ngforlet headerrow of headercolumngrouprows classuistatedefault pcolumnheadersheaderrowcolumnstr ngtemplate thead tfoot ngifhasfooter classuidatatabletfoot tr ngiffootercolumngroup classuistatedefault pcolumnfooterscolumnstr ngtemplate ngiffootercolumngroup tr ngforlet footerrow of footercolumngrouprows classuistatedefault pcolumnfootersfooterrowcolumnstr ngtemplate tfoot tbody ngclassuidatatabledata uiwidgetcontent true uidatatablehoverablerows rowhoverselectionmode ptablebodycolumnstbody table div ngtemplate ngifscrollable div classuidatatablescrollablewrapper uihelperclearfix ngclassmaxheightscrollheight div ngiffrozencolumns pscrollableviewfrozencolumns frozentrue ngstylewidththisfrozenwidth classuidatatablescrollableview uidatatablefrozenviewdiv div pscrollableviewscrollablecolumns ngstylewidththisunfrozenwidth left thisfrozenwidth classuidatatablescrollableview virtualscrollvirtualscroll onvirtualscrollonvirtualscrollevent ngclassuidatatableunfrozenview frozencolumnsdiv div ngtemplate ppaginator rowsrows firstfirst totalrecordstotalrecords pagelinksizepagelinks styleclassuipaginatorbottom alwaysshowalwaysshowpaginator onpagechangepaginateevent rowsperpageoptionsrowsperpageoptions ngifpaginator paginatorpositiontop paginatorposition bothppaginator div classuidatatablefooter uiwidgetheader ngiffooter ngcontent selectpfooterngcontent div div classuicolumnresizerhelper uistatehighlight styledisplaynonediv span classfa faarrowdown uidatatablereorderindicatorup styleposition absolute display nonespan span classfa faarrowup uidatatablereorderindicatordown styleposition absolute display nonespan div also i have added this new component in the declarations array in the appmodulets file', 'so i know that it is being included which is the reason why i am getting a parse error', 'the errors which i encounter in the console is unhandled promise rejection template parse errors cant bind to pcolumnheaders since it isnt a known property of tr', 'assuidatatablethead tr ngifheadercolumngroup classuistatedefault error pcolumnheaderscolumnstr ngtemplate ngifheadercolumngroup ngappmodulecsxdatatablecomponenthtml1474 cant bind to pcolumnheaders since it isnt a known property of tr', ' tr ngforlet headerrow of headercolumngrouprows classuistatedefault error pcolumnheadersheaderrowcolumnstr ngtemplate thead ngappmodulecsxdatatablecomponenthtml16100 cant bind to pcolumnfooters since it isnt a known property of tr', 'assuidatatabletfoot tr ngiffootercolumngroup classuistatedefault error pcolumnfooterscolumnstr ngtemplate ngiffootercolumngroup ngappmodulecsxdatatablecomponenthtml2074 cant bind to pcolumnfooters since it isnt a known property of tr', ' tr ngforlet footerrow of footercolumngrouprows classuistatedefault error pcolumnfootersfooterrowcolumnstr ngtemplate tfoot ngappmodulecsxdatatablecomponenthtml22100 cant bind to ptablebody since it isnt a known property of tbody', 'datatabledata uiwidgetcontent true uidatatablehoverablerows rowhoverselectionmode error ptablebodycolumnstbody table div ngappmodulecsxdatatablecomponenthtml25137 cant bind to pscrollableview since it isnt a known property of div', 'helperclearfix ngclassmaxheightscrollheight div ngiffrozencolumns error pscrollableviewfrozencolumns frozentrue ngstylewidththisfrozenwid ngappmodulecsxdatatablecomponenthtml3141 cant bind to pscrollableview since it isnt a known property of div', 'ozenwidth classuidatatablescrollableview uidatatablefrozenviewdiv div error pscrollableviewscrollablecolumns ngstylewidththisunfrozenwidth left thisfrozenwidt ngappmodulecsxdatatablecomponenthtml3319 cant bind to virtualscroll since it isnt a known property of div', 'isunfrozenwidth left thisfrozenwidth classuidatatablescrollableview error virtualscrollvirtualscroll onvirtualscrollonvirtualscrollevent ngclas ngappmodulecsxdatatablecomponenthtml3455 zone root task promisethen pcolumnheaders pcolumnfooters are all components which are already exported via the datatablemodule', 'i am unable to figure out how to make these parsing errors go away i am sure i am missing something', 'any help is much appreciated', 'update this is how my appmodulets looks', 'i have the datatablemodule browsermodule and formsmodule imported', 'i am able to use the standard primeng datatable component on my views just not able to override it', 'appmodulets import browsermodule from angularplatformbrowser import browseranimationsmodule from angularplatformbrowseranimations import ngmodule from angularcore import formsmodule from angularforms import httpmodule from angularhttp prime ng import autocompletemodule panelmenumodule menuitem menubarmodule overlaypanelmodule tabviewmodule buttonmodule codehighlightermodule dropdownmodule dialogmodule multiselectmodule inputtextmodule tooltipmodule checkboxmodule splitbuttonmodule radiobuttonmodule messagesmodule confirmdialogmodule confirmationservice accordionmodule panelmodule fieldsetmodule calendarmodule datatablemodule menumodule breadcrumbmodule treemodule domhandler chartmodule from primengprimeng import objectutils from nodemodulesprimengcomponentsutilsobjectutils appspecific import windowref from windowref import routing from approuting import mydatatablecomponent from componentsmydatatablecomponent ngmodule declarations datatablecomponent chartsgraphscomponent csxdatatablecomponent imports browsermodule formsmodule httpmodule routing autocompletemodule browseranimationsmodule panelmenumodule menubarmodule overlaypanelmodule tabviewmodule buttonmodule codehighlightermodule dropdownmodule multiselectmodule dialogmodule inputtextmodule tooltipmodule checkboxmodule splitbuttonmodule radiobuttonmodule messagesmodule confirmdialogmodule accordionmodule panelmodule fieldsetmodule calendarmodule datatablemodule menumodule breadcrumbmodule treemodule chartmodule providers domhandler objectutils bootstrap appcomponent export class appmodule ']"
How to define variables in spring's xmls to use in log4j.properties,"Kind of a puzzle here.
I have an application in WAR. There are web.xml and application context.xml in there, and also there is log4j.properties. This WAR runs in tomcat.
There is a possibility to use some variables in log4j.properties, e.g. log4j.appender.file.File=${catalina.base}/logs/app.log
I want to define a variable in web.xml or context.xml and use it in log4j.properties. For example, somehow set version=1.1 and use log4j.appender.file.File=${catalina.base}/logs/app-${version}.log. It should not be an environment variable.
Can I do it without recompiling the app?
ADD
shouldn't affect anything, but just in case...
Its web.xml looks like this:
<?xml version=""1.0"" encoding=""UTF-8""?>
<web-app xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance""
     xsi:schemaLocation=""http://java.sun.com/xml/ns/javaee
          http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd""
     version=""2.5""
     xmlns=""http://java.sun.com/xml/ns/javaee"">

<!-- Spring -->
<listener>
    <listener-class>org.springframework.web.context.ContextLoaderListener</listener-class>
</listener>

<context-param>
    <param-name>contextConfigLocation</param-name>
    <param-value>classpath:context.xml</param-value>
</context-param>

<!-- log4j -->
<listener>
    <listener-class>org.springframework.web.util.Log4jConfigListener</listener-class>
</listener>
<context-param>
    <param-name>log4jConfigLocation</param-name>
    <param-value>classpath:log4j.properties</param-value>
</context-param>
<context-param>
    <param-name>log4jRefreshInterval</param-name>
    <param-value>10000</param-value>
</context-param>
<context-param>
    <param-name>log4jExposeWebAppRoot</param-name>
    <param-value>false</param-value>
</context-param>
...
</web-app>

",<java><xml><spring><tomcat><log4j>,15,"java,xml,spring,tomcat,log4j",['how to define variables in springs xmls to use in log4jproperties'],"['kind of a puzzle here', 'i have an application in war', 'there are webxml and application contextxml in there and also there is log4jproperties', 'this war runs in tomcat', 'there is a possibility to use some variables in log4jproperties eg', 'log4jappenderfilefilecatalinabaselogsapplog i want to define a variable in webxml or contextxml and use it in log4jproperties', 'for example somehow set version11 and use log4jappenderfilefilecatalinabaselogsappversionlog', 'it should not be an environment variable', 'can i do it without recompiling the app', 'add shouldnt affect anything but just in case its webxml looks like this xml version10 encodingutf8 webapp xmlnsxsi xsischemalocation version25 xmlns spring listener listenerclassorgspringframeworkwebcontextcontextloaderlistenerlistenerclass listener contextparam paramnamecontextconfiglocationparamname paramvalueclasspathcontextxmlparamvalue contextparam log4j listener listenerclassorgspringframeworkwebutillog4jconfiglistenerlistenerclass listener contextparam paramnamelog4jconfiglocationparamname paramvalueclasspathlog4jpropertiesparamvalue contextparam contextparam paramnamelog4jrefreshintervalparamname paramvalue10000paramvalue contextparam contextparam paramnamelog4jexposewebapprootparamname paramvaluefalseparamvalue contextparam webapp']"
Eclipse - How to add a new MariaDB connection,"How can I add a new MariaDB connection to eclipse?
I am using the Data Source Explorer view, however when I try to create a new database connection there are connections for MySQL, Oracle, Informix... but no for MariaDB.
Can anyone help me?
",<mysql><eclipse><jdbc><database-connection><mariadb>,10,"mysql,eclipse,jdbc,database-connection,mariadb",['eclipse how to add a new mariadb connection'],"['how can i add a new mariadb connection to eclipse', 'i am using the data source explorer view however when i try to create a new database connection there are connections for mysql oracle informix but no for mariadb', 'can anyone help me']"
Issue with presenting UIImagePickerController in iOS 7,"My application runs in only landscape mode ! so I know UIImagePickerController presents only in portrait mode , so in iOS 6 , I had created a subclass of UIImagePickerController that forced UIImagePickerController to open in portrait mode:
@interface NonRotatingUIImagePickerController : UIImagePickerController

@end

@implementation NonRotatingUIImagePickerController

- (BOOL)shouldAutorotate {

    return NO;
}

@end


//presenting picker controller :

UIImagePickerController *ipc = [[NonRotatingUIImagePickerController alloc]init];
ipc.delegate = self;
[self presentViewController:ipc animated:YES completion:nil];

This worked fine in iOS 6 , but now in iOS 7 my app does crash because of this :
2013-10-31 14:56:01.028 Medad[1731:60b] *** Terminating app due to
uncaught exception 'UIApplicationInvalidInterfaceOrientation', reason:
'Supported orientations has no common orientation with the
application, and shouldAutorotate is returning YES'

This problem could be solved if I check Portrait in deployment info :

The problem is if I check this option my app does run in portrait too but I don't want it! 
How can I solve this issue?
",<ios><iphone><objective-c><xcode><ipad>,9,"ios,iphone,objective-c,xcode,ipad",['issue with presenting uiimagepickercontroller in ios 7'],"['my application runs in only landscape mode ', 'so i know uiimagepickercontroller presents only in portrait mode so in ios 6 i had created a subclass of uiimagepickercontroller that forced uiimagepickercontroller to open in portrait mode interface nonrotatinguiimagepickercontroller uiimagepickercontroller end implementation nonrotatinguiimagepickercontroller boolshouldautorotate return no end presenting picker controller uiimagepickercontroller ipc nonrotatinguiimagepickercontroller allocinit ipcdelegate self self presentviewcontrolleripc animatedyes completionnil this worked fine in ios 6 but now in ios 7 my app does crash because of this 20131031 145601028 medad173160b terminating app due to uncaught exception uiapplicationinvalidinterfaceorientation reason supported orientations has no common orientation with the application and shouldautorotate is returning yes this problem could be solved if i check portrait in deployment info the problem is if i check this option my app does run in portrait too but i dont want it', 'how can i solve this issue']"
Make Jcrop tracker not rotate when cropping a rotated image,"I'm trying to crop an image using Jcrop, but when I use jqueryrotate on the image, something weird happens.
I rotate the image 90 degress then I activate the JCrop, the JCrop does not follow the image rotated, so I also rotate the Jcrop-holder. The resulting image is ok, but when I select a section to crop, I have noticed that my tracker is also rotated. When I drag it up, it goes right, when I drag it left, it goes down.
What happens

Then it goes

How do I make the crop selection tool stay upright?
My html:
    <div class=""img-canvas"" style=""background-color:#cccccc;"" >
            <img id=""image_canv"" src=""<?php echo $imagesource;?>""> 
        </div> 

My Jquery:
$('#rotatephoto').click(function () {
value += 90;

JcropAPI = $('#image_canv').data('Jcrop');
    if(JcropAPI != null)
    {
    JcropAPI.destroy();
    }

var h = $('.img-canvas').height();
var w = $('.img-canvas').width();
$('.img-canvas').css(""position"",""fixed"");
$('.img-canvas').css(""width"",w);

$('.img-canvas').css(""height"",h);

$('#image_canv').Jcrop({
    onSelect: showCoords2,
    onChange: showCoords2,
    setSelect:   [ 0, 100, 50, 50 ]
    });

JcropAPI = $('#image_canv').data('Jcrop');
JcropAPI.enable();

var h2 = $('.jcrop-holder').height();
var w2 = $('.jcrop-holder').width();

if(h2  < 630)
{
var tempp = (630 - h2)/2;
$('.jcrop-holder').css(""margin-top"",tempp);
}
if(w2  < 630)
{
var tempp = (630 - w2)/2;
$('.jcrop-holder').css(""margin-left"",tempp);
} 

$('.jcrop-holder').rotate(value);
$(""#image_canv"").rotate(value);
});

",<jquery><image><rotation><crop><jcrop>,8,"jquery,image,rotation,crop,jcrop",['make jcrop tracker not rotate when cropping a rotated image'],"['im trying to crop an image using jcrop but when i use jqueryrotate on the image something weird happens', 'i rotate the image 90 degress then i activate the jcrop the jcrop does not follow the image rotated so i also rotate the jcropholder', 'the resulting image is ok but when i select a section to crop i have noticed that my tracker is also rotated', 'when i drag it up it goes right when i drag it left it goes down', 'what happens then it goes how do i make the crop selection tool stay upright', 'my html div classimgcanvas stylebackgroundcolorcccccc img idimagecanv srcphp echo imagesource div my jquery rotatephotoclickfunction value 90 jcropapi imagecanvdatajcrop ifjcropapi null jcropapidestroy var h imgcanvasheight var w imgcanvaswidth imgcanvascsspositionfixed imgcanvascsswidthw imgcanvascssheighth imagecanvjcrop onselect showcoords2 onchange showcoords2 setselect 0 100 50 50 jcropapi imagecanvdatajcrop jcropapienable var h2 jcropholderheight var w2 jcropholderwidth ifh2 630 var tempp 630 h22 jcropholdercssmargintoptempp ifw2 630 var tempp 630 w22 jcropholdercssmarginlefttempp jcropholderrotatevalue imagecanvrotatevalue ']"
"How do you remove the deploymentConfig, image streams, etc using Openshift OC?","After creating a new app using oc new-app location/nameofapp, many things are created: a deploymentConfig, an imagestream, a service, etc. I know you can run oc delete <label>. I would like to know how to delete all of these given the label.
",<docker><openshift><redhat><kubernetes><openshift-origin>,9,"docker,openshift,redhat,kubernetes,openshift-origin",['how do you remove the deploymentconfig image streams etc using openshift oc'],"['after creating a new app using oc newapp locationnameofapp many things are created a deploymentconfig an imagestream a service etc', 'i know you can run oc delete label', 'i would like to know how to delete all of these given the label']"
"I get ""Authorization has been denied for this request."" error message when using OWIN oAuth middleware (with separate Auth and Resource Server)","I am attempting to decouple my auth and resource server. I am following the example provided in this tutorial:
http://bitoftech.net/2014/09/24/decouple-owin-authorization-server-resource-server-oauth-2-0-web-api/
This is the code in my Startup.cs in my auth server:
using Microsoft.Owin;
using Microsoft.Owin.Security.OAuth;
using Owin;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Web;

namespace AuthServer.Web
{
   public class xxxxx
   {
      public void Configuration(IAppBuilder app) {
         ConfigureOAuth(app);
      }

      public void ConfigureOAuth(IAppBuilder app)
      {
         OAuthAuthorizationServerOptions OAuthServerOptions = new OAuthAuthorizationServerOptions()
         {
            AllowInsecureHttp = true,
            TokenEndpointPath = new PathString(""/token""),
            AccessTokenExpireTimeSpan = TimeSpan.FromDays(1),
            Provider = new SimpleAuthorizationServerProvider()
         };

         // Token Generation
         app.UseOAuthAuthorizationServer(OAuthServerOptions);
         app.UseOAuthBearerAuthentication(new OAuthBearerAuthenticationOptions());

      }
   }
}

This is the startup.cs in my resource server (i.e. my sample Web api application):
using Microsoft.Owin.Security.OAuth;
using Owin;
using System;
using System.Collections.Generic;
using System.Linq;
using System.Web;

namespace AuthTestApi.Web
{
   public class Startup
   {
      public void Configuration(IAppBuilder app)
      {
         app.UseOAuthBearerAuthentication(new OAuthBearerAuthenticationOptions());
         app.UseCors(Microsoft.Owin.Cors.CorsOptions.AllowAll);
      }      
   }
}

When I post the following request to the ""\token"" endpoint of my auth server I sucessfully receive a token:
{
access_token: ""PszrzJUtQUhX42GMryWjZiVHuKiJ9yCVH_1tZURumtC5mTj2tpuRDF3tXcN_VNIYuXY40IG0K7W3KASfJ9DlNIU2jMOkL2U5oEAXLNRRQuNYdEJ7dMPb14nW19JIaM4BMk00xfQ8MFRw0p6-uoh0-e-Q6iAiTwDNN3F7bYMF9qm874qhLWEcOt6dWQgwpdDUVPDi7F07-Ck0zAs48Dg5w4q93vDpFaQMrziJg9aaxN8"",
token_type: ""bearer"",
expires_in: 86399
}

When I post the following request to my controller I receive the ""Authorization has been denied for this request"" error message?
GET /api/Test HTTP/1.1
Host: localhost:63305
Accept: application/json
Content-Type: application/json
Authorization: Bearer PszrzJUtQUhX42GMryWjZiVHuKiJ9yCVH_1tZURumtC5mTj2tpuRDF3tXcN_VNIYuXY40IG0K7W3KASfJ9DlNIU2jMOkL2U5oEAXLNRRQuNYdEJ7dMPb14nW19JIaM4BMk00xfQ8MFRw0p6-uoh0-e-Q6iAiTwDNN3F7bYMF9qm874qhLWEcOt6dWQgwpdDUVPDi7F07-Ck0zAs48Dg5w4q93vDpFaQMrziJg9aaxN8
Cache-Control: no-cache
Postman-Token: aeca8515-70b1-ef2c-f317-bf66136dccab

My auth server and resource / web api projects are in different solutions and are running on different ports (...not sure if that matters but thought Id mention it).
At this point these 2 projects are making use of oAuth OWIN middleware (and has very little custom code). The middleware is blackbox somewhat and just need some assistance in figuring out why I am receiving this error message.
Also note that the I am running both servers in two Visual Studio 2013 Web application projects that are in different VS 2013 solutions that are running on different ports. I am not sure if that matters but thought I would mention it.
Thanks in advance.
",<asp.net><asp.net-web-api><oauth><oauth-2.0><owin>,26,"asp.net,asp.net-web-api,oauth,oauth-2.0,owin","['i get authorization has been denied for this request', 'error message when using owin oauth middleware with separate auth and resource server']","['i am attempting to decouple my auth and resource server', 'i am following the example provided in this tutorial this is the code in my startupcs in my auth server using microsoftowin using microsoftowinsecurityoauth using owin using system using systemcollectionsgeneric using systemlinq using systemweb namespace authserverweb public class xxxxx public void configurationiappbuilder app configureoauthapp public void configureoauthiappbuilder app oauthauthorizationserveroptions oauthserveroptions new oauthauthorizationserveroptions allowinsecurehttp true tokenendpointpath new pathstringtoken accesstokenexpiretimespan timespanfromdays1 provider new simpleauthorizationserverprovider token generation appuseoauthauthorizationserveroauthserveroptions appuseoauthbearerauthenticationnew oauthbearerauthenticationoptions this is the startupcs in my resource server ie', 'my sample web api application using microsoftowinsecurityoauth using owin using system using systemcollectionsgeneric using systemlinq using systemweb namespace authtestapiweb public class startup public void configurationiappbuilder app appuseoauthbearerauthenticationnew oauthbearerauthenticationoptions appusecorsmicrosoftowincorscorsoptionsallowall when i post the following request to the token endpoint of my auth server i sucessfully receive a token accesstoken pszrzjutquhx42gmrywjzivhukij9ycvh1tzurumtc5mtj2tpurdf3txcnvniyuxy40ig0k7w3kasfj9dlniu2jmokl2u5oeaxlnrrqunydej7dmpb14nw19jiam4bmk00xfq8mfrw0p6uoh0eq6iaitwdnn3f7bymf9qm874qhlwecot6dwqgwpdduvpdi7f07ck0zas48dg5w4q93vdpfaqmrzijg9aaxn8 tokentype bearer expiresin 86399 when i post the following request to my controller i receive the authorization has been denied for this request error message', 'get apitest http11 host localhost63305 accept applicationjson contenttype applicationjson authorization bearer pszrzjutquhx42gmrywjzivhukij9ycvh1tzurumtc5mtj2tpurdf3txcnvniyuxy40ig0k7w3kasfj9dlniu2jmokl2u5oeaxlnrrqunydej7dmpb14nw19jiam4bmk00xfq8mfrw0p6uoh0eq6iaitwdnn3f7bymf9qm874qhlwecot6dwqgwpdduvpdi7f07ck0zas48dg5w4q93vdpfaqmrzijg9aaxn8 cachecontrol nocache postmantoken aeca851570b1ef2cf317bf66136dccab my auth server and resource web api projects are in different solutions and are running on different ports not sure if that matters but thought id mention it', 'at this point these 2 projects are making use of oauth owin middleware and has very little custom code', 'the middleware is blackbox somewhat and just need some assistance in figuring out why i am receiving this error message', 'also note that the i am running both servers in two visual studio 2013 web application projects that are in different vs 2013 solutions that are running on different ports', 'i am not sure if that matters but thought i would mention it', 'thanks in advance']"
Is it possible to use just 1 UDPSocket for sending/receiving on the same port?,"I'm trying to send a DatagramPacket, and then must wait for an Acknowlegment from sever, so that I know if I have to resend the same packet or send the next one.. 
I'm using for that the same socket on the client, to send the datapacket and to receive the acknowlegment (ack), and same in the server's side, another socket that is used to receive the datapacket and then to send the acknowledgment to the client.. 
The 1st problem is that the client is sending the datapacket, the server is receiving it, then sends the acknowledgment to client, but the client blocks on receiving the Acknowledgment-packet. 
I'm making some System.out.println to identify where is the problem, but I couldnt find any solution to this problem.
The 2nd problem is that the Server is still always receiving data, and dont wait for the client to send something, i checked that because i got that lines(like ""got packet with length xxx"" ""ack sent with ackNr yyy"" ..."" printed on the server's side, all the time although the client is blocking after sending the 1st packet, because it's waiting for the acknowledgment that is not received! 
Here is the CLIENT's code:
package blatt7;

import java.io.File;
import java.io.FileInputStream;
import java.io.FileNotFoundException;
import java.io.IOException;
import java.net.DatagramPacket;
import java.net.DatagramSocket;
import java.net.InetAddress;
import java.net.SocketTimeoutException;
import java.net.UnknownHostException;
import java.nio.ByteBuffer;
import java.util.zip.CRC32;




public class FileSender { 


String zielRechner;
String filePath;
InetAddress host;
File file;
FileInputStream fis;
int readLength;
int sequenceNr = 0;
int receivedSeqNr = 1;
static int port = 7777;
int packetNr = 0;
byte[] packet = new byte[1216];
byte[] data = new byte[1200];
byte[] header = new byte[16];
byte[] readLengthByte = new byte[4];
byte[] sequenceNrByte = new byte[4];
byte[] checksumByte = new byte[8];
byte[] ackBuffer = new byte[4];
CRC32 checksumCalculator = new CRC32();
DatagramPacket dp;
DatagramPacket ackPacket;
DatagramSocket sendSocket = null;
//DatagramSocket ackSocket = null;
static boolean ackReceived = true;

public FileSender(String zielRechner, String filePath) throws UnknownHostException, FileNotFoundException {
    this.zielRechner = zielRechner;
    this.filePath = filePath;
    this.host = InetAddress.getByName(zielRechner);
    this.file = new File(filePath);
    fis = new FileInputStream(file);        
}

public void sendFile() throws IOException {

    while((readLength = fis.read(data)) != -1) {
        if (sequenceNr == 1)
            sequenceNr = 0;
        else
            sequenceNr = 1;

        readLengthByte = intToBytes(readLength);
        sequenceNrByte = intToBytes(sequenceNr);

        for(int i=0; i<4; i++) {
            header[8+i] = readLengthByte[i];                
        }

        for(int i=0; i<4; i++) {
            header[12+i] =sequenceNrByte[i];                
        }

        int j=0; 
        for (int i=0; i<packet.length; i++) {
            if (i < header.length) 
                packet[i] = header[i];
            else { 
                packet[i] = data[j];
                j++;
            }
        }

        checksumCalculator.reset();
        checksumCalculator.update(packet,8,8+readLength);
        checksumByte = longToBytes(checksumCalculator.getValue());

        for(int i=0; i < 8; i++) {
            packet[i] = checksumByte[i];
        }

        dp = new DatagramPacket(packet, packet.length, host, port);

        while(receivedSeqNr == sequenceNr && ackReceived) {
            try {
                ackReceived = false;
                sendSocket = new DatagramSocket();
                sendSocket.send(dp);
                sendSocket.setSoTimeout(10000);
                packetNr++;
                System.out.println(""Packet sent with seqNr: "" + sequenceNr + "" and length: "" + bytesToInt(readLengthByte, 0) + "" - PACKET NR: "" + packetNr);
                ackPacket = new DatagramPacket(ackBuffer, ackBuffer.length);
                System.out.println(""TEST!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"");
                sendSocket.receive(ackPacket);
                System.out.println(""Receiving ACK!!"");
                ackReceived = true;
                ackBuffer = ackPacket.getData();
                receivedSeqNr = bytesToInt(ackBuffer,0);
                System.out.println(""got SequenceNr with receivedSeq-Nr: "" + receivedSeqNr);
            } catch (SocketTimeoutException e) {
                    e.printStackTrace();
                    break;
            }
        }   
    }

    fis.close();
    System.out.println(""Transfer Completed Successfully!"");
    sendSocket.close();
}

public static byte[] longToBytes(long value) {
    ByteBuffer buffer = ByteBuffer.allocate(8);
    buffer.putLong(value);
    return buffer.array();
}

public static long bytesToLong(byte[] bytes, int index) {
    ByteBuffer buffer = ByteBuffer.allocate(8);
    buffer.put(bytes);
    buffer.flip();//need flip 
    return buffer.getLong(index);
}

public static byte[] intToBytes(int value) {
    ByteBuffer buffer = ByteBuffer.allocate(4);
    buffer.putInt(value);
    return buffer.array();
}

public static int bytesToInt(byte[] bytes, int index) {
    ByteBuffer buffer = ByteBuffer.allocate(4);
    buffer.put(bytes);
    buffer.flip();//need flip 
    return buffer.getInt(index);
}

public static void main(String[] args) throws IOException,ClassNotFoundException {

    FileSender sender = new FileSender(""localhost"", ""C:/Users/Kb/Desktop/Deepophile - Psychedelic Sessions.wav"");
    sender.sendFile();

}

}

and here is the SERVER's code:
package blatt7;

import java.io.IOException;
import java.net.DatagramPacket;
import java.net.DatagramSocket;
import java.net.InetAddress;
import java.net.SocketException;
import java.util.zip.CRC32;

public class FileReceiver {

byte[] incomingBuffer;
DatagramPacket incomingPacket;
DatagramSocket receiveSocket;
DatagramPacket ackPacket;
int packetCounter = 0;
int dataLength;
int receivedSeqNr;
long calculatedChecksum;
long receivedChecksum;
CRC32 checksumCalculator = new CRC32();
byte[] dataLengthByte = new byte[4];
byte[] receivedSeqNrByte = new byte[4];
byte[] receivedChecksumByte = new byte[8];
byte[] ackArray;


public FileReceiver() throws SocketException {
    incomingBuffer = new byte[1500];
    incomingPacket = new DatagramPacket(incomingBuffer, incomingBuffer.length);
}

public void receive() throws IOException {

    receiveSocket = new DatagramSocket(FileSender.port);
    receiveSocket.setSoTimeout(10000);
    System.out.println(""Server socket created. Waiting for incoming data..."");

    while(true && FileSender.ackReceived)
    {   
        receiveSocket.receive(incomingPacket);
        packetCounter++;

        for (int i=0; i <4; i++) {
            dataLengthByte[i] = incomingBuffer[8+i];
        }
        dataLength = FileSender.bytesToInt(dataLengthByte,0);

        checksumCalculator.reset();
        checksumCalculator.update(incomingBuffer, 8, dataLength+8);             
        calculatedChecksum = checksumCalculator.getValue();


        for (int i=0; i <4; i++) {
            receivedSeqNrByte[i] = incomingBuffer[12+i];
        }
        receivedSeqNr = FileSender.bytesToInt(receivedSeqNrByte,0);


        for (int i=0; i <8; i++) {
            receivedChecksumByte[i] = incomingBuffer[i];
        }
        long receivedChecksum = FileSender.bytesToLong(receivedChecksumByte,0);

        System.out.println(""Got packet with checksum: "" + receivedChecksum);
        System.out.println(""Server-calculated checksum: "" + calculatedChecksum);
        System.out.println(""Got packet with seqNr: "" + receivedSeqNr + "" and length: "" + dataLength);

        if (calculatedChecksum != receivedChecksum)  {
            sendACK(receivedSeqNr);
            System.out.println(""Packet have erros(s)! It must be sent another time!"");
        }
        else if(calculatedChecksum == receivedChecksum && receivedSeqNr == 1) {
            sendACK(0);
            System.out.println(""SeqNr '0' sent"");
        }
        else if (calculatedChecksum == receivedChecksum && receivedSeqNr == 0) {
            sendACK(1);
            System.out.println(""SeqNr '1' sent"");
        }
    }
}

public void sendACK(int seqNum) throws IOException {
    byte[] ackArray = FileSender.intToBytes(seqNum);
    ackPacket = new DatagramPacket(ackArray, ackArray.length, InetAddress.getByName(""localhost""), FileSender.port);
    receiveSocket.send(ackPacket);      
}

public static void main(String[] args) throws IOException,ClassNotFoundException {
    FileReceiver receiver = new FileReceiver();
    receiver.receive();     
}

}

You can try to execute it to see where the problem is... 
So PLEASE if you have ANY idea how can I solve this problem, let me know!
Thankyou verymuch!
Can anyone tell me where to find the received file? or how should I change my code so that I choose where to save it??
",<java><networking><udp><packet><datagram>,6,"java,networking,udp,packet,datagram",['is it possible to use just 1 udpsocket for sendingreceiving on the same port'],"['im trying to send a datagrampacket and then must wait for an acknowlegment from sever so that i know if i have to resend the same packet or send the next one im using for that the same socket on the client to send the datapacket and to receive the acknowlegment ack and same in the servers side another socket that is used to receive the datapacket and then to send the acknowledgment to the client the 1st problem is that the client is sending the datapacket the server is receiving it then sends the acknowledgment to client but the client blocks on receiving the acknowledgmentpacket', 'im making some systemoutprintln to identify where is the problem but i couldnt find any solution to this problem', 'the 2nd problem is that the server is still always receiving data and dont wait for the client to send something i checked that because i got that lineslike got packet with length xxx ack sent with acknr yyy printed on the servers side all the time although the client is blocking after sending the 1st packet because its waiting for the acknowledgment that is not received', 'here is the clients code package blatt7 import javaiofile import javaiofileinputstream import javaiofilenotfoundexception import javaioioexception import javanetdatagrampacket import javanetdatagramsocket import javanetinetaddress import javanetsockettimeoutexception import javanetunknownhostexception import javaniobytebuffer import javautilzipcrc32 public class filesender string zielrechner string filepath inetaddress host file file fileinputstream fis int readlength int sequencenr 0 int receivedseqnr 1 static int port 7777 int packetnr 0 byte packet new byte1216 byte data new byte1200 byte header new byte16 byte readlengthbyte new byte4 byte sequencenrbyte new byte4 byte checksumbyte new byte8 byte ackbuffer new byte4 crc32 checksumcalculator new crc32 datagrampacket dp datagrampacket ackpacket datagramsocket sendsocket null datagramsocket acksocket null static boolean ackreceived true public filesenderstring zielrechner string filepath throws unknownhostexception filenotfoundexception thiszielrechner zielrechner thisfilepath filepath thishost inetaddressgetbynamezielrechner thisfile new filefilepath fis new fileinputstreamfile public void sendfile throws ioexception whilereadlength fisreaddata 1 if sequencenr 1 sequencenr 0 else sequencenr 1 readlengthbyte inttobytesreadlength sequencenrbyte inttobytessequencenr forint i0 i4 i header8i readlengthbytei forint i0 i4 i header12i sequencenrbytei int j0 for int i0 ipacketlength i if i headerlength packeti headeri else packeti dataj j checksumcalculatorreset checksumcalculatorupdatepacket88readlength checksumbyte longtobyteschecksumcalculatorgetvalue forint i0 i 8 i packeti checksumbytei dp new datagrampacketpacket packetlength host port whilereceivedseqnr sequencenr ackreceived try ackreceived false sendsocket new datagramsocket sendsocketsenddp sendsocketsetsotimeout10000 packetnr systemoutprintlnpacket sent with seqnr sequencenr and length bytestointreadlengthbyte 0 packet nr packetnr ackpacket new datagrampacketackbuffer ackbufferlength systemoutprintlntest', ' sendsocketreceiveackpacket systemoutprintlnreceiving ack', ' ackreceived true ackbuffer ackpacketgetdata receivedseqnr bytestointackbuffer0 systemoutprintlngot sequencenr with receivedseqnr receivedseqnr catch sockettimeoutexception e eprintstacktrace break fisclose systemoutprintlntransfer completed successfully', ' sendsocketclose public static byte longtobyteslong value bytebuffer buffer bytebufferallocate8 bufferputlongvalue return bufferarray public static long bytestolongbyte bytes int index bytebuffer buffer bytebufferallocate8 bufferputbytes bufferflipneed flip return buffergetlongindex public static byte inttobytesint value bytebuffer buffer bytebufferallocate4 bufferputintvalue return bufferarray public static int bytestointbyte bytes int index bytebuffer buffer bytebufferallocate4 bufferputbytes bufferflipneed flip return buffergetintindex public static void mainstring args throws ioexceptionclassnotfoundexception filesender sender new filesenderlocalhost cuserskbdesktopdeepophile psychedelic sessionswav sendersendfile and here is the servers code package blatt7 import javaioioexception import javanetdatagrampacket import javanetdatagramsocket import javanetinetaddress import javanetsocketexception import javautilzipcrc32 public class filereceiver byte incomingbuffer datagrampacket incomingpacket datagramsocket receivesocket datagrampacket ackpacket int packetcounter 0 int datalength int receivedseqnr long calculatedchecksum long receivedchecksum crc32 checksumcalculator new crc32 byte datalengthbyte new byte4 byte receivedseqnrbyte new byte4 byte receivedchecksumbyte new byte8 byte ackarray public filereceiver throws socketexception incomingbuffer new byte1500 incomingpacket new datagrampacketincomingbuffer incomingbufferlength public void receive throws ioexception receivesocket new datagramsocketfilesenderport receivesocketsetsotimeout10000 systemoutprintlnserver socket created', 'waiting for incoming data whiletrue filesenderackreceived receivesocketreceiveincomingpacket packetcounter for int i0 i 4 i datalengthbytei incomingbuffer8i datalength filesenderbytestointdatalengthbyte0 checksumcalculatorreset checksumcalculatorupdateincomingbuffer 8 datalength8 calculatedchecksum checksumcalculatorgetvalue for int i0 i 4 i receivedseqnrbytei incomingbuffer12i receivedseqnr filesenderbytestointreceivedseqnrbyte0 for int i0 i 8 i receivedchecksumbytei incomingbufferi long receivedchecksum filesenderbytestolongreceivedchecksumbyte0 systemoutprintlngot packet with checksum receivedchecksum systemoutprintlnservercalculated checksum calculatedchecksum systemoutprintlngot packet with seqnr receivedseqnr and length datalength if calculatedchecksum receivedchecksum sendackreceivedseqnr systemoutprintlnpacket have erross', 'it must be sent another time', ' else ifcalculatedchecksum receivedchecksum receivedseqnr 1 sendack0 systemoutprintlnseqnr 0 sent else if calculatedchecksum receivedchecksum receivedseqnr 0 sendack1 systemoutprintlnseqnr 1 sent public void sendackint seqnum throws ioexception byte ackarray filesenderinttobytesseqnum ackpacket new datagrampacketackarray ackarraylength inetaddressgetbynamelocalhost filesenderport receivesocketsendackpacket public static void mainstring args throws ioexceptionclassnotfoundexception filereceiver receiver new filereceiver receiverreceive you can try to execute it to see where the problem is so please if you have any idea how can i solve this problem let me know', 'thankyou verymuch', 'can anyone tell me where to find the received file', 'or how should i change my code so that i choose where to save it', '']"
How to Shrink WebView size dynamically according to its content?,"A detailed explanation of issue can be understood from this question as the user had added image to explain it better.
I am loading Html content in my WebView. My layout is having many view and WebView is place inside ScrollView(as per layout requirement). Please don't answer as - ""Don't put WebView inside ScrollView"". I know that its not a good thing to put WebView inside a ScrollView, but as per requirement I need to do so. 
So, I have Left Fragment(showing List Items) and Right Fragment(Showing data reflected on selection of List Item from Left Fragment). Now, first of all when I load Html content inside WebV it shows correct. After that when I refresh WebView with new Html content the problem occurs.
Suppose, my first Html content is of 100 lines it shows correctly and then I reload WebView with my new Html content which is of 40 lines then the WebView is not shrinking and fitting to the content with 40 lines, it still remains as long as 100 lines showing white/blank space at the bottom.
So, it seems that WebView is able to re-size itself from less content which is previously loaded to more content but unable to re-size itself when the content is less than previously loaded content.
I had tried many ways,

Adding android:hardwareAccelerated=""true"" in Manifest
This Blog
Also many other ways and blog
Also I had tried to use mWebView.clearView(); which causes to re-size the size of WebView but at times the WebView start blinking which is just annoying. Similar to this video

But, couldn't find any proper solution. If anyone of you have the same issue before just let me know the best solution I could apply.
UPDATE -
After further googling it seems that this is a well-known issue in Honeycomb. This question also indicates the similar issue.
",<android><performance><android-layout><webview><android-widget>,28,"android,performance,android-layout,webview,android-widget",['how to shrink webview size dynamically according to its content'],"['a detailed explanation of issue can be understood from this question as the user had added image to explain it better', 'i am loading html content in my webview', 'my layout is having many view and webview is place inside scrollviewas per layout requirement', 'please dont answer as dont put webview inside scrollview', 'i know that its not a good thing to put webview inside a scrollview but as per requirement i need to do so', 'so i have left fragmentshowing list items and right fragmentshowing data reflected on selection of list item from left fragment', 'now first of all when i load html content inside webv it shows correct', 'after that when i refresh webview with new html content the problem occurs', 'suppose my first html content is of 100 lines it shows correctly and then i reload webview with my new html content which is of 40 lines then the webview is not shrinking and fitting to the content with 40 lines it still remains as long as 100 lines showing whiteblank space at the bottom', 'so it seems that webview is able to resize itself from less content which is previously loaded to more content but unable to resize itself when the content is less than previously loaded content', 'i had tried many ways adding androidhardwareacceleratedtrue in manifest this blog also many other ways and blog also i had tried to use mwebviewclearview which causes to resize the size of webview but at times the webview start blinking which is just annoying', 'similar to this video but couldnt find any proper solution', 'if anyone of you have the same issue before just let me know the best solution i could apply', 'update after further googling it seems that this is a wellknown issue in honeycomb', 'this question also indicates the similar issue']"
Seaborn multiple barplots,"I have a pandas dataframe that looks like this:
    class       men       woman   children
0   first   0.91468    0.667971   0.660562
1   second  0.30012    0.329380   0.882608
2   third   0.11899    0.189747   0.121259

How would I create a plot using seaborn that looks like this? Do I have to rearrange my data in some way?

(source: mwaskom at stanford.edu)
",<python><pandas><matplotlib><seaborn><grouped-bar-chart>,46,"python,pandas,matplotlib,seaborn,grouped-bar-chart",['seaborn multiple barplots'],"['i have a pandas dataframe that looks like this class men woman children 0 first 091468 0667971 0660562 1 second 030012 0329380 0882608 2 third 011899 0189747 0121259 how would i create a plot using seaborn that looks like this', 'do i have to rearrange my data in some way', 'source mwaskom at stanfordedu']"
How to use Update query in Flask Peewee?,"Hi I am using Flask Peewee and trying to update merchant_details model but it is not working.
Following is the error I am getting:

AttributeError: 'SelectQuery' object has no attribute 'update'

mdetails = merchant_details.filter(merchant_details.merchant_id==session['userid']).update(
         merchant_name=request.form['merchantname'],
          first_name=request.form['firstname'],
          last_name=request.form['lastname'],
        )

Please Help!
",<python><flask><models><flask-wtforms><peewee>,7,"python,flask,models,flask-wtforms,peewee",['how to use update query in flask peewee'],"['hi i am using flask peewee and trying to update merchantdetails model but it is not working', 'following is the error i am getting attributeerror selectquery object has no attribute update mdetails merchantdetailsfiltermerchantdetailsmerchantidsessionuseridupdate merchantnamerequestformmerchantname firstnamerequestformfirstname lastnamerequestformlastname please help']"
having cv2.imread reading images from file objects or memory-stream-like data (here non-extracted tar),"I have a .tar file containing several hundreds of pictures (.png). I need to process them via opencv. 
I am wondering whether - for efficiency reasons - it is possible to process them without passing by the disc. In other, words I want to read the pictures from the memory stream related to the tar file.
Consider for instance
 import tarfile
 import cv2

 tar0 = tarfile.open('mytar.tar')
 im = cv2.imread( tar0.extractfile('fname.png').read() )

The last line doesn't work as imread expects a file name rather than a stream.
Consider that this way of reading directly from the tar stream can be achieved e.g. for text (see e.g. this SO question).

Any suggestion to open the stream with the correct png encoding?
Untarring to ramdisk is of course an option, although I was looking for something more cachable.
",<python><performance><opencv><tar><imread>,8,"python,performance,opencv,tar,imread",['having cv2imread reading images from file objects or memorystreamlike data here nonextracted tar'],"['i have a tar file containing several hundreds of pictures png', 'i need to process them via opencv', 'i am wondering whether for efficiency reasons it is possible to process them without passing by the disc', 'in other words i want to read the pictures from the memory stream related to the tar file', 'consider for instance import tarfile import cv2 tar0 tarfileopenmytartar im cv2imread tar0extractfilefnamepngread the last line doesnt work as imread expects a file name rather than a stream', 'consider that this way of reading directly from the tar stream can be achieved eg', 'for text see eg', 'this so question', 'any suggestion to open the stream with the correct png encoding', 'untarring to ramdisk is of course an option although i was looking for something more cachable']"
Apollo MockedProvider not returning expected data,"I wrote a hook that calls apollo useQuery. It's pretty simple:
useDecider:
import { useState } from 'react';
import { useQuery, gql } from '@apollo/client';

export const GET_DECIDER = gql`
  query GetDecider($name: [String]!) {
    deciders(names: $name) {
      decision
      name
      value
    }
  }
`;

export const useDecider = name => {
  const [enabled, setEnabled] = useState(false);

  useQuery(GET_DECIDER, {
    variables: {
      name
    },
    onCompleted: data => {
      const decision = data?.deciders[0]?.decision;
      setEnabled(decision);
    },

    onError: error => {
      return error;
    }
  });

  return {
    enabled
  };
};

I'm trying to test it now and the MockedProvider is not returning the expected data:
import React from 'react';
import { render, screen } from '@testing-library/react';
import '@testing-library/jest-dom';
import { MockedProvider } from '@apollo/client/testing';
import { useDecider, GET_DECIDER } from './useDecider';

const getMock = (value = false, decider = '') => [
  {
    request: {
      query: GET_DECIDER,
      variables: {
        name: decider
      }
    },
    result: () => {
      console.log('APOLLO RESULT');

      return {
        data: {
          deciders: [
            {
              decision: value,
              name: decider,
              value: 10
            }
          ]
        }
      };
    }
  }
];

const FakeComponent = ({ decider }) => {
  const { enabled } = useDecider(decider);
  return <div>{enabled ? 'isEnabled' : 'isDisabled'}</div>;
};

const WrappedComponent = ({ decider, value }) => (
  <MockedProvider mocks={getMock(value, decider)} addTypename={false}>
    <FakeComponent decider={decider} />
  </MockedProvider>
);

describe('useDecider', () => {
  it('when decider returns true', () => {
    // should return true
    render(<WrappedComponent decider=""fake_decider"" value={true} />);
    screen.debug();
    const result = screen.getByText('isEnabled');
    expect(result).toBeInTheDocument();
  });
});

",<javascript><reactjs><apollo><react-apollo><apollo-client>,5,"javascript,reactjs,apollo,react-apollo,apollo-client",['apollo mockedprovider not returning expected data'],"['i wrote a hook that calls apollo usequery', 'its pretty simple usedecider import usestate from react import usequery gql from apolloclient export const getdecider gql query getdecidername string', ' decidersnames name decision name value export const usedecider name const enabled setenabled usestatefalse usequerygetdecider variables name oncompleted data const decision datadeciders0decision setenableddecision onerror error return error return enabled im trying to test it now and the mockedprovider is not returning the expected data import react from react import render screen from testinglibraryreact import testinglibraryjestdom import mockedprovider from apolloclienttesting import usedecider getdecider from usedecider const getmock value false decider request query getdecider variables name decider result consolelogapollo result return data deciders decision value name decider value 10 const fakecomponent decider const enabled usedeciderdecider return divenabled ', 'isenabled isdisableddiv const wrappedcomponent decider value mockedprovider mocksgetmockvalue decider addtypenamefalse fakecomponent deciderdecider mockedprovider describeusedecider itwhen decider returns true should return true renderwrappedcomponent deciderfakedecider valuetrue screendebug const result screengetbytextisenabled expectresulttobeinthedocument ']"
Best way to automatically check out and compile Eclipse projects with Ant in Hudson or another CI tool?,"We have several products which have a lot of shared code and which must be maintained several versions back.
To handle this we use a lot of Eclipse projects, some contain library jars, and some contain shared source code (in several projects to avoid getting a giant heap with numerous dependencies while being able to compile everything from scratch to ensure that source and binaries are consistent).  We manage those with projectSet.psf's as these can directly pull all projects out from CVS and leave a fully prepared workspace.  We do not do ant builds directly or use maven.
We now want to be able to put all these projects and their various versions in a Continous Integration tool -  I like Hudson but this is just a matter of taste - which essentially means that we need to get an automatic way to check out the projects to a fresh workspace, and compile the source folders as described in the project-files in each project.  Hudson does not provide such an approach to build a project, so I have been considering what the best way to approach this would be.
Ideas have been

Find or write an ant plugin/converter that understands projectSet.psf's and map to cvs-checkout and compile tags.
Create the build.xml files from within Eclipse and use those.  I tried this, and found the result to be verbose and with absolute locations which is not good with automatic tools putting files where they want to.
Write a Hudson plugin which understands projectSet.psf's to derive a configuration and build it.
Just bite the bullet and manually create and update the CI configuration whenever stuff breaks - I don't like this :)

I'd really like to hear about other peoples experiences so I can decide how to approach this.  

Edit: Another option might be using a CI which knows better about Eclipse projects and/or project sets.  We are not religious - this is just a matter of getting stuff running without having to do everything ourselves.  Would Cruise Control be a better option perhaps?  Others?

Edit:  Found that ant4eclipse has a ""Team Project Set"" facility.  http://ant4eclipse.sourceforge.net/

Edit: Used the ant4eclipse and ant-contrib ant extensions to build a complete workspace as a sjgned runnable jar file similar to the Runnable Jar facility in Eclipse 3.5M6.  I am still depending on Eclipse to create the initial empty workspace, and extract the ProjectSet, so that is the next hurdle.

Edit:  Ended up with a dual configuration, namely that Hudson extracts the same set of modules as listed in the ProjectSet.pdf file from CVS (which needs to have the same tag) causing them to be located next to each other.   Then ant4eclipse works well with the projectSet.psf file embedded in the main module.  Caveat:  Module list in Hudson must be manually updated, and it appears that a manual workspace cleanup is needed afterwards to let Hudson ""discover"" that there is more projects now than earlier.  This has now worked well for us for a couple of months, but it was quite tedious to get everything working inside the ant file.

Edit:  The ""Use Team Projects"" with ant4eclipse and a Ctrl-A, Ctrl-C in Project Panel with a Ctrl-V in the CVS projects in Hudson has turned out to work well enough for us to live with (for mature projects this is very rarely changed).  I am awaiting the release of ant4eclipse 1.0 - http://www.ant4eclipse.org/, currently in milestone 2 - to see how much homegrown functionality can be replaced with ant4eclipse things.
Edit:  ant4eclipse is as of 20100609 in M4 so the schedule at http://www.ant4eclipse.org/node?page=1 is slipping somewhat.

Edit:  My conclusion after using our ant4eclipse approach for a longer period is that the build script get very gnarly and is hard to maintain.  Also the Team ProjectSet facility (which ant4eclipse use to locate the projects) which works well for CVS based repositories, but not after we migrated to git (which is a big thing in itself).   New projects will most likely be based on maven, as this has good support in Jenkins.
",<java><eclipse><continuous-integration><hudson><cvs>,9,"java,eclipse,continuous-integration,hudson,cvs",['best way to automatically check out and compile eclipse projects with ant in hudson or another ci tool'],"['we have several products which have a lot of shared code and which must be maintained several versions back', 'to handle this we use a lot of eclipse projects some contain library jars and some contain shared source code in several projects to avoid getting a giant heap with numerous dependencies while being able to compile everything from scratch to ensure that source and binaries are consistent', 'we manage those with projectsetpsfs as these can directly pull all projects out from cvs and leave a fully prepared workspace', 'we do not do ant builds directly or use maven', 'we now want to be able to put all these projects and their various versions in a continous integration tool i like hudson but this is just a matter of taste which essentially means that we need to get an automatic way to check out the projects to a fresh workspace and compile the source folders as described in the projectfiles in each project', 'hudson does not provide such an approach to build a project so i have been considering what the best way to approach this would be', 'ideas have been find or write an ant pluginconverter that understands projectsetpsfs and map to cvscheckout and compile tags', 'create the buildxml files from within eclipse and use those', 'i tried this and found the result to be verbose and with absolute locations which is not good with automatic tools putting files where they want to', 'write a hudson plugin which understands projectsetpsfs to derive a configuration and build it', 'just bite the bullet and manually create and update the ci configuration whenever stuff breaks i dont like this id really like to hear about other peoples experiences so i can decide how to approach this', 'edit another option might be using a ci which knows better about eclipse projects andor project sets', 'we are not religious this is just a matter of getting stuff running without having to do everything ourselves', 'would cruise control be a better option perhaps', 'others', 'edit found that ant4eclipse has a team project set facility', 'edit used the ant4eclipse and antcontrib ant extensions to build a complete workspace as a sjgned runnable jar file similar to the runnable jar facility in eclipse 35m6', 'i am still depending on eclipse to create the initial empty workspace and extract the projectset so that is the next hurdle', 'edit ended up with a dual configuration namely that hudson extracts the same set of modules as listed in the projectsetpdf file from cvs which needs to have the same tag causing them to be located next to each other', 'then ant4eclipse works well with the projectsetpsf file embedded in the main module', 'caveat module list in hudson must be manually updated and it appears that a manual workspace cleanup is needed afterwards to let hudson discover that there is more projects now than earlier', 'this has now worked well for us for a couple of months but it was quite tedious to get everything working inside the ant file', 'edit the use team projects with ant4eclipse and a ctrla ctrlc in project panel with a ctrlv in the cvs projects in hudson has turned out to work well enough for us to live with for mature projects this is very rarely changed', 'i am awaiting the release of ant4eclipse 10 currently in milestone 2 to see how much homegrown functionality can be replaced with ant4eclipse things', 'edit ant4eclipse is as of 20100609 in m4 so the schedule at is slipping somewhat', 'edit my conclusion after using our ant4eclipse approach for a longer period is that the build script get very gnarly and is hard to maintain', 'also the team projectset facility which ant4eclipse use to locate the projects which works well for cvs based repositories but not after we migrated to git which is a big thing in itself', 'new projects will most likely be based on maven as this has good support in jenkins']"
Comparing Java swing MVC with Android design pattern,"I'm doing a small research on design patterns in various platforms and I have prior experience in programming with Java.
While reading these posts: MVC pattern on Android and MVC architecture in Android,
I had an interesting question in mind: Why Java swing MVC can not be compared with Android development pattern? or Why we can't say that Android follows MVC? (in the context of overall ""look and feel"").
In one answer, someone clarified MVC as:

Model: What to render

View: How to render

Controller: Events, user input


OK. well, now what I understand is:
Java Swing MVC:

In Java swing MVC, component class is an abstract class for all
attributes in visual environment. There is a distinct keyword called
controls is used for some components such as buttons, lists etc.
So, all controls and components are part of Model in MVC.

Container inherits component. and there are several
LayoutManagers that defines layouts and place of components in
container. Also there are Listenershave to be registered with
according EventSources. So, they all are the View in MVC.

Class that implements Listener interface methods in which we put our main
logic and there are some EventClasses for each event. They all are
part of Controller in MVC.


putting all these examples together in an image; in swing MVC we have:

Android design pattern (visualizing as MVC):

I think widgets are same as controls here. Also, there are some
other EventSources.They all act as a Model.

View package has viewgroups (that also contains several kinds of
layouts.) and Listener interfaces. they all are the part of
View in MVC.

Same as swing MVC, we can say Listener interface methods and  activities are
the part of controller.


putting all together in an image; in Android we have:

As per above comparison, I consider following similarities:

Container - same as View

Layout managers - same as ViewGroup

Listeners - overall same in both architecture

controls - overall same as widgets

Event delegation (registering appropriate listener with Event source and then implementing Listener's methods) - overall same in both architecture


So, can anyone explain which are the things that makes the Android design pattern different than Java swing MVC pattern?
or If you believe that both are different things (in the context of design patterns used for development), then explain why?
",<java><android><swing><design-patterns><model-view-controller>,9,"java,android,swing,design-patterns,model-view-controller",['comparing java swing mvc with android design pattern'],"['im doing a small research on design patterns in various platforms and i have prior experience in programming with java', 'while reading these posts mvc pattern on android and mvc architecture in android i had an interesting question in mind why java swing mvc can not be compared with android development pattern', 'or why we cant say that android follows mvc', 'in the context of overall look and feel', 'in one answer someone clarified mvc as model what to render view how to render controller events user input ok well now what i understand is java swing mvc in java swing mvc component class is an abstract class for all attributes in visual environment', 'there is a distinct keyword called controls is used for some components such as buttons lists etc', 'so all controls and components are part of model in mvc', 'container inherits component', 'and there are several layoutmanagers that defines layouts and place of components in container', 'also there are listenershave to be registered with according eventsources', 'so they all are the view in mvc', 'class that implements listener interface methods in which we put our main logic and there are some eventclasses for each event', 'they all are part of controller in mvc', 'putting all these examples together in an image in swing mvc we have android design pattern visualizing as mvc i think widgets are same as controls here', 'also there are some other eventsourcesthey all act as a model', 'view package has viewgroups that also contains several kinds of layouts', 'and listener interfaces', 'they all are the part of view in mvc', 'same as swing mvc we can say listener interface methods and activities are the part of controller', 'putting all together in an image in android we have as per above comparison i consider following similarities container same as view layout managers same as viewgroup listeners overall same in both architecture controls overall same as widgets event delegation registering appropriate listener with event source and then implementing listeners methods overall same in both architecture so can anyone explain which are the things that makes the android design pattern different than java swing mvc pattern', 'or if you believe that both are different things in the context of design patterns used for development then explain why']"
Implement a read receipt feature in Firebase group messaging app,"I'd like to implement a 'Seen' feature in my Firebase group messaging app. Can you kindly advise the best and most efficient approach to take (working code will be appreciated)? For example, the app would show ""Seen by 6"" or ""Seen by 15"" on a group message.
Here's my project: https://github.com/firebase/friendlychat/tree/master/android
Here's the MainActivity: https://github.com/firebase/friendlychat/blob/master/android/app/src/main/java/com/google/firebase/codelab/friendlychat/MainActivity.java
",<java><android><firebase><firebase-realtime-database><firebase-cloud-messaging>,12,"java,android,firebase,firebase-realtime-database,firebase-cloud-messaging",['implement a read receipt feature in firebase group messaging app'],"['id like to implement a seen feature in my firebase group messaging app', 'can you kindly advise the best and most efficient approach to take working code will be appreciated', 'for example the app would show seen by 6 or seen by 15 on a group message', 'heres my project heres the mainactivity']"
Is it possible to edit file and commit github/bitbucket from browser,"I want to use editor in browser and save in github without server. Just like text editor in github/bitbucket could new file and save it
I want to know are there any REST api of this 2 services to easily commit file like that
Or a git library in js that could work without the need to pull all files in to our machine
edit:
After 2018 both service already expose their API. This question is outdated
",<github><bitbucket><github-api><git-commit><bitbucket-api>,7,"github,bitbucket,github-api,git-commit,bitbucket-api",['is it possible to edit file and commit githubbitbucket from browser'],"['i want to use editor in browser and save in github without server', 'just like text editor in githubbitbucket could new file and save it i want to know are there any rest api of this 2 services to easily commit file like that or a git library in js that could work without the need to pull all files in to our machine edit after 2018 both service already expose their api', 'this question is outdated']"
How to use Python distutils?,"I wrote a quick program in python to add a gtk GUI to a cli program. I was wondering how I can create an installer using distutils. Since it's just a GUI frontend for a command line app it only works in *nix anyway so I'm not worried about it being cross platform.
my main goal is to create a .deb package for debian/ubuntu users, but I don't understand make/configure files. I've primarily been a web developer up until now.
edit: Does anyone know of a project that uses distutils so I could see it in action and, you know, actually try building it?
Here are a few useful links

Ubuntu Python Packaging Guide
This Guide is very helpful. I don't know how I missed it during my initial wave of gooling. It even walks you through packaging up an existing python application
The Ubuntu MOTU Project
This is the official package maintaining project at ubuntu. Anyone can join, and there are lots of tutorials and info about creating packages, of all types, which include the above 'python packaging guide'.
""Python distutils to deb?"" - Ars Technica Forum discussion
According to this conversation, you can't just use distutils. It doesn't follow the debian packaging format (or something like that). I guess that's why you need dh_make as seen in the Ubuntu Packaging guide
""A bdist_deb command for distutils
This one has some interesting discussion (it's also how I found the ubuntu guide) about concatenating a zip-file and a shell script to create some kind of universal executable (anything with python and bash that is). weird. Let me know if anyone finds more info on this practice because I've never heard of it.
Description of the deb format and how distutils fit in - python mailing list

",<python><linux><installation><debian><distutils>,25,"python,linux,installation,debian,distutils",['how to use python distutils'],"['i wrote a quick program in python to add a gtk gui to a cli program', 'i was wondering how i can create an installer using distutils', 'since its just a gui frontend for a command line app it only works in nix anyway so im not worried about it being cross platform', 'my main goal is to create a deb package for debianubuntu users but i dont understand makeconfigure files', 'ive primarily been a web developer up until now', 'edit does anyone know of a project that uses distutils so i could see it in action and you know actually try building it', 'here are a few useful links ubuntu python packaging guide this guide is very helpful', 'i dont know how i missed it during my initial wave of gooling', 'it even walks you through packaging up an existing python application the ubuntu motu project this is the official package maintaining project at ubuntu', 'anyone can join and there are lots of tutorials and info about creating packages of all types which include the above python packaging guide', 'python distutils to deb', ' ars technica forum discussion according to this conversation you cant just use distutils', 'it doesnt follow the debian packaging format or something like that', 'i guess thats why you need dhmake as seen in the ubuntu packaging guide a bdistdeb command for distutils this one has some interesting discussion its also how i found the ubuntu guide about concatenating a zipfile and a shell script to create some kind of universal executable anything with python and bash that is', 'weird', 'let me know if anyone finds more info on this practice because ive never heard of it', 'description of the deb format and how distutils fit in python mailing list']"
NodeJS REST authentication using Passport and OAuth2 + social network,"I'm working on REST api using NodeJS. For authentication I decided to use Passport. I want truly RESTful api. So it means I have to use tokens instead of sessions. 
I want to let users login using username and password, or using social networks like Facebook, Google and Twitter. 
I make my own OAuth2.0 server for issuing Access and Refresh tokens using oauth2orize module. So now I can register new user and then issue them tokens. 
I followed this tutorial: 
http://aleksandrov.ws/2013/09/12/restful-api-with-nodejs-plus-mongodb/
Verifying user for route:
// api ------------------------------------------------------------------------------------
    app.get('/api/userInfo',
        passport.authenticate('bearer', { session: false }),
        function(req, res) {
            // req.authInfo is set using the `info` argument supplied by
            // `BearerStrategy`.  It is typically used to indicate scope of the token,
            // and used in access control checks.  For illustrative purposes, this
            // example simply returns the scope in the response.
            res.json({ user_id: req.user.userId, name: req.user.username, scope: req.authInfo.scope })
        }
    );

All this works quite well. Unfortunately I don't know how to implement social authentication.
I was reading this tutorial:
http://scotch.io/tutorials/javascript/easy-node-authentication-facebook 

But in this tutorial they are not making a truly RESTful api. I already implemented user schema according this tutorial where tokens for local user are stored in separated models.
// define the schema for our user model
var userSchema = mongoose.Schema({
    local: {
        username: {
            type: String,
            unique: true,
            required: true
        },
        hashedPassword: {
            type: String,
            required: true
        },
        created: {
            type: Date,
            default: Date.now
        }
    },
    facebook: {
        id: String,
        token: String,
        email: String,
        name: String
    },
    twitter: {
        id: String,
        token: String,
        displayName: String,
        username: String
    },
    google: {
        id: String,
        token: String,
        email: String,
        name: String
    }
});

But now, how can I verify user?
passport.authenticate('bearer', { session: false }),

this is verifying only bearer token against to my db, but how can I verify social tokens? Am I missing something? 
",<node.js><express><passport.js><access-token><facebook-access-token>,23,"node.js,express,passport.js,access-token,facebook-access-token",['nodejs rest authentication using passport and oauth2 social network'],"['im working on rest api using nodejs', 'for authentication i decided to use passport', 'i want truly restful api', 'so it means i have to use tokens instead of sessions', 'i want to let users login using username and password or using social networks like facebook google and twitter', 'i make my own oauth20 server for issuing access and refresh tokens using oauth2orize module', 'so now i can register new user and then issue them tokens', 'i followed this tutorial verifying user for route api appgetapiuserinfo passportauthenticatebearer session false functionreq res reqauthinfo is set using the info argument supplied by bearerstrategy', 'it is typically used to indicate scope of the token and used in access control checks', 'for illustrative purposes this example simply returns the scope in the response', 'resjson userid requseruserid name requserusername scope reqauthinfoscope all this works quite well', 'unfortunately i dont know how to implement social authentication', 'i was reading this tutorial but in this tutorial they are not making a truly restful api', 'i already implemented user schema according this tutorial where tokens for local user are stored in separated models', ' define the schema for our user model var userschema mongooseschema local username type string unique true required true hashedpassword type string required true created type date default datenow facebook id string token string email string name string twitter id string token string displayname string username string google id string token string email string name string but now how can i verify user', 'passportauthenticatebearer session false this is verifying only bearer token against to my db but how can i verify social tokens', 'am i missing something']"
Coerce types in different namespaces with Identical layout in C#,"I've started writing an interface for FedEx's webservice APIs.  They have 3 different APIs that I'm interested in; Rate, Ship, and Track.  I am generating the service proxies with SvcUtil.exe.
The different service endpoints are each specified by FedEx in their own WSDL files.  Each service endpoint has it's own xml namespace (e.g. http://fedex.com/ws/rate/v5 and http://fedex.com/ws/ship/v5)
The service endpoints do use quite a few identical types such as Address, Measurements, Weight, AuthenticationDetail, ClientDetail, etc...
And here is where the problem lies, I can provide all the WSDL files at the same time to SvcUtil.exe and normally it would coalesce any identical types into a single shared type, but since each of FedEx's services are in their own namespace, and they redeclare these types in each WSDL file under that namespace what I end up with instead is an Address, Address1, and Address2 one for each namespace.
To solve that issue, what I do now is to run each WSDL through svcutil separately and put them each in their own .NET namespace (e.g. FedEx.Rate, FedEx.Ship, FedEx.Track).  The problem with this is that now I have a distinct address type in each namespace (Fedex.Rate.Address, FedEx.Ship.Address).
This makes it difficult to generalize the code used between the services like a GetAuthenticationDetail() factory method so I don't have to repeat that code in every place I use the different services.
Is there any way in C# to Coerce FedEx.Rate.Address to FedEx.Ship.Address?
",<c#><.net><web-services><types><coerce>,13,"c#,.net,web-services,types,coerce",['coerce types in different namespaces with identical layout in c'],"['ive started writing an interface for fedexs webservice apis', 'they have 3 different apis that im interested in rate ship and track', 'i am generating the service proxies with svcutilexe', 'the different service endpoints are each specified by fedex in their own wsdl files', 'each service endpoint has its own xml namespace eg', 'and the service endpoints do use quite a few identical types such as address measurements weight authenticationdetail clientdetail etc and here is where the problem lies i can provide all the wsdl files at the same time to svcutilexe and normally it would coalesce any identical types into a single shared type but since each of fedexs services are in their own namespace and they redeclare these types in each wsdl file under that namespace what i end up with instead is an address address1 and address2 one for each namespace', 'to solve that issue what i do now is to run each wsdl through svcutil separately and put them each in their own net namespace eg', 'fedexrate fedexship fedextrack', 'the problem with this is that now i have a distinct address type in each namespace fedexrateaddress fedexshipaddress', 'this makes it difficult to generalize the code used between the services like a getauthenticationdetail factory method so i dont have to repeat that code in every place i use the different services', 'is there any way in c to coerce fedexrateaddress to fedexshipaddress']"
How do I programatically take a screenshot of an application in Linux?,"How do I programatically take a screenshot of an application in Linux? I'm using c++. Any idea? For windows there are a lot of resources but I can't find anything for linux
Any help?
Thanks
",<linux><api><unix><screenshot><printscreen>,7,"linux,api,unix,screenshot,printscreen",['how do i programatically take a screenshot of an application in linux'],"['how do i programatically take a screenshot of an application in linux', 'im using c', 'any idea', 'for windows there are a lot of resources but i cant find anything for linux any help', 'thanks']"
Could not load the template HTML file in Karma tests for a Angular directive,"Despite some people having the same issues (like [here][1] or [there][2]), I do not succeed to test my directive in my Angular (1.2.25) application.
Here is my project structure:
myapp
  +- src/main/java/resources/META-INF/resources/workflow/directives
  |   +- directives.js
  |   +- *.html  (all templates)
  +- src/test/javascript
      +- karma.conf.js
      +- spec/directives
          +- text-input.spec.js

(yes, not a good structure, but my Angular application is stuck in a Java project)
My karma configuration:
// Karma configuration
module.exports = function (config) {

    config.set({
        ...
        // base path, that will be used to resolve files and exclude
        basePath: '',
        // testing framework to use (jasmine/mocha/qunit/...)
        frameworks: ['jasmine'],
        // list of files / patterns to load in the browser
        files: [
            // Third parties dependencies: jQuery, Angular, Angular modules, Angular mocks
            '../../main/resources/META-INF/resources/workflow/bower_components/...', 

            // My directives
            '../../main/resources/META-INF/resources/workflow/directives/*.html',
            '../../main/resources/META-INF/resources/workflow/directives/*.js',

            // My application
            '../../main/resources/META-INF/resources/workflow/scripts/*.js',
            '../../main/resources/META-INF/resources/workflow/app/**/*.js',

            // My Test files
            'spec/directives/*.js'
        ],

        // list of files / patterns to exclude
        exclude: [],
        // web server port
        port: 8888,

        browsers: [ 'Chrome' ],

        // Which plugins to enable
        plugins: [
            'karma-ng-html2js-preprocessor',
            'karma-chrome-launcher',
            'karma-jasmine'
        ],

        preprocessors: {
            '../../main/resources/META-INF/resources/workflow/directives/*.html': [ 'ng-html2js' ]
        },
        ngHtml2JsPreprocessor: {
            // Not sure what to put here...
        },
        ...
    });
};

My test:
describe('directive: text-input', function() {
    var element, scope;
    beforeEach(module('myApp'));

    beforeEach(inject(function($rootScope, $compile) {
        scope = $rootScope.$new();
        element = '<div my-input-text data-label=""Foo"" data-model=""bar""></div>';
        element = $compile(element)(scope);
        scope.$digest();
    }));

    describe('basics tests', function() {
        it('should be editable', function () {
            expect(element.text()).toBe('Foo');
        });
    });
});

And the directive itself:
var myDirs = angular.module('my-directives', []);

// Text input
myDirs.directive('myInputText', function () {
    return {
        replace: true,
        templateUrl: 'directives/text-input.html',
        scope: {
            label: '=',
            readOnly: '=',
            code: '=',
            model: '='
        }
    };
});

When running the tests (grunt karma), I get that error:
Chrome 31.0.1650 (Windows 7) directive: text-input basics tests should be editable FAILED
    Error: Unexpected request: GET directives/text-input.html
    No more request expected

I still don't get what I do wrong in my preprocessor. I've tried a lot of different configuration in the ngHtml2JsPreprocessor, but the error is always the same.
I saw in the DEBUG logs that the pre processor is working on my template HTML files:
DEBUG [preprocessor.html2js]: Processing ""d:/dev/my-app/src/main/resources/META-INF/resources/workflow/directives/text-input.html"".

Thanks.
",<javascript><angularjs><angularjs-directive><karma-runner><karma-jasmine>,5,"javascript,angularjs,angularjs-directive,karma-runner,karma-jasmine",['could not load the template html file in karma tests for a angular directive'],"['despite some people having the same issues like here1 or there2 i do not succeed to test my directive in my angular 1225 application', 'here is my project structure myapp srcmainjavaresourcesmetainfresourcesworkflowdirectives directivesjs html all templates srctestjavascript karmaconfjs specdirectives textinputspecjs yes not a good structure but my angular application is stuck in a java project my karma configuration karma configuration moduleexports function config configset base path that will be used to resolve files and exclude basepath testing framework to use jasminemochaqunit frameworks jasmine list of files patterns to load in the browser files third parties dependencies jquery angular angular modules angular mocks mainresourcesmetainfresourcesworkflowbowercomponents my directives mainresourcesmetainfresourcesworkflowdirectiveshtml mainresourcesmetainfresourcesworkflowdirectivesjs my application mainresourcesmetainfresourcesworkflowscriptsjs mainresourcesmetainfresourcesworkflowappjs my test files specdirectivesjs list of files patterns to exclude exclude web server port port 8888 browsers chrome which plugins to enable plugins karmanghtml2jspreprocessor karmachromelauncher karmajasmine preprocessors mainresourcesmetainfresourcesworkflowdirectiveshtml nghtml2js nghtml2jspreprocessor not sure what to put here my test describedirective textinput function var element scope beforeeachmodulemyapp beforeeachinjectfunctionrootscope compile scope rootscopenew element div myinputtext datalabelfoo datamodelbardiv element compileelementscope scopedigest describebasics tests function itshould be editable function expectelementtexttobefoo and the directive itself var mydirs angularmodulemydirectives text input mydirsdirectivemyinputtext function return replace true templateurl directivestextinputhtml scope label readonly code model when running the tests grunt karma i get that error chrome 3101650 windows 7 directive textinput basics tests should be editable failed error unexpected request get directivestextinputhtml no more request expected i still dont get what i do wrong in my preprocessor', 'ive tried a lot of different configuration in the nghtml2jspreprocessor but the error is always the same', 'i saw in the debug logs that the pre processor is working on my template html files debug preprocessorhtml2js processing ddevmyappsrcmainresourcesmetainfresourcesworkflowdirectivestextinputhtml', 'thanks']"
How to scroll the UITableviewcell scroll up when the keyboard appears?,"
Possible Duplicate:
Table View scroll when text field begin editing iphone 

I have loaded many UITextFields in UITableview. Maximum i have 15 UITextFields in UITableView cells. I want to move(Scroll) up the the Cell when the Keyboard/UIActionSheet(UIPickerView) appears. Please suggest/guide me any sample code to solve this problem. Thanks in advance. 
",<iphone><uitableview><keyboard><scroll><appearance>,6,"iphone,uitableview,keyboard,scroll,appearance",['how to scroll the uitableviewcell scroll up when the keyboard appears'],"[' possible duplicate table view scroll when text field begin editing iphone i have loaded many uitextfields in uitableview', 'maximum i have 15 uitextfields in uitableview cells', 'i want to movescroll up the the cell when the keyboarduiactionsheetuipickerview appears', 'please suggestguide me any sample code to solve this problem', 'thanks in advance']"
Compiler does not deduce template parameters (map std::vector -> std::vector),"I have the following template.
template<typename T, typename U>
std::vector<U> map(const std::vector<T> &v, std::function<U(const T&)> f) {
    std::vector<U> res;
    res.reserve(v.size());
    std::transform(std::begin(v), std::end(v), std::end(res), f);
    return res;
}

When I use it in my code I have the specify the template parameters. Why is the compiler not able to deduce this for me? How do I have to change my template definition to make this work?
vector<int> numbers = { 1, 3, 5 };

// vector<string> strings = map(numbers, [] (int x) { return string(x,'X'); });

vector<string> strings = map<int, string>(numbers, [] (int x) { return string(x,'X'); });

Runnable code: http://ideone.com/FjGnxd
The original code in this question comes from here: The std::transform-like function that returns transformed container
",<c++><templates><c++11><vector><std>,11,"c++,templates,c++11,vector,std",['compiler does not deduce template parameters map stdvector stdvector'],"['i have the following template', 'templatetypename t typename u stdvectoru mapconst stdvectort v stdfunctionuconst t f stdvectoru res resreservevsize stdtransformstdbeginv stdendv stdendres f return res when i use it in my code i have the specify the template parameters', 'why is the compiler not able to deduce this for me', 'how do i have to change my template definition to make this work', 'vectorint numbers 1 3 5 vectorstring strings mapnumbers int x return stringxx vectorstring strings mapint stringnumbers int x return stringxx runnable code the original code in this question comes from here the stdtransformlike function that returns transformed container']"
Beautifulsoup split text in tag by <br/>,"Is it possible to split a text from a tag by br tags?
I have this tag contents: [u'+420 777 593 531', <br/>, u'+420 776 593 531', <br/>, u'+420 775 593 531']
And I want to get only numbers.
Any advices?
EDIT:
[x for x in dt.find_next_sibling('dd').contents if x!=' <br/>']

Does not work at all.
",<python><text><tags><beautifulsoup><newline>,10,"python,text,tags,beautifulsoup,newline",['beautifulsoup split text in tag by br'],"['is it possible to split a text from a tag by br tags', 'i have this tag contents u420 777 593 531 br u420 776 593 531 br u420 775 593 531 and i want to get only numbers', 'any advices', 'edit x for x in dtfindnextsiblingddcontents if x br does not work at all']"
Getting uncaughtException: Error: Cannot find module '...\.next\server\app\home\lib\worker.js' when trying to use pino.transport in Next.js,"I have created a Next.js project with typescript using create-next-app. For logging of this particular project I have decided to use Pino logging library as it is recommended by Next.js itself.
When I am using Pino without its transport functionality it runs perfectly fine. Below is pino definition code which run perfectly:-
import pino from 'pino';

const logger = pino({
    level: process.env.NEXT_PUBLIC_LOG_LEVEL,
    formatters: {
        level: (label) => {
            return { level: label.toUpperCase() };
        },
        bindings: (bindings) => {
            return { host: bindings.hostname };
        },
    },
});

export default logger;

But when I am using Pino transport, the code is mentioned below (I have installed pino-pretty as a dev dependency):-
import pino from 'pino';

const logger1 = pino({
    transport: {
        target: 'pino-pretty',
    },
});

logger1.info('hi');
export default logger1;


I get the below mentioned error
- error uncaughtException: Error: Cannot find module 'C:\starttwo-productionlot-frontend\.next\server\app\home\lib\worker.js'
    at Module._resolveFilename (node:internal/modules/cjs/loader:1075:15)
    at Module._load (node:internal/modules/cjs/loader:920:27)
    at Function.executeUserEntryPoint [as runMain] (node:internal/modules/run_main:81:12)
    at MessagePort.<anonymous> (node:internal/main/worker_thread:164:24)
    at [nodejs.internal.kHybridDispatch] (node:internal/event_target:737:20)
    at exports.emitMessage (node:internal/per_context/messageport:23:28) {
  digest: undefined
}
- error node_modules\thread-stream\index.js (195:31) @ Worker.onWorkerExit
- error uncaughtException: Error: the worker thread exited
    at Worker.onWorkerExit (webpack-internal:///(sc_server)/./node_modules/thread-stream/index.js:163:34)
    at Worker.emit (node:events:513:28)
    at [kOnExit] (node:internal/worker:289:10)
    at Worker.<computed>.onexit (node:internal/worker:209:20)
    at Worker.callbackTrampoline (node:internal/async_hooks:130:17) {
  digest: undefined
}


I get the same error with this code as well (Here i have a question, do we need to install pino/file using npm?):-
import pino from 'pino';
const transport = pino.transport({
  target: 'pino/file',
  options: { destination: '/path/to/file' }
})
pino(transport)

I am using the loggers on server side, that is only in next.js page.tsx file who does not have ""use client"" directive
Can you please me to solve this error
I tried implementing the sample code provided in pino official docs, but i get the same above mentioned error, the code was as follows:-
In my-transport.tsx:-
import { createWriteStream } from 'fs'

export default () => {
  return createWriteStream('.../app/app.log)')// /app/app.log -- location of log file 
}

In logger.tsx:-
const pino = require('pino')
const transport = pino.transport({
  target: '/absolute/path/to/my-transport.mjs'
})
export default pino(transport)

Is there any restriction on using pino.transport() in next.js. Can we use it in client as well as server side?
How can i use transport functionality in pino?
",<typescript><next.js><next.js13><pinojs><pino>,8,"typescript,next.js,next.js13,pinojs,pino",['getting uncaughtexception error cannot find module nextserverapphomelibworkerjs when trying to use pinotransport in nextjs'],"['i have created a nextjs project with typescript using createnextapp', 'for logging of this particular project i have decided to use pino logging library as it is recommended by nextjs itself', 'when i am using pino without its transport functionality it runs perfectly fine', 'below is pino definition code which run perfectly import pino from pino const logger pino level processenvnextpublicloglevel formatters level label return level labeltouppercase bindings bindings return host bindingshostname export default logger but when i am using pino transport the code is mentioned below i have installed pinopretty as a dev dependency import pino from pino const logger1 pino transport target pinopretty logger1infohi export default logger1 i get the below mentioned error error uncaughtexception error cannot find module cstarttwoproductionlotfrontendnextserverapphomelibworkerjs at moduleresolvefilename nodeinternalmodulescjsloader107515 at moduleload nodeinternalmodulescjsloader92027 at functionexecuteuserentrypoint as runmain nodeinternalmodulesrunmain8112 at messageportanonymous nodeinternalmainworkerthread16424 at nodejsinternalkhybriddispatch nodeinternaleventtarget73720 at exportsemitmessage nodeinternalpercontextmessageport2328 digest undefined error nodemodulesthreadstreamindexjs 19531 workeronworkerexit error uncaughtexception error the worker thread exited at workeronworkerexit webpackinternalscservernodemodulesthreadstreamindexjs16334 at workeremit nodeevents51328 at konexit nodeinternalworker28910 at workercomputedonexit nodeinternalworker20920 at workercallbacktrampoline nodeinternalasynchooks13017 digest undefined i get the same error with this code as well here i have a question do we need to install pinofile using npm', ' import pino from pino const transport pinotransport target pinofile options destination pathtofile pinotransport i am using the loggers on server side that is only in nextjs pagetsx file who does not have use client directive can you please me to solve this error i tried implementing the sample code provided in pino official docs but i get the same above mentioned error the code was as follows in mytransporttsx import createwritestream from fs export default return createwritestreamappapplog appapplog location of log file in loggertsx const pino requirepino const transport pinotransport target absolutepathtomytransportmjs export default pinotransport is there any restriction on using pinotransport in nextjs', 'can we use it in client as well as server side', 'how can i use transport functionality in pino']"
jQuery bounce moving out of place?,"I'm trying to use the jQuery UI bounce effect on a button positioned with css ""left"" on mouseover. It seems to work, however if you mouse over back and forth over it a few times it moves out of place and sticks to the left. I'm not really sure why it's doing this. Here's my code: http://jsbin.com/afoyiz/1/edit
",<javascript><jquery><html><css><bounce>,12,"javascript,jquery,html,css,bounce",['jquery bounce moving out of place'],"['im trying to use the jquery ui bounce effect on a button positioned with css left on mouseover', 'it seems to work however if you mouse over back and forth over it a few times it moves out of place and sticks to the left', 'im not really sure why its doing this', 'heres my code']"
Pytorch getting RuntimeError: Found dtype Double but expected Float,"I am trying to implement a neural net in PyTorch but it doesn't seem to work. The problem seems to be in the training loop. I've spend several hours into this but can't get it right. Please help, thanks.
I haven't added the data preprocessing parts.
# importing libraries
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
import torch.nn.functional as F

# get x function (dataset related stuff)
def Getx(idx):
    sample = samples[idx]
    vector = Calculating_bottom(sample)
    vector = torch.as_tensor(vector, dtype = torch.float64)
    
    return vector

# get y function (dataset related stuff)
def Gety(idx):
    y = np.array(train.iloc[idx, 4], dtype = np.float64)
    y = torch.as_tensor(y, dtype = torch.float64)
    
    return y

# dataset
class mydataset(Dataset):

    def __init__(self):
        super().__init__()

    def __getitem__(self, index):
        x = Getx(index)
        y = Gety(index)
        
        return x, y

    def __len__(self):
        return len(train)
    
dataset = mydataset()

# sample dataset value
print(dataset.__getitem__(0))

(tensor([ 5.,  5.,  8., 14.], dtype=torch.float64), tensor(-0.3403, dtype=torch.float64))
# data-loader
dataloader = DataLoader(dataset, batch_size = 1, shuffle = True)

# nn architecture
class Net(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(4, 4)
        self.fc2 = nn.Linear(4, 2)
        self.fc3 = nn.Linear(2, 1)

    def forward(self, x):
        x = x.float()
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

model = Net()

# device
device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')
model.to(device)

# hyper-parameters
criterion = nn.MSELoss()
optimizer = torch.optim.SGD(model.parameters(), lr=0.001)

# training loop

for epoch in range(5):
    
    for batch in dataloader:
        
        # unpacking
        x, y = batch
        x.to(device)
        y.to(device)
        
        # reset gradients
        optimizer.zero_grad()
        
        # forward propagation through the network
        out = model(x)
        
        # calculate the loss
        loss = criterion(out, y)
        
        # backpropagation
        loss.backward()
        
        # update the parameters
        optimizer.step()

Error:
/opt/conda/lib/python3.7/site-packages/torch/nn/modules/loss.py:446: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-18-3f68fcee9ff3> in <module>
     20 
     21         # backpropagation
---> 22         loss.backward()
     23 
     24         # update the parameters

/opt/conda/lib/python3.7/site-packages/torch/tensor.py in backward(self, gradient, retain_graph, create_graph)
    219                 retain_graph=retain_graph,
    220                 create_graph=create_graph)
--> 221         torch.autograd.backward(self, gradient, retain_graph, create_graph)
    222 
    223     def register_hook(self, hook):

/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py in backward(tensors, grad_tensors, retain_graph, create_graph, grad_variables)
    130     Variable._execution_engine.run_backward(
    131         tensors, grad_tensors_, retain_graph, create_graph,
--> 132         allow_unreachable=True)  # allow_unreachable flag
    133 
    134 

RuntimeError: Found dtype Double but expected Float

",<python><deep-learning><casting><pytorch><precision>,18,"python,deep-learning,casting,pytorch,precision",['pytorch getting runtimeerror found dtype double but expected float'],"['i am trying to implement a neural net in pytorch but it doesnt seem to work', 'the problem seems to be in the training loop', 'ive spend several hours into this but cant get it right', 'please help thanks', 'i havent added the data preprocessing parts', ' importing libraries import pandas as pd import numpy as np import torch import torchnn as nn from torchutilsdata import dataset from torchutilsdata import dataloader import torchnnfunctional as f get x function dataset related stuff def getxidx sample samplesidx vector calculatingbottomsample vector torchastensorvector dtype torchfloat64 return vector get y function dataset related stuff def getyidx y nparraytrainilocidx 4 dtype npfloat64 y torchastensory dtype torchfloat64 return y dataset class mydatasetdataset def initself superinit def getitemself index x getxindex y getyindex return x y def lenself return lentrain dataset mydataset sample dataset value printdatasetgetitem0 tensor 5 5 8 14', ' dtypetorchfloat64 tensor03403 dtypetorchfloat64 dataloader dataloader dataloaderdataset batchsize 1 shuffle true nn architecture class netnnmodule def initself superinit selffc1 nnlinear4 4 selffc2 nnlinear4 2 selffc3 nnlinear2 1 def forwardself x x xfloat x freluselffc1x x freluselffc2x x selffc3x return x model net device device torchdevicecuda if torchcudaisavailable else torchdevicecpu modeltodevice hyperparameters criterion nnmseloss optimizer torchoptimsgdmodelparameters lr0001 training loop for epoch in range5 for batch in dataloader unpacking x y batch xtodevice ytodevice reset gradients optimizerzerograd forward propagation through the network out modelx calculate the loss loss criterionout y backpropagation lossbackward update the parameters optimizerstep error optcondalibpython37sitepackagestorchnnmoduleslosspy446 userwarning using a target size torchsize1 that is different to the input size torchsize1 1', 'this will likely lead to incorrect results due to broadcasting', 'please ensure they have the same size', 'return fmselossinput target reductionselfreduction runtimeerror traceback most recent call last ipythoninput183f68fcee9ff3 in module 20 21 backpropagation 22 lossbackward 23 24 update the parameters optcondalibpython37sitepackagestorchtensorpy in backwardself gradient retaingraph creategraph 219 retaingraphretaingraph 220 creategraphcreategraph 221 torchautogradbackwardself gradient retaingraph creategraph 222 223 def registerhookself hook optcondalibpython37sitepackagestorchautogradinitpy in backwardtensors gradtensors retaingraph creategraph gradvariables 130 variableexecutionenginerunbackward 131 tensors gradtensors retaingraph creategraph 132 allowunreachabletrue allowunreachable flag 133 134 runtimeerror found dtype double but expected float']"
Is there a standard higher order function for applying a transformation several times?,"I'm thinking of a function like this:
> let applyN (initial : 't) (n:int) (f : 't -> 't) = seq {1..n} |> Seq.fold (fun s _ -> f s) initial;;

val applyN : initial:'t -> n:int -> f:('t -> 't) -> 't

> applyN 0 10 (fun x -> x + 1);;
val it : int = 10

Note: The code is F# but I tagged the question with haskell, ocaml and ml tags because if the function doesn't exist in F# libraries but it exists in other languages I would like to use the same name
",<haskell><f#><functional-programming><ocaml><ml>,6,"haskell,f#,functional-programming,ocaml,ml",['is there a standard higher order function for applying a transformation several times'],['im thinking of a function like this let applyn initial t nint f t t seq 1n seqfold fun s f s initial val applyn initialt nint ft t t applyn 0 10 fun x x 1 val it int 10 note the code is f but i tagged the question with haskell ocaml and ml tags because if the function doesnt exist in f libraries but it exists in other languages i would like to use the same name']
Finding rows that don't contain numeric data in Oracle,"I am trying to locate some problematic records in a very large Oracle table.  The column should contain all numeric data even though it is a varchar2 column.  I need to find the records which don't contain numeric data (The to_number(col_name) function throws an error when I try to call it on this column).
",<sql><oracle><varchar><numeric><varchar2>,28,"sql,oracle,varchar,numeric,varchar2",['finding rows that dont contain numeric data in oracle'],"['i am trying to locate some problematic records in a very large oracle table', 'the column should contain all numeric data even though it is a varchar2 column', 'i need to find the records which dont contain numeric data the tonumbercolname function throws an error when i try to call it on this column']"
Push notification not getting delivered via service workers,"We have deployed the chrome service worker on our website in July 2015 and have over 380K active subscribers of which over 90% are mobile devices. 
But we are encountering issues with the service worker. When a user's cache gets cleared or  when many of the mobile apps like cleanmaster and other utility apps on a phone clear cache on a user's mobile.  In that case  we do not have any access to device token of that user. And hence even with 380K active users for which google sends us message ids we only get 50K impressions which is a very low ratio. 
Our push notification subscription is implemented on a seperate subdomain as we could not make the entire site https then. 
I have 2 queries:

We would love to know if Google is working on setting up a canonical system (Which is there in GCM for mobile apps) through which even if the user's cache gets cleared via these apps he might be able to get push notifications. Our users have complained again and again that even after subscription they are not receiving push that's when we went deeper and figured this out. 
Also is there a way through which we can ensure we get back those users ? 

",<google-chrome><mobile><push-notification><service-worker><web-push>,7,"google-chrome,mobile,push-notification,service-worker,web-push",['push notification not getting delivered via service workers'],"['we have deployed the chrome service worker on our website in july 2015 and have over 380k active subscribers of which over 90 are mobile devices', 'but we are encountering issues with the service worker', 'when a users cache gets cleared or when many of the mobile apps like cleanmaster and other utility apps on a phone clear cache on a users mobile', 'in that case we do not have any access to device token of that user', 'and hence even with 380k active users for which google sends us message ids we only get 50k impressions which is a very low ratio', 'our push notification subscription is implemented on a seperate subdomain as we could not make the entire site https then', 'i have 2 queries we would love to know if google is working on setting up a canonical system which is there in gcm for mobile apps through which even if the users cache gets cleared via these apps he might be able to get push notifications', 'our users have complained again and again that even after subscription they are not receiving push thats when we went deeper and figured this out', 'also is there a way through which we can ensure we get back those users ']"
Using varchar(MAX) vs TEXT on SQL Server,"I just read that the VARCHAR(MAX) datatype (which can store close to 2GB of char data) is the recommended replacement for the TEXT datatype in SQL Server 2005 and Next SQL SERVER versions. 
If I want to search inside a column for any string, which operation is quicker?

Using a the LIKE clause against a VARCHAR(MAX) column?
WHERE COL1 LIKE '%search string%'
Using the TEXT column and put a Full Text Index/Catalog on this column, and then search using the CONTAINS clause?
WHERE CONTAINS (Col1, 'MyToken')

",<sql-server><performance><text><varchar><sql-types>,220,"sql-server,performance,text,varchar,sql-types",['using varcharmax vs text on sql server'],"['i just read that the varcharmax datatype which can store close to 2gb of char data is the recommended replacement for the text datatype in sql server 2005 and next sql server versions', 'if i want to search inside a column for any string which operation is quicker', 'using a the like clause against a varcharmax column', 'where col1 like search string using the text column and put a full text indexcatalog on this column and then search using the contains clause', 'where contains col1 mytoken']"
Is is possible to use a combination of ValidationRules and INotifyDataErrorInfo for wpf validation?,"In WPF there are 3 ways to do validation:

Validation Rules
IDataErrorInfo
INotifyDataErrorInfo

Is it possible to use a combination of these at the same time? For my needs, I would like to validate new rules with the flexibility of INotifyDataErrorInfo, but don't want to interfere with existing ValidationRules for the same object I want to validate.
",<c#><wpf><validation><idataerrorinfo><inotifydataerrorinfo>,8,"c#,wpf,validation,idataerrorinfo,inotifydataerrorinfo",['is is possible to use a combination of validationrules and inotifydataerrorinfo for wpf validation'],"['in wpf there are 3 ways to do validation validation rules idataerrorinfo inotifydataerrorinfo is it possible to use a combination of these at the same time', 'for my needs i would like to validate new rules with the flexibility of inotifydataerrorinfo but dont want to interfere with existing validationrules for the same object i want to validate']"
How to check FCM Message status?,"How do I receive an Acknowledgement with FCM that a message was received? I have a progressive web app that checks if a user has a fcm token saved in the db, and uses FCM if they do and resorts to SMS (through twilio) if they do not.  The problem is that """"Successfully sent fcm message"" is logged even when the browser is closed, as messages are queued until the browser is reopened.
How can I tell that a message was actually received by the user, and isn't stuck waiting in a queue? If Chrome is closed, I want an SMS to send immediately.
const functions = require('firebase-functions');
const admin = require('firebase-admin');

const serviceAccount = require('./service-account.json');
admin.initializeApp({
  credential: admin.credential.cert(serviceAccount),
  databaseURL: `https://${process.env.GCLOUD_PROJECT}.firebaseio.com`
});

function sendFCM(uid, title, body) {
  const payload = {
    notification: {
      title: title,
      body: body,
      click_action: ""https://www.google.com""
    }
  };

  const payloadOptions = {
    timeToLive: 0
  };

  getUserDetails(uid).then((details) => {
    if (details.fcmToken !== undefined) {
      // send fcm message
      return admin.messaging().sendToDevice(details.fcmToken, payload, payloadOptions)
        .then(response => {
          console.log(""Successfully sent fcm message"");
        })
        .catch((err) => {
          console.log(""Failed to send fcm message"");
          return sendSMS(details.phone_number, body);
        });;
    } else {
      console.log(""No fcm token found for uid"", uid);
      return sendSMS(details.phone_number, body);
    }
  })
}

",<node.js><firebase><web><firebase-cloud-messaging><service-worker>,6,"node.js,firebase,web,firebase-cloud-messaging,service-worker",['how to check fcm message status'],"['how do i receive an acknowledgement with fcm that a message was received', 'i have a progressive web app that checks if a user has a fcm token saved in the db and uses fcm if they do and resorts to sms through twilio if they do not', 'the problem is that successfully sent fcm message is logged even when the browser is closed as messages are queued until the browser is reopened', 'how can i tell that a message was actually received by the user and isnt stuck waiting in a queue', 'if chrome is closed i want an sms to send immediately', 'const functions requirefirebasefunctions const admin requirefirebaseadmin const serviceaccount requireserviceaccountjson admininitializeapp credential admincredentialcertserviceaccount databaseurl function sendfcmuid title body const payload notification title title body body clickaction const payloadoptions timetolive 0 getuserdetailsuidthendetails if detailsfcmtoken undefined send fcm message return adminmessagingsendtodevicedetailsfcmtoken payload payloadoptions thenresponse consolelogsuccessfully sent fcm message catcherr consolelogfailed to send fcm message return sendsmsdetailsphonenumber body else consolelogno fcm token found for uid uid return sendsmsdetailsphonenumber body ']"
"Arabic language in php/mysql appears ""????"" question marks in html","
Possible Duplicate:
Save Data in Arabic in MySQL database 

I have a problem with retrieving Arabic data from MYSQL database using PHP, it appears as question marks ""????"" in HTML:

I have a database with ""utf8_general_ci"" as collation.
The database contains some data in Arabic Language.
The HTML encoding is ""UTF-8"".
When I tried to retrieve the data in HTML, it appears as ""?????"".

Please Help !!!
",<php><mysql><encode><arabic><html-encode>,27,"php,mysql,encode,arabic,html-encode","['arabic language in phpmysql appears ', 'question marks in html']","[' possible duplicate save data in arabic in mysql database i have a problem with retrieving arabic data from mysql database using php it appears as question marks ', 'in html i have a database with utf8generalci as collation', 'the database contains some data in arabic language', 'the html encoding is utf8', 'when i tried to retrieve the data in html it appears as ', 'please help ', '', '']"
"Extracting (subject,predicate,object) from dependency tree","I'm interested in extracting triples (subject,predicate,object) from questions.
For example, I would like to transform the following question : 

Who is the wife of the president of the USA?

to : 

(x,isWifeOf,y) ∧ (y,isPresidentof,USA)

x and y are unknows that we have to find in order to answer the question (/\ denotes the conjunction).
I have read a lot of papers about this topic and I would like to perform this task using existing parsers such as Stanford parser. I know that parsers output 2 types of data : 

parse structure tree (constituency relations)
dependency tree (dependency relations)

Some papers try to build triples from the parse structure tree (e.g., Triple Extraction from Sentences), however this approach seems to be too weak to deal with complicated questions.
On the other hand, dependency trees contain a lot of relevant information to perform the triple extraction. A lot of papers claim to do that, however I didn't find any of them that gives explicitely a detailed procedure or an algorithm. Most of the time, authors say they analyze the dependencies to produce triples according to some rules they didn't give.
Does anyone know any paper with more information on extracting (subject,predicate,object) from dependency tree of a question?
",<nlp><rdf><stanford-nlp><nlp-question-answering><dependency-parsing>,11,"nlp,rdf,stanford-nlp,nlp-question-answering,dependency-parsing",['extracting subjectpredicateobject from dependency tree'],"['im interested in extracting triples subjectpredicateobject from questions', 'for example i would like to transform the following question who is the wife of the president of the usa', 'to xiswifeofy yispresidentofusa x and y are unknows that we have to find in order to answer the question denotes the conjunction', 'i have read a lot of papers about this topic and i would like to perform this task using existing parsers such as stanford parser', 'i know that parsers output 2 types of data parse structure tree constituency relations dependency tree dependency relations some papers try to build triples from the parse structure tree eg triple extraction from sentences however this approach seems to be too weak to deal with complicated questions', 'on the other hand dependency trees contain a lot of relevant information to perform the triple extraction', 'a lot of papers claim to do that however i didnt find any of them that gives explicitely a detailed procedure or an algorithm', 'most of the time authors say they analyze the dependencies to produce triples according to some rules they didnt give', 'does anyone know any paper with more information on extracting subjectpredicateobject from dependency tree of a question']"
How could I safely find the absolute difference between 2 signed integers in C?,"An absolute difference would be the absolute value of the difference between 2 numbers. Suppose I have 2 int variables (x and y) and I would like to find the absolute difference. An easy solution would be:
unsigned diff = abs(x-y);

However these invoke undefined behavior and give incorrect results if overflow occurs such as if x is INT_MIN and y is INT_MAX. This returns 1 (assuming wraparound behavior) instead of UINT_MAX as expected.
",<c><math><difference><absolute-value><absolute-difference>,6,"c,math,difference,absolute-value,absolute-difference",['how could i safely find the absolute difference between 2 signed integers in c'],"['an absolute difference would be the absolute value of the difference between 2 numbers', 'suppose i have 2 int variables x and y and i would like to find the absolute difference', 'an easy solution would be unsigned diff absxy however these invoke undefined behavior and give incorrect results if overflow occurs such as if x is intmin and y is intmax', 'this returns 1 assuming wraparound behavior instead of uintmax as expected']"
gsm network card port mapping with udp sockets in python,"I have a python server listening for udp packets and responding back to the sender. In the clients I am creating connections back to the server in the same port. The clients work over gsm network and their ip's are not public so there is some port mapping done by the network, so the server can contact them back, I assume.
What happens is that sometimes the port mapping must be getting some problems, because the opened socket is still being able to communicate client->server but not the reverse.
It got to a point where I have two clients with the same pair (ip,address). In the server, when I receive messages from them, using sock.recvfrom, I know clearly that the messages are from two different clients taking into account their content, but the address is the same.
I've put a nc -l on the server and run nc on each client and its clear that both gsm cards are sharing the same external ip, so the last one to open the port, gets its mapping and the older one is working, assuming that it still has the mapping (without having it anymore).
I didn't make the original code I'm using so I can't really explain why a specific given port is used for the clients reaching out the server, but it seems to me that even with random ports the problem would persist because the network is remapping the port after some time (I imagine it should be after some event like gsm signal loss).
Anyone has any idea of what can I do to avoid this situation?
",<python><sockets><networking><udp><gsm>,7,"python,sockets,networking,udp,gsm",['gsm network card port mapping with udp sockets in python'],"['i have a python server listening for udp packets and responding back to the sender', 'in the clients i am creating connections back to the server in the same port', 'the clients work over gsm network and their ips are not public so there is some port mapping done by the network so the server can contact them back i assume', 'what happens is that sometimes the port mapping must be getting some problems because the opened socket is still being able to communicate clientserver but not the reverse', 'it got to a point where i have two clients with the same pair ipaddress', 'in the server when i receive messages from them using sockrecvfrom i know clearly that the messages are from two different clients taking into account their content but the address is the same', 'ive put a nc l on the server and run nc on each client and its clear that both gsm cards are sharing the same external ip so the last one to open the port gets its mapping and the older one is working assuming that it still has the mapping without having it anymore', 'i didnt make the original code im using so i cant really explain why a specific given port is used for the clients reaching out the server but it seems to me that even with random ports the problem would persist because the network is remapping the port after some time i imagine it should be after some event like gsm signal loss', 'anyone has any idea of what can i do to avoid this situation']"
How to call flash actionscript callback method from javascript?,"I tried to call a flash callback method from JavaScript.
But it seems not working.
The flash action script example code is like below [Simplified]:
import flash.events.ActivityEvent; 
import flash.events.StatusEvent; 
import flash.external.ExternalInterface;

var test_var = ExternalInterface.addCallback(""js_method_to_call"", flash_method);


function flash_method()
{   
  return ""test""; 
}

The javascript example code is written below [Simplified]:
 function callFlashMethod(){
   var flashFile = eval(""window.document.test"");
   flashFile.js_method_to_call;
 }
 function loadTest(){
   swfobject.embedSWF(""test.swf"", ""test"", ""1"", ""1"", ""10.0.0"", false);
 }

 $(document).ready(function(){
   loadTest();
   callFlashMethod();
 });

It is always display the error in fire bug console ""flashFile.js_method_to_call is not a function"".
",<javascript><jquery><flash><actionscript-3><swfobject>,5,"javascript,jquery,flash,actionscript-3,swfobject",['how to call flash actionscript callback method from javascript'],"['i tried to call a flash callback method from javascript', 'but it seems not working', 'the flash action script example code is like below simplified import flasheventsactivityevent import flasheventsstatusevent import flashexternalexternalinterface var testvar externalinterfaceaddcallbackjsmethodtocall flashmethod function flashmethod return test the javascript example code is written below simplified function callflashmethod var flashfile evalwindowdocumenttest flashfilejsmethodtocall function loadtest swfobjectembedswftestswf test 1 1 1000 false documentreadyfunction loadtest callflashmethod it is always display the error in fire bug console flashfilejsmethodtocall is not a function']"
Time Complexity of a printf()?,"I'd like to determine time complexity of a printf such as:
{
    printf(""%d"",
           i);
}

Or:
{
    printf(""%c"",
           array[i]);
}

Is it correct to assume that time complexity of a printf is always O(1) or not?
[EDIT] Let's take a function that swaps two values:
void swap(...)

{

      tmp = x;
      x = y;    
      y = tmp;  

}

Every assignment expression costs 1 (in terms of time complexity), so T(n) = 1 + 1 + 1 = 3 which means O(1). But what can I say about this function?
void swap(...)

{

      tmp = x;
      x = y;    
      y = tmp;  

      printf(""Value of x: %d"", x);
      printf(""Value of y: %d"", y);

}

Can I say that T(n) is still O(1) in this case?
",<c><time><printf><big-o><complexity-theory>,5,"c,time,printf,big-o,complexity-theory",['time complexity of a printf'],"['id like to determine time complexity of a printf such as printfd i or printfc arrayi is it correct to assume that time complexity of a printf is always o1 or not', 'edit lets take a function that swaps two values void swap tmp x x y y tmp every assignment expression costs 1 in terms of time complexity so tn 1 1 1 3 which means o1', 'but what can i say about this function', 'void swap tmp x x y y tmp printfvalue of x d x printfvalue of y d y can i say that tn is still o1 in this case']"
Scheduling jobs in a DAG-manner,"We have a system with different types of jobs. Let's call them for example:
job_1
job_2
job_3

They all require different sets of parameters (and optional parameters). I.e. we run job_1(x) for different x= A, B, C .... job_2 runs for a set of parameters that is dependent on the results of job_1(x) and also job_2 loads data that job_A(x) stored. And so on.
The result is a tree structure of dependencies. Now, these jobs occasionally fail for one reason or another. So, if job_A for x=B fails that branch of the tree will fail completely and shouldn't run. All the other branches should run though.
All the jobs are written in Python and use parallelism (based on spawning SLURM jobs). They are scheduled with cron. This is obviously not very and has two major drawbacks:

It is very hard to debug. All the jobs run whether a job higher in the tree failed or not. It is hard to see where the problem is without a deep understanding of the dependencies.
If higher job (for example job_A) is not finished job_B might be scheduled to run, and fails or runs based on stale date.

In order to tackle that problem we were looking at airflow for scheduling or visualization because it is written in Python and it seems to roughly fit our needs. I see different challenges though:

The dependency tree of jobs is either very general (i.e. job_B depends on job_A) or very wide (i.e. job_B(y) for a 100 parameters depends on job_A(x=A). The visualized tree in the first case would have roughly 10 leaves but would make debugging very hard because the job might just have failed for a certain parameter. The visualized tree in the latter case would be very wide and have roughly 300 leaves. It would be more accurate but the visualization might be hard to read. Can we filter failed jobs, and just look at their dependencies?
We have parallelism within the job (and we need it otherwise the jobs run for more than a day, and we want to rerun the whole lot every day) does that screw up our scheduling?
We want to change our jobs and data management as little as possible.
Can we implement the rule system of what jobs to spawn next in a easily understandable way?

Is airflow a good choice for this? I understand there are a few others (luigi, Azkaban etc.) out there which are somewhat related to the Hadoop stack (which we are not using because it is not Big Data). How much hacking is required? How much hacking is sensible? 
",<python><linux><cron><scheduled-tasks><airflow>,6,"python,linux,cron,scheduled-tasks,airflow",['scheduling jobs in a dagmanner'],"['we have a system with different types of jobs', 'lets call them for example job1 job2 job3 they all require different sets of parameters and optional parameters', 'ie', 'we run job1x for different x a b c job2 runs for a set of parameters that is dependent on the results of job1x and also job2 loads data that jobax stored', 'and so on', 'the result is a tree structure of dependencies', 'now these jobs occasionally fail for one reason or another', 'so if joba for xb fails that branch of the tree will fail completely and shouldnt run', 'all the other branches should run though', 'all the jobs are written in python and use parallelism based on spawning slurm jobs', 'they are scheduled with cron', 'this is obviously not very and has two major drawbacks it is very hard to debug', 'all the jobs run whether a job higher in the tree failed or not', 'it is hard to see where the problem is without a deep understanding of the dependencies', 'if higher job for example joba is not finished jobb might be scheduled to run and fails or runs based on stale date', 'in order to tackle that problem we were looking at airflow for scheduling or visualization because it is written in python and it seems to roughly fit our needs', 'i see different challenges though the dependency tree of jobs is either very general ie', 'jobb depends on joba or very wide ie', 'jobby for a 100 parameters depends on jobaxa', 'the visualized tree in the first case would have roughly 10 leaves but would make debugging very hard because the job might just have failed for a certain parameter', 'the visualized tree in the latter case would be very wide and have roughly 300 leaves', 'it would be more accurate but the visualization might be hard to read', 'can we filter failed jobs and just look at their dependencies', 'we have parallelism within the job and we need it otherwise the jobs run for more than a day and we want to rerun the whole lot every day does that screw up our scheduling', 'we want to change our jobs and data management as little as possible', 'can we implement the rule system of what jobs to spawn next in a easily understandable way', 'is airflow a good choice for this', 'i understand there are a few others luigi azkaban etc', 'out there which are somewhat related to the hadoop stack which we are not using because it is not big data', 'how much hacking is required', 'how much hacking is sensible']"
"PG::UndefinedFunction: ERROR: function array_append(anyarray, anyelement) does not exist","In my application we have few test cases which are configured with GitHub workflow,Even I do have only space related changes on file but still getting below error. Not sure why my specs are still failing it was working fine before.
An error occurred in a `before(:suite)` hook.
Failure/Error: ActiveMedian.create_function

ActiveRecord::StatementInvalid:
  PG::UndefinedFunction: ERROR:  function array_append(anyarray, anyelement) does not exist
  :       CREATE OR REPLACE FUNCTION median(anyarray)
           RETURNS float8 AS
        $$
          WITH q AS
          (
             SELECT val
             FROM unnest($***) val
             WHERE VAL IS NOT NULL
             ORDER BY ***
          ),
          cnt AS
          (
            SELECT COUNT(*) AS c FROM q
          )
          SELECT AVG(val)::float8
          FROM
          (
            SELECT val FROM q
            LIMIT  2 - MOD((SELECT c FROM cnt), 2)
            OFFSET GREATEST(CEIL((SELECT c FROM cnt) / 2.0) - ***,0)
          ) q2;
        $$
        LANGUAGE sql IMMUTABLE;

        DROP AGGREGATE IF EXISTS median(numeric);
        DROP AGGREGATE IF EXISTS median(double precision);
        DROP AGGREGATE IF EXISTS median(anyelement);
        CREATE AGGREGATE median(anyelement) (
          SFUNC=array_append,
          STYPE=anyarray,
          FINALFUNC=median,
          INITCOND='{}'
        );
# ./spec/rails_helper.rb:***54:in `seed'
# ./spec/rails_helper.rb:***:in `block (2 levels) in <top (required)>'
# ------------------
# --- Caused by: ---

# PG::UndefinedFunction:
#   ERROR:  function array_append(anyarray, anyelement) does not exist
#   ./spec/rails_helper.rb:***54:in `seed'

There is ActiveMedian.create_function on spec/rails_helper.rb which might causing the issue.
Any lead or suggestion would be appreciated
",<ruby-on-rails><ruby><postgresql><github><rspec>,5,"ruby-on-rails,ruby,postgresql,github,rspec",['pgundefinedfunction error function arrayappendanyarray anyelement does not exist'],"['in my application we have few test cases which are configured with github workfloweven i do have only space related changes on file but still getting below error', 'not sure why my specs are still failing it was working fine before', 'an error occurred in a beforesuite hook', 'failureerror activemediancreatefunction activerecordstatementinvalid pgundefinedfunction error function arrayappendanyarray anyelement does not exist create or replace function mediananyarray returns float8 as with q as select val from unnest val where val is not null order by cnt as select count as c from q select avgvalfloat8 from select val from q limit 2 modselect c from cnt 2 offset greatestceilselect c from cnt 20 0 q2 language sql immutable drop aggregate if exists mediannumeric drop aggregate if exists mediandouble precision drop aggregate if exists mediananyelement create aggregate mediananyelement sfuncarrayappend stypeanyarray finalfuncmedian initcond specrailshelperrb54in seed specrailshelperrbin block 2 levels in top required caused by pgundefinedfunction error function arrayappendanyarray anyelement does not exist specrailshelperrb54in seed there is activemediancreatefunction on specrailshelperrb which might causing the issue', 'any lead or suggestion would be appreciated']"
"Unmarshalling Error: unexpected element (uri:url, local:""objectname""). Expected elements are <{}objectname>","I'm using jaxb2-marshaller to generate classes to communicate with a webservice. Java-classes are generated with use of some wsdl files.
Everything is okay now, but when I'm trying to use some of the generated classes, i got this unmarshalling error, altough I use the generated ObjectFactory classes.
Some of the stack:
org.springframework.ws.soap.client.SoapFaultClientException: Unmarshalling Error: unexpected element (uri:""http://xxxxxxxxx"", local:""customer""). Expected elements are <{}customer> 
    at org.springframework.ws.soap.client.core.SoapFaultMessageResolver.resolveFault(SoapFaultMessageResolver.java:38)
    at org.springframework.ws.client.core.WebServiceTemplate.handleFault(WebServiceTemplate.java:826)
    at org.springframework.ws.client.core.WebServiceTemplate.doSendAndReceive(WebServiceTemplate.java:621)
    at org.springframework.ws.client.core.WebServiceTemplate.sendAndReceive(WebServiceTemplate.java:555)
    at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:390)
    at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:383)
    at org.springframework.ws.client.core.WebServiceTemplate.marshalSendAndReceive(WebServiceTemplate.java:373)
    at einvoice.service.CustomerService.createCustomer(CustomerService.java:40)
    at einvoice.controller.facturatie.FacturatieOverzichtController.handleRenderRequest(FacturatieOverzichtController.java:36)
    at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)

And my class:
@Service
public class CustomerService {

    @Autowired
    private WebServiceTemplate customerDaoTemplate;

    private ObjectFactory customerObjectFactory;

    public CustomerService() {
        customerObjectFactory = new ObjectFactory();    
    }

    public boolean createCustomer(Customer c)
    {
        System.out.println(""CREATING CUSTOMER"");
        einvoice.proxy.customerdaoservice.Customer customer = customerObjectFactory.createCustomer();
        customer.setConnectionURL(""test"");
        customer.setUid(""testuid"");
        customer.setName(""KorneelTest"");

        Create create = customerObjectFactory.createCreate();
        create.setCustomer(customer);

        try
        {
            customerDaoTemplate.marshalSendAndReceive(customerObjectFactory.createCreate(create));
            return true;
        }
        catch(Exception ex)
        {
            ex.printStackTrace();
            return false;
        }
    }

It's the createCustomer() method that shows this error.
The generated ObjectFactory class:

//
// This file was generated by the JavaTM Architecture for XML Binding(JAXB) Reference Implementation, v2.2.7 
// See <a href=""http://java.sun.com/xml/jaxb"">http://java.sun.com/xml/jaxb</a> 
// Any modifications to this file will be lost upon recompilation of the source schema. 
// Generated on: 2014.09.12 at 12:04:04 PM CEST 
//


package einvoice.proxy.customerdaoservice;

import javax.xml.bind.JAXBElement;
import javax.xml.bind.annotation.XmlElementDecl;
import javax.xml.bind.annotation.XmlRegistry;
import javax.xml.namespace.QName;


/**
 * This object contains factory methods for each 
 * Java content interface and Java element interface 
 * generated in the be.icredit.einvoice.proxy.customerdaoservice package. 
 * <p>An ObjectFactory allows you to programatically 
 * construct new instances of the Java representation 
 * for XML content. The Java representation of XML 
 * content can consist of schema derived interfaces 
 * and classes representing the binding of schema 
 * type definitions, element declarations and model 
 * groups.  Factory methods for each of these are 
 * provided in this class.
 * 
 */
@XmlRegistry
public class ObjectFactory {

    private final static QName _AbstractFilter_QNAME = new QName(""http://xxxxxxx/"", ""abstractFilter"");
    private final static QName _Customer_QNAME = new QName(""http://xxxxxxx/"", ""customer"");
    private final static QName _FindSingleResponse_QNAME = new QName(""http://xxxxxxx/"", ""findSingleResponse"");
    private final static QName _Create_QNAME = new QName(""http://xxxxxxx/"", ""create"");
    private final static QName _Find_QNAME = new QName(""http://xxxxxxx/"", ""find"");
    private final static QName _CreateResponse_QNAME = new QName(""xxxxxxx/"", ""createResponse"");
    private final static QName _FindResponse_QNAME = new QName(""http://xxxxxxx/"", ""findResponse"");
    private final static QName _UpdateResponse_QNAME = new QName(""http://xxxxxxx/"", ""updateResponse"");
    private final static QName _FindSingle_QNAME = new QName(""http://xxxxxxx/"", ""findSingle"");
    private final static QName _CustomerFilter_QNAME = new QName(""http://xxxxxxx/"", ""customerFilter"");
    private final static QName _Update_QNAME = new QName(""http://xxxxxxx/"", ""update"");
    private final static QName _AbstractEntity_QNAME = new QName(""http://xxxxxxx/"", ""abstractEntity"");

    /**
     * Create a new ObjectFactory that can be used to create new instances of schema derived classes for package: be.icredit.einvoice.proxy.customerdaoservice
     * 
     */
    public ObjectFactory() {
    }

    /**
     * Create an instance of {@link Update }
     * 
     */
    public Update createUpdate() {
        return new Update();
    }

    /**
     * Create an instance of {@link CustomerFilter }
     * 
     */
    public CustomerFilter createCustomerFilter() {
        return new CustomerFilter();
    }

    /**
     * Create an instance of {@link UpdateResponse }
     * 
     */
    public UpdateResponse createUpdateResponse() {
        return new UpdateResponse();
    }

    /**
     * Create an instance of {@link FindSingle }
     * 
     */
    public FindSingle createFindSingle() {
        return new FindSingle();
    }

    /**
     * Create an instance of {@link FindResponse }
     * 
     */
    public FindResponse createFindResponse() {
        return new FindResponse();
    }

    /**
     * Create an instance of {@link CreateResponse }
     * 
     */
    public CreateResponse createCreateResponse() {
        return new CreateResponse();
    }

    /**
     * Create an instance of {@link FindSingleResponse }
     * 
     */
    public FindSingleResponse createFindSingleResponse() {
        return new FindSingleResponse();
    }

    /**
     * Create an instance of {@link Customer }
     * 
     */
    public Customer createCustomer() {
        return new Customer();
    }

    /**
     * Create an instance of {@link Create }
     * 
     */
    public Create createCreate() {
        return new Create();
    }

    /**
     * Create an instance of {@link Find }
     * 
     */
    public Find createFind() {
        return new Find();
    }

    /**
     * Create an instance of {@link Pager }
     * 
     */
    public Pager createPager() {
        return new Pager();
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link AbstractFilter }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""abstractFilter"")
    public JAXBElement<AbstractFilter> createAbstractFilter(AbstractFilter value) {
        return new JAXBElement<AbstractFilter>(_AbstractFilter_QNAME, AbstractFilter.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link Customer }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""customer"")
    public JAXBElement<Customer> createCustomer(Customer value) {
        return new JAXBElement<Customer>(_Customer_QNAME, Customer.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link FindSingleResponse }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""findSingleResponse"")
    public JAXBElement<FindSingleResponse> createFindSingleResponse(FindSingleResponse value) {
        return new JAXBElement<FindSingleResponse>(_FindSingleResponse_QNAME, FindSingleResponse.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link Create }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""create"")
    public JAXBElement<Create> createCreate(Create value) {
        return new JAXBElement<Create>(_Create_QNAME, Create.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link Find }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""find"")
    public JAXBElement<Find> createFind(Find value) {
        return new JAXBElement<Find>(_Find_QNAME, Find.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link CreateResponse }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""createResponse"")
    public JAXBElement<CreateResponse> createCreateResponse(CreateResponse value) {
        return new JAXBElement<CreateResponse>(_CreateResponse_QNAME, CreateResponse.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link FindResponse }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""findResponse"")
    public JAXBElement<FindResponse> createFindResponse(FindResponse value) {
        return new JAXBElement<FindResponse>(_FindResponse_QNAME, FindResponse.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link UpdateResponse }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""updateResponse"")
    public JAXBElement<UpdateResponse> createUpdateResponse(UpdateResponse value) {
        return new JAXBElement<UpdateResponse>(_UpdateResponse_QNAME, UpdateResponse.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link FindSingle }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""findSingle"")
    public JAXBElement<FindSingle> createFindSingle(FindSingle value) {
        return new JAXBElement<FindSingle>(_FindSingle_QNAME, FindSingle.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link CustomerFilter }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""customerFilter"")
    public JAXBElement<CustomerFilter> createCustomerFilter(CustomerFilter value) {
        return new JAXBElement<CustomerFilter>(_CustomerFilter_QNAME, CustomerFilter.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link Update }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""update"")
    public JAXBElement<Update> createUpdate(Update value) {
        return new JAXBElement<Update>(_Update_QNAME, Update.class, null, value);
    }

    /**
     * Create an instance of {@link JAXBElement }{@code <}{@link AbstractEntity }{@code >}}
     * 
     */
    @XmlElementDecl(namespace = ""http://xxxxxxx/"", name = ""abstractEntity"")
    public JAXBElement<AbstractEntity> createAbstractEntity(AbstractEntity value) {
        return new JAXBElement<AbstractEntity>(_AbstractEntity_QNAME, AbstractEntity.class, null, value);
    }

}

The package-info.java class:
//
// This file was generated by the JavaTM Architecture for XML Binding(JAXB) Reference Implementation, v2.2.7 
// See <a href=""http://java.sun.com/xml/jaxb"">http://java.sun.com/xml/jaxb</a> 
// Any modifications to this file will be lost upon recompilation of the source schema. 
// Generated on: 2014.09.12 at 03:44:51 PM CEST 
//

@javax.xml.bind.annotation.XmlSchema(namespace = ""http://xxxxxxx/"")
package einvoice.proxy.customerdaoservice;

",<java><spring><unmarshalling><jaxb2><maven-jaxb2-plugin>,10,"java,spring,unmarshalling,jaxb2,maven-jaxb2-plugin","['unmarshalling error unexpected element uriurl localobjectname', 'expected elements are objectname']","['im using jaxb2marshaller to generate classes to communicate with a webservice', 'javaclasses are generated with use of some wsdl files', 'everything is okay now but when im trying to use some of the generated classes i got this unmarshalling error altough i use the generated objectfactory classes', 'some of the stack orgspringframeworkwssoapclientsoapfaultclientexception unmarshalling error unexpected element uri localcustomer', 'expected elements are customer at orgspringframeworkwssoapclientcoresoapfaultmessageresolverresolvefaultsoapfaultmessageresolverjava38 at orgspringframeworkwsclientcorewebservicetemplatehandlefaultwebservicetemplatejava826 at orgspringframeworkwsclientcorewebservicetemplatedosendandreceivewebservicetemplatejava621 at orgspringframeworkwsclientcorewebservicetemplatesendandreceivewebservicetemplatejava555 at orgspringframeworkwsclientcorewebservicetemplatemarshalsendandreceivewebservicetemplatejava390 at orgspringframeworkwsclientcorewebservicetemplatemarshalsendandreceivewebservicetemplatejava383 at orgspringframeworkwsclientcorewebservicetemplatemarshalsendandreceivewebservicetemplatejava373 at einvoiceservicecustomerservicecreatecustomercustomerservicejava40 at einvoicecontrollerfacturatiefacturatieoverzichtcontrollerhandlerenderrequestfacturatieoverzichtcontrollerjava36 at sunreflectnativemethodaccessorimplinvoke0native method and my class service public class customerservice autowired private webservicetemplate customerdaotemplate private objectfactory customerobjectfactory public customerservice customerobjectfactory new objectfactory public boolean createcustomercustomer c systemoutprintlncreating customer einvoiceproxycustomerdaoservicecustomer customer customerobjectfactorycreatecustomer customersetconnectionurltest customersetuidtestuid customersetnamekorneeltest create create customerobjectfactorycreatecreate createsetcustomercustomer try customerdaotemplatemarshalsendandreceivecustomerobjectfactorycreatecreatecreate return true catchexception ex exprintstacktrace return false its the createcustomer method that shows this error', 'the generated objectfactory class this file was generated by the javatm architecture for xml bindingjaxb reference implementation v227 see a href any modifications to this file will be lost upon recompilation of the source schema', ' generated on 20140912 at 120404 pm cest package einvoiceproxycustomerdaoservice import javaxxmlbindjaxbelement import javaxxmlbindannotationxmlelementdecl import javaxxmlbindannotationxmlregistry import javaxxmlnamespaceqname this object contains factory methods for each java content interface and java element interface generated in the beicrediteinvoiceproxycustomerdaoservice package', ' pan objectfactory allows you to programatically construct new instances of the java representation for xml content', 'the java representation of xml content can consist of schema derived interfaces and classes representing the binding of schema type definitions element declarations and model groups', 'factory methods for each of these are provided in this class', ' xmlregistry public class objectfactory private final static qname abstractfilterqname new qname abstractfilter private final static qname customerqname new qname customer private final static qname findsingleresponseqname new qname findsingleresponse private final static qname createqname new qname create private final static qname findqname new qname find private final static qname createresponseqname new qnamexxxxxxx createresponse private final static qname findresponseqname new qname findresponse private final static qname updateresponseqname new qname updateresponse private final static qname findsingleqname new qname findsingle private final static qname customerfilterqname new qname customerfilter private final static qname updateqname new qname update private final static qname abstractentityqname new qname abstractentity create a new objectfactory that can be used to create new instances of schema derived classes for package beicrediteinvoiceproxycustomerdaoservice public objectfactory create an instance of link update public update createupdate return new update create an instance of link customerfilter public customerfilter createcustomerfilter return new customerfilter create an instance of link updateresponse public updateresponse createupdateresponse return new updateresponse create an instance of link findsingle public findsingle createfindsingle return new findsingle create an instance of link findresponse public findresponse createfindresponse return new findresponse create an instance of link createresponse public createresponse createcreateresponse return new createresponse create an instance of link findsingleresponse public findsingleresponse createfindsingleresponse return new findsingleresponse create an instance of link customer public customer createcustomer return new customer create an instance of link create public create createcreate return new create create an instance of link find public find createfind return new find create an instance of link pager public pager createpager return new pager create an instance of link jaxbelement code link abstractfilter code xmlelementdeclnamespace name abstractfilter public jaxbelementabstractfilter createabstractfilterabstractfilter value return new jaxbelementabstractfilterabstractfilterqname abstractfilterclass null value create an instance of link jaxbelement code link customer code xmlelementdeclnamespace name customer public jaxbelementcustomer createcustomercustomer value return new jaxbelementcustomercustomerqname customerclass null value create an instance of link jaxbelement code link findsingleresponse code xmlelementdeclnamespace name findsingleresponse public jaxbelementfindsingleresponse createfindsingleresponsefindsingleresponse value return new jaxbelementfindsingleresponsefindsingleresponseqname findsingleresponseclass null value create an instance of link jaxbelement code link create code xmlelementdeclnamespace name create public jaxbelementcreate createcreatecreate value return new jaxbelementcreatecreateqname createclass null value create an instance of link jaxbelement code link find code xmlelementdeclnamespace name find public jaxbelementfind createfindfind value return new jaxbelementfindfindqname findclass null value create an instance of link jaxbelement code link createresponse code xmlelementdeclnamespace name createresponse public jaxbelementcreateresponse createcreateresponsecreateresponse value return new jaxbelementcreateresponsecreateresponseqname createresponseclass null value create an instance of link jaxbelement code link findresponse code xmlelementdeclnamespace name findresponse public jaxbelementfindresponse createfindresponsefindresponse value return new jaxbelementfindresponsefindresponseqname findresponseclass null value create an instance of link jaxbelement code link updateresponse code xmlelementdeclnamespace name updateresponse public jaxbelementupdateresponse createupdateresponseupdateresponse value return new jaxbelementupdateresponseupdateresponseqname updateresponseclass null value create an instance of link jaxbelement code link findsingle code xmlelementdeclnamespace name findsingle public jaxbelementfindsingle createfindsinglefindsingle value return new jaxbelementfindsinglefindsingleqname findsingleclass null value create an instance of link jaxbelement code link customerfilter code xmlelementdeclnamespace name customerfilter public jaxbelementcustomerfilter createcustomerfiltercustomerfilter value return new jaxbelementcustomerfiltercustomerfilterqname customerfilterclass null value create an instance of link jaxbelement code link update code xmlelementdeclnamespace name update public jaxbelementupdate createupdateupdate value return new jaxbelementupdateupdateqname updateclass null value create an instance of link jaxbelement code link abstractentity code xmlelementdeclnamespace name abstractentity public jaxbelementabstractentity createabstractentityabstractentity value return new jaxbelementabstractentityabstractentityqname abstractentityclass null value the packageinfojava class this file was generated by the javatm architecture for xml bindingjaxb reference implementation v227 see a href any modifications to this file will be lost upon recompilation of the source schema', ' generated on 20140912 at 034451 pm cest javaxxmlbindannotationxmlschemanamespace package einvoiceproxycustomerdaoservice']"
Akka: testing monitoring\death watch,"In my scenario I have 2 actors:

watchee (I use TestProbe)
watcher (Watcher wrapped into TestActorRef to expose some internal state I track in my test)

Watcher should take some actions when watchee dies.
Here is the complete test case I've written so far:
class TempTest(_system: ActorSystem) extends TestKit(_system) with ImplicitSender with FunSuiteLike with Matchers with BeforeAndAfterAll {

  def this() = this(ActorSystem(""TempTest""))

  override def afterAll {
    TestKit.shutdownActorSystem(system)
  }

  class WatcherActor(watchee: ActorRef) extends Actor {

    var state = ""initial""
    context.watch(watchee)

    override def receive: Receive = {
      case ""start"" =>
        state = ""start""
      case _: Terminated =>
        state = ""terminated""
    }

  }

  test(""example"") {
    val watchee = TestProbe()
    val watcher = TestActorRef[WatcherActor](Props(new WatcherActor(watchee.ref)))

    assert(watcher.underlyingActor.state === ""initial"")

    watcher ! ""start"" // ""start"" will be sent and handled by watcher synchronously
    assert(watcher.underlyingActor.state === ""start"")

    system.stop(watchee.ref) // will cause Terminated to be sent and handled asynchronously by watcher
    Thread.sleep(100) // what is the best way to avoid blocking here?
    assert(watcher.underlyingActor.state === ""terminated"")
  }

}

Now, since all involved actors use CallingThreadDispatcher (all Akka's test helpers gets constructed using props with .withDispatcher(CallingThreadDispatcher.Id)) I can safely assume that when this statement returns:
watcher ! ""start""

... the ""start"" message is already processed by WatchingActor and thus I can make assertions based in the watcher.underlyingActor.state
However, based on my observations, when I stop watchee using system.stop or by sending Kill to it the Terminated message produced as a side effect of watchee death gets executed asynchronously, in another thread.
Not-a-solution is to stop watchee, block thread for some time and verify Watcher state after that, but I'd like to know how to I do this the right way (i.e. how to be sure that after killing actor it's watcher received and processed Terminated message signaling it's death)? 
",<scala><testing><akka><akka-testkit><akka-monitoring>,6,"scala,testing,akka,akka-testkit,akka-monitoring",['akka testing monitoringdeath watch'],"['in my scenario i have 2 actors watchee i use testprobe watcher watcher wrapped into testactorref to expose some internal state i track in my test watcher should take some actions when watchee dies', 'here is the complete test case ive written so far class temptestsystem actorsystem extends testkitsystem with implicitsender with funsuitelike with matchers with beforeandafterall def this thisactorsystemtemptest override def afterall testkitshutdownactorsystemsystem class watcheractorwatchee actorref extends actor var state initial contextwatchwatchee override def receive receive case start state start case terminated state terminated testexample val watchee testprobe val watcher testactorrefwatcheractorpropsnew watcheractorwatcheeref assertwatcherunderlyingactorstate initial watcher ', 'start start will be sent and handled by watcher synchronously assertwatcherunderlyingactorstate start systemstopwatcheeref will cause terminated to be sent and handled asynchronously by watcher threadsleep100 what is the best way to avoid blocking here', 'assertwatcherunderlyingactorstate terminated now since all involved actors use callingthreaddispatcher all akkas test helpers gets constructed using props with withdispatchercallingthreaddispatcherid i can safely assume that when this statement returns watcher ', 'start the start message is already processed by watchingactor and thus i can make assertions based in the watcherunderlyingactorstate however based on my observations when i stop watchee using systemstop or by sending kill to it the terminated message produced as a side effect of watchee death gets executed asynchronously in another thread', 'notasolution is to stop watchee block thread for some time and verify watcher state after that but id like to know how to i do this the right way ie', 'how to be sure that after killing actor its watcher received and processed terminated message signaling its death']"
Setting Visibility of Datagrid rows to Collapsed seems to break scrollbar?,"I have a Datagrid containing items as List, one property in this custom list is a bool which determines visibility (the visibility can be toggled by a checkbox).
I have that working as this:
<Style x:Key=""RowStyle"" TargetType=""DataGridRow"">
    <Style.Triggers>
        <DataTrigger Binding=""{Binding Path=IsVisible}"" Value=""False"">
            <Setter Property=""Visibility"" Value=""Collapsed""/>
        </DataTrigger>
        <DataTrigger Binding=""{Binding Path=IsVisible}"" Value=""True"">
            <Setter Property=""Visibility"" Value=""Visible""/>
        </DataTrigger>
    </Style.Triggers>
</Style>

And my Datagrid is like:
<DataGrid Name=""dataList"" DataContext=""{StaticResource DataViewSource}"" ItemsSource=""{Binding}"" 
          ItemContainerStyle=""{StaticResource RowStyle}""
          ScrollViewer.VerticalScrollBarVisibility=""Auto""
          ScrollViewer.HorizontalScrollBarVisibility=""Auto""
          AutoGenerateColumns=""False"" 
          CanUserAddRows=""False"" 
          CanUserDeleteRows=""False"" 
          IsReadOnly=""True""
          CanUserReorderColumns=""True"" CanUserSortColumns=""True""> ..etc

Assume I have 100 rows and when toggling the visibility, 80 of those rows are collapsed.
The issue is: the scrollbar doesn't seem to update when the visibility of items is changed. In appearance it will look as if those 80 rows are still visible (small drag bar) but when trying to scroll through the 20 items that are visible, it requires a lot more scrolling because the scrollbar is assuming that it's still having to scroll through 100 items or something.
Is there a way I can inform the scrollbar of visibility changes? Or should I handle the scroll event myself and remove the scrollbar from the datagrid?
",<c#><wpf><scroll><datagrid><visibility>,5,"c#,wpf,scroll,datagrid,visibility",['setting visibility of datagrid rows to collapsed seems to break scrollbar'],"['i have a datagrid containing items as list one property in this custom list is a bool which determines visibility the visibility can be toggled by a checkbox', 'i have that working as this style xkeyrowstyle targettypedatagridrow styletriggers datatrigger bindingbinding pathisvisible valuefalse setter propertyvisibility valuecollapsed datatrigger datatrigger bindingbinding pathisvisible valuetrue setter propertyvisibility valuevisible datatrigger styletriggers style and my datagrid is like datagrid namedatalist datacontextstaticresource dataviewsource itemssourcebinding itemcontainerstylestaticresource rowstyle scrollviewerverticalscrollbarvisibilityauto scrollviewerhorizontalscrollbarvisibilityauto autogeneratecolumnsfalse canuseraddrowsfalse canuserdeleterowsfalse isreadonlytrue canuserreordercolumnstrue canusersortcolumnstrue etc assume i have 100 rows and when toggling the visibility 80 of those rows are collapsed', 'the issue is the scrollbar doesnt seem to update when the visibility of items is changed', 'in appearance it will look as if those 80 rows are still visible small drag bar but when trying to scroll through the 20 items that are visible it requires a lot more scrolling because the scrollbar is assuming that its still having to scroll through 100 items or something', 'is there a way i can inform the scrollbar of visibility changes', 'or should i handle the scroll event myself and remove the scrollbar from the datagrid']"
V8 native syntax in Chrome,"Nodejs has special flag --allow-natives-syntax. Is it possible to pass such thing to Google Chrome? Or maybe devtools provide some other way to access such information?
// running node with `--allow-natives-syntax` flag

var obj = { a: true, b: false };
console.log(%HasFastProperties(obj)); // true (Fast mode)
delete obj.a;
console.log(%HasFastProperties(obj)); // false (Dictionary mode)

",<javascript><google-chrome><debugging><google-chrome-devtools><v8>,5,"javascript,google-chrome,debugging,google-chrome-devtools,v8",['v8 native syntax in chrome'],"['nodejs has special flag allownativessyntax', 'is it possible to pass such thing to google chrome', 'or maybe devtools provide some other way to access such information', ' running node with allownativessyntax flag var obj a true b false consoleloghasfastpropertiesobj true fast mode delete obja consoleloghasfastpropertiesobj false dictionary mode']"
Ruby on Rails - When to use params.permit! and how to replace it,"I'm working on a legacy rails application and the controllers have many instances of params.permit!. When running a Brakeman scan on it, params.permit! opens up the application to mass assignment vulnerabilities.
My question is- what is the most effective way to get around this params.permit! vulnerability and replace it?
",<ruby-on-rails><ruby><security><actioncontroller><brakeman>,9,"ruby-on-rails,ruby,security,actioncontroller,brakeman","['ruby on rails when to use paramspermit', 'and how to replace it']","['im working on a legacy rails application and the controllers have many instances of paramspermit', 'when running a brakeman scan on it paramspermit', 'opens up the application to mass assignment vulnerabilities', 'my question is what is the most effective way to get around this paramspermit', 'vulnerability and replace it']"
Cannot install NodeJs: /usr/bin/env: node: No such file or directory,"I'm trying to install nodeJs into my Ubuntu 14.04 in order to use GruntJs.
I've read about Ubuntu different way of doing it (issues?), so this is what I've done in order to install it:
sudo apt-get install npm

sudo npm install -g grunt-cli

Typing grunt after that I've got the error:
/usr/bin/env: node: No such file or directory

So, I've tried:
curl -sL https://deb.nodesource.com/setup | sudo bash -

sudo apt-get install -y nodejs

sudo apt-get update

And trying again, and still getting the error, I've tried:
sudo add-apt-repository https://launchpad.net/~chris-lea/+archive/node.js/

sudo apt-get install -y nodejs

I've got this message:
nodejs is already the newest version.
0 to upgrade, 0 to newly install, 0 to remove and 3 not to upgrade.

I did try a cleanup just in case:
sudo apt-get autoremove

But nope, the error is still there: when I type grunt I still get /usr/bin/env: node: No such file or directory
What should I do?
",<node.js><ubuntu><gruntjs><npm-install><node-modules>,362,"node.js,ubuntu,gruntjs,npm-install,node-modules",['cannot install nodejs usrbinenv node no such file or directory'],"['im trying to install nodejs into my ubuntu 1404 in order to use gruntjs', 'ive read about ubuntu different way of doing it issues', ' so this is what ive done in order to install it sudo aptget install npm sudo npm install g gruntcli typing grunt after that ive got the error usrbinenv node no such file or directory so ive tried curl sl sudo bash sudo aptget install y nodejs sudo aptget update and trying again and still getting the error ive tried sudo addaptrepository sudo aptget install y nodejs ive got this message nodejs is already the newest version', '0 to upgrade 0 to newly install 0 to remove and 3 not to upgrade', 'i did try a cleanup just in case sudo aptget autoremove but nope the error is still there when i type grunt i still get usrbinenv node no such file or directory what should i do']"
Unit of Work with Repository Pattern MVC 5 & EF 6,"I put together a sample of how I am using the Unit of Work & Repository pattern based on my understanding.  Can anyone please let me know if I am implementing this the correct way?  If I am not, how can I improve it?
Thanks in advance, it's much appreciated.
I have an EF model with two entities: Topic and Subtopic.  The EF model is called CommonGood.
Unit of Work:
/// <summary>
/// Implementation of a UnitOfWork class
/// </summary>
public static class UnitOfWork
{
    /// <summary>
    /// Gets the default context
    /// </summary>
    /// <returns>A new instance of the default context</returns>
    public static CommonGoodEntities GetContext()
    {
        return new CommonGoodEntities();
    }
}

IGenericRepository:
public interface IRepository<T>
{
    /// <summary>
    /// Gets all entities
    /// </summary>        
    /// <returns>All entities</returns>
    IEnumerable<T> GetAll();

    /// <summary>
    /// Gets all entities matching the predicate
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>All entities matching the predicate</returns>
    IEnumerable<T> GetAll(Expression<Func<T, bool>> predicate);

    /// <summary>
    /// Set based on where condition
    /// </summary>
    /// <param name=""predicate"">The predicate</param>
    /// <returns>The records matching the given condition</returns>
    IQueryable<T> Where(Expression<Func<T, bool>> predicate);

    /// <summary>
    /// Finds an entity matching the predicate
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>An entity matching the predicate</returns>
    IEnumerable<T> Find(Expression<Func<T, bool>> predicate);

    /// <summary>
    /// Determines if there are any entities matching the predicate
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>True if a match was found</returns>
    bool Any(Expression<Func<T, bool>> predicate);

    /// <summary>
    /// Returns the first entity that matches the predicate
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>An entity matching the predicate</returns>
    T First(Expression<Func<T, bool>> predicate);

    /// <summary>
    /// Returns the first entity that matches the predicate else null
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>An entity matching the predicate else null</returns>
    T FirstOrDefault(Expression<Func<T, bool>> predicate);

    /// <summary>
    /// Adds a given entity to the context
    /// </summary>
    /// <param name=""entity"">The entity to add to the context</param>
    void Add(T entity);

    /// <summary>
    /// Deletes a given entity from the context
    /// </summary>
    /// <param name=""entity"">The entity to delete</param>
    void Delete(T entity);

    /// <summary>
    /// Attaches a given entity to the context
    /// </summary>
    /// <param name=""entity"">The entity to attach</param>
    void Attach(T entity);
}

Generic Repository:
public class GenericRepository<T> : IRepository<T> where T : class
{
    /// <summary>
    /// The database context for the repository
    /// </summary>
    private DbContext _context;

    /// <summary>
    /// The data set of the repository
    /// </summary>
    private IDbSet<T> _dbSet;

    /// <summary>
    /// Initializes a new instance of the <see cref=""GenericRepository{T}"" /> class.        
    /// </summary>
    /// <param name=""context"">The context for the repository</param>        
    public GenericRepository(DbContext context)
    {
        this._context = context;
        this._dbSet = this._context.Set<T>();
    }

    /// <summary>
    /// Gets all entities
    /// </summary>        
    /// <returns>All entities</returns>
    public IEnumerable<T> GetAll()
    {
        return this._dbSet;
    }

    /// <summary>
    /// Gets all entities matching the predicate
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>All entities matching the predicate</returns>
    public IEnumerable<T> GetAll(System.Linq.Expressions.Expression<Func<T, bool>> predicate)
    {
        return this._dbSet.Where(predicate);
    }

    /// <summary>
    /// Set based on where condition
    /// </summary>
    /// <param name=""predicate"">The predicate</param>
    /// <returns>The records matching the given condition</returns>
    public IQueryable<T> Where(Expression<Func<T, bool>> predicate)
    {
        return this._dbSet.Where(predicate);
    }

    /// <summary>
    /// Finds an entity matching the predicate
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>An entity matching the predicate</returns>
    public IEnumerable<T> Find(System.Linq.Expressions.Expression<Func<T, bool>> predicate)
    {
        return this._dbSet.Where(predicate);
    }

    /// <summary>
    /// Determines if there are any entities matching the predicate
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>True if a match was found</returns>
    public bool Any(Expression<Func<T, bool>> predicate)
    {
        return this._dbSet.Any(predicate);
    }

    /// <summary>
    /// Returns the first entity that matches the predicate
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>An entity matching the predicate</returns>
    public T First(Expression<Func<T, bool>> predicate)
    {
        return this._dbSet.First(predicate);
    }

    /// <summary>
    /// Returns the first entity that matches the predicate else null
    /// </summary>
    /// <param name=""predicate"">The filter clause</param>
    /// <returns>An entity matching the predicate else null</returns>
    public T FirstOrDefault(Expression<Func<T, bool>> predicate)
    {
        return this._dbSet.FirstOrDefault(predicate);
    }

    /// <summary>
    /// Adds a given entity to the context
    /// </summary>
    /// <param name=""entity"">The entity to add to the context</param>
    public void Add(T entity)
    {
        this._dbSet.Add(entity);
    }

    /// <summary>
    /// Deletes a given entity from the context
    /// </summary>
    /// <param name=""entity"">The entity to delete</param>
    public void Delete(T entity)
    {
        this._dbSet.Remove(entity);
    }

    /// <summary>
    /// Attaches a given entity to the context
    /// </summary>
    /// <param name=""entity"">The entity to attach</param>
    public void Attach(T entity)
    {
        this._dbSet.Attach(entity);
    }
}

Controller:
public class HomeController : Controller
{
    /// <summary>
    /// The context used for the controller
    /// </summary>
    private DbContext _context;

    /// <summary>
    /// Initializes a new instance of the <see cref=""HomeController""/> class.
    /// </summary>        
    public HomeController()
    {
        this._context = UnitOfWork.GetContext();
    }

    public JsonResult GetTopics()
    {
        var topics = new GenericRepository<Topic>(this._context).GetAll().ToList();            
        return this.Json(topics, JsonRequestBehavior.AllowGet);
    }

    /// <summary>
    /// Disposes of the context if the currently disposing
    /// </summary>
    /// <param name=""disposing"">A value indicating whether or not the application is disposing</param>
    protected override void Dispose(bool disposing)
    {
        if (disposing)
        {
            this._context.Dispose();
        }

        base.Dispose(disposing);
    }
}

Essentially I want to make sure I am accessing data in the proper way and making sure I am not overlooking anything.  Again, thanks!
",<c#><asp.net-mvc><entity-framework><repository-pattern><unit-of-work>,6,"c#,asp.net-mvc,entity-framework,repository-pattern,unit-of-work",['unit of work with repository pattern mvc 5 ef 6'],"['i put together a sample of how i am using the unit of work repository pattern based on my understanding', 'can anyone please let me know if i am implementing this the correct way', 'if i am not how can i improve it', 'thanks in advance its much appreciated', 'i have an ef model with two entities topic and subtopic', 'the ef model is called commongood', 'unit of work summary implementation of a unitofwork class summary public static class unitofwork summary gets the default context summary returnsa new instance of the default contextreturns public static commongoodentities getcontext return new commongoodentities igenericrepository public interface irepositoryt summary gets all entities summary returnsall entitiesreturns ienumerablet getall summary gets all entities matching the predicate summary param namepredicatethe filter clauseparam returnsall entities matching the predicatereturns ienumerablet getallexpressionfunct bool predicate summary set based on where condition summary param namepredicatethe predicateparam returnsthe records matching the given conditionreturns iqueryablet whereexpressionfunct bool predicate summary finds an entity matching the predicate summary param namepredicatethe filter clauseparam returnsan entity matching the predicatereturns ienumerablet findexpressionfunct bool predicate summary determines if there are any entities matching the predicate summary param namepredicatethe filter clauseparam returnstrue if a match was foundreturns bool anyexpressionfunct bool predicate summary returns the first entity that matches the predicate summary param namepredicatethe filter clauseparam returnsan entity matching the predicatereturns t firstexpressionfunct bool predicate summary returns the first entity that matches the predicate else null summary param namepredicatethe filter clauseparam returnsan entity matching the predicate else nullreturns t firstordefaultexpressionfunct bool predicate summary adds a given entity to the context summary param nameentitythe entity to add to the contextparam void addt entity summary deletes a given entity from the context summary param nameentitythe entity to deleteparam void deletet entity summary attaches a given entity to the context summary param nameentitythe entity to attachparam void attacht entity generic repository public class genericrepositoryt irepositoryt where t class summary the database context for the repository summary private dbcontext context summary the data set of the repository summary private idbsett dbset summary initializes a new instance of the see crefgenericrepositoryt class', ' summary param namecontextthe context for the repositoryparam public genericrepositorydbcontext context thiscontext context thisdbset thiscontextsett summary gets all entities summary returnsall entitiesreturns public ienumerablet getall return thisdbset summary gets all entities matching the predicate summary param namepredicatethe filter clauseparam returnsall entities matching the predicatereturns public ienumerablet getallsystemlinqexpressionsexpressionfunct bool predicate return thisdbsetwherepredicate summary set based on where condition summary param namepredicatethe predicateparam returnsthe records matching the given conditionreturns public iqueryablet whereexpressionfunct bool predicate return thisdbsetwherepredicate summary finds an entity matching the predicate summary param namepredicatethe filter clauseparam returnsan entity matching the predicatereturns public ienumerablet findsystemlinqexpressionsexpressionfunct bool predicate return thisdbsetwherepredicate summary determines if there are any entities matching the predicate summary param namepredicatethe filter clauseparam returnstrue if a match was foundreturns public bool anyexpressionfunct bool predicate return thisdbsetanypredicate summary returns the first entity that matches the predicate summary param namepredicatethe filter clauseparam returnsan entity matching the predicatereturns public t firstexpressionfunct bool predicate return thisdbsetfirstpredicate summary returns the first entity that matches the predicate else null summary param namepredicatethe filter clauseparam returnsan entity matching the predicate else nullreturns public t firstordefaultexpressionfunct bool predicate return thisdbsetfirstordefaultpredicate summary adds a given entity to the context summary param nameentitythe entity to add to the contextparam public void addt entity thisdbsetaddentity summary deletes a given entity from the context summary param nameentitythe entity to deleteparam public void deletet entity thisdbsetremoveentity summary attaches a given entity to the context summary param nameentitythe entity to attachparam public void attacht entity thisdbsetattachentity controller public class homecontroller controller summary the context used for the controller summary private dbcontext context summary initializes a new instance of the see crefhomecontroller class', ' summary public homecontroller thiscontext unitofworkgetcontext public jsonresult gettopics var topics new genericrepositorytopicthiscontextgetalltolist return thisjsontopics jsonrequestbehaviorallowget summary disposes of the context if the currently disposing summary param namedisposinga value indicating whether or not the application is disposingparam protected override void disposebool disposing if disposing thiscontextdispose basedisposedisposing essentially i want to make sure i am accessing data in the proper way and making sure i am not overlooking anything', 'again thanks']"
How to convert a callback code to promise in ES6,"I am learning the ES6 standard so I start from a very basic example code.
There are callback hells exist in JavaScript so this time I do want to avoid using callbacks. But I met a problem that I don't really know how to convert a callback style code to a promise.
For example, if I have such code looks like below 
module.exports = (x, y, callback) => {
  try {
    if (x < 0 || y < 0) {
      throw new Error('Rectangle dimensions are wrong.');
    } else {
      callback(null, {
        perimeter() {
          return (2 * (x + y));
        },
        area() {
          return (x * y);
        },
      });
    }
  } catch (error) {
    callback(error, null);
  }
};

How should I convert it to a Promise in ES6? Is that a kind of recommended behavior that convert callbacks to promises?
I have read this example but I was actually confused by the result. I think before I start to rewrite my callbacks to promises I need to understand this first.
let promise = new Promise(function(resolve, reject) {
  console.log('Promise');
  resolve();
});

promise.then(function() {
  console.log('Resolved.');
});

console.log('Hi!');

// Promise
// Hi!
// Resolved 

My understanding is that Promise runs immediately after getting created. But I don't know why the code in then method will be run last.
",<javascript><asynchronous><callback><promise><ecmascript-6>,5,"javascript,asynchronous,callback,promise,ecmascript-6",['how to convert a callback code to promise in es6'],"['i am learning the es6 standard so i start from a very basic example code', 'there are callback hells exist in javascript so this time i do want to avoid using callbacks', 'but i met a problem that i dont really know how to convert a callback style code to a promise', 'for example if i have such code looks like below moduleexports x y callback try if x 0 y 0 throw new errorrectangle dimensions are wrong', ' else callbacknull perimeter return 2 x y area return x y catch error callbackerror null how should i convert it to a promise in es6', 'is that a kind of recommended behavior that convert callbacks to promises', 'i have read this example but i was actually confused by the result', 'i think before i start to rewrite my callbacks to promises i need to understand this first', 'let promise new promisefunctionresolve reject consolelogpromise resolve promisethenfunction consolelogresolved', ' consoleloghi', ' promise hi', ' resolved my understanding is that promise runs immediately after getting created', 'but i dont know why the code in then method will be run last']"
GNU Compilers vs. Visual Studio on Arrays Allocated w/ Length Constant w/in a Scope,"I'm aware that if you set a dynamic value in c/c++ you can't use that value within brackets to allocate an array (which would make it a so-called variable length array (VLA), which the current C++ standard does not support)...
i.e. See:
C++ : Variable Length Array
http://en.wikipedia.org/wiki/Variable-length_array
What I don't quite get (and what I haven't see asked precisely here) is why GNU c/c++ compilers (gcc, g++) are okay with using dynamic allocation based on an integer value (as far as I can tell) so long as that value is a constant within the scope of the array allocation, but Visual Studio's does not support this and will refuse to compile the code, spitting out errors.
e.g. in g++
void Foo(const unsigned int bar)
{
  double myStuff[bar];
  //... do stuff...
}

...compiles just fine...
But the same code refuses to compile in versions of VS I've used, unless whatever I pass to bar is const in all scopes or is a #define, static const, etc.
I would suspect that maybe GNU compilers  use the scope to infer that this value is a constant within that scope and either simply assign it to a malloc or handle it specially somehow.  
My questions are:

Who (VS or GNU) is closer to the standard in terms of how they
handle this? 
Is there a way to do this VS using [] on a value that's constant within scope, but not globally const throughout the entire program without a malloc call?
Are there any issues I should be aware of if I use this in my
GNU-compiled code?

",<c++><c><arrays><dynamic><constants>,5,"c++,c,arrays,dynamic,constants",['gnu compilers vs visual studio on arrays allocated w length constant win a scope'],"['im aware that if you set a dynamic value in cc you cant use that value within brackets to allocate an array which would make it a socalled variable length array vla which the current c standard does not support ie', 'see c variable length array what i dont quite get and what i havent see asked precisely here is why gnu cc compilers gcc g are okay with using dynamic allocation based on an integer value as far as i can tell so long as that value is a constant within the scope of the array allocation but visual studios does not support this and will refuse to compile the code spitting out errors', 'eg', 'in g void fooconst unsigned int bar double mystuffbar do stuff compiles just fine but the same code refuses to compile in versions of vs ive used unless whatever i pass to bar is const in all scopes or is a define static const etc', 'i would suspect that maybe gnu compilers use the scope to infer that this value is a constant within that scope and either simply assign it to a malloc or handle it specially somehow', 'my questions are who vs or gnu is closer to the standard in terms of how they handle this', 'is there a way to do this vs using on a value thats constant within scope but not globally const throughout the entire program without a malloc call', 'are there any issues i should be aware of if i use this in my gnucompiled code']"
How to reconcile Visual Studio comment expectations with code having Doxygen comments?,"It is normal for code that was written for Doxygen processing to have lines like this.
int myVariable; ///< description of myVariable

However, when Visual Studio (e.g. VS 2015) is working with code prepared with these Doxygen comments, its tooltip information for myVariable will show
XML comment contains invalid XML: Whitespace is not allowed at this location.
The problem appears to be the presence of ""<"" immediately following ""///"".  That appears to be interpreted by Visual Studio as signalling (improperly formatted) XML content.  However, this combination is present with the ""<"" to signal to Doxygen that the comment applies to the preceding item on the line, not to a following item.
Assume that we are talking about an existing body of code that already follows this Doxygen convention.  It is already written this way in many places.
Is there a way to adjust or teach or set Visual Studio so that it will treat such comments as normal documenting comments for the preceding item such that they will appear in the tooltips for these items?
",<xml><visual-studio><comments><tooltip><doxygen>,7,"xml,visual-studio,comments,tooltip,doxygen",['how to reconcile visual studio comment expectations with code having doxygen comments'],"['it is normal for code that was written for doxygen processing to have lines like this', 'int myvariable description of myvariable however when visual studio eg', 'vs 2015 is working with code prepared with these doxygen comments its tooltip information for myvariable will show xml comment contains invalid xml whitespace is not allowed at this location', 'the problem appears to be the presence of immediately following ', 'that appears to be interpreted by visual studio as signalling improperly formatted xml content', 'however this combination is present with the to signal to doxygen that the comment applies to the preceding item on the line not to a following item', 'assume that we are talking about an existing body of code that already follows this doxygen convention', 'it is already written this way in many places', 'is there a way to adjust or teach or set visual studio so that it will treat such comments as normal documenting comments for the preceding item such that they will appear in the tooltips for these items']"
"Can curlies be omitted for try and/or catch blocks, as for if and else ones?","if (foo) {
  bar;
}

can be shortened to 
if(foo) bar;

since it's only one statement in the block.
I'm wondering if the same applies to try/catch... I don't like extra cruft in my code.
",<javascript><syntax><if-statement><try-catch><curly-braces>,12,"javascript,syntax,if-statement,try-catch,curly-braces",['can curlies be omitted for try andor catch blocks as for if and else ones'],"['if foo bar can be shortened to iffoo bar since its only one statement in the block', 'im wondering if the same applies to trycatch i dont like extra cruft in my code']"
AngularJS + Karma: reuse a mock service when unit testing directives or controllers,"I'm working with AngularJS + Karma.
configService manages the settings of my app (e.g. the background-color, wether it's on debug mode, general permissions...). It loads initial data with $http. I wrote the test successfully for the service but my directives and controllers use it.
When I write the unit tests for directives, I have to mock the service. 
I know I can do:
spyOn(configService, 'getBackgroundColor').andCallFake(function (params) {
   return ""red"";
});

but the service has 25+ methods and initial data load. I don't feel like writing (and maintaining) this spyOn thing in every test suite. What's more, I load data in the factory with $http, and that should be mocked as well. if I just inject the service and mock the calls, I'll still make the http get request.
What do you think would be the best way to reuse a mock?
",<angularjs><unit-testing><jasmine><karma-runner><code-reuse>,9,"angularjs,unit-testing,jasmine,karma-runner,code-reuse",['angularjs karma reuse a mock service when unit testing directives or controllers'],"['im working with angularjs karma', 'configservice manages the settings of my app eg', 'the backgroundcolor wether its on debug mode general permissions', 'it loads initial data with http', 'i wrote the test successfully for the service but my directives and controllers use it', 'when i write the unit tests for directives i have to mock the service', 'i know i can do spyonconfigservice getbackgroundcolorandcallfakefunction params return red but the service has 25 methods and initial data load', 'i dont feel like writing and maintaining this spyon thing in every test suite', 'whats more i load data in the factory with http and that should be mocked as well', 'if i just inject the service and mock the calls ill still make the http get request', 'what do you think would be the best way to reuse a mock']"
Creating TfRecords from a list of strings and feeding a Graph in tensorflow after decoding,"The aim was to create a database of TfRecords. 
Given: I have 23 folders each contain 7500 image, and 23 text file, each with 7500 line describing features for the 7500 images in separate folders. 
I created the database through this code: 
import tensorflow as tf
import numpy as np
from PIL import Image

def _Float_feature(value):
    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))

def _bytes_feature(value):
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

def _int64_feature(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))

def create_image_annotation_data():
    # Code to read images and features.
    # images represent a list of numpy array of images, and features_labels represent a list of strings
    # where each string represent the whole set of features for each image. 
    return images, features_labels

# This is the starting point of the program.
# Now I have the images stored as list of numpy array, and the features as list of strings.
images, annotations = create_image_annotation_data()

tfrecords_filename = ""database.tfrecords""
writer = tf.python_io.TFRecordWriter(tfrecords_filename)

for img, ann in zip(images, annotations):

    # Note that the height and width are needed to reconstruct the original image.
    height = img.shape[0]
    width = img.shape[1]

    # This is how data is converted into binary
    img_raw = img.tostring()
    example = tf.train.Example(features=tf.train.Features(feature={
        'height': _int64_feature(height),
        'width': _int64_feature(width),
        'image_raw': _bytes_feature(img_raw),
        'annotation_raw': _bytes_feature(tf.compat.as_bytes(ann))
    }))

    writer.write(example.SerializeToString())

writer.close()

reconstructed_images = []

record_iterator = tf.python_io.tf_record_iterator(path=tfrecords_filename)

for string_record in record_iterator:
    example = tf.train.Example()
    example.ParseFromString(string_record)

    height = int(example.features.feature['height']
                 .int64_list
                 .value[0])

    width = int(example.features.feature['width']
                .int64_list
                .value[0])

    img_string = (example.features.feature['image_raw']
                  .bytes_list
                  .value[0])

    annotation_string = (example.features.feature['annotation_raw']
                         .bytes_list
                         .value[0])

    img_1d = np.fromstring(img_string, dtype=np.uint8)
    reconstructed_img = img_1d.reshape((height, width, -1))
    annotation_reconstructed = annotation_string.decode('utf-8')

Therefore, after converting images and text into tfRecords and after being able to read them and convert images into numpy and the (binary text) into string in python, I tried to go the extra mile by using a filename_queue with a reader (The purpose was to provide the graph with batch of data rather one peace of data at a time. Additionally, the aim was to enqueue and dequeue the queue of examples through different threads, therefore, making training the network faster)
Therefore, I used the following code:
import tensorflow as tf
import numpy as np
import time

image_file_list = [""database.tfrecords""]
batch_size = 16

# Make a queue of file names including all the JPEG images files in the relative
# image directory.
filename_queue = tf.train.string_input_producer(image_file_list, num_epochs=1, shuffle=False)

reader = tf.TFRecordReader()

# Read a whole file from the queue, the first returned value in the tuple is the
# filename which we are ignoring.
_, serialized_example = reader.read(filename_queue)

features = tf.parse_single_example(
      serialized_example,
      # Defaults are not specified since both keys are required.
      features={
          'height': tf.FixedLenFeature([], tf.int64),
          'width': tf.FixedLenFeature([], tf.int64),
          'image_raw': tf.FixedLenFeature([], tf.string),
          'annotation_raw': tf.FixedLenFeature([], tf.string)
      })

image = tf.decode_raw(features['image_raw'], tf.uint8)
annotation = tf.decode_raw(features['annotation_raw'], tf.float32)

height = tf.cast(features['height'], tf.int32)
width = tf.cast(features['width'], tf.int32)

image = tf.reshape(image, [height, width, 3])

# Note that the minimum after dequeue is needed to make sure that the queue is not empty after dequeuing so that
# we don't run into errors
'''
min_after_dequeue = 100
capacity = min_after_dequeue + 3 * batch_size
ann, images_batch = tf.train.batch([annotation, image],
                                   shapes=[[1], [112, 112, 3]],
                                   batch_size=batch_size,
                                   capacity=capacity,
                                   num_threads=1)
'''

# Start a new session to show example output.
with tf.Session() as sess:
    merged = tf.summary.merge_all()
    train_writer = tf.summary.FileWriter('C:/Users/user/Documents/tensorboard_logs/New_Runs', sess.graph)

    # Required to get the filename matching to run.
    tf.global_variables_initializer().run()

    # Coordinate the loading of image files.
    coord = tf.train.Coordinator()
    threads = tf.train.start_queue_runners(coord=coord)

    for steps in range(16):
        t1 = time.time()
        annotation_string, batch, summary = sess.run([annotation, image, merged])
        t2 = time.time()
        print('time to fetch 16 faces:', (t2 - t1))
        print(annotation_string)
        tf.summary.image(""image_batch"", image)
        train_writer.add_summary(summary, steps)

    # Finish off the filename queue coordinator.
    coord.request_stop()
    coord.join(threads)

Finally, after running the above code, I got the following error:
OutOfRangeError (see above for traceback): FIFOQueue '_0_input_producer' is closed and has insufficient elements (requested 1, current size 0)
     [[Node: ReaderReadV2 = ReaderReadV2[_device=""/job:localhost/replica:0/task:0/cpu:0""](TFRecordReaderV2, input_producer)]]
Another Question:

How to decode binary database (tfrecords) to retrieve back the features stored ""as python string data structure"".
How to use the tf.train.batch to create a batch of examples to feed the network. 

Thank you!!
Any help is much appreciated.
",<python><tensorflow><binary><batch-processing><string-decoding>,5,"python,tensorflow,binary,batch-processing,string-decoding",['creating tfrecords from a list of strings and feeding a graph in tensorflow after decoding'],"['the aim was to create a database of tfrecords', 'given i have 23 folders each contain 7500 image and 23 text file each with 7500 line describing features for the 7500 images in separate folders', 'i created the database through this code import tensorflow as tf import numpy as np from pil import image def floatfeaturevalue return tftrainfeaturefloatlisttftrainfloatlistvaluevalue def bytesfeaturevalue return tftrainfeaturebyteslisttftrainbyteslistvaluevalue def int64featurevalue return tftrainfeatureint64listtftrainint64listvaluevalue def createimageannotationdata code to read images and features', ' images represent a list of numpy array of images and featureslabels represent a list of strings where each string represent the whole set of features for each image', 'return images featureslabels this is the starting point of the program', ' now i have the images stored as list of numpy array and the features as list of strings', 'images annotations createimageannotationdata tfrecordsfilename databasetfrecords writer tfpythoniotfrecordwritertfrecordsfilename for img ann in zipimages annotations note that the height and width are needed to reconstruct the original image', 'height imgshape0 width imgshape1 this is how data is converted into binary imgraw imgtostring example tftrainexamplefeaturestftrainfeaturesfeature height int64featureheight width int64featurewidth imageraw bytesfeatureimgraw annotationraw bytesfeaturetfcompatasbytesann writerwriteexampleserializetostring writerclose reconstructedimages recorditerator tfpythoniotfrecorditeratorpathtfrecordsfilename for stringrecord in recorditerator example tftrainexample exampleparsefromstringstringrecord height intexamplefeaturesfeatureheight int64list value0 width intexamplefeaturesfeaturewidth int64list value0 imgstring examplefeaturesfeatureimageraw byteslist value0 annotationstring examplefeaturesfeatureannotationraw byteslist value0 img1d npfromstringimgstring dtypenpuint8 reconstructedimg img1dreshapeheight width 1 annotationreconstructed annotationstringdecodeutf8 therefore after converting images and text into tfrecords and after being able to read them and convert images into numpy and the binary text into string in python i tried to go the extra mile by using a filenamequeue with a reader the purpose was to provide the graph with batch of data rather one peace of data at a time', 'additionally the aim was to enqueue and dequeue the queue of examples through different threads therefore making training the network faster therefore i used the following code import tensorflow as tf import numpy as np import time imagefilelist databasetfrecords batchsize 16 make a queue of file names including all the jpeg images files in the relative image directory', 'filenamequeue tftrainstringinputproducerimagefilelist numepochs1 shufflefalse reader tftfrecordreader read a whole file from the queue the first returned value in the tuple is the filename which we are ignoring', ' serializedexample readerreadfilenamequeue features tfparsesingleexample serializedexample defaults are not specified since both keys are required', 'features height tffixedlenfeature tfint64 width tffixedlenfeature tfint64 imageraw tffixedlenfeature tfstring annotationraw tffixedlenfeature tfstring image tfdecoderawfeaturesimageraw tfuint8 annotation tfdecoderawfeaturesannotationraw tffloat32 height tfcastfeaturesheight tfint32 width tfcastfeatureswidth tfint32 image tfreshapeimage height width 3 note that the minimum after dequeue is needed to make sure that the queue is not empty after dequeuing so that we dont run into errors minafterdequeue 100 capacity minafterdequeue 3 batchsize ann imagesbatch tftrainbatchannotation image shapes1 112 112 3 batchsizebatchsize capacitycapacity numthreads1 start a new session to show example output', 'with tfsession as sess merged tfsummarymergeall trainwriter tfsummaryfilewritercusersuserdocumentstensorboardlogsnewruns sessgraph required to get the filename matching to run', 'tfglobalvariablesinitializerrun coordinate the loading of image files', 'coord tftraincoordinator threads tftrainstartqueuerunnerscoordcoord for steps in range16 t1 timetime annotationstring batch summary sessrunannotation image merged t2 timetime printtime to fetch 16 faces t2 t1 printannotationstring tfsummaryimageimagebatch image trainwriteraddsummarysummary steps finish off the filename queue coordinator', 'coordrequeststop coordjointhreads finally after running the above code i got the following error outofrangeerror see above for traceback fifoqueue 0inputproducer is closed and has insufficient elements requested 1 current size 0 node readerreadv2 readerreadv2devicejoblocalhostreplica0task0cpu0tfrecordreaderv2 inputproducer another question how to decode binary database tfrecords to retrieve back the features stored as python string data structure', 'how to use the tftrainbatch to create a batch of examples to feed the network', 'thank you', 'any help is much appreciated']"
npm run build works fine on local machine but shows error on remote ubuntu server,"I'm trying to deploy my MERN app on the digital ocean remote ubuntu server. After git clone, I did npm install to my root folder, client folder, and server folder. But when I tried to run npm start from the root folder then only the server app was running and an error came on the client-side. So I did cd into the client folder and tried the command npm run build (which I did on my local machine as well and the optimized build got created successfully) but it showed the below error on the remote server
> client@0.1.0 build /home/nishant/apps/rentaporta/client
> react-scripts build

Creating an optimized production build...
The build failed because the process exited too early. This probably means the system ran out of memory or someone called `kill -9` on the process.
npm ERR! code ELIFECYCLE
npm ERR! errno 1
npm ERR! client@0.1.0 build: `react-scripts build`
npm ERR! Exit status 1
npm ERR! 
npm ERR! Failed at the client@0.1.0 build script.
npm ERR! This is probably not a problem with npm. There is likely additional logging output above.

npm ERR! A complete log of this run can be found in:
npm ERR!     /home/nishant/.npm/_logs/2020-10-27T05_22_30_755Z-debug.log

I deleted node_modules, package-lock.json, and tried the npm ci command as well but there was no improvement. My folder structure is
root
 client
 server

Below is my package.json script in root folder
  ""scripts"": {
    ""test"": ""echo \""Error: no test specified\"" && exit 1"",
    ""client-install"": ""npm install --prefix client"",
    ""server-install"": ""npm install ---prefix server"",
    ""server"": ""npm start --prefix server"",
    ""client"": ""npm start --prefix client"",
    ""build-client"": ""npm run build --prefix client"",
    ""dev"": ""concurrently \""npm run server\""  \""npm run client\"""",
    ""start"": ""npm run server-install & concurrently \""npm run build-client\""  \""npm run server\""""
  },

Please, someone, help me. If you need more explanation I'm ready to put more details as needed.
",<node.js><reactjs><devops><web-deployment><digital-ocean>,5,"node.js,reactjs,devops,web-deployment,digital-ocean",['npm run build works fine on local machine but shows error on remote ubuntu server'],"['im trying to deploy my mern app on the digital ocean remote ubuntu server', 'after git clone i did npm install to my root folder client folder and server folder', 'but when i tried to run npm start from the root folder then only the server app was running and an error came on the clientside', 'so i did cd into the client folder and tried the command npm run build which i did on my local machine as well and the optimized build got created successfully but it showed the below error on the remote server client010 build homenishantappsrentaportaclient reactscripts build creating an optimized production build the build failed because the process exited too early', 'this probably means the system ran out of memory or someone called kill 9 on the process', 'npm err', 'code elifecycle npm err', 'errno 1 npm err', 'client010 build reactscripts build npm err', 'exit status 1 npm err', 'npm err', 'failed at the client010 build script', 'npm err', 'this is probably not a problem with npm', 'there is likely additional logging output above', 'npm err', 'a complete log of this run can be found in npm err', 'homenishantnpmlogs20201027t052230755zdebuglog i deleted nodemodules packagelockjson and tried the npm ci command as well but there was no improvement', 'my folder structure is root client server below is my packagejson script in root folder scripts test echo error no test specified exit 1 clientinstall npm install prefix client serverinstall npm install prefix server server npm start prefix server client npm start prefix client buildclient npm run build prefix client dev concurrently npm run server npm run client start npm run serverinstall concurrently npm run buildclient npm run server please someone help me', 'if you need more explanation im ready to put more details as needed']"
"Spring @Autowired fields - which access modifier, private or package-private?","Let's say that we use the @Autowired annotation over various fields in a class, and that we didn't write setters or constructors that can also set the fields.
Question - what should the access modifier be, private or package-private (i.e. none) ?
For example: 
public class MyClass {
    @Autowired
    private MyService myService;
}

vs
public class MyClass {
    @Autowired
    MyService myService;
}

In the first case (private fields) Spring uses reflection to wire up the field, even if it doesn't have a setter.
The second case (package-private fields) allows us to be able to access those fields (for example, to set up mocks) if we need to extend the class for testing purposes.
So both cases work fine, but which is more recommended, particularly with regards to testing?
",<java><spring><unit-testing><private><access-modifiers>,23,"java,spring,unit-testing,private,access-modifiers",['spring autowired fields which access modifier private or packageprivate'],"['lets say that we use the autowired annotation over various fields in a class and that we didnt write setters or constructors that can also set the fields', 'question what should the access modifier be private or packageprivate ie', 'none ', 'for example public class myclass autowired private myservice myservice vs public class myclass autowired myservice myservice in the first case private fields spring uses reflection to wire up the field even if it doesnt have a setter', 'the second case packageprivate fields allows us to be able to access those fields for example to set up mocks if we need to extend the class for testing purposes', 'so both cases work fine but which is more recommended particularly with regards to testing']"
In C how do you redirect stdin/stdout/stderr to files when making an execvp() or similar call?,"I have the following code:
pid_t pid = fork();
if (pid == -1)
{
    // ...
}
else if (pid == 0)
{
    stdin = someopenfile;
    stdout = someotherfile;
    stderr = somethirdopenfile;
    execvp(args[0], args);
    // handle error ...
}
else
{
    // ...
}

The problem is, the input/output of the execvp() call is still the console, rather than the files. Clearly I am doing something wrong, what is the right way to do this?
",<c><linux><unix><exec><io-redirection>,24,"c,linux,unix,exec,io-redirection",['in c how do you redirect stdinstdoutstderr to files when making an execvp or similar call'],"['i have the following code pidt pid fork if pid 1 else if pid 0 stdin someopenfile stdout someotherfile stderr somethirdopenfile execvpargs0 args handle error else the problem is the inputoutput of the execvp call is still the console rather than the files', 'clearly i am doing something wrong what is the right way to do this']"
AWS Cognito User Authentication,"OK. Here is my thing. 
We are building a small application on top of Lumen/Laravel. We need the user management to be completely taken care by AWS cognito. 
Basically 2 simple functionalities. 

Push the user details to AWS cognito user pool upon user signup request. 
Authenticate the user against cognito user pool with simple email/mobile and password upon login request. 

We need to do this using PHP.
Now the problem is, I am not able to find any PHP API docs with a clear procedure or examples. Cognito is providing API;s only for Android, IOS, JS, Unity and Xamarian. I need a similar kind of documentation for PHP. 
Do anyone has a working example for just the above 2 features using cognito API's with PHP. 
Note: I have almost spent more than a day and half figuring out whether and how this can be done. So please just dont send me any link which appears first or second on your google search. High possibility I might have already seen that link with no luck. 
Any help would be appreciated. 
",<php><laravel><amazon-web-services><lumen><amazon-cognito>,12,"php,laravel,amazon-web-services,lumen,amazon-cognito",['aws cognito user authentication'],"['ok here is my thing', 'we are building a small application on top of lumenlaravel', 'we need the user management to be completely taken care by aws cognito', 'basically 2 simple functionalities', 'push the user details to aws cognito user pool upon user signup request', 'authenticate the user against cognito user pool with simple emailmobile and password upon login request', 'we need to do this using php', 'now the problem is i am not able to find any php api docs with a clear procedure or examples', 'cognito is providing apis only for android ios js unity and xamarian', 'i need a similar kind of documentation for php', 'do anyone has a working example for just the above 2 features using cognito apis with php', 'note i have almost spent more than a day and half figuring out whether and how this can be done', 'so please just dont send me any link which appears first or second on your google search', 'high possibility i might have already seen that link with no luck', 'any help would be appreciated']"
XMPPFramework - Retrieving Openfire Message Archives,"Spent hours trying to solve this problem and I'm stumped!
Trying to grab the Chat History between 2 users on my OpenFire server and I read that I plugin was needed to do this.
So, I installed the 'Open Archive' plugin on my OpenFire server and send the following XML (as per the XMPP-0136 protocol documentation):
<iq type=""get"" id=""page1"">
   <retrieve xmlns=""urn:xmpp:archive"" with=""username@server.com"" start=""1469-07-21T02:56:15Z"">
      <set xmlns=""http://jabber.org/protocol/rsm"">
         <max>100</max>
      </set>
   </retrieve>
</iq>

In code, this is achieved via the following:
NSXMLElement *iQ = [NSXMLElement elementWithName:@""iq""];
[iQ addAttributeWithName:@""type"" stringValue:@""get""];
[iQ addAttributeWithName:@""id"" stringValue:@""page1""];

NSXMLElement *retrieve = [NSXMLElement elementWithName:@""retrieve""];
[retrieve addAttributeWithName:@""xmlns"" stringValue:@""urn:xmpp:archive""];
[retrieve addAttributeWithName:@""with"" stringValue:@""username@server.com""];
[retrieve addAttributeWithName:@""start"" stringValue:@""1469-07-21T02:56:15Z""];

NSXMLElement *set = [NSXMLElement elementWithName:@""set""];
[set addAttributeWithName:@""xmlns"" stringValue:@""http://jabber.org/protocol/rsm""];
NSXMLElement *max = [NSXMLElement elementWithName:@""max""];
max.stringValue = @""100"";
[set addChild:max];

[retrieve addChild:set];
[iQ addChild:retrieve];

[[[self appDelegate] xmppStream] sendElement:iQ];

Which returns the following error:
<iq xmlns=""jabber:client"" type=""error"" id=""page1"" to=""username@server.com"">
   <error code=""404"" type=""cancel"">
      <item-not-found xmlns=""urn:ietf:params:xml:ns:xmpp-stanzas""/>
   </error>
</iq>

My Xcode project can successfully send/receive messages to the user I'm trying to receive chat history from so I really don't know what I'm doing wrong. Also the Plugin enables me to search through Chat Messages (via OpenFire admin) with successful results so it seems to be working and storing the messages.
Any help would be appreciated. Thanks!
",<ios><objective-c><xmpp><openfire><xmppframework>,5,"ios,objective-c,xmpp,openfire,xmppframework",['xmppframework retrieving openfire message archives'],"['spent hours trying to solve this problem and im stumped', 'trying to grab the chat history between 2 users on my openfire server and i read that i plugin was needed to do this', 'so i installed the open archive plugin on my openfire server and send the following xml as per the xmpp0136 protocol documentation iq typeget idpage1 retrieve xmlnsurnxmpparchive withusernameservercom start14690721t025615z set xmlns max100max set retrieve iq in code this is achieved via the following nsxmlelement iq nsxmlelement elementwithnameiq iq addattributewithnametype stringvalueget iq addattributewithnameid stringvaluepage1 nsxmlelement retrieve nsxmlelement elementwithnameretrieve retrieve addattributewithnamexmlns stringvalueurnxmpparchive retrieve addattributewithnamewith stringvalueusernameservercom retrieve addattributewithnamestart stringvalue14690721t025615z nsxmlelement set nsxmlelement elementwithnameset set addattributewithnamexmlns stringvalue nsxmlelement max nsxmlelement elementwithnamemax maxstringvalue 100 set addchildmax retrieve addchildset iq addchildretrieve self appdelegate xmppstream sendelementiq which returns the following error iq xmlnsjabberclient typeerror idpage1 tousernameservercom error code404 typecancel itemnotfound xmlnsurnietfparamsxmlnsxmppstanzas error iq my xcode project can successfully sendreceive messages to the user im trying to receive chat history from so i really dont know what im doing wrong', 'also the plugin enables me to search through chat messages via openfire admin with successful results so it seems to be working and storing the messages', 'any help would be appreciated', 'thanks']"
Rewrite with Nginx and PHP fastcgi still sends old request_uri to backend (php and symfony),"I am trying to migrate a php-website running the symfony framework to nginx and php over fastcgi.
It all works well usining the Symfony howto from http://wiki.nginx.org/ but I run into trouble with a custom rewrite rule.
My goal is to rewrite urls of of the form /aaaa to /view/shorthand/aaaa. The request should then be handeled by php and symfony.
Old apache rewrite rule:
RewriteRule ^([0-9a-f]+)$ index.php/view/shorthand/$1 [L]

Nginx rules i have tried:
rewrite ^/([0-9a-f]+)$ /view/shorthand/$1 break;
rewrite ^/([0-9a-f]+)$ /index.php/view/shorthand/$1 break;

They all get sent to fastcgi but the request_uri still seems to be /aaaa since I get this error:
FastCGI sent in stderr: ""Action ""aaaa/index"" does not exist"" while reading response header from upstream

I have also tried using try_files without any luck. Please advice.
",<php><symfony1><url-rewriting><nginx><fastcgi>,6,"php,symfony1,url-rewriting,nginx,fastcgi",['rewrite with nginx and php fastcgi still sends old requesturi to backend php and symfony'],"['i am trying to migrate a phpwebsite running the symfony framework to nginx and php over fastcgi', 'it all works well usining the symfony howto from but i run into trouble with a custom rewrite rule', 'my goal is to rewrite urls of of the form aaaa to viewshorthandaaaa', 'the request should then be handeled by php and symfony', 'old apache rewrite rule rewriterule 09af indexphpviewshorthand1 l nginx rules i have tried rewrite 09af viewshorthand1 break rewrite 09af indexphpviewshorthand1 break they all get sent to fastcgi but the requesturi still seems to be aaaa since i get this error fastcgi sent in stderr action aaaaindex does not exist while reading response header from upstream i have also tried using tryfiles without any luck', 'please advice']"
Why does “while(true)” without “Thread.sleep” cause 100% CPU usage on Linux but not on Windows?,"I have created a simple program in java:
public static void main(String[] args) throws InterruptedException {
    while (true) 
        ;
}

If I run this on a Linux machine, it shows 100% CPU usage, but doesn't cause the OS to appear slow.  However, if I run the exact same code on Windows, it only shows about 20% CPU usage.
I am using Oracle JRE on Windows and OpenJDK 6 on Linux.
I'm wondering if Windows' scheduler preempt threads randomly and Linux's doesn't?
",<java><linux><windows><multithreading><cpu-usage>,161,"java,linux,windows,multithreading,cpu-usage",['why does whiletrue without threadsleep cause 100 cpu usage on linux but not on windows'],"['i have created a simple program in java public static void mainstring args throws interruptedexception while true if i run this on a linux machine it shows 100 cpu usage but doesnt cause the os to appear slow', 'however if i run the exact same code on windows it only shows about 20 cpu usage', 'i am using oracle jre on windows and openjdk 6 on linux', 'im wondering if windows scheduler preempt threads randomly and linuxs doesnt']"
Why is LINQ to SQL entity association creating a new (duplicate) row when inserting a new record?,"I am trying to insert a new entity using LINQ-to-SQL, and entity is associated with a User entity. The insert of the new entity is successful, but my existing User entity gets inserted as if it were a new User. The code looks something like the following:
var someEntity = new Entity();
someEntity.User = this.User;
dataContextInstance.SomeEntities.InsertOnSubmit(someEntity);
dataContextInstance.SubmitChanges();

Does anyone know why the user is being inserted as a brand new entity into the Users table? It would seem that the User.UserId would become the foreign key value in the UserId column of the row mapped to the someEntity that is being inserted.
Thanks for any help/suggestions/comments
",<c#><.net><asp.net><linq><linq-to-sql>,6,"c#,.net,asp.net,linq,linq-to-sql",['why is linq to sql entity association creating a new duplicate row when inserting a new record'],"['i am trying to insert a new entity using linqtosql and entity is associated with a user entity', 'the insert of the new entity is successful but my existing user entity gets inserted as if it were a new user', 'the code looks something like the following var someentity new entity someentityuser thisuser datacontextinstancesomeentitiesinsertonsubmitsomeentity datacontextinstancesubmitchanges does anyone know why the user is being inserted as a brand new entity into the users table', 'it would seem that the useruserid would become the foreign key value in the userid column of the row mapped to the someentity that is being inserted', 'thanks for any helpsuggestionscomments']"
Alternative to Java3D,"Colleagues of mine are using Java3D for visualizing results of finite element simulations. The problem is that Java3D seems to be somehow dead, and it is a pain on OSX. This is one of the reasons we are looking for alternatives.
Quite a lot of work has gone into our current implementation based on Java3D, so the question is how much effort it would be to move away from Java3D.
JOGL is one option, but looks like a lot of work.
Has anyone suggestions for alternatives? Any experiences with such a migration?
",<java><3d><visualization><jogl><java-3d>,13,"java,3d,visualization,jogl,java-3d",['alternative to java3d'],"['colleagues of mine are using java3d for visualizing results of finite element simulations', 'the problem is that java3d seems to be somehow dead and it is a pain on osx', 'this is one of the reasons we are looking for alternatives', 'quite a lot of work has gone into our current implementation based on java3d so the question is how much effort it would be to move away from java3d', 'jogl is one option but looks like a lot of work', 'has anyone suggestions for alternatives', 'any experiences with such a migration']"
Save Windows Form Size,"I'm developing a piece in VB.NET.  Inside my primary form, I'm creating a new form to use as a dialog.  I was wondering if there was a way to, upon the close of the new dialog, save it's size settings for each user (probably in a file on their machine, through XML or something?)
",<windows><vb.net><winforms><preferences><savestate>,7,"windows,vb.net,winforms,preferences,savestate",['save windows form size'],"['im developing a piece in vbnet', 'inside my primary form im creating a new form to use as a dialog', 'i was wondering if there was a way to upon the close of the new dialog save its size settings for each user probably in a file on their machine through xml or something']"
C++ decimal data types,"Is there a way to use decimal data types such as decimal32, decimal64 or decimal128in my C++ programs?
",<c++><types><floating-point><double><decimal>,43,"c++,types,floating-point,double,decimal",['c decimal data types'],['is there a way to use decimal data types such as decimal32 decimal64 or decimal128in my c programs']
Jackson deserialization on multiple types,"I have an abstract class called Instance and then two implementations of that, UserInstance and HardwareInstance. The issue I am having is that when I call the rest endpoint for a @POST into the database, I ideally wanted it to be like .../rest/soexample/instance/create where the instance is passed to the REST endpoint. If Instance wasn't abstract with more than one implementation it would be fine, but since I have 2 I am getting a Jackson.databind error.
"" problem: abstract types either need to be mapped to concrete types, have custom deserializer, or be instantiated with additional type information""
After looking up a solution to this I found a SO answer that said I could use something like:
@JsonDeserialize(as=UserInstance.class)
But it seem's like that isonly useful if there is one implementation of the abstract class. Assuming I can't call it twice since there would be no way for it to decide which type of instance it would be.
So I am wondering what is the best way to handle this situation? Should I create different endpoints? Like:
.../rest/soexample/userinstance/create & .../rest/soexample/hardwareinstance/create
I am not too sure as I am a noobie @ REST related things, though actively trying to learn. Thanks!
",<java><json><rest><jackson><deserialization>,25,"java,json,rest,jackson,deserialization",['jackson deserialization on multiple types'],"['i have an abstract class called instance and then two implementations of that userinstance and hardwareinstance', 'the issue i am having is that when i call the rest endpoint for a post into the database i ideally wanted it to be like restsoexampleinstancecreate where the instance is passed to the rest endpoint', 'if instance wasnt abstract with more than one implementation it would be fine but since i have 2 i am getting a jacksondatabind error ', 'problem abstract types either need to be mapped to concrete types have custom deserializer or be instantiated with additional type information after looking up a solution to this i found a so answer that said i could use something like jsondeserializeasuserinstanceclass but it seems like that isonly useful if there is one implementation of the abstract class', 'assuming i cant call it twice since there would be no way for it to decide which type of instance it would be', 'so i am wondering what is the best way to handle this situation', 'should i create different endpoints', 'like restsoexampleuserinstancecreate restsoexamplehardwareinstancecreate i am not too sure as i am a noobie rest related things though actively trying to learn', 'thanks']"
"""Error: Cannot find module 'metro-core'"" when starting an Expo project","Whenever I start Expo Go with the expo start command, this error appears :
Error: Cannot find module 'metro-core'
Require stack:
- /usr/local/lib/node_modules/expo/node_modules/@expo/cli/build/src/start/server/metro/instantiateMetro.js
- /usr/local/lib/node_modules/expo/node_modules/@expo/cli/build/src/start/server/metro/MetroBundlerDevServer.js
- /usr/local/lib/node_modules/expo/node_modules/@expo/cli/build/src/start/server/DevServerManager.js
- /usr/local/lib/node_modules/expo/node_modules/@expo/cli/build/src/start/startAsync.js
- /usr/local/lib/node_modules/expo/node_modules/@expo/cli/build/src/start/index.js
- /usr/local/lib/node_modules/expo/node_modules/@expo/cli/build/bin/cli

I have tried to reinstall metro-core, but with no effect.
",<node.js><react-native><npm><expo><metro-bundler>,12,"node.js,react-native,npm,expo,metro-bundler",['error cannot find module metrocore when starting an expo project'],['whenever i start expo go with the expo start command this error appears error cannot find module metrocore require stack usrlocallibnodemodulesexponodemodulesexpoclibuildsrcstartservermetroinstantiatemetrojs usrlocallibnodemodulesexponodemodulesexpoclibuildsrcstartservermetrometrobundlerdevserverjs usrlocallibnodemodulesexponodemodulesexpoclibuildsrcstartserverdevservermanagerjs usrlocallibnodemodulesexponodemodulesexpoclibuildsrcstartstartasyncjs usrlocallibnodemodulesexponodemodulesexpoclibuildsrcstartindexjs usrlocallibnodemodulesexponodemodulesexpoclibuildbincli i have tried to reinstall metrocore but with no effect']
Indexing and syntax highlighting not working in Xcode when using a Makefile to build,"I'm using Xcode for a C++ project that uses a Makefile to build. The problem is, that Xcode doesn't seem to index the source on the fly (or at all). I have no syntax highlighting, no live compile error warnings and I can't ""Jump to definition"", because I get a ""Symbol Not Found"" error.
Is it possible to get Xcode doing all these things when using Makefiles or will I have to add an additional C++ target?
",<c++><xcode><makefile><clang><lldb>,5,"c++,xcode,makefile,clang,lldb",['indexing and syntax highlighting not working in xcode when using a makefile to build'],"['im using xcode for a c project that uses a makefile to build', 'the problem is that xcode doesnt seem to index the source on the fly or at all', 'i have no syntax highlighting no live compile error warnings and i cant jump to definition because i get a symbol not found error', 'is it possible to get xcode doing all these things when using makefiles or will i have to add an additional c target']"
Set default value for Postgres JSON column in Rails < 4,"So I'm starting to use the Postgres JSON datatype, now that there's a lot of fun stuff you can do with it.
In one of my Rails apps which is not yet Rails 4 (where support for Postgres JSON has been added) I added a JSON column like this:
create_table :foo do |t|
  t.column :bar, :json
end

but I can't figure out how to set a default value for the column.
I tried all variations like {}, '{}', '{}'::json, '[]'::json etc. but I either get an error when the migration runs or it simply doesn't work, meaning the migration runs but, when I create a new Foo, bar is nil.
",<ruby-on-rails><json><ruby-on-rails-3.2><rails-postgresql><pg>,17,"ruby-on-rails,json,ruby-on-rails-3.2,rails-postgresql,pg",['set default value for postgres json column in rails 4'],"['so im starting to use the postgres json datatype now that theres a lot of fun stuff you can do with it', 'in one of my rails apps which is not yet rails 4 where support for postgres json has been added i added a json column like this createtable foo do t tcolumn bar json end but i cant figure out how to set a default value for the column', 'i tried all variations like json json etc', 'but i either get an error when the migration runs or it simply doesnt work meaning the migration runs but when i create a new foo bar is nil']"
Typescript Box produces a union type that is too complex to represent,"Rendering a Box produces the following error:

Expression produces a union type that is too complex to represent.ts(2590)

As I can see here, this is due to having both @mui/material and @react-three/drei & @react-three/fiber installed.
What is the reasoning behind this error? I'm only importing the Box component from mui. Is there a type mixup or something? What would be the solution/workaround?
Steps to reproduce:

Setup a cra app: npx create-react-app my-app --template typescript
Add the following packages to your package.json

  ""dependencies"": {
    ""@azure/msal-browser"": ""^2.18.0"",
    ""@azure/msal-react"": ""^1.1.0"",
    ""@emotion/react"": ""^11.5.0"",
    ""@emotion/styled"": ""^11.3.0"",
    ""@mui/icons-material"": ""^5.0.4"",
    ""@mui/lab"": ""^5.0.0-alpha.51"",
    ""@mui/material"": ""^5.0.4"",
    ""@mui/system"": ""^5.0.4"",
    ""@react-three/drei"": ""^7.16.8"",
    ""@react-three/fiber"": ""^7.0.17"",
    ""axios"": ""^0.23.0"",
    ""dotenv"": ""^10.0.0"",
    ""localforage"": ""^1.10.0"",
    ""react"": ""^17.0.2"",
    ""react-dom"": ""^17.0.2"",
    ""react-router"": ""^5.2.1"",
    ""react-router-dom"": ""^5.3.0"",
    ""react-scripts"": ""4.0.3"",
    ""three"": ""^0.133.1"",
    ""three-stdlib"": ""^2.5.4"",
    ""web-vitals"": ""^1.1.2"",
    ""zustand"": ""^3.5.14""
  },
  ""devDependencies"": {
    ""@testing-library/jest-dom"": ""^5.14.1"",
    ""@testing-library/react"": ""^11.2.7"",
    ""@testing-library/user-event"": ""^12.8.3"",
    ""@types/jest"": ""^26.0.24"",
    ""@types/node"": ""^12.20.33"",
    ""@types/react"": ""^17.0.30"",
    ""@types/react-dom"": ""^17.0.9"",
    ""@types/react-router-dom"": ""^5.3.1"",
    ""@types/three"": ""^0.133.1"",
    ""@typescript-eslint/eslint-plugin"": ""^4.29.3"",
    ""@typescript-eslint/parser"": ""^4.29.3"",
    ""cross-env"": ""^7.0.3"",
    ""eslint-config-airbnb"": ""^18.2.1"",
    ""eslint-config-airbnb-typescript"": ""^14.0.1"",
    ""eslint-config-prettier"": ""^8.3.0"",
    ""eslint-plugin-import"": ""^2.25.2"",
    ""eslint-plugin-jsx-a11y"": ""^6.4.1"",
    ""eslint-plugin-react"": ""^7.26.1"",
    ""eslint-plugin-react-hooks"": ""^4.2.0"",
    ""jest-when"": ""^3.4.1"",
    ""rimraf"": ""^3.0.2"",
    ""typescript"": ""^4.4.4""
  },


Run npm install
Make sure you're running on Typescript v4.4.4
Add the following component to your src. I name it ThreeRenderer.tsx:

import { Html, OrbitControls, PerspectiveCamera, useGLTF, useProgress } from '@react-three/drei';
import { Canvas, useFrame } from '@react-three/fiber';
import { FC, Suspense, useEffect, useRef, useState } from 'react';
import { AnimationAction, AnimationMixer } from 'three';
import { GLTF, GLTFLoader } from 'three-stdlib';
import create from 'zustand';
import { devtools } from 'zustand/middleware';

export const useGLTFModel = create<{ readonly model: () => GLTF | undefined }>(
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  devtools((set) => ({
    model: () => undefined
  }))
);

export const useGLTFAnimationAction = create<{ readonly animationAction: () => AnimationAction[] | undefined }>(
  // eslint-disable-next-line @typescript-eslint/no-unused-vars
  devtools((set) => ({
    animationAction: () => undefined
  }))
);

interface ModelProps {
  readonly gltfPath: string;
  readonly onLoad: () => void;
}

const Model: FC<ModelProps> = ({ gltfPath, onLoad }) => {
  const model = useGLTF(gltfPath, undefined, undefined, (loader: GLTFLoader) => {
    loader.manager.onLoad = onLoad;
  });

  // Refs
  const rootRef = useRef();
  const animationActionsRef = useRef<AnimationAction[]>();

  // Mixer
  const [mixer] = useState(() => new AnimationMixer(model.scene));
  useFrame((_state, delta) => mixer.update(delta));

  // Effects
  useEffect(() => {
    useGLTFModel.setState({ model: () => model });

    animationActionsRef.current = model.animations.map((animation) => mixer.clipAction(animation, rootRef.current));
    useGLTFAnimationAction.setState({ animationAction: () => animationActionsRef.current });

    return () => {
      model.animations.map((animation) => mixer.uncacheClip(animation));
    };
  }, [model, mixer]);

  return <primitive ref={rootRef.current} object={model.scene} />;
};

const Progress = () => {
  const { progress } = useProgress();
  return (
    <Html center>
      <span style={{ color: 'white' }}>{progress}% loaded</span>
    </Html>
  );
};

const ThreeRenderer: FC<ModelProps> = ({ gltfPath, onLoad }): JSX.Element => {
  const cameraRef = useRef();

  return (
    <Canvas>
      <PerspectiveCamera ref={cameraRef} position={[0, 5, 5]} />
      <OrbitControls camera={cameraRef.current} />
      <ambientLight intensity={0.5} />
      <Suspense fallback={<Progress />}>
        {/* <Environment preset=""city"" /> */}
        <Model gltfPath={gltfPath} onLoad={onLoad} />
      </Suspense>
    </Canvas>
  );
};

export default ThreeRenderer;



Go to App.tsx and add a Box component from @mui/material.

import React from 'react';
import logo from './logo.svg';
import './App.css';
import {Box} from '@mui/material';

function App() {
  return (
    <div className=""App"">
      <header className=""App-header"">
        <img src={logo} className=""App-logo"" alt=""logo"" />
        <p>
          Edit <code>src/App.tsx</code> and save to reload.
        </p>
        <a
          className=""App-link""
          href=""https://reactjs.org""
          target=""_blank""
          rel=""noopener noreferrer""
        >
          Learn React
        </a>
        <Box>

        </Box>
      </header>
    </div>
  );
}

export default App;



You should see the error appear. What I see:


NOTE
Please try to reproduce this error locally in VSCode or your preferred editor. I did not manage to reproduce this on codesandbox for example. I don't know why there the issue does not appear. I suspect that's because they use a different typescript version.
UPDATE
I've opened issues on both MUI and react-three:

react-three-fiber
mui

",<reactjs><typescript><three.js><material-ui><react-typescript>,7,"reactjs,typescript,three.js,material-ui,react-typescript",['typescript box produces a union type that is too complex to represent'],"['rendering a box produces the following error expression produces a union type that is too complex to representts2590 as i can see here this is due to having both muimaterial and reactthreedrei reactthreefiber installed', 'what is the reasoning behind this error', 'im only importing the box component from mui', 'is there a type mixup or something', 'what would be the solutionworkaround', 'steps to reproduce setup a cra app npx createreactapp myapp template typescript add the following packages to your packagejson dependencies azuremsalbrowser 2180 azuremsalreact 110 emotionreact 1150 emotionstyled 1130 muiiconsmaterial 504 muilab 500alpha51 muimaterial 504 muisystem 504 reactthreedrei 7168 reactthreefiber 7017 axios 0230 dotenv 1000 localforage 1100 react 1702 reactdom 1702 reactrouter 521 reactrouterdom 530 reactscripts 403 three 01331 threestdlib 254 webvitals 112 zustand 3514 devdependencies testinglibraryjestdom 5141 testinglibraryreact 1127 testinglibraryuserevent 1283 typesjest 26024 typesnode 122033 typesreact 17030 typesreactdom 1709 typesreactrouterdom 531 typesthree 01331 typescripteslinteslintplugin 4293 typescripteslintparser 4293 crossenv 703 eslintconfigairbnb 1821 eslintconfigairbnbtypescript 1401 eslintconfigprettier 830 eslintpluginimport 2252 eslintpluginjsxa11y 641 eslintpluginreact 7261 eslintpluginreacthooks 420 jestwhen 341 rimraf 302 typescript 444 run npm install make sure youre running on typescript v444 add the following component to your src', 'i name it threerenderertsx import html orbitcontrols perspectivecamera usegltf useprogress from reactthreedrei import canvas useframe from reactthreefiber import fc suspense useeffect useref usestate from react import animationaction animationmixer from three import gltf gltfloader from threestdlib import create from zustand import devtools from zustandmiddleware export const usegltfmodel create readonly model gltf undefined eslintdisablenextline typescripteslintnounusedvars devtoolsset model undefined export const usegltfanimationaction create readonly animationaction animationaction undefined eslintdisablenextline typescripteslintnounusedvars devtoolsset animationaction undefined interface modelprops readonly gltfpath string readonly onload void const model fcmodelprops gltfpath onload const model usegltfgltfpath undefined undefined loader gltfloader loadermanageronload onload refs const rootref useref const animationactionsref userefanimationaction mixer const mixer usestate new animationmixermodelscene useframestate delta mixerupdatedelta effects useeffect usegltfmodelsetstate model model animationactionsrefcurrent modelanimationsmapanimation mixerclipactionanimation rootrefcurrent usegltfanimationactionsetstate animationaction animationactionsrefcurrent return modelanimationsmapanimation mixeruncacheclipanimation model mixer return primitive refrootrefcurrent objectmodelscene const progress const progress useprogress return html center span style color white progress loadedspan html const threerenderer fcmodelprops gltfpath onload jsxelement const cameraref useref return canvas perspectivecamera refcameraref position0 5 5 orbitcontrols cameracamerarefcurrent ambientlight intensity05 suspense fallbackprogress environment presetcity model gltfpathgltfpath onloadonload suspense canvas export default threerenderer go to apptsx and add a box component from muimaterial', 'import react from react import logo from logosvg import appcss import box from muimaterial function app return div classnameapp header classnameappheader img srclogo classnameapplogo altlogo p edit codesrcapptsxcode and save to reload', 'p a classnameapplink href targetblank relnoopener noreferrer learn react a box box header div export default app you should see the error appear', 'what i see note please try to reproduce this error locally in vscode or your preferred editor', 'i did not manage to reproduce this on codesandbox for example', 'i dont know why there the issue does not appear', 'i suspect thats because they use a different typescript version', 'update ive opened issues on both mui and reactthree reactthreefiber mui']"
Customized error responses for ApiVersioning errors in webapi dotnet core,"I am creating a package lib for all the errors in a Webapi service. This library will be used for providing custom responses for BadRequest, BadArgument, ApiVersionsing etc.. related errors. I need help in customizing Apiversion related errors for - ApiVersionUnspecified, UnsupportedApiVersion, InvalidApiVersion, AmbiguousApiVersion. I have follow this article to include api-versioning for my project - https://www.hanselman.com/blog/ASPNETCoreRESTfulWebAPIVersioningMadeEasy.aspx
I have checked the github wiki for the above package and found that ""Depending on the desired behavior, you can extend the DefaultErrorResponseProvider or you can implement your own IErrorResponseProvider from stratch.
To wire up an alternate error response behavior, replace the default provider with your own:""
options => options.ErrorResponses = new MyErrorResponseProvider();

However; I am not quite getting how can I customize the default error responses in MyErrorResponseProvider class. Can somebody please provide me with any example so I can get started with this?
Thanks in advance!
",<c#><error-handling><.net-core><custom-error-handling><api-versioning>,7,"c#,error-handling,.net-core,custom-error-handling,api-versioning",['customized error responses for apiversioning errors in webapi dotnet core'],"['i am creating a package lib for all the errors in a webapi service', 'this library will be used for providing custom responses for badrequest badargument apiversionsing etc related errors', 'i need help in customizing apiversion related errors for apiversionunspecified unsupportedapiversion invalidapiversion ambiguousapiversion', 'i have follow this article to include apiversioning for my project i have checked the github wiki for the above package and found that depending on the desired behavior you can extend the defaulterrorresponseprovider or you can implement your own ierrorresponseprovider from stratch', 'to wire up an alternate error response behavior replace the default provider with your own options optionserrorresponses new myerrorresponseprovider however i am not quite getting how can i customize the default error responses in myerrorresponseprovider class', 'can somebody please provide me with any example so i can get started with this', 'thanks in advance']"
Get N'th line of multiple files in linux,"The task I'm trying to accomplish is, I have this kind of files:
test1.csv test2.csv test3.csv etc...
And I want to get 3'rd line of every file. Right now, I can get 3'rd lines using awk, or sed like 
echo |  awk 'FNR == 3 { print; exit }' test1.csv >> last_file.csv or using sed or tail.
But when I try to do this on multiple files, It cannot get the lines. I want to do like this, 
echo |  awk 'FNR == 3 { print; exit }' test*.csv >> last_file.csv
How can I achieve this?
Thank you.
",<linux><csv><awk><sed><echo>,10,"linux,csv,awk,sed,echo",['get nth line of multiple files in linux'],"['the task im trying to accomplish is i have this kind of files test1csv test2csv test3csv etc and i want to get 3rd line of every file', 'right now i can get 3rd lines using awk or sed like echo awk fnr 3 print exit test1csv lastfilecsv or using sed or tail', 'but when i try to do this on multiple files it cannot get the lines', 'i want to do like this echo awk fnr 3 print exit testcsv lastfilecsv how can i achieve this', 'thank you']"
Github actions not working after npm start,"I have a very simple config in order to run e2e tests with Cypress using Github Actions in a Nextjs app. When it reaches the npm start command, although it seems to work since it gives the correct output: > Ready on http://localhost:3000, the step stays in pending state without ever advancing to the next step.
Any suggestions on how to fix this?
Following github actions config (.github/workflows/nodejs.yml):
name: Node CI

on: [push]

jobs:
  build:

    runs-on: ubuntu-latest

    strategy:
      matrix:
        node-version: [8.x, 10.x, 12.x]

    steps:
    - uses: actions/checkout@v1
    - name: Use Node.js ${{ matrix.node-version }}
      uses: actions/setup-node@v1
      with:
        node-version: ${{ matrix.node-version }}
    - name: npm install, build, and test
      run: |
        npm ci
        npm run build --if-present
        npm start
        npx wait-on http://localhost:3000
      env:
        CI: true
    - name: Run Cypress
      run: |
        npx cypress run
      env:
        CI: true

",<node.js><continuous-integration><next.js><cypress><github-actions>,6,"node.js,continuous-integration,next.js,cypress,github-actions",['github actions not working after npm start'],"['i have a very simple config in order to run e2e tests with cypress using github actions in a nextjs app', 'when it reaches the npm start command although it seems to work since it gives the correct output ready on the step stays in pending state without ever advancing to the next step', 'any suggestions on how to fix this', 'following github actions config githubworkflowsnodejsyml name node ci on push jobs build runson ubuntulatest strategy matrix nodeversion 8x 10x 12x steps uses actionscheckoutv1 name use nodejs matrixnodeversion uses actionssetupnodev1 with nodeversion matrixnodeversion name npm install build and test run npm ci npm run build ifpresent npm start npx waiton env ci true name run cypress run npx cypress run env ci true']"
NgRx: How to use services in meta-reducers?,"I use a custom middleware (meta-reducer) to print my ngrx-store each time an action is dipatched. I wrote my middleware directly inside app.module.ts (where else should I put it ?):
app.module.ts
// ...imports

// ...

// FIXME:
/**
 * console.log action and state(before action) each time an action is dipatched
 * @param reducer reducer
 */
export function debug(reducer: ActionReducer<AppState, Actions>): ActionReducer<AppState, Actions> {

    const logger = new LoggerService(); ////////////// ERROR \\\\\\\\\\\\\\

    return (state, action) => {

        logger.storeInfo('ACTION', action);
        logger.storeInfo('STATE', state);

        return reducer(state, action);
    };
}

export const metaReducers: MetaReducer<any>[] = [
    debug,
];

@NgModule({
    declarations: [AppComponent, LoggerServiceComponent],
    entryComponents: [],
    imports: [
        // ...
        StoreModule.forRoot(reducers, { metaReducers }),
        StoreRouterConnectingModule.forRoot(), // Connects RouterModule with StoreModule
    ],
    providers: [
       // ...
    ],
    bootstrap: [AppComponent],
})
export class AppModule {}

There is an error because my LoggerService has a store injected (because I want all my logs to be stored in ngx-store. But I can't access the store neither !. Furthermore, I'm sure that's not the good way of accessing the singleton instance of a service...

Should I put my meta reducer inside a class, and then accessing the function of that class, but how do I do it ?
Is there a general method to access any service, like SomeClass.getServiceInstance(type) ?
Do you have other ideas on how to do it ?

[EDIT 1] - using META_REDUCERS (1st try - failing)
app.module.ts
import { LoggerService } from './services/logger.service';
import { AppState, Actions } from './app.state';
import { StoreModule, MetaReducer, ActionReducer, META_REDUCERS } from '@ngrx/store';

/**
 * Injects a `LoggerService` inside a `MetaReducer`
 * @param logger a service that allows to log and store console.log() messages
 * @returns a `MetaReducer`
 */
function debugFactory(logger: LoggerService): MetaReducer<AppState> {
    return (reducer: ActionReducer<AppState, Actions>): ActionReducer<AppState, Actions> => {
        return (state, action) => {

           logger.storeInfo('ACTION', action);
           logger.storeInfo('STATE', state);

           return reducer(state, action);
        };
    };
}

/**
 * Injects a LoggerService inside the debug `MetaReducer` function
 * @param logger a service that allows to log and store console.log() messages
 * @returns A list of `MetaReducer`
 */
export function getMetaReducers(logger: LoggerService): MetaReducer<AppState>[] {
    return [debugFactory(logger)];
}

const reducers = {
    layout: layoutReducer,
    preferences: preferencesReducer,
    router: routerReducer,
    debug: debugReducer,
};

@NgModule({
    declarations: [AppComponent ],
    entryComponents: [],
    imports: [
        // ...
        StoreModule.forRoot(reducers),
        StoreRouterConnectingModule.forRoot(), // Connects RouterModule with StoreModule
    ],
    providers: [
        // ...
        {
            provide: META_REDUCERS,
            deps: [LoggerService],
            useFactory: getMetaReducers,
            multi: true,
        },
    ],
    bootstrap: [AppComponent],
})
export class AppModule {}

This should work, according to the document but I have the following error at runtime:
TypeError: ""fn is not a function""

Corresponding to this function (in the njrx-store library):
/**
 * @param {...?} functions
 * @return {?}
 */
function compose(...functions) {
    return (/**
     * @param {?} arg
     * @return {?}
     */
    function (arg) {
        if (functions.length === 0) {
            return arg;
        }
        /** @type {?} */
        const last = functions[functions.length - 1];
        /** @type {?} */
        const rest = functions.slice(0, -1);
        return rest.reduceRight((/**
         * @param {?} composed
         * @param {?} fn
         * @return {?}
         */
        (composed, fn) => {
             return fn(composed) // <----- HERE
        }), last(arg));
    });
}

In the debugger, it shows that the function array (...functions) contains some functions and one array, which I suspect is the result of the method getMetaReducers. I suspect either the example is wrong or there is a problem with the implementation of the compose method.
Tell me if you see any wrong things in my code.
[EDIT 2] - using USER_PROVIDED_META_REDUCERS as mentioned in answer (2nd try - failing)
code that have been edited
// OLD

    providers: [
        // ...
        {
            provide: META_REDUCERS,
            deps: [LoggerService],
            useFactory: getMetaReducers,
            multi: true,
        },
    ],

// NEW

    providers: [
        // ...
        {
            provide: USER_PROVIDED_META_REDUCERS,
            deps: [LoggerService],
            useFactory: getMetaReducers,
        },
    ],

It seems that my LoggerService is either not correctly passed nor initialized because I have now this error:
core.js:9110 ERROR TypeError: Cannot read property 'storeInfo' of undefined
    at http://localhost:8102/main.js:636:20
    at http://localhost:8102/vendor.js:109798:20
    at computeNextEntry (http://localhost:8102/vendor.js:108628:21)
    at recomputeStates (http://localhost:8102/vendor.js:108681:15)
    at http://localhost:8102/vendor.js:109029:26
    at ScanSubscriber.StoreDevtools.liftedAction$.pipe.Object.state [as accumulator] (http://localhost:8102/vendor.js:109081:38)
    at ScanSubscriber._tryNext (http://localhost:8102/vendor.js:120261:27)
    at ScanSubscriber._next (http://localhost:8102/vendor.js:120254:25)
    at ScanSubscriber.next (http://localhost:8102/vendor.js:114391:18)
    at WithLatestFromSubscriber._next (http://localhost:8102/vendor.js:122330:34)

if I comment those lines:
        logger.storeInfo('ACTION', action);
        logger.storeInfo('STATE', state);

No exception will be thrown, but my logger won't work either.
But at least the store configures itself correcly, the problem now is just that the LoggerService is either not correctly passed nor initialized. I guess I'm still doing something wrong
",<angular><ionic-framework><dependency-injection><ionic4><ngrx>,9,"angular,ionic-framework,dependency-injection,ionic4,ngrx",['ngrx how to use services in metareducers'],"['i use a custom middleware metareducer to print my ngrxstore each time an action is dipatched', 'i wrote my middleware directly inside appmodulets where else should i put it ', ' appmodulets imports fixme consolelog action and statebefore action each time an action is dipatched param reducer reducer export function debugreducer actionreducerappstate actions actionreducerappstate actions const logger new loggerservice error return state action loggerstoreinfoaction action loggerstoreinfostate state return reducerstate action export const metareducers metareducerany debug ngmodule declarations appcomponent loggerservicecomponent entrycomponents imports storemoduleforrootreducers metareducers storerouterconnectingmoduleforroot connects routermodule with storemodule providers bootstrap appcomponent export class appmodule there is an error because my loggerservice has a store injected because i want all my logs to be stored in ngxstore', 'but i cant access the store neither ', 'furthermore im sure thats not the good way of accessing the singleton instance of a service should i put my meta reducer inside a class and then accessing the function of that class but how do i do it ', 'is there a general method to access any service like someclassgetserviceinstancetype ', 'do you have other ideas on how to do it ', 'edit 1 using metareducers 1st try failing appmodulets import loggerservice from servicesloggerservice import appstate actions from appstate import storemodule metareducer actionreducer metareducers from ngrxstore injects a loggerservice inside a metareducer param logger a service that allows to log and store consolelog messages returns a metareducer function debugfactorylogger loggerservice metareducerappstate return reducer actionreducerappstate actions actionreducerappstate actions return state action loggerstoreinfoaction action loggerstoreinfostate state return reducerstate action injects a loggerservice inside the debug metareducer function param logger a service that allows to log and store consolelog messages returns a list of metareducer export function getmetareducerslogger loggerservice metareducerappstate return debugfactorylogger const reducers layout layoutreducer preferences preferencesreducer router routerreducer debug debugreducer ngmodule declarations appcomponent entrycomponents imports storemoduleforrootreducers storerouterconnectingmoduleforroot connects routermodule with storemodule providers provide metareducers deps loggerservice usefactory getmetareducers multi true bootstrap appcomponent export class appmodule this should work according to the document but i have the following error at runtime typeerror fn is not a function corresponding to this function in the njrxstore library param ', 'functions return ', ' function composefunctions return param ', 'arg return ', ' function arg if functionslength 0 return arg type ', ' const last functionsfunctionslength 1 type ', ' const rest functionsslice0 1 return restreduceright param ', 'composed param ', 'fn return ', ' composed fn return fncomposed here lastarg in the debugger it shows that the function array functions contains some functions and one array which i suspect is the result of the method getmetareducers', 'i suspect either the example is wrong or there is a problem with the implementation of the compose method', 'tell me if you see any wrong things in my code', 'edit 2 using userprovidedmetareducers as mentioned in answer 2nd try failing code that have been edited old providers provide metareducers deps loggerservice usefactory getmetareducers multi true new providers provide userprovidedmetareducers deps loggerservice usefactory getmetareducers it seems that my loggerservice is either not correctly passed nor initialized because i have now this error corejs9110 error typeerror cannot read property storeinfo of undefined at at at computenextentry at recomputestates at at scansubscriberstoredevtoolsliftedactionpipeobjectstate as accumulator at scansubscribertrynext at scansubscribernext at scansubscribernext at withlatestfromsubscribernext if i comment those lines loggerstoreinfoaction action loggerstoreinfostate state no exception will be thrown but my logger wont work either', 'but at least the store configures itself correcly the problem now is just that the loggerservice is either not correctly passed nor initialized', 'i guess im still doing something wrong']"
How to handle WM_ERASEBKGND to avoid flickering?,"I have on a form some custom progress bars which are updated/refreshed twice per second and they are flickering. 
TMyProgressBar = class(TCustomControl)

I inherited the control from TCustomControl, because I needed Handle and some TWinControl events. The controls (up to 64 items) are created dynamically and put on a ScrollBox. When progress is updated I first call InvalidateRect.
All painting work (a set of rectangles, DrawText, etc - inspired from here) are performed in a memory DC and then BitBlt-ed on the control's DC. It is anyway flickering, it seems like component dis-appears and re-appears. IMHO it is caused by background erasing.
In this flickering-free drawing advice it is written to handle WM_ERASEBKGND in the following way: 
type
  TMyProgressBar = class(TCustomControl)
    procedure WMEraseBkGnd(var Message:TMessage); message WM_ERASEBKGND;

procedure TMyProgressBar.WMEraseBkGnd(var Message: TMessage);
begin
  Message.Result := 1;
end;

But in another component, by TMS (TAdvProgressBar), Result is set to 0 for the same message.
Now the Windows documentation states:

An application should return nonzero if it erases the background;
  otherwise, it should return zero.

I tested both variants (Result = 0, 1), and to my surprise both avoid flickering.
So now, what do I have to put in my Delphi code? What is the correct way?
",<delphi><winapi><delphi-7><gdi><flicker>,9,"delphi,winapi,delphi-7,gdi,flicker",['how to handle wmerasebkgnd to avoid flickering'],"['i have on a form some custom progress bars which are updatedrefreshed twice per second and they are flickering', 'tmyprogressbar classtcustomcontrol i inherited the control from tcustomcontrol because i needed handle and some twincontrol events', 'the controls up to 64 items are created dynamically and put on a scrollbox', 'when progress is updated i first call invalidaterect', 'all painting work a set of rectangles drawtext etc inspired from here are performed in a memory dc and then bitblted on the controls dc', 'it is anyway flickering it seems like component disappears and reappears', 'imho it is caused by background erasing', 'in this flickeringfree drawing advice it is written to handle wmerasebkgnd in the following way type tmyprogressbar classtcustomcontrol procedure wmerasebkgndvar messagetmessage message wmerasebkgnd procedure tmyprogressbarwmerasebkgndvar message tmessage begin messageresult 1 end but in another component by tms tadvprogressbar result is set to 0 for the same message', 'now the windows documentation states an application should return nonzero if it erases the background otherwise it should return zero', 'i tested both variants result 0 1 and to my surprise both avoid flickering', 'so now what do i have to put in my delphi code', 'what is the correct way']"
string.equals not working for me,"This is the useful part of code:
java.util.List<Element> elems = src.getAllElements();
Iterator it = elems.iterator();
Element el;
String key,value,date="""",place="""";
String [] data;
int k=0;
Segment content;
String contentstr;
String classname;

while(it.hasNext()){

    el = (Element)it.next();

    if(el.getName().equals(""span""))
    {

            classname=el.getAttributeValue(""class"");
        if(classname.equals(""edit_body""))
        {
            //java.util.List<Element> elemsinner = el.getChildElements();
            //Iterator itinner = elemsinner.iterator();


            content=el.getContent();

            contentstr=content.toString();


            if(true)
            {


                System.out.println(""Done!"");

                System.out.println(classname);

                System.out.println(contentstr);


            }
       }
    }

}

No output. But if I remove the if(classname.equals(""edit_body"")) condition it does print (in one of the iterations):
Done!
edit_body
&quot;I honestly think it is better to be a failure at something you love than to be a success at something you hate.&quot;

Can't get the bug part... help!
I am using an external java library BTW for html parsing.
BTW there are two errors at the start of the output, which is there in both the cases, with or without if condition.: 
Dec 20, 2012 11:53:11 AM net.htmlparser.jericho.LoggerProviderJava$JavaLogger error SEVERE: EndTag br at (r1992,c60,p94048) not recognised as type '/normal' because its name and closing delimiter are separated by characters other than white space 

Dec 20, 2012 11:53:11 AM net.htmlparser.jericho.LoggerProviderJava$JavaLogger error SEVERE: Encountered possible EndTag at (r1992,c60,p94048) whose content does not match a registered EndTagType 

Hope that wont cause the error
Ok guys, Somebody explain me please! ""edit_body"".equals(el.getAttributeValue(""class"")) worked!!
",<java><html><string><parsing><compare>,6,"java,html,string,parsing,compare",['stringequals not working for me'],"['this is the useful part of code javautillistelement elems srcgetallelements iterator it elemsiterator element el string keyvaluedateplace string data int k0 segment content string contentstr string classname whileithasnext el elementitnext ifelgetnameequalsspan classnameelgetattributevalueclass ifclassnameequalseditbody javautillistelement elemsinner elgetchildelements iterator itinner elemsinneriterator contentelgetcontent contentstrcontenttostring iftrue systemoutprintlndone', ' systemoutprintlnclassname systemoutprintlncontentstr no output', 'but if i remove the ifclassnameequalseditbody condition it does print in one of the iterations done', 'editbody quoti honestly think it is better to be a failure at something you love than to be a success at something you hatequot cant get the bug part help', 'i am using an external java library btw for html parsing', 'btw there are two errors at the start of the output which is there in both the cases with or without if condition', ' dec 20 2012 115311 am nethtmlparserjerichologgerproviderjavajavalogger error severe endtag br at r1992c60p94048 not recognised as type normal because its name and closing delimiter are separated by characters other than white space dec 20 2012 115311 am nethtmlparserjerichologgerproviderjavajavalogger error severe encountered possible endtag at r1992c60p94048 whose content does not match a registered endtagtype hope that wont cause the error ok guys somebody explain me please', 'editbodyequalselgetattributevalueclass worked', '']"
Using CGImageProperties to get EXIF properties,"I want to be able to add a text comment to the metadata of a JPEG and be able to read it back from within an iphone app.
I thought this would be fairly simple as ios4 contains support for EXIF info. So I added metadata using a Windows tool called used AnalogExif and read it back from my app using:
NSData *jpeg = UIImageJPEGRepresentation(myUIImage,1.0);

CGImageSourceRef  source = CGImageSourceCreateWithData((CFDataRef)jpeg, NULL);
NSDictionary *metadata = (NSDictionary *) CGImageSourceCopyPropertiesAtIndex(source,0,NULL);

NSMutableDictionary *metadataAsMutable = [[metadata mutableCopy]autorelease];
[metadata release];

NSMutableDictionary *EXIFDictionary = [[[metadataAsMutable objectForKey:(NSString *)kCGImagePropertyExifDictionary]

And that works...to a point :)
What I get back in the metadata dictionary is something like:
(gdb) po metadata
{
   ColorModel = RGB;
   Depth = 8;
   Orientation = 1;
   PixelHeight = 390;
   PixelWidth = 380;
   ""{Exif}"" =     {
      ColorSpace = 1;
      PixelXDimension = 380;
      PixelYDimension = 390;
   };
   ""{JFIF}"" =     {
      DensityUnit = 0;
      JFIFVersion = (
        1,
        1
      );
      XDensity = 1;
      YDensity = 1;
   };
   ""{TIFF}"" =     {
      Orientation = 1;
   };
}

But thats all I can get! I've edited the JPEG file with every EXIF editor I can find (mostly PC ones I should say) and although they all say I have added JPEG comments and EXIF captions and keywords, none of that info seems to be available from the Apple SDK in my app.
Has anyone managed to set a text field in the metadata of a jpeg and manage to read it back from an iphone app?
I didn't want to use a third party library if at all possible
many thanks in advance
",<xcode><uiimage><exif><iptc><cgimagesource>,5,"xcode,uiimage,exif,iptc,cgimagesource",['using cgimageproperties to get exif properties'],"['i want to be able to add a text comment to the metadata of a jpeg and be able to read it back from within an iphone app', 'i thought this would be fairly simple as ios4 contains support for exif info', 'so i added metadata using a windows tool called used analogexif and read it back from my app using nsdata jpeg uiimagejpegrepresentationmyuiimage10 cgimagesourceref source cgimagesourcecreatewithdatacfdatarefjpeg null nsdictionary metadata nsdictionary cgimagesourcecopypropertiesatindexsource0null nsmutabledictionary metadataasmutable metadata mutablecopyautorelease metadata release nsmutabledictionary exifdictionary metadataasmutable objectforkeynsstring kcgimagepropertyexifdictionary and that worksto a point what i get back in the metadata dictionary is something like gdb po metadata colormodel rgb depth 8 orientation 1 pixelheight 390 pixelwidth 380 exif colorspace 1 pixelxdimension 380 pixelydimension 390 jfif densityunit 0 jfifversion 1 1 xdensity 1 ydensity 1 tiff orientation 1 but thats all i can get', 'ive edited the jpeg file with every exif editor i can find mostly pc ones i should say and although they all say i have added jpeg comments and exif captions and keywords none of that info seems to be available from the apple sdk in my app', 'has anyone managed to set a text field in the metadata of a jpeg and manage to read it back from an iphone app', 'i didnt want to use a third party library if at all possible many thanks in advance']"
How do I enable/disable hotspot or tethering mode programmatically on Android?,"I see many references on Android's website to local Only Hotspot
However I need to manage the cellular hotspot programmatically from a background service as I can do manually from the pulldown menu.
This used to be done like:
method = wifiManager.getClass().getDeclaredMethod(""setWifiApEnabled"", WifiConfiguration.class, Boolean.TYPE);
method.invoke(wifiManager, wifiConfiguration, activated);

However this feature has been deprecated.
My wireless provider (AT&T) is trying to charge me differently based on what device is connected and how. The network should be agnostic to devices and just transport my packets to their destination. I hope this is not related, but I am worried we our losing control over our devices.
Does Android really not provide simple API calls for managing the hotspot?
",<java><android><android-wifi><wifimanager><android-developer-api>,5,"java,android,android-wifi,wifimanager,android-developer-api",['how do i enabledisable hotspot or tethering mode programmatically on android'],"['i see many references on androids website to local only hotspot however i need to manage the cellular hotspot programmatically from a background service as i can do manually from the pulldown menu', 'this used to be done like method wifimanagergetclassgetdeclaredmethodsetwifiapenabled wificonfigurationclass booleantype methodinvokewifimanager wificonfiguration activated however this feature has been deprecated', 'my wireless provider att is trying to charge me differently based on what device is connected and how', 'the network should be agnostic to devices and just transport my packets to their destination', 'i hope this is not related but i am worried we our losing control over our devices', 'does android really not provide simple api calls for managing the hotspot']"
Ignore pattern for eclipse workspace,"Do you have a good ignore pattern for svn, git, etc. that handles an eclipse workspace? I want to version handle all projects in the workspace. It has to ignore all the eclipse configuration, compiled files, and output folders.
",<eclipse><svn><language-agnostic><version-control><development-environment>,8,"eclipse,svn,language-agnostic,version-control,development-environment",['ignore pattern for eclipse workspace'],"['do you have a good ignore pattern for svn git etc', 'that handles an eclipse workspace', 'i want to version handle all projects in the workspace', 'it has to ignore all the eclipse configuration compiled files and output folders']"
"Can an ASP.NET MVC2 site have an optional enum route parameter? If so, can we default that value if not provided?","can I have a route like...
routes.MapRoute(
    ""Boundaries-Show"",
    ""Boundaries"",
     new 
     {
         controller = ""Boundaries"", 
         action = ""Show"",
         locationType = UrlParameter.Optional
     });

Where the action method is...
[HttpGet]
public ActionResult Show(int? aaa, int? bbb, LocationType locationType) { ... }

and if the person doesn't provide a value for locationType .. then it defaults to LocationType.Unknown.
Is this possible?
Update #1
I've stripped back the action method to contain ONE method (just until I get this working). It now looks like this ..
[HttpGet]
public ActionResult Show(LocationType locationType = LocationType.Unknown) { .. }

.. and I get this error message...

The parameters dictionary contains an
  invalid entry for parameter
  'locationType' for method
  'System.Web.Mvc.ActionResult
  Show(MyProject.Core.LocationType)' in
  'MyProject.Controllers.GeoSpatialController'.
  The dictionary contains a value of
  type 'System.Int32', but the parameter
  requires a value of type
  'MyProject.Core.LocationType'.
  Parameter name: parameters

Is it thinking that the optional route parameter LocationType is an int32 and not a custom Enum ?
",<.net><asp.net-mvc><asp.net-mvc-2><enums><routes>,7,".net,asp.net-mvc,asp.net-mvc-2,enums,routes","['can an aspnet mvc2 site have an optional enum route parameter', 'if so can we default that value if not provided']","['can i have a route like routesmaproute boundariesshow boundaries new controller boundaries action show locationtype urlparameteroptional where the action method is httpget public actionresult showint', 'aaa int', 'bbb locationtype locationtype and if the person doesnt provide a value for locationtype then it defaults to locationtypeunknown', 'is this possible', 'update 1 ive stripped back the action method to contain one method just until i get this working', 'it now looks like this httpget public actionresult showlocationtype locationtype locationtypeunknown and i get this error message the parameters dictionary contains an invalid entry for parameter locationtype for method systemwebmvcactionresult showmyprojectcorelocationtype in myprojectcontrollersgeospatialcontroller', 'the dictionary contains a value of type systemint32 but the parameter requires a value of type myprojectcorelocationtype', 'parameter name parameters is it thinking that the optional route parameter locationtype is an int32 and not a custom enum ']"
Unable to Cast() generic dictionary item to DictionaryEntry when enumerated via non-generic IDictionary,"I have some code that iterates over a non-generic IDictionary by first calling the LINQ Cast method. However I get an invalid cast exception when passing a generic dictionary implementation even though I'm specifically using it via the non-generic IDictionary interface.
IDictionary dict = new Dictionary<object, object> {{""test"", ""test""}};
foreach (var item in dict)
{
    Debug.Assert(item is DictionaryEntry); // works
}
dict.Cast<DictionaryEntry>().ToList();     // FAILS

Why does the Cast method above fail when the normal iteration doesn't? Is there a reliable way to transform a non-generic dictionary into an enumeration of DictionaryEntry without resorting to manual list building?
",<.net><linq><dictionary><casting><linq-to-objects>,5,".net,linq,dictionary,casting,linq-to-objects",['unable to cast generic dictionary item to dictionaryentry when enumerated via nongeneric idictionary'],"['i have some code that iterates over a nongeneric idictionary by first calling the linq cast method', 'however i get an invalid cast exception when passing a generic dictionary implementation even though im specifically using it via the nongeneric idictionary interface', 'idictionary dict new dictionaryobject object test test foreach var item in dict debugassertitem is dictionaryentry works dictcastdictionaryentrytolist fails why does the cast method above fail when the normal iteration doesnt', 'is there a reliable way to transform a nongeneric dictionary into an enumeration of dictionaryentry without resorting to manual list building']"
How can I present a native UIViewController in React Native? (Can't use just a UIView),"I'm trying to use ABNewPersonViewController in my React Native app. This is how it's used in Objective-C:
ABNewPersonViewController *picker = [[ABNewPersonViewController alloc] init];
picker.newPersonViewDelegate = self;

UINavigationController *navigation = [[UINavigationController alloc] initWithRootViewController:picker];
[self presentViewController:navigation animated:NO completion:nil];

How would I do this in React Native? I can't write a bridged UI component since it's a UIViewController, not a UIView. 
Please don't tell me to reimplement it 😟
",<javascript><ios><objective-c><reactjs><react-native>,24,"javascript,ios,objective-c,reactjs,react-native","['how can i present a native uiviewcontroller in react native', 'cant use just a uiview']","['im trying to use abnewpersonviewcontroller in my react native app', 'this is how its used in objectivec abnewpersonviewcontroller picker abnewpersonviewcontroller alloc init pickernewpersonviewdelegate self uinavigationcontroller navigation uinavigationcontroller alloc initwithrootviewcontrollerpicker self presentviewcontrollernavigation animatedno completionnil how would i do this in react native', 'i cant write a bridged ui component since its a uiviewcontroller not a uiview', 'please dont tell me to reimplement it ']"
CSV copy to Postgres with array of custom type using JDBC,"I have a custom type defined in my database as
CREATE TYPE address AS (ip inet, port int);

And a table that uses this type in an array:
CREATE TABLE my_table (
  addresses  address[] NULL
)

I have a sample CSV file with the following contents
{(10.10.10.1,80),(10.10.10.2,443)}
{(10.10.10.3,8080),(10.10.10.4,4040)}

And I use the following code snippet to perform my COPY:
    Class.forName(""org.postgresql.Driver"");

    String input = loadCsvFromFile();

    Reader reader = new StringReader(input);

    Connection connection = DriverManager.getConnection(
            ""jdbc:postgresql://db_host:5432/db_name"", ""user"",
            ""password"");

    CopyManager copyManager = connection.unwrap(PGConnection.class).getCopyAPI();

    String copyCommand = ""COPY my_table (addresses) "" + 
                         ""FROM STDIN WITH ("" + 
                           ""DELIMITER '\t', "" + 
                           ""FORMAT csv, "" + 
                           ""NULL '\\N', "" + 
                           ""ESCAPE '\""', "" +
                           ""QUOTE '\""')"";

    copyManager.copyIn(copyCommand, reader);

Executing this program produces the following exception:
Exception in thread ""main"" org.postgresql.util.PSQLException: ERROR: malformed record literal: ""(10.10.10.1""
  Detail: Unexpected end of input.
  Where: COPY only_address, line 1, column addresses: ""{(10.10.10.1,80),(10.10.10.2,443)}""
    at org.postgresql.core.v3.QueryExecutorImpl.receiveErrorResponse(QueryExecutorImpl.java:2422)
    at org.postgresql.core.v3.QueryExecutorImpl.processCopyResults(QueryExecutorImpl.java:1114)
    at org.postgresql.core.v3.QueryExecutorImpl.endCopy(QueryExecutorImpl.java:963)
    at org.postgresql.core.v3.CopyInImpl.endCopy(CopyInImpl.java:43)
    at org.postgresql.copy.CopyManager.copyIn(CopyManager.java:185)
    at org.postgresql.copy.CopyManager.copyIn(CopyManager.java:160)

I have tried with different combinations of the parentheses in the input but cannot seem to get the COPY working. Any ideas where I might be going wrong?
",<java><database><postgresql><jdbc><postgresql-9.5>,18,"java,database,postgresql,jdbc,postgresql-9.5",['csv copy to postgres with array of custom type using jdbc'],"['i have a custom type defined in my database as create type address as ip inet port int and a table that uses this type in an array create table mytable addresses address null i have a sample csv file with the following contents 1010101801010102443 1010103808010101044040 and i use the following code snippet to perform my copy classfornameorgpostgresqldriver string input loadcsvfromfile reader reader new stringreaderinput connection connection drivermanagergetconnection jdbcpostgresqldbhost5432dbname user password copymanager copymanager connectionunwrappgconnectionclassgetcopyapi string copycommand copy mytable addresses from stdin with delimiter t format csv null n escape quote copymanagercopyincopycommand reader executing this program produces the following exception exception in thread main orgpostgresqlutilpsqlexception error malformed record literal 1010101 detail unexpected end of input', 'where copy onlyaddress line 1 column addresses 1010101801010102443 at orgpostgresqlcorev3queryexecutorimplreceiveerrorresponsequeryexecutorimpljava2422 at orgpostgresqlcorev3queryexecutorimplprocesscopyresultsqueryexecutorimpljava1114 at orgpostgresqlcorev3queryexecutorimplendcopyqueryexecutorimpljava963 at orgpostgresqlcorev3copyinimplendcopycopyinimpljava43 at orgpostgresqlcopycopymanagercopyincopymanagerjava185 at orgpostgresqlcopycopymanagercopyincopymanagerjava160 i have tried with different combinations of the parentheses in the input but cannot seem to get the copy working', 'any ideas where i might be going wrong']"
Creating New Columns in Power BI with a Python Script,"I am trying to run a python script so that I can create a household count based on the residential address column and residential city column. Both columns just contain strings. 
The script that I have tried can be seen below:
dataset['id'] =dataset.groupby(['RESIDENTIAL_ADDRESS1','RESIDENTIAL_CITY']).ngroup()
dataset['household_count'] = dataset.groupby(['id'])['id'].transform('count')

Yet, it gives me this error after 20,000 rows:
DataSource.Error: ADO.NET: A problem occurred while processing your Python script. Here are the technical details: [DataFormat.Error] We couldn't convert to Number. Details:DataSourceKind=Python DataSourcePath=Python Message=A problem occurred while processing your Python script. Here are the technical details: [DataFormat.Error] We couldn't convert to Number. ErrorCode=-2147467259.
Is there any way to fix this? This code works in python every single time and the error code make absolutely no sense in Power BI and I would greatly appreciate any advice on how to do this with DAX.
",<python><group-by><powerbi><dax><powerbi-desktop>,6,"python,group-by,powerbi,dax,powerbi-desktop",['creating new columns in power bi with a python script'],"['i am trying to run a python script so that i can create a household count based on the residential address column and residential city column', 'both columns just contain strings', 'the script that i have tried can be seen below datasetid datasetgroupbyresidentialaddress1residentialcityngroup datasethouseholdcount datasetgroupbyididtransformcount yet it gives me this error after 20000 rows datasourceerror adonet a problem occurred while processing your python script', 'here are the technical details dataformaterror we couldnt convert to number', 'detailsdatasourcekindpython datasourcepathpython messagea problem occurred while processing your python script', 'here are the technical details dataformaterror we couldnt convert to number', 'errorcode2147467259', 'is there any way to fix this', 'this code works in python every single time and the error code make absolutely no sense in power bi and i would greatly appreciate any advice on how to do this with dax']"
Can I use arbitrary metrics to search KD-Trees?,"I just finished implementing a kd-tree for doing fast nearest neighbor searches. I'm interested in playing around with different distance metrics other than the Euclidean distance. My understanding of the kd-tree is that the speedy kd-tree search is not guaranteed to give exact searches if the metric is non-Euclidean, which means that I might need to implement a new data structure and search algorithm if I want to try out new metrics for my search.
I have two questions:

Does using a kd-tree permanently tie me to the Euclidean distance?
If so, what other sorts of algorithms should I try that work for arbitrary metrics? I don't have a ton of time to implement lots of different data structures, but other structures I'm thinking about include cover trees and vp-trees.

",<algorithm><math><search><data-structures><machine-learning>,11,"algorithm,math,search,data-structures,machine-learning",['can i use arbitrary metrics to search kdtrees'],"['i just finished implementing a kdtree for doing fast nearest neighbor searches', 'im interested in playing around with different distance metrics other than the euclidean distance', 'my understanding of the kdtree is that the speedy kdtree search is not guaranteed to give exact searches if the metric is noneuclidean which means that i might need to implement a new data structure and search algorithm if i want to try out new metrics for my search', 'i have two questions does using a kdtree permanently tie me to the euclidean distance', 'if so what other sorts of algorithms should i try that work for arbitrary metrics', 'i dont have a ton of time to implement lots of different data structures but other structures im thinking about include cover trees and vptrees']"
Best way to remove multiple items matching a predicate from a .NET Dictionary?,"I need to remove multiple items from a Dictionary.
A simple way to do that is as follows :
  List<string> keystoremove= new List<string>();
  foreach (KeyValuePair<string,object> k in MyCollection)
     if (k.Value.Member==foo)
        keystoremove.Add(k.Key);
  foreach (string s in keystoremove)
        MyCollection.Remove(s);

The reason why I can't directly Remove the items in the foreach block is that this would throw an Exception (""Collection was modified..."")
I'd like to do the following :
 MyCollection.RemoveAll(x =>x.Member==foo)

But the Dictionary<> class doesn't expose a RemoveAll(Predicate<> Match) method, like the List<> Class does.
What's the best way (both performance wise and elegant wise) to do that?
",<c#><.net><linq><collections><dictionary>,77,"c#,.net,linq,collections,dictionary",['best way to remove multiple items matching a predicate from a net dictionary'],"['i need to remove multiple items from a dictionary', 'a simple way to do that is as follows liststring keystoremove new liststring foreach keyvaluepairstringobject k in mycollection if kvaluememberfoo keystoremoveaddkkey foreach string s in keystoremove mycollectionremoves the reason why i cant directly remove the items in the foreach block is that this would throw an exception collection was modified id like to do the following mycollectionremoveallx xmemberfoo but the dictionary class doesnt expose a removeallpredicate match method like the list class does', 'whats the best way both performance wise and elegant wise to do that']"
Instruments leaks stopping after app starts,"So I want use Leaks to find the leaks in my app. In Xcode, I go to ""Product"" and then hit ""Profile"". In Instruments I select Leaks and it starts.
My app is starting and Leaks is running. But just as soon as my app is finished starting and I can use it, Leaks stops.
Is there anybody else with the same problem or maybe knows how to fix this?
",<objective-c><xcode><ipad><instruments><memory-leaks>,8,"objective-c,xcode,ipad,instruments,memory-leaks",['instruments leaks stopping after app starts'],"['so i want use leaks to find the leaks in my app', 'in xcode i go to product and then hit profile', 'in instruments i select leaks and it starts', 'my app is starting and leaks is running', 'but just as soon as my app is finished starting and i can use it leaks stops', 'is there anybody else with the same problem or maybe knows how to fix this']"
TortoiseSVN error: Working copy path does not exist in repository,"I've got a file that I tried to commit using TortoiseSVN, but it gave me the error that the working copy path does not exist, and I have to update my working copy first. So I tried a variety of things:

Reverting the file to a previous version
Deleting the file, trying to commit without it, then trying to re-add it
Deleting the entire folder in my working directory and and re-updating it
Doing a clean-up
Resolving any conflicts
Using the Repo browser to manually add the file to the repository, then trying to re-update, then re-deleting it through the Repo browser

And after all this, I still get the same error. I can't even do a fresh check-out because of the error:
""Working copy path 'path/to/file' does not exist in repository.""
I'm completely out of ideas at this point. Help!
",<svn><repository><tortoisesvn><commit><working-copy>,6,"svn,repository,tortoisesvn,commit,working-copy",['tortoisesvn error working copy path does not exist in repository'],"['ive got a file that i tried to commit using tortoisesvn but it gave me the error that the working copy path does not exist and i have to update my working copy first', 'so i tried a variety of things reverting the file to a previous version deleting the file trying to commit without it then trying to readd it deleting the entire folder in my working directory and and reupdating it doing a cleanup resolving any conflicts using the repo browser to manually add the file to the repository then trying to reupdate then redeleting it through the repo browser and after all this i still get the same error', 'i cant even do a fresh checkout because of the error working copy path pathtofile does not exist in repository', 'im completely out of ideas at this point', 'help']"
"How to decode url to path in python, django","Hi I need to convert url to path, what i got is this url as bellow: 
url = u'/static/media/uploads/gallery/Marrakech%2C%20Morocco_be3Ij2N.jpg'

and what to be looked something like this:
path = u'/static/media/uploads/gallery/Marrakech, Morocco_be3Ij2N.jpg'

thx.
",<python><django><python-2.7><url><path>,27,"python,django,python-2.7,url,path",['how to decode url to path in python django'],['hi i need to convert url to path what i got is this url as bellow url ustaticmediauploadsgallerymarrakech2c20moroccobe3ij2njpg and what to be looked something like this path ustaticmediauploadsgallerymarrakech moroccobe3ij2njpg thx']
Optional or Conditional model associations in Rails,"I have a user model.
Users can have 1 of 3 roles: role1, role2, role3. This is represented by a 'role' column in the user model.
Each role has a unique profile. role1_profile, role2_profile, role3_profile. Each *_profile is a model.
How do I represent this optional association in Rails?
I've tried it two different ways: 
class User < ActiveRecord::Base
    #FIRST WAY
    if current_user.role == 'role1' then has_one :role1_profile end 
    #SECOND WAY
    has_one :role1_profile, :conditions => ['user.role = ?', 'role1']
end

But that doesn't work. What is the right way to do this? 
",<ruby-on-rails><activerecord><associations><belongs-to><has-one>,5,"ruby-on-rails,activerecord,associations,belongs-to,has-one",['optional or conditional model associations in rails'],"['i have a user model', 'users can have 1 of 3 roles role1 role2 role3', 'this is represented by a role column in the user model', 'each role has a unique profile', 'role1profile role2profile role3profile', 'each profile is a model', 'how do i represent this optional association in rails', 'ive tried it two different ways class user activerecordbase first way if currentuserrole role1 then hasone role1profile end second way hasone role1profile conditions userrole ', ' role1 end but that doesnt work', 'what is the right way to do this']"
What's the cmake generator for Visual Studio 2019,"With Visual Studio 2017, I used the generator ""Visual Studio 15 2017 Win64"" for cmake. After updating to Visual Studio 2019, what's the new corresponding generator? 
",<c++><visual-studio><cmake><compilation><updates>,16,"c++,visual-studio,cmake,compilation,updates",['whats the cmake generator for visual studio 2019'],"['with visual studio 2017 i used the generator visual studio 15 2017 win64 for cmake', 'after updating to visual studio 2019 whats the new corresponding generator']"
Using Eureka as a registry using REST APIs,"We have been using Eureka with our Spring Boot applications for few months now. We have enabled service lookup between applications using @DiscoveryClient annotations. The registrations, lease renewals and deregistration works as expected.
Recently, we have encountered a scenario where we have non-Java application component (written in C++), which is exposes 3 REST service endpoints that many of our Spring Boot Java applications would use. We are trying to see if the C++ component can make use of the Eureka server's REST APIs to register itself when it came up, so that the Spring Boot Java applications can perform the usual lookup via Eureka to get in touch with the C++ component.
Since I cannot use the Eureka Client in the C++ components (obviously), I started testing direct REST APIs (as described here) using Postman. The registration worked without any problems by sending a JSON payload using POST method to http://eurekaserver:8761/eureka/apps/FOO-APP (with instanceId = 1111 and hostName = foo-app).  I can query http://eurekaserver:8761/eureka/apps and can see FOO-APP listed there as expected.  
However, when I try the cancel operation using DELETE method to http://eurekaserver:8761/eureka/apps/FOO-APP/1111 or http://eurekaserver:8761/eureka/apps/FOO-APP/foo-app, I get a 404 error.
With instanceId:
{
  ""timestamp"": 1447479397996,
  ""status"": 404,
  ""error"": ""Not Found"",
  ""message"": ""Not Found"",
  ""path"": ""/eureka/apps/FOO-APP/1111""
}

OR (same outcome for hostName):
{
  ""timestamp"": 1447479397996,
  ""status"": 404,
  ""error"": ""Not Found"",
  ""message"": ""Not Found"",
  ""path"": ""/eureka/apps/FOO-APP/foo-app""
}

I tried different combinations, but I am not able to make this work. I have a feeling I am missing something obvious - may be something small. Any help on this would be appreciated.
PS: Eureka REST endpoint documentation mentions ""v2"" in the URL. However, that does not work in my case. Registration (which works for me) does not use ""v2"" as described above. If someone could validate this, that would be helpful as well.  There just doesn't seem to be enough material on this.
",<java><spring><rest><spring-cloud><netflix-eureka>,9,"java,spring,rest,spring-cloud,netflix-eureka",['using eureka as a registry using rest apis'],"['we have been using eureka with our spring boot applications for few months now', 'we have enabled service lookup between applications using discoveryclient annotations', 'the registrations lease renewals and deregistration works as expected', 'recently we have encountered a scenario where we have nonjava application component written in c which is exposes 3 rest service endpoints that many of our spring boot java applications would use', 'we are trying to see if the c component can make use of the eureka servers rest apis to register itself when it came up so that the spring boot java applications can perform the usual lookup via eureka to get in touch with the c component', 'since i cannot use the eureka client in the c components obviously i started testing direct rest apis as described here using postman', 'the registration worked without any problems by sending a json payload using post method to with instanceid 1111 and hostname fooapp', 'i can query and can see fooapp listed there as expected', 'however when i try the cancel operation using delete method to or i get a 404 error', 'with instanceid timestamp 1447479397996 status 404 error not found message not found path eurekaappsfooapp1111 or same outcome for hostname timestamp 1447479397996 status 404 error not found message not found path eurekaappsfooappfooapp i tried different combinations but i am not able to make this work', 'i have a feeling i am missing something obvious may be something small', 'any help on this would be appreciated', 'ps eureka rest endpoint documentation mentions v2 in the url', 'however that does not work in my case', 'registration which works for me does not use v2 as described above', 'if someone could validate this that would be helpful as well', 'there just doesnt seem to be enough material on this']"
Can I modify the dynamic linker and use without recompiling the glibc?,"I am trying to modify the dynamic linker provided in the libc6(2.15-0ubuntu20.2) on a 64 bit Ubuntu machine.
So currently my code is using the same version of the glibc library. (I have downloaded the source code for the same and working on it). My question is that is it possible to modify and build only the linker source code which is present in glibc\elf\ directory without building the entire glibc library.
And if it is possible how can I make my test program to switch using the new version of dynamic linker that I have build myself instead of using the default unmodified linker.
Any pointers or suggestions are highly appreciated.
(If any more information is needed please let me know)
EDIT::
@constantius
I followed the steps in the post linked by you to build ld.so.
But I am getting following error on the make and I checked ld.so is not there in the elf.
The error is::
/var/services/homes/abhi/test/ld/eglibc-build/elf/librtld.os: In function `generic_getcwd':
/var/services/homes/abhi/test/ld/eglibc-2.15/elf/../sysdeps/posix/getcwd.c:356: undefined reference to `__closedir'
/var/services/homes/abhi/test/ld/eglibc-2.15/elf/../sysdeps/posix/getcwd.c:368: undefined reference to `__fdopendir'
/var/services/homes/abhi/test/ld/eglibc-2.15/elf/../sysdeps/posix/getcwd.c:384: undefined reference to `__readdir'
/var/services/homes/abhi/test/ld/eglibc-2.15/elf/../sysdeps/posix/getcwd.c:397: undefined reference to `rewinddir'
/var/services/homes/abhi/test/ld/eglibc-2.15/elf/../sysdeps/posix/getcwd.c:528: undefined reference to `__closedir'
/var/services/homes/abhi/test/ld/eglibc-2.15/elf/../sysdeps/posix/getcwd.c:490: undefined reference to `__closedir'
collect2: error: ld returned 1 exit status
make[2]: *** [/var/services/homes/abhi/test/ld/eglibc-build/elf/ld.so] Error 1
make[2]: Leaving directory `/var/services/homes/abhi/test/ld/eglibc-2.15/elf'
make[1]: *** [elf/subdir_lib] Error 2
make[1]: Leaving directory `/var/services/homes/abhi/test/ld/eglibc-2.15'
make: *** [all] Error 2

NOTE With the same infrastructure I can build and install the full GLIBC so I dont think there is an error with the infrastructure.
-- I guess the error is some where related to editing Makeconfig to all-subdirs = csu elf gmon io misc posix setjmp signal stdlib string time. 
--Any suggestions on this..
SOLVED
Need to add dirent in the all-subdirs list in addition to what we edited before
Thanks
",<c><linux><compiler-construction><linker><glibc>,5,"c,linux,compiler-construction,linker,glibc",['can i modify the dynamic linker and use without recompiling the glibc'],"['i am trying to modify the dynamic linker provided in the libc62150ubuntu202 on a 64 bit ubuntu machine', 'so currently my code is using the same version of the glibc library', 'i have downloaded the source code for the same and working on it', 'my question is that is it possible to modify and build only the linker source code which is present in glibcelf directory without building the entire glibc library', 'and if it is possible how can i make my test program to switch using the new version of dynamic linker that i have build myself instead of using the default unmodified linker', 'any pointers or suggestions are highly appreciated', 'if any more information is needed please let me know edit constantius i followed the steps in the post linked by you to build ldso', 'but i am getting following error on the make and i checked ldso is not there in the elf', 'the error is varserviceshomesabhitestldeglibcbuildelflibrtldos in function genericgetcwd varserviceshomesabhitestldeglibc215elfsysdepsposixgetcwdc356 undefined reference to closedir varserviceshomesabhitestldeglibc215elfsysdepsposixgetcwdc368 undefined reference to fdopendir varserviceshomesabhitestldeglibc215elfsysdepsposixgetcwdc384 undefined reference to readdir varserviceshomesabhitestldeglibc215elfsysdepsposixgetcwdc397 undefined reference to rewinddir varserviceshomesabhitestldeglibc215elfsysdepsposixgetcwdc528 undefined reference to closedir varserviceshomesabhitestldeglibc215elfsysdepsposixgetcwdc490 undefined reference to closedir collect2 error ld returned 1 exit status make2 varserviceshomesabhitestldeglibcbuildelfldso error 1 make2 leaving directory varserviceshomesabhitestldeglibc215elf make1 elfsubdirlib error 2 make1 leaving directory varserviceshomesabhitestldeglibc215 make all error 2 note with the same infrastructure i can build and install the full glibc so i dont think there is an error with the infrastructure', ' i guess the error is some where related to editing makeconfig to allsubdirs csu elf gmon io misc posix setjmp signal stdlib string time', 'any suggestions on this solved need to add dirent in the allsubdirs list in addition to what we edited before thanks']"
iPhone - get number of days between two dates,"I'm writing a GTD app for the iPhone. For the due tasks, I want to display something like ""Due tomorrow"" or ""Due yesterday"" or ""Due July 18th"". Obviously, I need to display ""Tomorrow"" even if the task is less than 24 hours away (e.g. the user checks at 11pm on Saturday and sees there's a task on Sunday at 8am). So, I wrote a method to get the number of days in between two dates. Here's the code...
NSDateFormatter *dateFormatter = [[NSDateFormatter alloc] init];
[dateFormatter setDateFormat:@""yyyy-MM-dd-HH-mm""];

NSDate *nowDate = [dateFormatter dateFromString:@""2010-01-01-15-00""];
NSDate *dueDate = [dateFormatter dateFromString:@""2010-01-02-14-00""];

NSLog(@""NSDate *nowDate = %@"", nowDate);
NSLog(@""NSDate *dueDate = %@"", dueDate);

NSCalendar *calendar = [NSCalendar currentCalendar];

NSDateComponents *differenceComponents = [calendar components:(NSDayCalendarUnit)
                                                     fromDate:nowDate
                                                       toDate:dueDate
                                                      options:0];

NSLog(@""Days between dates: %d"", [differenceComponents day]);

... and here's the output:
NSDate *nowDate = 2010-01-01 15:00:00 -0700
NSDate *dueDate = 2010-01-02 14:00:00 -0700
Days between dates: 0

As you can see, the method returns incorrect results. It should have returned 1 as the number of days between the two days. What am I doing wrong here?
EDIT: I wrote another method. I haven't done extensive unit tests, but so far it seems to work:
+ (NSInteger)daysFromDate:(NSDate *)fromDate inTimeZone:(NSTimeZone *)fromTimeZone untilDate:(NSDate *)toDate inTimeZone:(NSTimeZone *)toTimeZone {

    NSCalendar *calendar = [NSCalendar currentCalendar];
    unsigned unitFlags = NSYearCalendarUnit | NSMonthCalendarUnit | NSDayCalendarUnit | NSHourCalendarUnit | NSMinuteCalendarUnit | NSSecondCalendarUnit;

    [calendar setTimeZone:fromTimeZone];
    NSDateComponents *fromDateComponents = [calendar components:unitFlags fromDate:fromDate];

    [calendar setTimeZone:toTimeZone];
    NSDateComponents *toDateComponents = [calendar components:unitFlags fromDate:toDate];

    [calendar setTimeZone:[NSTimeZone defaultTimeZone]];
    NSDate *adjustedFromDate = [calendar dateFromComponents:fromDateComponents];
    NSDate *adjustedToDate = [calendar dateFromComponents:toDateComponents];

    NSTimeInterval timeIntervalBetweenDates = [adjustedToDate timeIntervalSinceDate:adjustedFromDate];
    NSInteger daysBetweenDates = (NSInteger)(timeIntervalBetweenDates / (60.0 * 60.0 * 24.0));

    NSDateComponents *midnightBeforeFromDateComponents = [[NSDateComponents alloc] init];
    [midnightBeforeFromDateComponents setYear:[fromDateComponents year]];
    [midnightBeforeFromDateComponents setMonth:[fromDateComponents month]];
    [midnightBeforeFromDateComponents setDay:[fromDateComponents day]];

    NSDate *midnightBeforeFromDate = [calendar dateFromComponents:midnightBeforeFromDateComponents];
    [midnightBeforeFromDateComponents release];

    NSDate *midnightAfterFromDate = [[NSDate alloc] initWithTimeInterval:(60.0 * 60.0 * 24.0)
                                                               sinceDate:midnightBeforeFromDate];

    NSTimeInterval timeIntervalBetweenToDateAndMidnightBeforeFromDate = [adjustedToDate timeIntervalSinceDate:midnightBeforeFromDate];
    NSTimeInterval timeIntervalBetweenToDateAndMidnightAfterFromDate = [adjustedToDate timeIntervalSinceDate:midnightAfterFromDate];

    if (timeIntervalBetweenToDateAndMidnightBeforeFromDate < 0.0) {

        // toDate is before the midnight before fromDate

        timeIntervalBetweenToDateAndMidnightBeforeFromDate -= daysBetweenDates * 60.0 * 60.0 * 24.0;

        if (timeIntervalBetweenToDateAndMidnightBeforeFromDate < 0.0)
            daysBetweenDates -= 1;
    }
    else if (timeIntervalBetweenToDateAndMidnightAfterFromDate >= 0.0) {

        // toDate is after the midnight after fromDate

        timeIntervalBetweenToDateAndMidnightAfterFromDate -= daysBetweenDates * 60.0 * 60.0 * 24.0;

        if (timeIntervalBetweenToDateAndMidnightAfterFromDate >= 0.0)
            daysBetweenDates += 1;
    }

    [midnightAfterFromDate release];

    return daysBetweenDates;
}

",<iphone><cocoa><cocoa-touch><nsdate><nsdatecomponents>,5,"iphone,cocoa,cocoa-touch,nsdate,nsdatecomponents",['iphone get number of days between two dates'],"['im writing a gtd app for the iphone', 'for the due tasks i want to display something like due tomorrow or due yesterday or due july 18th', 'obviously i need to display tomorrow even if the task is less than 24 hours away eg', 'the user checks at 11pm on saturday and sees theres a task on sunday at 8am', 'so i wrote a method to get the number of days in between two dates', 'heres the code nsdateformatter dateformatter nsdateformatter alloc init dateformatter setdateformatyyyymmddhhmm nsdate nowdate dateformatter datefromstring201001011500 nsdate duedate dateformatter datefromstring201001021400 nslognsdate nowdate nowdate nslognsdate duedate duedate nscalendar calendar nscalendar currentcalendar nsdatecomponents differencecomponents calendar componentsnsdaycalendarunit fromdatenowdate todateduedate options0 nslogdays between dates d differencecomponents day and heres the output nsdate nowdate 20100101 150000 0700 nsdate duedate 20100102 140000 0700 days between dates 0 as you can see the method returns incorrect results', 'it should have returned 1 as the number of days between the two days', 'what am i doing wrong here', 'edit i wrote another method', 'i havent done extensive unit tests but so far it seems to work nsintegerdaysfromdatensdate fromdate intimezonenstimezone fromtimezone untildatensdate todate intimezonenstimezone totimezone nscalendar calendar nscalendar currentcalendar unsigned unitflags nsyearcalendarunit nsmonthcalendarunit nsdaycalendarunit nshourcalendarunit nsminutecalendarunit nssecondcalendarunit calendar settimezonefromtimezone nsdatecomponents fromdatecomponents calendar componentsunitflags fromdatefromdate calendar settimezonetotimezone nsdatecomponents todatecomponents calendar componentsunitflags fromdatetodate calendar settimezonenstimezone defaulttimezone nsdate adjustedfromdate calendar datefromcomponentsfromdatecomponents nsdate adjustedtodate calendar datefromcomponentstodatecomponents nstimeinterval timeintervalbetweendates adjustedtodate timeintervalsincedateadjustedfromdate nsinteger daysbetweendates nsintegertimeintervalbetweendates 600 600 240 nsdatecomponents midnightbeforefromdatecomponents nsdatecomponents alloc init midnightbeforefromdatecomponents setyearfromdatecomponents year midnightbeforefromdatecomponents setmonthfromdatecomponents month midnightbeforefromdatecomponents setdayfromdatecomponents day nsdate midnightbeforefromdate calendar datefromcomponentsmidnightbeforefromdatecomponents midnightbeforefromdatecomponents release nsdate midnightafterfromdate nsdate alloc initwithtimeinterval600 600 240 sincedatemidnightbeforefromdate nstimeinterval timeintervalbetweentodateandmidnightbeforefromdate adjustedtodate timeintervalsincedatemidnightbeforefromdate nstimeinterval timeintervalbetweentodateandmidnightafterfromdate adjustedtodate timeintervalsincedatemidnightafterfromdate if timeintervalbetweentodateandmidnightbeforefromdate 00 todate is before the midnight before fromdate timeintervalbetweentodateandmidnightbeforefromdate daysbetweendates 600 600 240 if timeintervalbetweentodateandmidnightbeforefromdate 00 daysbetweendates 1 else if timeintervalbetweentodateandmidnightafterfromdate 00 todate is after the midnight after fromdate timeintervalbetweentodateandmidnightafterfromdate daysbetweendates 600 600 240 if timeintervalbetweentodateandmidnightafterfromdate 00 daysbetweendates 1 midnightafterfromdate release return daysbetweendates ']"
No valid crumb was included in the request - Jenkins on Windows,"I installed Jenkins 2.46.2 on Windows Server 2012 and integrated it with GitBucket.
I am trying the trigger the build when a change is pushed to GitBucket.
I tried to add a webhook but I get this error:


  Error 403 No valid crumb was included in the request
   HTTP ERROR 403 Problem accessing
  /jenkins/gitbucket-webhook/. Reason:  No valid crumb was included
in the requestPowered by
  Jetty:// 

",<windows><jenkins><http-status-code-403><git-push><gitbucket>,11,"windows,jenkins,http-status-code-403,git-push,gitbucket",['no valid crumb was included in the request jenkins on windows'],"['i installed jenkins 2462 on windows server 2012 and integrated it with gitbucket', 'i am trying the trigger the build when a change is pushed to gitbucket', 'i tried to add a webhook but i get this error error 403 no valid crumb was included in the request http error 403 problem accessing jenkinsgitbucketwebhook', 'reason no valid crumb was included in the requestpowered by jetty']"
.NET: Do I need to keep a reference to WebClient while downloading asynchronously?,"I use the following method in a piece of production code:
private void DownloadData(Uri uri)
{
    WebClient webClient = new WebClient();
    DownloadDataCompletedEventHandler eh = null;
    eh = delegate(object sender, DownloadDataCompletedEventArgs e)
        {
            webClient.DownloadDataCompleted -= eh;
            ((IDisposable) webClient).Dispose();
            OnDataDownloaded();
        };
    webClient.DownloadDataCompleted += eh;
    webClient.DownloadDataAsync(uri);
}

I am now worried that a hard to reproduce bug might be caused by the WebClient instance being garbage collected before the DownloadDataCompleted event is called: after exiting my DownloadData() method, there are no obvious references to the WebClient object, so that could plausibly happen.
So my question is: can this realistically happen? I can not reproduce the problem, so there might be some internal things happening that prevents the WebClient object from being garbage collected (e.g. the object might register itself with a global object somewhere while waiting for the response).
The code is running on .NET 2.0 if that makes any difference.
",<c#><.net><asynchronous><garbage-collection><webclient>,13,"c#,.net,asynchronous,garbage-collection,webclient",['net do i need to keep a reference to webclient while downloading asynchronously'],"['i use the following method in a piece of production code private void downloaddatauri uri webclient webclient new webclient downloaddatacompletedeventhandler eh null eh delegateobject sender downloaddatacompletedeventargs e webclientdownloaddatacompleted eh idisposable webclientdispose ondatadownloaded webclientdownloaddatacompleted eh webclientdownloaddataasyncuri i am now worried that a hard to reproduce bug might be caused by the webclient instance being garbage collected before the downloaddatacompleted event is called after exiting my downloaddata method there are no obvious references to the webclient object so that could plausibly happen', 'so my question is can this realistically happen', 'i can not reproduce the problem so there might be some internal things happening that prevents the webclient object from being garbage collected eg', 'the object might register itself with a global object somewhere while waiting for the response', 'the code is running on net 20 if that makes any difference']"
Run PHP code after button click but without refreshing page,"I have a form in HTML to apply a Discount Coupon to a current shopping cart.
I would like the user to just click on APPLY (after entering the coupon code) and then without refreshing the page, to have some PHP code run so it computes the corresponding discount.
Here is my form:
<form action="""">
   <input type=""text"" name=""couponCode"">
   <input type=""submit"" value=""Apply"">
</form>

PHP to be run:
if (isset($_REQUEST['couponCode']) && $_REQUEST['couponCode']!='') 
{
 $couponCode = $_REQUEST['couponCode'];
    if ($couponCode == ""TEST1"") 
    {
    $discount=0.2;
    }
}

How would this be done using javascript?
",<php><jquery><forms><button><coupon>,5,"php,jquery,forms,button,coupon",['run php code after button click but without refreshing page'],"['i have a form in html to apply a discount coupon to a current shopping cart', 'i would like the user to just click on apply after entering the coupon code and then without refreshing the page to have some php code run so it computes the corresponding discount', 'here is my form form action input typetext namecouponcode input typesubmit valueapply form php to be run if issetrequestcouponcode requestcouponcode couponcode requestcouponcode if couponcode test1 discount02 how would this be done using javascript']"
"SBT build, run main class from subproject on Compile and run","I have a simple build tool Multi-Project problem...
I have the following directory structure represents my java sbt projects:
/project1
/project2
/project3

So all projects share a common direct parent folder.
Projects 2 and 3 are referenced in project 1's build.sbt like this:
.dependsOn(project2, project3)
.aggregate(project2, project3)

lazy val project2 = ProjectRef(file(""../project2""), ""project2"")

lazy val project3 = ProjectRef(file(""../project3""), ""project3"")

This way there's a dependency between project1 and the others.
All is fine to this point and everything works as it should.
But now I want to execute the main method from project2 before anything else is executed.
When I execute the ""run"" task from the parent (project1), I want a specific class from project2 to have its main method executed. How do I do this? 
The sbt documentation explains that ""Aggregation means that running a task on the aggregate project will also run it on the aggregated projects."":
http://www.scala-sbt.org/0.13.5/docs/Getting-Started/Multi-Project.html#aggregation 
I'm not seeing my main class on projet2 been executed. I also added this to project2's build.sbt:
mainClass in (Compile, run) := Some(""Main"")

The goal of the projet is to generate code at Compiletime and runtime. Project2's job is to generate Java and Javascript code. The could should be generated before the other projects are built. 
Is that possible? If not, I'll have to settle for running project2 independently from the other projects.
=]
",<java><scala><sbt><multi-project><subproject>,10,"java,scala,sbt,multi-project,subproject",['sbt build run main class from subproject on compile and run'],"['i have a simple build tool multiproject problem i have the following directory structure represents my java sbt projects project1 project2 project3 so all projects share a common direct parent folder', 'projects 2 and 3 are referenced in project 1s buildsbt like this dependsonproject2 project3 aggregateproject2 project3 lazy val project2 projectreffileproject2 project2 lazy val project3 projectreffileproject3 project3 this way theres a dependency between project1 and the others', 'all is fine to this point and everything works as it should', 'but now i want to execute the main method from project2 before anything else is executed', 'when i execute the run task from the parent project1 i want a specific class from project2 to have its main method executed', 'how do i do this', 'the sbt documentation explains that aggregation means that running a task on the aggregate project will also run it on the aggregated projects', ' im not seeing my main class on projet2 been executed', 'i also added this to project2s buildsbt mainclass in compile run somemain the goal of the projet is to generate code at compiletime and runtime', 'project2s job is to generate java and javascript code', 'the could should be generated before the other projects are built', 'is that possible', 'if not ill have to settle for running project2 independently from the other projects', '']"
UITextView's inputView on iOS 7,"I'm trying to create a custom keyboard for a UITextField, the background of this inputView should be transparent, I have set the background color in the view's xib file to ""clear color"". It is working great on iOS 6 and earlier.. but on iOS 7 it not working
Any idea how can I make it work? I want it to be fully transparent
",<iphone><ios><uitextfield><custom-controls><ios7>,6,"iphone,ios,uitextfield,custom-controls,ios7",['uitextviews inputview on ios 7'],"['im trying to create a custom keyboard for a uitextfield the background of this inputview should be transparent i have set the background color in the views xib file to clear color', 'it is working great on ios 6 and earlier but on ios 7 it not working any idea how can i make it work', 'i want it to be fully transparent']"
Host IDeskBand in a Windows Form,"I'm trying to display the Address toolbar from the Windows Taskbar in my own WinForm.  I can get the CLSID of the Address toobar ({01E04581-4EEE-11d0-BFE9-00AA005B4383}), and I can get an IDeskBand reference to it.  But... then what?
Guid bandCLSID = new Guid(""{01E04581-4EEE-11d0-BFE9-00AA005B4383}"");
Type bandType = Type.GetTypeFromCLSID(bandCLSID);
IDeskBand deskband = (IDeskBand)Activator.CreateInstance(bandType);

I've tried hosting it in an AxHost, but the Address toolbar is not an ActiveX control.  I've tried calling
(deskband as IOleObjectWithSite).SetSite(various interfaces);

or
(deskband as IDockingWindow).ShowDW(true);

as well as various other interfaces and their methods, but nothing I do seems to get me anywhere.  I'd be overjoyed if I could actually see that toolbar appear anywhere.  But I can't seem to bridge the gap between having the IDeskBand reference and plugging it into my Windows Form.
Has anybody attempted this before, and gotten further than I have?
",<c#><.net><winforms><interop><winforms-interop>,12,"c#,.net,winforms,interop,winforms-interop",['host ideskband in a windows form'],"['im trying to display the address toolbar from the windows taskbar in my own winform', 'i can get the clsid of the address toobar 01e045814eee11d0bfe900aa005b4383 and i can get an ideskband reference to it', 'but then what', 'guid bandclsid new guid01e045814eee11d0bfe900aa005b4383 type bandtype typegettypefromclsidbandclsid ideskband deskband ideskbandactivatorcreateinstancebandtype ive tried hosting it in an axhost but the address toolbar is not an activex control', 'ive tried calling deskband as ioleobjectwithsitesetsitevarious interfaces or deskband as idockingwindowshowdwtrue as well as various other interfaces and their methods but nothing i do seems to get me anywhere', 'id be overjoyed if i could actually see that toolbar appear anywhere', 'but i cant seem to bridge the gap between having the ideskband reference and plugging it into my windows form', 'has anybody attempted this before and gotten further than i have']"
Calculate Centroid WITHIN / INSIDE a SpatialPolygon,"In Software like ArcMap one can create centroids for polygons within a polygon. In cases like the one shown below this is necessary. 
In R it is possible to calculate centroids of spatial polygons with rgeos::gCentroid(). However there is no way to force the calculation of centroids within the polygon. 
library(rgdal)
library(rgeos)

x <- readWKT(""POLYGON ((1441727.5096940901130438 6550163.0046194596216083, 
             1150685.2609429201111197 6669225.7427449300885201, 
             975398.4520359700545669 6603079.7771196700632572, 
             866257.6087542800232768 6401334.5819626096636057, 
             836491.9242229099618271 6106985.0349301798269153, 
             972091.1537546999752522 5835786.5758665995672345, 
             1547561.0546945100650191 5782869.8033663900569081, 
             1408654.5268814601004124 5600968.3978968998417258, 
             720736.4843787000281736 5663807.0652409195899963, 
             598366.4479719599476084 6001151.4899297598749399, 
             654590.5187534400029108 6341803.2128998702391982, 
             869564.9070355399744585 6784981.1825891500338912, 
             1451649.4045378800947219 6788288.4808704098686576, 
             1441727.5096940901130438 6550163.0046194596216083))"")
plot(x)

This is the polygon x

gCentroid() creates a centroid which in this specific case is located outside of the polygon. Despite being geometrically correct, some applications require centroids within the polygon, as they can be calculated by ArcMap. 
xCent <- gCentroid(x, byid = TRUE)
points(xCent, col = ""red"", pch = 16)


A desired output (from ArcMap) looks like this: 

Is there any possibility to generate centroids like this in R?
EDIT:
After some digging, it turns out that ArcMap picks a random point within the Polygon:

""For an input polygon: the output point will be inside the polygon.""

Thus the question has to be: is there a function that creates a point at any random position WITHIN the polygons?
",<r><gis><polygon><geospatial><centroid>,9,"r,gis,polygon,geospatial,centroid",['calculate centroid within inside a spatialpolygon'],"['in software like arcmap one can create centroids for polygons within a polygon', 'in cases like the one shown below this is necessary', 'in r it is possible to calculate centroids of spatial polygons with rgeosgcentroid', 'however there is no way to force the calculation of centroids within the polygon', 'libraryrgdal libraryrgeos x readwktpolygon 14417275096940901130438 65501630046194596216083 11506852609429201111197 66692257427449300885201 9753984520359700545669 66030797771196700632572 8662576087542800232768 64013345819626096636057 8364919242229099618271 61069850349301798269153 9720911537546999752522 58357865758665995672345 15475610546945100650191 57828698033663900569081 14086545268814601004124 56009683978968998417258 7207364843787000281736 56638070652409195899963 5983664479719599476084 60011514899297598749399 6545905187534400029108 63418032128998702391982 8695649070355399744585 67849811825891500338912 14516494045378800947219 67882884808704098686576 14417275096940901130438 65501630046194596216083 plotx this is the polygon x gcentroid creates a centroid which in this specific case is located outside of the polygon', 'despite being geometrically correct some applications require centroids within the polygon as they can be calculated by arcmap', 'xcent gcentroidx byid true pointsxcent col red pch 16 a desired output from arcmap looks like this is there any possibility to generate centroids like this in r', 'edit after some digging it turns out that arcmap picks a random point within the polygon for an input polygon the output point will be inside the polygon', 'thus the question has to be is there a function that creates a point at any random position within the polygons']"
Static Binding and Dynamic Binding,"I am really confused about dynamic binding and static binding. I have read that determining the type of an object at compile time is called static binding and determining it at runtime is called dynamic binding.
What happens in the code below:
Static binding or dynamic binding?
What kind of polymorphism does this show?
class Animal
{
    void eat()
    {
        System.out.println(""Animal is eating"");
    }
}

class Dog extends Animal
{
    void eat()
    {
        System.out.println(""Dog is eating"");
    }
}

public static void main(String args[])
{
    Animal a=new Animal();
    a.eat();
}

",<java><oop><polymorphism><dynamic-binding><static-binding>,32,"java,oop,polymorphism,dynamic-binding,static-binding",['static binding and dynamic binding'],"['i am really confused about dynamic binding and static binding', 'i have read that determining the type of an object at compile time is called static binding and determining it at runtime is called dynamic binding', 'what happens in the code below static binding or dynamic binding', 'what kind of polymorphism does this show', 'class animal void eat systemoutprintlnanimal is eating class dog extends animal void eat systemoutprintlndog is eating public static void mainstring args animal anew animal aeat ']"
How can a bash script know the directory it is installed in when it is sourced with . operator?,"What I'd like to do is to include settings from a file into my current interactive bash shell like this:
$ . /path/to/some/dir/.settings
The problem is that the .settings script also needs to use the ""."" operator to include other files like this:
. .extra_settings
How do I reference the relative path for .extra_settings in the .settings file? These two files are always stored in the same directory, but the path to this directory will be different depending on where these files were installed.
The operator always knows the /path/to/some/dir/ as shown above.  How can the .settings file know the directory where it is installed?  I would rather not have an install process that records the name of the installed directory.
",<linux><bash><unix><shell><scripting>,13,"linux,bash,unix,shell,scripting","['how can a bash script know the directory it is installed in when it is sourced with ', 'operator']","['what id like to do is to include settings from a file into my current interactive bash shell like this ', 'pathtosomedirsettings the problem is that the settings script also needs to use the ', 'operator to include other files like this ', 'extrasettings how do i reference the relative path for extrasettings in the settings file', 'these two files are always stored in the same directory but the path to this directory will be different depending on where these files were installed', 'the operator always knows the pathtosomedir as shown above', 'how can the settings file know the directory where it is installed', 'i would rather not have an install process that records the name of the installed directory']"
Linq query with nullable sum,"from i in Db.Items
select new VotedItem
{
    ItemId = i.ItemId,
    Points = (from v in Db.Votes
              where b.ItemId == v.ItemId
              select v.Points).Sum()
}

I got this query, however it fails if no votes are found with exception:
The null value cannot be assigned to a member with type System.Int32 which is a non-nullable value type.

I assume its because sum returns an int and not a nullable int, giving sum a int? as input only give the same error, probably cause sum only workes on ints.
Any good workaround for this?
",<c#><linq><linq-to-sql><sum><nullable>,74,"c#,linq,linq-to-sql,sum,nullable",['linq query with nullable sum'],"['from i in dbitems select new voteditem itemid iitemid points from v in dbvotes where bitemid vitemid select vpointssum i got this query however it fails if no votes are found with exception the null value cannot be assigned to a member with type systemint32 which is a nonnullable value type', 'i assume its because sum returns an int and not a nullable int giving sum a int', 'as input only give the same error probably cause sum only workes on ints', 'any good workaround for this']"
Settings.bundle version number is updating as $(MARKETING_VERSION),"I have an app which was setting versions automatically when I incremented from 
XCode > General > Version.
But recently I have updated XCode to 11.0 and seems the script is not working as expected:
version=`/usr/libexec/PlistBuddy -c ""Print CFBundleShortVersionString"" $SRCROOT/MyApp/Info.plist`
version+="" (""
version+=`/usr/libexec/PlistBuddy -c ""Print CFBundleVersion"" $SRCROOT/MyApp/Info.plist`
version+="")""
/usr/libexec/PlistBuddy ""$SRCROOT/MyApp/Settings.bundle/Root.plist"" -c ""set PreferenceSpecifiers:1:DefaultValue $version""

Above script suppose to automatically update version and would have been visible in Settings > App.

But the question is there any change need to be done for this script to make automatically update version number from XCode?
Currently it is being replaced by scripts as $(MARKETING_VERSION) when version is incremented from XCode > General > Version which is not correct.
",<ios><scripting><versioning><xcode11><settings.bundle>,11,"ios,scripting,versioning,xcode11,settings.bundle",['settingsbundle version number is updating as marketingversion'],"['i have an app which was setting versions automatically when i incremented from xcode general version', 'but recently i have updated xcode to 110 and seems the script is not working as expected versionusrlibexecplistbuddy c print cfbundleshortversionstring srcrootmyappinfoplist version versionusrlibexecplistbuddy c print cfbundleversion srcrootmyappinfoplist version usrlibexecplistbuddy srcrootmyappsettingsbundlerootplist c set preferencespecifiers1defaultvalue version above script suppose to automatically update version and would have been visible in settings app', 'but the question is there any change need to be done for this script to make automatically update version number from xcode', 'currently it is being replaced by scripts as marketingversion when version is incremented from xcode general version which is not correct']"
Filehandle for Output from System Command in Perl,"Is there a filehandle/handle for the output of a system command I execute in Perl? 
",<perl><ipc><pipe><stdio><filehandle>,6,"perl,ipc,pipe,stdio,filehandle",['filehandle for output from system command in perl'],['is there a filehandlehandle for the output of a system command i execute in perl']
Type safety: Unchecked cast from Object to List<MyObject>,"I have a ListView listing a custom object (let's say MyObject).
I want to filter it dynamically through an EditText so I had to implement a getFilter() with a publishResults method: 
@Override
protected void publishResults(CharSequence constraint, FilterResults results) {
    MyObjectAdapter.this.setItems((List<MyObject>) results.values);
    MyObjectAdapter.this.notifyDataSetChanged();
}

At this point, Eclipse complains: Type safety: Unchecked cast from Object to List<MyObject>
I am sure this cast will always be true, but Eclipse only suggests to add @SuppressWarnings(""unchecked"") but I'm totally against SuppressWarnings because it's only hiding the problem, not a solution...
I tried adding:
if(results.values instanceof List<MyObject>)

But Eclipse complains again, and this solves nothing...
Cannot perform instanceof check against parameterized type List<MyObject>. Use the form List<?>
I know the casting will always be correct, but which is the proper way to make the code to be sure results.values is actually a List<MyObject> ?
Thanks in advance!
",<android><listview><casting><filter><custom-object>,29,"android,listview,casting,filter,custom-object",['type safety unchecked cast from object to listmyobject'],"['i have a listview listing a custom object lets say myobject', 'i want to filter it dynamically through an edittext so i had to implement a getfilter with a publishresults method override protected void publishresultscharsequence constraint filterresults results myobjectadapterthissetitemslistmyobject resultsvalues myobjectadapterthisnotifydatasetchanged at this point eclipse complains type safety unchecked cast from object to listmyobject i am sure this cast will always be true but eclipse only suggests to add suppresswarningsunchecked but im totally against suppresswarnings because its only hiding the problem not a solution i tried adding ifresultsvalues instanceof listmyobject but eclipse complains again and this solves nothing cannot perform instanceof check against parameterized type listmyobject', 'use the form list i know the casting will always be correct but which is the proper way to make the code to be sure resultsvalues is actually a listmyobject ', 'thanks in advance']"
Textarea lags after registering `keydown` events using Javascript,"How does one go about attaching a bunch of code to an onkeydown event, but keep entering text into a textarea fast and crisp? Anything more than a couple of IF statements seems to slow it down quite considerably.
EDIT: I should add (can't believe I forgot!) that this doesn't affect desktop browsers. It's mainly an issue with iPhone Safari. Other mobile browsers might be affected as well, but we're focusing on iPhone Safari since it executes JS the best (AFAIK)
",<javascript><html><events><textarea><keydown>,5,"javascript,html,events,textarea,keydown",['textarea lags after registering keydown events using javascript'],"['how does one go about attaching a bunch of code to an onkeydown event but keep entering text into a textarea fast and crisp', 'anything more than a couple of if statements seems to slow it down quite considerably', 'edit i should add cant believe i forgot', 'that this doesnt affect desktop browsers', 'its mainly an issue with iphone safari', 'other mobile browsers might be affected as well but were focusing on iphone safari since it executes js the best afaik']"
