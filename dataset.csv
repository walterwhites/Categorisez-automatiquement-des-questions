title,body,tags,score
What does if __name__ == &quot;__main__&quot;: do?,"What does this do, and why should one include the  if  statement? 
 if __name__ == ""__main__"":
    print(""Hello, World!"")
 
 
 If you are trying to close a question where someone should be using this idiom and isn't, consider closing as a duplicate of  Why is Python running my module when I import it, and how do I stop it?  instead. For questions where someone simply hasn't called any functions, or incorrectly expects a function named  main  to be used as an entry point automatically, use  Why doesn't the main() function run when I start a Python script? Where does the script start running? . 
","['python', 'namespaces', 'program-entry-point', 'python-module', 'idioms']",8139
What are metaclasses in Python?,"What are  metaclasses ? What are they used for? 
","['python', 'oop', 'metaclass', 'python-class', 'python-datamodel']",7326
How do I execute a program or call a system command?,"How do I call an external command within Python as if I had typed it in a shell or command prompt? 
","['python', 'shell', 'terminal', 'subprocess', 'command']",6072
"How do I create a directory, and any missing parent directories?","How do I create a directory at a given path, and also create any missing parent directories along that path? For example, the Bash command  mkdir -p /path/to/nested/directory  does this. 
","['python', 'exception', 'path', 'directory', 'operating-system']",5603
@staticmethod vs @classmethod in Python,"What is the difference between a method  decorated  with  @staticmethod  and one decorated with  @classmethod ? 
","['python', 'oop', 'static-methods', 'python-decorators', 'class-method']",4608
How to copy files,"How do I copy a file in Python? 
","['python', 'file', 'copy', 'filesystems', 'file-copying']",3749
What does ** (double star/asterisk) and * (star/asterisk) do for parameters?,"What do  *args  and  **kwargs  mean in these function definitions? 
 def foo(x, y, *args):
    pass

def bar(x, y, **kwargs):
    pass
 
 
 See  What do ** (double star/asterisk) and * (star/asterisk) mean in a function call?  for the complementary question about arguments. 
","['python', 'syntax', 'parameter-passing', 'variadic-functions', 'argument-unpacking']",3355
Understanding Python super() with __init__() methods,"Why is  super()  used? 
 Is there a difference between using  Base.__init__  and  super().__init__ ? 
 class Base(object):
    def __init__(self):
        print ""Base created""
        
class ChildA(Base):
    def __init__(self):
        Base.__init__(self)
        
class ChildB(Base):
    def __init__(self):
        super(ChildB, self).__init__()
        
ChildA() 
ChildB()
 
","['python', 'class', 'oop', 'inheritance', 'super']",3201
How do I change the size of figures drawn with Matplotlib?,"How do I change the size of figure drawn with Matplotlib? 
","['python', 'pandas', 'matplotlib', 'seaborn', 'figsize']",3184
How do I make function decorators and chain them together?,"How do I make two decorators in Python that would do the following? 
 @make_bold
@make_italic
def say():
   return ""Hello""
 
 Calling  say()  should return: 
 ""<b><i>Hello</i></b>""
 
","['python', 'function', 'decorator', 'python-decorators', 'chain']",3146
What is the difference between Python&#39;s list methods append and extend?,"What's the difference between the list methods  append()  and  extend() ? 
","['python', 'list', 'data-structures', 'append', 'extend']",3111
Why is &quot;1000000000000000 in range(1000000000000001)&quot; so fast in Python 3?,"It is my understanding that the  range()  function, which is actually  an object type in Python 3 , generates its contents on the fly, similar to a generator. 
 This being the case, I would have expected the following line to take an inordinate amount of time because, in order to determine whether 1 quadrillion is in the range, a quadrillion values would have to be generated: 
 1_000_000_000_000_000 in range(1_000_000_000_000_001)
 
 Furthermore: it seems that no matter how many zeroes I add on, the calculation more or less takes the same amount of time (basically instantaneous). 
 I have also tried things like this, but the calculation is still almost instant: 
 # count by tens
1_000_000_000_000_000_000_000 in range(0,1_000_000_000_000_000_000_001,10)
 
 If I try to implement my own range function, the result is not so nice! 
 def my_crappy_range(N):
    i = 0
    while i < N:
        yield i
        i += 1
    return
 
 What is the  range()  object doing under the hood that makes it so fast? 
 
 Martijn Pieters's answer  was chosen for its completeness, but also see  abarnert's first answer  for a good discussion of what it means for  range  to be a full-fledged  sequence  in Python 3, and some information/warning regarding potential inconsistency for  __contains__  function optimization across Python implementations.  abarnert's other answer  goes into some more detail and provides links for those interested in the history behind the optimization in Python 3 (and lack of optimization of  xrange  in Python 2). Answers  by poke  and  by wim  provide the relevant C source code and explanations for those who are interested. 
","['python', 'performance', 'python-3.x', 'range', 'python-internals']",2986
Renaming column names in Pandas,"I want to change the column labels of a Pandas DataFrame from 
 ['$a', '$b', '$c', '$d', '$e']
 
 to 
 ['a', 'b', 'c', 'd', 'e']
 
","['python', 'pandas', 'replace', 'dataframe', 'rename']",2937
How to sort a list of dictionaries by a value of the dictionary in Python?,"How do I sort a list of dictionaries by a specific key's value? Given: 
 [{'name': 'Homer', 'age': 39}, {'name': 'Bart', 'age': 10}]
 
 When sorted by  name , it should become: 
 [{'name': 'Bart', 'age': 10}, {'name': 'Homer', 'age': 39}]
 
","['python', 'list', 'sorting', 'dictionary', 'data-structures']",2757
How do I parse a string to a float or int?,"How can I convert an  str  to a  float ? 
 ""545.2222"" -> 545.2222
 
 Or an  str  to a  int ? 
 ""31"" -> 31
 
 
 For the reverse, see  Convert integer to string in Python  and  Converting a float to a string without rounding it . 
 Please instead use  How can I read inputs as numbers?  to close duplicate questions where OP received a string  from user input  and immediately wants to convert it, or was hoping for  input  (in 3.x) to convert the type automatically. 
","['python', 'parsing', 'floating-point', 'type-conversion', 'integer']",2720
How do I escape curly-brace ({}) characters in a string while using .format (or an f-string)?,"Non-working example: 
 print("" \{ Hello \} {0} "".format(42))
 
 Desired output: 
  {Hello} 42 
 
","['python', 'string', 'format', 'string-formatting', 'curly-braces']",2486
How to check if an object has an attribute?,"How do I check if an object has some attribute? For example: 
 >>> a = SomeClass()
>>> a.property
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: SomeClass instance has no attribute 'property'
 
 How do I tell if  a  has the attribute  property  before using it? 
","['python', 'class', 'object', 'attributes', 'attributeerror']",2410
Why is reading lines from stdin much slower in C++ than Python?,"I wanted to compare reading lines of string input from stdin using Python and C++ and was shocked to see my C++ code run an order of magnitude slower than the equivalent Python code. Since my C++ is rusty and I'm not yet an expert Pythonista, please tell me if I'm doing something wrong or if I'm misunderstanding something. 
 
 ( TLDR answer:  include the statement:  cin.sync_with_stdio(false)  or just use  fgets  instead. 
 TLDR results:  scroll all the way down to the bottom of my question and look at the table.) 
 
 C++ code: 
 #include <iostream>
#include <time.h>

using namespace std;

int main() {
    string input_line;
    long line_count = 0;
    time_t start = time(NULL);
    int sec;
    int lps;

    while (cin) {
        getline(cin, input_line);
        if (!cin.eof())
            line_count++;
    };

    sec = (int) time(NULL) - start;
    cerr << ""Read "" << line_count << "" lines in "" << sec << "" seconds."";
    if (sec > 0) {
        lps = line_count / sec;
        cerr << "" LPS: "" << lps << endl;
    } else
        cerr << endl;
    return 0;
}

// Compiled with:
// g++ -O3 -o readline_test_cpp foo.cpp
 
 Python Equivalent: 
 #!/usr/bin/env python
import time
import sys

count = 0
start = time.time()

for line in  sys.stdin:
    count += 1

delta_sec = int(time.time() - start_time)
if delta_sec >= 0:
    lines_per_sec = int(round(count/delta_sec))
    print(""Read {0} lines in {1} seconds. LPS: {2}"".format(count, delta_sec,
       lines_per_sec))
 
 Here are my results: 
 $ cat test_lines | ./readline_test_cpp
Read 5570000 lines in 9 seconds. LPS: 618889

$ cat test_lines | ./readline_test.py
Read 5570000 lines in 1 seconds. LPS: 5570000
 
 I should note that I tried this both under Mac OS X v10.6.8 (Snow Leopard) and Linux 2.6.32 (Red Hat Linux 6.2). The former is a MacBook Pro, and the latter is a very beefy server, not that this is too pertinent. 
 $ for i in {1..5}; do echo ""Test run $i at `date`""; echo -n ""CPP:""; cat test_lines | ./readline_test_cpp ; echo -n ""Python:""; cat test_lines | ./readline_test.py ; done
 
 Test run 1 at Mon Feb 20 21:29:28 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 2 at Mon Feb 20 21:29:39 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 3 at Mon Feb 20 21:29:50 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 4 at Mon Feb 20 21:30:01 EST 2012
CPP:   Read 5570001 lines in 9 seconds. LPS: 618889
Python:Read 5570000 lines in 1 seconds. LPS: 5570000
Test run 5 at Mon Feb 20 21:30:11 EST 2012
CPP:   Read 5570001 lines in 10 seconds. LPS: 557000
Python:Read 5570000 lines in  1 seconds. LPS: 5570000
 
 
 Tiny benchmark addendum and recap 
 For completeness, I thought I'd update the read speed for the same file on the same box with the original (synced) C++ code. Again, this is for a 100M line file on a fast disk. Here's the comparison, with several solutions/approaches: 
 
 
 
 
 Implementation 
 Lines per second 
 
 
 
 
 python (default) 
 3,571,428 
 
 
 cin (default/naive) 
 819,672 
 
 
 cin (no sync) 
 12,500,000 
 
 
 fgets 
 14,285,714 
 
 
 wc (not fair comparison) 
 54,644,808 
 
 
 
","['python', 'c++', 'benchmarking', 'iostream', 'getline']",2173
Is there a way to run Python on Android?,"We are working on an  S60  version and this platform has a nice Python API.. 
 However, there is nothing official about Python on Android, but since  Jython  exists, is there a way to let the snake and the robot work together?? 
","['android', 'python', 'jython', 'ase', 'android-scripting']",2085
"What is the difference between venv, pyvenv, pyenv, virtualenv, virtualenvwrapper, pipenv, etc?","Python 3.3 includes in its standard library the new package  venv . What does it do, and how does it differ from all the other packages that match the regex  (py)?(v|virtual|pip)?env ? 
","['python', 'virtualenv', 'virtualenvwrapper', 'pyenv', 'python-venv']",2055
Installing specific package version with pip,"I am trying to install version 1.2.2 of  MySQL_python , using a fresh virtualenv created with the  --no-site-packages  option. The current version shown in PyPi is  1.2.3 . Is there a way to install the older version? I have tried: 
 pip install MySQL_python==1.2.2
 
 However, when installed, it still shows  MySQL_python-1.2.3-py2.6.egg-info  in the site packages. Is this a problem specific to this package, or am I doing something wrong? 
","['python', 'mysql', 'pip', 'pypi', 'mysql-python']",1921
Selecting multiple columns in a Pandas dataframe,"How do I select columns  a  and  b  from  df , and save them into a new dataframe  df1 ? 
 index  a   b   c
1      2   3   4
2      3   4   5
 
 Unsuccessful attempt: 
 df1 = df['a':'b']
df1 = df.ix[:, 'a':'b']
 
","['python', 'pandas', 'dataframe', 'select', 'indexing']",1726
Relative imports for the trilliоnth time,"I've been here: 
 
 PEP 328 – Imports: Multi-Line and Absolute/Relative 
 Modules, Packages 
 Python packages: relative imports 
 Python relative import example code does not work 
 Relative imports in Python 2.5 
 Relative imports in Python 
 Python: Disabling relative import 
 
 and plenty of URLs that I did not copy, some on SO, some on other sites, back when I thought I'd have the solution quickly. 
 The forever-recurring question is this: how do I solve this ""Attempted relative import in non-package"" message? 
 
 ImportError: attempted relative import with no known parent package 
 
 I built an exact replica of the package on pep-0328: 
 package/
    __init__.py
    subpackage1/
        __init__.py
        moduleX.py
        moduleY.py
    subpackage2/
        __init__.py
        moduleZ.py
    moduleA.py
 
 The imports were done from the console. 
 I did make functions named spam and eggs in their appropriate modules.  Naturally, it didn't work.  The answer is apparently in the 4th URL I listed, but it's all alumni to me. There was this response on one of the URLs I visited: 
 
 Relative imports use a module's name attribute to determine that module's position in the package hierarchy. If the module's name does not contain any package information (e.g. it is set to 'main') then relative imports are resolved as if the module were a top level module, regardless of where the module is actually located on the file system. 
 
 The above response looks promising, but it's all hieroglyphs to me. How do I make Python not return to me ""Attempted relative import in non-package""? It has an answer that involves  -m , supposedly. 
 Why does Python give that error message? What does by ""non-package"" mean? Why and how do you define a 'package'? 
","['python', 'import', 'relative-path', 'python-packaging', 'relative-import']",1721
How do I profile a Python script?,"Project Euler  and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to  __main__ . 
 What is a good way to profile how long a Python program takes to run? 
","['python', 'performance', 'optimization', 'time-complexity', 'profiling']",1682
Why do Python classes inherit object?,"Why does the following class declaration inherit from  object ? 
 class MyClass(object):
    ...
 
","['python', 'class', 'oop', 'object', 'inheritance']",1674
Creating a singleton in Python,"This question is not for the discussion of whether or not the  singleton design pattern  is desirable, is an anti-pattern, or for any religious wars, but to discuss how this pattern is best implemented in Python in such a way that is most pythonic. In this instance I define 'most pythonic' to mean that it follows the 'principle of least astonishment' . 
 I have multiple classes which would become singletons (my use-case is for a logger, but this is not important). I do not wish to clutter several classes with added gumph when I can simply inherit or decorate. 
 Best methods: 
 
 Method 1: A decorator 
 def singleton(class_):
    instances = {}
    def getinstance(*args, **kwargs):
        if class_ not in instances:
            instances[class_] = class_(*args, **kwargs)
        return instances[class_]
    return getinstance

@singleton
class MyClass(BaseClass):
    pass
 
 Pros 
 
 Decorators are additive in a way that is often more intuitive than multiple inheritance. 
 
 Cons 
 
 While objects created using  MyClass()  would be true singleton objects,  MyClass  itself is a function, not a class, so you cannot call class methods from it. Also for 
 x = MyClass();
y = MyClass();
t = type(n)();
 
 
 
 then  x == y  but  x != t && y != t 
 
 Method 2: A base class 
 class Singleton(object):
    _instance = None
    def __new__(class_, *args, **kwargs):
        if not isinstance(class_._instance, class_):
            class_._instance = object.__new__(class_, *args, **kwargs)
        return class_._instance

class MyClass(Singleton, BaseClass):
    pass
 
 Pros 
 
 It's a true class 
 
 Cons 
 
 Multiple inheritance - eugh!  __new__  could be overwritten during inheritance from a second base class? One has to think more than is necessary. 
 
 
 Method 3: A  metaclass 
 class Singleton(type):
    _instances = {}
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)
        return cls._instances[cls]

#Python2
class MyClass(BaseClass):
    __metaclass__ = Singleton

#Python3
class MyClass(BaseClass, metaclass=Singleton):
    pass
 
 Pros 
 
 It's a true class 
 Auto-magically covers inheritance 
 Uses  __metaclass__  for its proper purpose (and made me aware of it) 
 
 Cons 
 
 Are there any? 
 
 
 Method 4: decorator returning a class with the same name 
 def singleton(class_):
    class class_w(class_):
        _instance = None
        def __new__(class_, *args, **kwargs):
            if class_w._instance is None:
                class_w._instance = super(class_w,
                                    class_).__new__(class_,
                                                    *args,
                                                    **kwargs)
                class_w._instance._sealed = False
            return class_w._instance
        def __init__(self, *args, **kwargs):
            if self._sealed:
                return
            super(class_w, self).__init__(*args, **kwargs)
            self._sealed = True
    class_w.__name__ = class_.__name__
    return class_w

@singleton
class MyClass(BaseClass):
    pass
 
 Pros 
 
 It's a true class 
 Auto-magically covers inheritance 
 
 Cons 
 
 Is there not an overhead for creating each new class? Here we are creating two classes for each class we wish to make a singleton. While this is fine in my case, I worry that this might not scale. Of course there is a matter of debate as to whether it aught to be too easy to scale this pattern... 
 What is the point of the  _sealed  attribute 
 Can't call methods of the same name on base classes using  super()  because they will recurse. This means you can't customize  __new__  and can't subclass a class that needs you to call up to  __init__ . 
 
 
 Method 5: a module 
 a module file  singleton.py 
 Pros 
 
 Simple is better than complex 
 
 Cons 
 
 Not lazily instantiated 
 
","['python', 'singleton', 'decorator', 'base-class', 'metaclass']",1659
How to change the order of DataFrame columns?,"I have the following DataFrame ( df ): 
 import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.rand(10, 5))
 
 I add more column(s) by assignment: 
 df['mean'] = df.mean(1)
 
 How can I move the column  mean  to the front, i.e. set it as first column leaving the order of the other columns untouched? 
","['python', 'pandas', 'dataframe', 'sorting', 'indexing']",1609
Change column type in pandas,"I created a DataFrame from a list of lists: 
 table = [
    ['a',  '1.2',  '4.2' ],
    ['b',  '70',   '0.03'],
    ['x',  '5',    '0'   ],
]

df = pd.DataFrame(table)
 
 How do I convert the columns to specific types? In this case, I want to convert columns 2 and 3 into floats. 
 Is there a way to specify the types while converting the list to DataFrame? Or is it better to create the DataFrame first and then loop through the columns to change the dtype for each column? Ideally I would like to do this in a dynamic way because there can be hundreds of columns, and I don't want to specify exactly which columns are of which type. All I can guarantee is that each column contains values of the same type. 
","['python', 'pandas', 'dataframe', 'types', 'casting']",1500
UnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode character u&#39;\xa0&#39; in position 20: ordinal not in range(128),"I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.  
 The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a  UnicodeEncodeError . I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error. 
 One of the sections of code that is causing problems is shown below: 
 agent_telno = agent.find('div', 'agent_contact_number')
agent_telno = '' if agent_telno is None else agent_telno.contents[0]
p.agent_info = str(agent_contact + ' ' + agent_telno).strip()
 
 Here is a stack trace produced on SOME strings when the snippet above is run: 
 Traceback (most recent call last):
  File ""foobar.py"", line 792, in <module>
    p.agent_info = str(agent_contact + ' ' + agent_telno).strip()
UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128)
 
 I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English. 
 Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem? 
","['python', 'unicode', 'beautifulsoup', 'python-2.x', 'python-unicode']",1495
Is there a built-in function to print all the current properties and values of an object?,"So what I'm looking for here is something like PHP's  print_r  function. 
 This is so I can debug my scripts by seeing what's the state of the object in question. 
","['python', 'debugging', 'introspection', 'pretty-print', 'python-datamodel']",1465
Removing duplicates in lists,"How can I check if a list has any duplicates and return a new list without duplicates? 
","['python', 'algorithm', 'list', 'duplicates', 'intersection']",1453
How to drop rows of Pandas DataFrame whose value in a certain column is NaN,"I have this DataFrame and want only the records whose EPS column is not NaN: 
                  STK_ID  EPS  cash
STK_ID RPT_Date                   
601166 20111231  601166  NaN   NaN
600036 20111231  600036  NaN    12
600016 20111231  600016  4.3   NaN
601009 20111231  601009  NaN   NaN
601939 20111231  601939  2.5   NaN
000001 20111231  000001  NaN   NaN
 
 ...i.e. something like  df.drop(....)  to get this resulting dataframe: 
                   STK_ID  EPS  cash
STK_ID RPT_Date                   
600016 20111231  600016  4.3   NaN
601939 20111231  601939  2.5   NaN
 
 How do I do that? 
","['python', 'pandas', 'dataframe', 'indexing', 'nan']",1424
How to deal with SettingWithCopyWarning in Pandas,"Background 
 I just upgraded my Pandas from 0.11 to 0.13.0rc1. Now, the application is popping out many new warnings. One of them like this: 
 E:\FinReporter\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_index,col_indexer] = value instead
  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE
 
 I want to know what exactly it means?  Do I need to change something? 
 How should I suspend the warning if I insist to use  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE ? 
 The function that gives warnings 
 def _decode_stock_quote(list_of_150_stk_str):
    """"""decode the webpage and return dataframe""""""

    from cStringIO import StringIO

    str_of_all = """".join(list_of_150_stk_str)

    quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}
    quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)
    quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]
    quote_df['TClose'] = quote_df['TPrice']
    quote_df['RT']     = 100 * (quote_df['TPrice']/quote_df['TPCLOSE'] - 1)
    quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE
    quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE
    quote_df['STK_ID'] = quote_df['STK'].str.slice(13,19)
    quote_df['STK_Name'] = quote_df['STK'].str.slice(21,30)#.decode('gb2312')
    quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])
    
    return quote_df
 
 More warning messages 
 E:\FinReporter\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_index,col_indexer] = value instead
  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE
E:\FinReporter\FM_EXT.py:450: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_index,col_indexer] = value instead
  quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE
E:\FinReporter\FM_EXT.py:453: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_index,col_indexer] = value instead
  quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])
 
","['python', 'pandas', 'dataframe', 'chained-assignment', 'pandas-settingwithcopy-warning']",1384
How does the @property decorator work in Python?,"I would like to understand how the built-in function  property  works. What confuses me is that  property  can also be used as a decorator, but it only takes arguments when used as a built-in function and not when used as a decorator. 
 This example is from the  documentation : 
 class C:
    def __init__(self):
        self._x = None

    def getx(self):
        return self._x
    def setx(self, value):
        self._x = value
    def delx(self):
        del self._x
    x = property(getx, setx, delx, ""I'm the 'x' property."")
 
 property 's arguments are  getx ,  setx ,  delx  and a doc string. 
 In the code below  property  is used as a decorator. The object of it is the  x  function, but in the code above there is no place for an object function in the arguments. 
 class C:
    def __init__(self):
        self._x = None

    @property
    def x(self):
        """"""I'm the 'x' property.""""""
        return self._x

    @x.setter
    def x(self, value):
        self._x = value

    @x.deleter
    def x(self):
        del self._x
 
 How are the  x.setter  and  x.deleter  decorators created in this case? 
","['python', 'properties', 'decorator', 'python-decorators', 'python-internals']",1353
Get a list from Pandas DataFrame column headers,"I want to get a list of the column headers from a Pandas DataFrame.  The DataFrame will come from user input, so I won't know how many columns there will be or what they will be called. 
 For example, if I'm given a DataFrame like this: 
     y  gdp  cap
0   1    2    5
1   2    3    9
2   8    7    2
3   3    4    7
4   6    7    7
5   4    8    3
6   8    2    8
7   9    9   10
8   6    6    4
9  10   10    7
 
 I would get a list like this: 
 ['y', 'gdp', 'cap']
 
","['python', 'pandas', 'dataframe', 'list', 'header']",1341
What is a mixin and why is it useful?,"In  Programming Python , Mark Lutz mentions the term  mixin . I am from a C/C++/C# background and I have not heard the term before. What is a mixin? 
 Reading between the lines of  this example  (which I have linked to because it is quite long), I am presuming it is a case of using multiple inheritance to extend a class as opposed to proper subclassing. Is this right? 
 Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition? 
 What separates a mixin from multiple inheritance? Is it just a matter of semantics? 
","['python', 'oop', 'multiple-inheritance', 'mixins', 'python-class']",1335
Why does comparing strings using either &#39;==&#39; or &#39;is&#39; sometimes produce a different result?,"Two string variables are set to the same value.  s1 == s2  always returns  True , but  s1 is s2  sometimes returns  False . 
 If I open my Python interpreter and do the same  is  comparison, it succeeds: 
 >>> s1 = 'text'
>>> s2 = 'text'
>>> s1 is s2
True
 
 Why is this? 
","['python', 'string', 'comparison', 'identity', 'equality']",1314
Get difference between two lists with Unique Entries,"I have two lists in Python: 
 temp1 = ['One', 'Two', 'Three', 'Four']
temp2 = ['One', 'Two']
 
 Assuming the elements in each list are unique, I want to create a third list with items from the first list which are not in the second list: 
 temp3 = ['Three', 'Four']
 
 Are there any fast ways without cycles and checking? 
","['python', 'performance', 'list', 'set', 'set-difference']",1231
How do I type hint a method with the type of the enclosing class?,"I have the following code in Python 3: 
 class Position:

    def __init__(self, x: int, y: int):
        self.x = x
        self.y = y

    def __add__(self, other: Position) -> Position:
        return Position(self.x + other.x, self.y + other.y)
 
 But my editor (PyCharm) says that the reference  Position  can not be resolved (in the  __add__  method). How should I specify that I expect the return type to be of type  Position ? 
 Edit: I think this is actually a PyCharm issue. It actually uses the information in its warnings, and code completion. 
 
 But correct me if I'm wrong, and need to use some other syntax. 
","['python', 'python-3.x', 'pycharm', 'type-hinting', 'python-typing']",1224
How do I trim whitespace?,"Is there a Python function that will trim whitespace (spaces and tabs) from a string? 
 So that given input  ""  \t example string\t  ""  becomes  ""example string"" . 
","['python', 'string', 'whitespace', 'trim', 'strip']",1215
What are &quot;named tuples&quot; in Python?,"
 What are named tuples and how do I use them? 
 When should I use named tuples instead of normal tuples, or vice versa? 
 Are there ""named lists"" too? (i.e. mutable named tuples) 
 
 
 For the last question specifically, see also  Existence of mutable named tuple in Python? . 
","['python', 'types', 'tuples', 'terminology', 'namedtuple']",1207
&quot;Large data&quot; workflows using pandas,"I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons. 
 One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about ""big data"" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive. 
 My first thought is to use  HDFStore  to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this: 
 What are some best-practice workflows for accomplishing the following: 
 
 Loading flat files into a permanent, on-disk database structure 
 Querying that database to retrieve data to feed into a pandas data structure 
 Updating the database after manipulating pieces in pandas 
 
 Real-world examples would be much appreciated, especially from anyone who uses pandas on ""large data"". 
 Edit -- an example of how I would like this to work: 
 
 Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. 
 In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. 
 I would create new columns by performing various operations on the selected columns. 
 I would then have to append these new columns into the database structure. 
 
 I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem. 
 Edit -- Responding to Jeff's questions specifically: 
 
 I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. 
 Typical operations involve combining several columns using conditional logic into a new, compound column. For example,  if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B' .  The result of these operations is a new column for every record in my dataset. 
 Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. 
 A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. 
 It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. 
 The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns. 
 
 It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance). 
","['python', 'mongodb', 'pandas', 'hdf5', 'large-data']",1182
What is the difference between old style and new style classes in Python?,"What is the difference between old style and new style classes in Python?  When should I use one or the other? 
","['python', 'class', 'oop', 'types', 'new-style-class']",1126
List comprehension vs. lambda + filter,"I have a list that I want to filter by an attribute of the items. 
 Which of the following is preferred (readability, performance, other reasons)? 
 xs = [x for x in xs if x.attribute == value]
 
 xs = filter(lambda x: x.attribute == value, xs)
 
","['python', 'list', 'functional-programming', 'filter', 'lambda']",1104
What is the difference between pip and conda?,"I know  pip  is a package manager for python packages. However, I saw the installation on IPython's website use  conda  to install IPython. 
 Can I use  pip  to install IPython? Why should I use  conda  as another python package manager when I already have  pip ? 
 What is the difference between  pip  and  conda ? 
","['python', 'pip', 'ipython', 'package-managers', 'conda']",1095
Importing modules from parent folder,"I am running Python 2.5. 
 This is my folder tree: 
 ptdraft/
  nib.py
  simulations/
    life/
      life.py
 
 (I also have  __init__.py  in each folder, omitted here for readability) 
 How do I import the  nib  module from inside the  life  module? I am hoping it is possible to do without tinkering with sys.path. 
 Note: The main module being run is in the  ptdraft  folder. 
","['python', 'module', 'path', 'directory', 'python-import']",1089
What is the naming convention in Python for variables and functions?,"Coming from a C# background the naming convention for variables and methods are usually either camelCase or PascalCase: 
 // C# example
string thisIsMyVariable = ""a""
public void ThisIsMyMethod()
 
 In Python, I have seen the above but I have also seen snake_case being used: 
 # python example
this_is_my_variable = 'a'
def this_is_my_function():
 
 Is there a more preferable, definitive coding style for Python? 
","['python', 'naming-conventions', 'camelcasing', 'pascalcasing', 'snakecasing']",1068
How do I determine the size of an object in Python?,"How do I get the size occupied in memory by an object in Python? 
","['python', 'object', 'memory', 'memory-management', 'sizeof']",1038
UnicodeDecodeError: &#39;charmap&#39; codec can&#39;t decode byte X in position Y: character maps to &lt;undefined&gt;,"I'm trying to get a Python 3 program to do some manipulations with a text file filled with information. However, when trying to read the file I get the following error: 
 Traceback (most recent call last):  
  File ""SCRIPT LOCATION"", line NUMBER, in <module>  
    text = file.read()
  File ""C:\Python31\lib\encodings\cp1252.py"", line 23, in decode  
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 2907500: character maps to `<undefined>`  
 
 
 After reading this Q&A, see  How to determine the encoding of text  if you need help figuring out the encoding of the file you are trying to open. 
","['python', 'python-3.x', 'unicode', 'file-io', 'decode']",1033
"How do I remove duplicates from a list, while preserving order?","How do I remove duplicates from a list, while preserving order? Using a set to remove duplicates destroys the original order.
Is there a built-in or a Pythonic idiom? 
","['python', 'list', 'duplicates', 'list-comprehension', 'unique']",1033
"What are the differences between the urllib, urllib2, urllib3 and requests module?","In Python, what are the differences between the  urllib ,  urllib2 ,  urllib3  and  requests  modules? Why are there three? They seem to do the same thing... 
","['python', 'python-requests', 'urllib', 'urllib2', 'urllib3']",1030
How to use to find files recursively?,"I would like to list all files recursively in a directory. I currently have a directory structure like this: 
 
 src/main.c 
 src/dir/file1.c 
 src/another-dir/file2.c 
 src/another-dir/nested/files/file3.c 
 
 I've tried to do the following: 
 from glob import glob

glob(os.path.join('src','*.c'))
 
 But this will only get be files directly in the  src  subfolder, e.g. I get  main.c  but I will not get  file1.c ,  file2.c  etc. 
 from glob import glob

glob(os.path.join('src','*.c'))
glob(os.path.join('src','*','*.c'))
glob(os.path.join('src','*','*','*.c'))
glob(os.path.join('src','*','*','*','*.c'))
 
 But this is obviously limited and clunky, how can I do this properly? 
","['python', 'path', 'filesystems', 'glob', 'fnmatch']",1010
Deleting DataFrame row in Pandas based on column value,"I have the following DataFrame: 
              daysago  line_race rating        rw    wrating
 line_date                                                 
2007-03-31       62         11     56  1.000000  56.000000
2007-03-10       83         11     67  1.000000  67.000000
2007-02-10      111          9     66  1.000000  66.000000
2007-01-13      139         10     83  0.880678  73.096278
2006-12-23      160         10     88  0.793033  69.786942
2006-11-09      204          9     52  0.636655  33.106077
2006-10-22      222          8     66  0.581946  38.408408
2006-09-29      245          9     70  0.518825  36.317752
2006-09-16      258         11     68  0.486226  33.063381
2006-08-30      275          8     72  0.446667  32.160051
2006-02-11      475          5     65  0.164591  10.698423
2006-01-13      504          0     70  0.142409   9.968634
2006-01-02      515          0     64  0.134800   8.627219
2005-12-06      542          0     70  0.117803   8.246238
2005-11-29      549          0     70  0.113758   7.963072
2005-11-22      556          0     -1  0.109852  -0.109852
2005-11-01      577          0     -1  0.098919  -0.098919
2005-10-20      589          0     -1  0.093168  -0.093168
2005-09-27      612          0     -1  0.083063  -0.083063
2005-09-07      632          0     -1  0.075171  -0.075171
2005-06-12      719          0     69  0.048690   3.359623
2005-05-29      733          0     -1  0.045404  -0.045404
2005-05-02      760          0     -1  0.039679  -0.039679
2005-04-02      790          0     -1  0.034160  -0.034160
2005-03-13      810          0     -1  0.030915  -0.030915
2004-11-09      934          0     -1  0.016647  -0.016647
 
 I need to remove the rows where  line_race  is equal to  0 . What's the most efficient way to do this? 
","['python', 'pandas', 'dataframe', 'performance', 'delete-row']",1002
Is there any way to kill a Thread?,"Is it possible to terminate a running thread without setting/checking any flags/semaphores/etc.? 
","['python', 'multithreading', 'python-multithreading', 'kill', 'terminate']",988
Is there a list of Pytz Timezones?,"I would like to know what are all the possible values for the timezone argument in the Python library pytz. How to do it? 
","['python', 'django', 'datetime', 'timezone', 'pytz']",979
Why use pip over easy_install?,"A  tweet  reads:  
 
 Don't use easy_install, unless you
  like stabbing yourself in the face.
  Use pip. 
 
 Why use pip over easy_install? Doesn't the  fault lie with PyPI and package authors mostly ? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to  strongly  favor pip over easy_install? 
 (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community) 
","['python', 'pip', 'setuptools', 'easy-install', 'pypi']",975
"Writing a list to a file with Python, with newlines","How do I write a list to a file?  writelines()  doesn't insert newline characters, so I need to do: 
 f.writelines([f""{line}\n"" for line in lines])
 
","['python', 'file', 'list', 'file-io', 'newline']",961
Combine two columns of text in pandas dataframe,"I have a dataframe that looks like 
 Year  quarter
2000       q2
2001       q3
 
 How do I add a new column by combining these columns to get the following dataframe? 
 Year  quarter  period
2000       q2  2000q2
2001       q3  2001q3
 
","['python', 'pandas', 'string', 'dataframe', 'string-concatenation']",951
How to make IPython notebook matplotlib plot inline,"I am trying to use IPython notebook on MacOS X with Python 2.7.2 and IPython 1.1.0. 
 I cannot get matplotlib graphics to show up inline. 
 import matplotlib
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline  
 
 I have also tried  %pylab inline  and the ipython command line arguments  --pylab=inline  but this makes no difference. 
 x = np.linspace(0, 3*np.pi, 500)
plt.plot(x, np.sin(x**2))
plt.title('A simple chirp')
plt.show()
 
 Instead of inline graphics, I get this: 
 <matplotlib.figure.Figure at 0x110b9c450>
 
 And  matplotlib.get_backend()  shows that I have the  'module://IPython.kernel.zmq.pylab.backend_inline'  backend. 
","['python', 'matplotlib', 'jupyter-notebook', 'ipython', 'data-visualization']",946
How are iloc and loc different?,"Can someone explain how these two methods of slicing are different? I've seen  the docs 
and I've seen previous similar questions ( 1 ,  2 ), but I still find myself unable to understand how they are different. To me, they seem interchangeable in large part, because they are at the lower levels of slicing. 
 For example, say we want to get the first five rows of a  DataFrame .  How is it that these two work? 
 df.loc[:5]
df.iloc[:5]
 
 Can someone present cases where the distinction in uses are clearer? 
 
 Once upon a time, I also wanted to know how these two functions differed from  df.ix[:5]  but  ix  has been removed from pandas 1.0, so I don't care anymore. 
","['python', 'pandas', 'dataframe', 'indexing', 'pandas-loc']",939
Why does Python code run faster in a function?,"def main():
    for i in xrange(10**8):
        pass
main()
 
 This piece of code in Python runs in  (Note: The timing is done with the time function in BASH in Linux.) 
 real    0m1.841s
user    0m1.828s
sys     0m0.012s
 
 However, if the for loop isn't placed within a function,  
 for i in xrange(10**8):
    pass
 
 then it runs for a much longer time: 
 real    0m4.543s
user    0m4.524s
sys     0m0.012s
 
 Why is this? 
","['python', 'performance', 'profiling', 'benchmarking', 'cpython']",930
How do I parse an ISO 8601-formatted date?,"I need to parse  RFC 3339  strings like  ""2008-09-03T20:56:35.450686Z""  into Python's  datetime  type. 
 I have found  strptime  in the Python standard library, but it is not very convenient. 
 What is the best way to do this? 
","['python', 'datetime', 'iso8601', 'datetime-parsing', 'rfc3339']",917
Pandas Merging 101,"
 How can I perform a ( INNER | ( LEFT | RIGHT | FULL )  OUTER )  JOIN  with pandas? 
 How do I add NaNs for missing rows after a merge? 
 How do I get rid of NaNs after merging? 
 Can I merge on the index? 
 How do I merge multiple DataFrames? 
 Cross join with pandas 
 merge ?  join ?  concat ?  update ? Who? What? Why?! 
 
 ... and more. I've seen these recurring questions asking about various facets of the pandas merge functionality. Most of the information regarding merge and its various use cases today is fragmented across dozens of badly worded, unsearchable posts. The aim here is to collate some of the more important points for posterity. 
 This Q&A is meant to be the next installment in a series of helpful user guides on common pandas idioms (see  this post on pivoting , and  this post on concatenation , which I will be touching on, later). 
 Please note that this post is  not  meant to be a replacement for  the documentation , so please read that as well! Some of the examples are taken from there. 
 
 Table of Contents 
 For ease of access. 
 
 Merging basics - basic types of joins  (read this first) 
 
 Index-based joins 
 
 Generalizing to multiple DataFrames 
 
 Cross join 
 
 
","['python', 'pandas', 'join', 'merge', 'concatenation']",914
python exception message capturing,"import ftplib
import urllib2
import os
import logging
logger = logging.getLogger('ftpuploader')
hdlr = logging.FileHandler('ftplog.log')
formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
hdlr.setFormatter(formatter)
logger.addHandler(hdlr)
logger.setLevel(logging.INFO)
FTPADDR = ""some ftp address""

def upload_to_ftp(con, filepath):
    try:
        f = open(filepath,'rb')                # file to send
        con.storbinary('STOR '+ filepath, f)         # Send the file
        f.close()                                # Close file and FTP
        logger.info('File successfully uploaded to '+ FTPADDR)
    except, e:
        logger.error('Failed to upload to ftp: '+ str(e))
 
 This doesn't seem to work, I get syntax error, what is the proper way of doing this for logging all kind of exceptions to a file 
","['python', 'exception', 'logging', 'except', 'python-logging']",911
How do I update/upgrade pip itself from inside my virtual environment?,"I'm able to update pip-managed packages, but how do I update pip itself? According to  pip --version , I currently have pip 1.1 installed in my virtualenv and I want to update to the latest version.  
 What's the command for that? Do I need to use distribute or is there a native pip or virtualenv command? I've already tried  pip update  and  pip update pip  with no success. 
","['python', 'upgrade', 'virtualenv', 'pip', 'package-managers']",910
How do I get the day of week given a date?,"I want to find out the following:
given a date ( datetime  object), what is the corresponding day of the week? 
 For instance, Sunday is the first day, Monday: second day.. and so on 
 And then if the input is something like today's date. 
 Example 
 >>> today = datetime.datetime(2017, 10, 20)
>>> today.get_weekday()  # what I look for
 
 The output is maybe  6  (since it's Friday) 
","['python', 'date', 'datetime', 'time', 'weekday']",900
"&quot;TypeError: a bytes-like object is required, not &#39;str&#39;&quot; when handling file content in Python 3","I've very recently migrated to Python 3.5.
This code was working properly in Python 2.7: 
 with open(fname, 'rb') as f:
    lines = [x.strip() for x in f.readlines()]

for line in lines:
    tmp = line.strip().lower()
    if 'some-pattern' in tmp: continue
    # ... code
 
 But in 3.5, on the  if 'some-pattern' in tmp: continue  line, I get an error which says: 
 TypeError: a bytes-like object is required, not 'str'
 
 I was unable to fix the problem using  .decode()  on either side of the  in , nor could I fix it using 
     if tmp.find('some-pattern') != -1: continue
 
 What is wrong, and how do I fix it? 
","['python', 'python-3.x', 'string', 'file', 'byte']",891
How do I set the figure title and axes labels font size?,"I am creating a figure in Matplotlib like this: 
 from matplotlib import pyplot as plt

fig = plt.figure()
plt.plot(data)
fig.suptitle('test title')
plt.xlabel('xlabel')
plt.ylabel('ylabel')
fig.savefig('test.jpg')
 
 I want to specify font sizes for the figure title and the axis labels. I need all three to be different font sizes, so setting a global font size ( mpl.rcParams['font.size']=x ) is not what I want. How do I set font sizes for the figure title and the axis labels individually? 
","['python', 'matplotlib', 'axis', 'yaxis', 'x-axis']",889
error: Unable to find vcvarsall.bat,"I tried to install the Python package  dulwich : 
 pip install dulwich
 
 But I get a cryptic error message: 
 error: Unable to find vcvarsall.bat
 
 The same happens if I try installing the package manually: 
 > python setup.py install
running build_ext
building 'dulwich._objects' extension
error: Unable to find vcvarsall.bat
 
","['python', 'windows', 'pip', 'setup.py', 'failed-installation']",878
"Saving UTF-8 texts with json.dumps as UTF-8, not as a \u escape sequence","Sample code (in a  REPL ): 
 import json
json_string = json.dumps(""ברי צקלה"")
print(json_string)
 
 Output: 
 ""\u05d1\u05e8\u05d9 \u05e6\u05e7\u05dc\u05d4""
 
 The problem: it's not human readable. My (smart) users want to verify or even edit text files with JSON dumps (and I’d rather not use XML). 
 Is there a way to serialize objects into UTF-8 JSON strings (instead of  \uXXXX )? 
","['python', 'json', 'unicode', 'utf-8', 'escaping']",878
Filter pandas DataFrame by substring criteria,"I have a pandas DataFrame with a column of string values. I need to select rows based on partial string matches. 
 Something like this idiom: 
 re.search(pattern, cell_in_question) 
 
 returning a boolean. I am familiar with the syntax of  df[df['A'] == ""hello world""]  but can't seem to find a way to do the same with a partial string match, say  'hello' . 
","['python', 'pandas', 'regex', 'string', 'dataframe']",873
How to see normal print output created during pytest run?,"Sometimes I want to just insert some print statements in my code, and see what gets printed out when I exercise it. My usual way to ""exercise"" it is with existing pytest tests. But when I run these, I don't seem able to see any standard output (at least from within PyCharm, my IDE). 
 Is there a simple way to see standard output during a pytest run? 
","['python', 'logging', 'printing', 'pytest', 'flags']",854
"Truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()","I want to filter my dataframe with an  or  condition to keep rows with a particular column's values that are outside the range  [-0.25, 0.25] . I tried: 
 df = df[(df['col'] < -0.25) or (df['col'] > 0.25)]
 
 But I get the error: 
 
 ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). 
 
","['python', 'pandas', 'dataframe', 'boolean', 'filtering']",847
How to filter Pandas dataframe using &#39;in&#39; and &#39;not in&#39; like in SQL,"How can I achieve the equivalents of SQL's  IN  and  NOT IN ? 
 I have a list with the required values. Here's the scenario: 
 df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})
countries_to_keep = ['UK', 'China']

# pseudo-code:
df[df['country'] not in countries_to_keep]
 
 My current way of doing this is as follows: 
 df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})
df2 = pd.DataFrame({'country': ['UK', 'China'], 'matched': True})

# IN
df.merge(df2, how='inner', on='country')

# NOT IN
not_in = df.merge(df2, how='left', on='country')
not_in = not_in[pd.isnull(not_in['matched'])]
 
 But this seems like a horrible kludge. Can anyone improve on it? 
","['python', 'pandas', 'dataframe', 'filtering', 'sql-function']",845
What is the difference between range and xrange functions in Python 2.X?,"Apparently xrange is faster but I have no idea why it's faster (and no proof besides the anecdotal so far that it is faster) or what besides that is different about 
 for i in range(0, 20):
for i in xrange(0, 20):
 
","['python', 'loops', 'range', 'python-2.x', 'xrange']",845
How to test multiple variables for equality against a single value?,"I'm trying to make a function that will compare multiple variables to an integer and output a string of three letters. I was wondering if there was a way to translate this into Python. So say: 
 x = 0
y = 1
z = 3
mylist = []

if x or y or z == 0:
    mylist.append(""c"")
if x or y or z == 1:
    mylist.append(""d"")
if x or y or z == 2:
    mylist.append(""e"")
if x or y or z == 3: 
    mylist.append(""f"")
 
 which would return a list of: 
 [""c"", ""d"", ""f""]
 
","['python', 'if-statement', 'comparison', 'match', 'boolean-logic']",842
What&#39;s the difference between a module and package in Python?,"What's the difference between a module and package in Python? 
 See also:  What's the difference between ""package"" and ""module""?  (for other languages) 
","['python', 'module', 'package', 'terminology', 'difference']",837
Shuffle DataFrame rows,"I have the following DataFrame: 
     Col1  Col2  Col3  Type
0      1     2     3     1
1      4     5     6     1
...
20     7     8     9     2
21    10    11    12     2
...
45    13    14    15     3
46    16    17    18     3
...
 
 The DataFrame is read from a CSV file. All rows which have  Type  1 are on top, followed by the rows with  Type  2, followed by the rows with  Type  3, etc. 
 I would like to shuffle the order of the DataFrame's rows so that all  Type 's are mixed. A possible result could be: 
     Col1  Col2  Col3  Type
0      7     8     9     2
1     13    14    15     3
...
20     1     2     3     1
21    10    11    12     2
...
45     4     5     6     1
46    16    17    18     3
...
 
 How can I achieve this? 
","['python', 'pandas', 'dataframe', 'permutation', 'shuffle']",835
How to fix &quot;Attempted relative import in non-package&quot; even with __init__.py,"I'm trying to follow  PEP 328 , with the following directory structure: 
 pkg/
  __init__.py
  components/
    core.py
    __init__.py
  tests/
    core_test.py
    __init__.py
 
 In  core_test.py  I have the following import statement 
 from ..components.core import GameLoopEvents
 
 However, when I run, I get the following error: 
 tests$ python core_test.py 
Traceback (most recent call last):
  File ""core_test.py"", line 3, in <module>
    from ..components.core import GameLoopEvents
ValueError: Attempted relative import in non-package
 
 Searching around I found "" relative path not working even with __init__.py "" and "" Import a module from a relative path "" but they didn't help. 
 Is there anything I'm missing here? 
","['python', 'package', 'python-import', 'importerror', 'init']",835
How to combine multiple QuerySets in Django?,"I'm trying to build the search for a Django site I am building, and in that search, I am searching across three different models. And to get pagination on the search result list, I would like to use a generic object_list view to display the results. But to do that, I have to merge three QuerySets into one. 
 How can I do that? I've tried this: 
 result_list = []
page_list = Page.objects.filter(
    Q(title__icontains=cleaned_search_term) |
    Q(body__icontains=cleaned_search_term))
article_list = Article.objects.filter(
    Q(title__icontains=cleaned_search_term) |
    Q(body__icontains=cleaned_search_term) |
    Q(tags__icontains=cleaned_search_term))
post_list = Post.objects.filter(
    Q(title__icontains=cleaned_search_term) |
    Q(body__icontains=cleaned_search_term) |
    Q(tags__icontains=cleaned_search_term))

for x in page_list:
    result_list.append(x)
for x in article_list:
    result_list.append(x)
for x in post_list:
    result_list.append(x)

return object_list(
    request,
    queryset=result_list,
    template_object_name='result',
    paginate_by=10,
    extra_context={
        'search_term': search_term},
    template_name=""search/result_list.html"")
 
 But this doesn't work. I get an error when I try to use that list in the generic view. The list is missing the clone attribute. 
 How can I merge the three lists,  page_list ,  article_list  and  post_list ? 
","['python', 'django', 'search', 'django-queryset', 'django-q']",829
How to convert index of a pandas dataframe into a column,"How to convert an index of a dataframe into a column? 
 For example: 
         gi       ptt_loc
 0  384444683      593  
 1  384444684      594 
 2  384444686      596  
 
 to 
     index1    gi       ptt_loc
 0  0     384444683      593  
 1  1     384444684      594 
 2  2     384444686      596  
 
","['python', 'pandas', 'dataframe', 'indexing', 'series']",816
How to change a string into uppercase?,"How can I convert a string into uppercase in Python? 
 When I tried to research the problem, I found something about  string.ascii_uppercase , but it couldn't solve the problem: 
 >>> s = 'sdsd'
>>> s.ascii_uppercase
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'str' object has no attribute 'ascii_uppercase'
 
 
 See  How do I lowercase a string in Python?  for the opposite. 
","['python', 'string', 'function', 'uppercase', 'string-conversion']",808
Why shouldn&#39;t I use PyPy over CPython if PyPy is 6.3 times faster?,"I've been hearing a lot about the  PyPy  project. They claim it is 6.3 times faster than the  CPython  interpreter on  their site . 
 Whenever we talk about dynamic languages like Python, speed is one of the top issues. To solve this, they say PyPy is 6.3 times faster. 
 The second issue is parallelism, the infamous  Global Interpreter Lock  (GIL). For this, PyPy says it  can give GIL-less Python . 
 If PyPy can solve these great challenges, what are its weaknesses that are preventing wider adoption? That is to say, what's preventing someone like me, a typical Python developer, from switching to PyPy  right now ?  
","['python', 'performance', 'jit', 'pypy', 'cpython']",801
TypeError: &#39;module&#39; object is not callable,"File ""C:\Users\Administrator\Documents\Mibot\oops\blinkserv.py"", line 82, in __init__
    self.serv = socket(AF_INET,SOCK_STREAM)
TypeError: 'module' object is not callable
 
 Why am I getting this error?
I'm confused. 
 How can I solve this error? 
","['python', 'sockets', 'typeerror', 'python-module', 'callable']",798
Why is [] faster than list()?,"I compared the processing speeds of  []  and  list()  on Python 3.11 
 $ python -m timeit '[]'
20000000 loops, best of 5: 11.3 nsec per loop
$ python -m timeit 'list()'
10000000 loops, best of 5: 26.1 nsec per loop
 
 and was surprised to discover that  []  runs about two times faster than  list() . I got very similar results for  {}  and  dict() 
 $ python -m timeit '{}'
20000000 loops, best of 5: 11.6 nsec per loop
$ python -m timeit 'dict()'
10000000 loops, best of 5: 27.1 nsec per loop
 
 Why is this? Do  []  and  {}  (and probably  ()  and  '' , too) immediately pass back a copies of some empty stock literal while their explicitly-named counterparts ( list() ,  dict() ,  tuple() ,  str() ) fully go about creating an object, whether or not they actually have elements? 
","['python', 'performance', 'list', 'instantiation', 'literals']",796
How do I call a parent class&#39;s method from a child class in Python?,"When creating a simple object hierarchy in Python, I'd like to be able to invoke methods of the parent class from a derived class.  In Perl and Java, there is a keyword for this ( super ).  In Perl, I might do this: 
 package Foo;

sub frotz {
    return ""Bamf"";
}

package Bar;
@ISA = qw(Foo);

sub frotz {
   my $str = SUPER::frotz();
   return uc($str);
}
 
 In Python, it appears that I have to name the parent class explicitly from the child.
In the example above, I'd have to do something like  Foo::frotz() .   
 This doesn't seem right since this behavior makes it hard to make deep hierarchies.  If children need to know what class defined an inherited method, then all sorts of information pain is created.   
 Is this an actual limitation in python, a gap in my understanding or both? 
","['python', 'class', 'oop', 'object', 'inheritance']",795
"Constructing pandas DataFrame from values in variables gives &quot;ValueError: If using all scalar values, you must pass an index&quot;","I have two variables as follows. 
 a = 2
b = 3
 
 I want to construct a DataFrame from this: 
 df2 = pd.DataFrame({'A':a, 'B':b})
 
 This generates an error: 
 ValueError: If using all scalar values, you must pass an index
 
 I tried this also: 
 df2 = (pd.DataFrame({'a':a, 'b':b})).reset_index()
 
 This gives the same error message. How do I do what I want? 
","['python', 'pandas', 'dataframe', 'valueerror', 'scalar']",790
What is the best way to remove accents (normalize) in a Python unicode string?,"I have a Unicode string in Python, and I would like to remove all the accents (diacritics). 
 I found on the web an elegant way to do this (in Java): 
 
 convert the Unicode string to its  long normalized form  (with a separate character for letters and diacritics) 
 remove all the characters whose Unicode type is ""diacritic"". 
 
 Do I need to install a library such as pyICU or is this possible with just the Python standard library?  And what about python 3? 
 Important note: I would like to avoid code with an explicit mapping from accented characters to their non-accented counterpart. 
","['python', 'python-3.x', 'unicode', 'python-2.x', 'diacritics']",790
What do ** (double star/asterisk) and * (star/asterisk) mean in a function call?,"In code like  zip(*x)  or  f(**k) , what do the  *  and  **  respectively mean? How does Python implement that behaviour, and what are the performance implications? 
 
 See also:  Expanding tuples into arguments . Please use that one to close questions where OP needs to use  *  on an argument and doesn't know it exists. Similarly, use  Converting Python dict to kwargs?  for the case of using  ** . 
 See  What does ** (double star/asterisk) and * (star/asterisk) do for parameters?  for the complementary question about parameters. 
","['python', 'syntax', 'parameter-passing', 'iterable-unpacking', 'argument-unpacking']",790
"Get statistics for each group (such as count, mean, etc) using pandas GroupBy?","I have a dataframe  df  and I use several columns from it to  groupby : 
 df['col1','col2','col3','col4'].groupby(['col1','col2']).mean()
 
 In the above way, I almost get the table (dataframe) that I need. What is missing is an additional column that contains number of rows in each group. In other words, I have mean but I also would like to know how many were used to get these means. For example in the first group there are 8 values and in the second one 10 and so on. 
 In short: How do I get  group-wise  statistics for a dataframe? 
","['python', 'pandas', 'dataframe', 'group-by', 'statistics']",788
How can I force division to be floating point? Division keeps rounding down to 0?,"I have two integer values  a  and  b , but I need their ratio in floating point.  I know that  a < b  and I want to calculate  a / b , so if I use integer division I'll always get 0 with a remainder of  a . 
 How can I force  c  to be a floating point number in Python 2 in the following? 
 c = a / b
 
 
 In 3.x, the behaviour is reversed; see  Why does integer division yield a float instead of another integer?  for the opposite, 3.x-specific problem. 
","['python', 'floating-point', 'integer', 'division', 'python-2.x']",784
Set value for particular cell in pandas DataFrame using index,"I have created a Pandas DataFrame 
 df = DataFrame(index=['A','B','C'], columns=['x','y'])
 
 Now, I would like to assign a value to particular cell, for example to row  C  and column  x . In other words, I would like to perform the following transformation: 
      x    y             x    y
A  NaN  NaN        A  NaN  NaN
B  NaN  NaN   ⟶   B  NaN  NaN
C  NaN  NaN        C   10  NaN
 
 with this code: 
 df.xs('C')['x'] = 10
 
 However, the contents of  df  has not changed. The dataframe contains yet again only  NaN s. How do I what I want? 
","['python', 'pandas', 'dataframe', 'cell', 'nan']",780
How do I properly assert that an exception gets raised in pytest?,"Code: 
 # coding=utf-8
import pytest


def whatever():
    return 9/0

def test_whatever():
    try:
        whatever()
    except ZeroDivisionError as exc:
        pytest.fail(exc, pytrace=True)
 
 Output: 
 ================================ test session starts =================================
platform linux2 -- Python 2.7.3 -- py-1.4.20 -- pytest-2.5.2
plugins: django, cov
collected 1 items 

pytest_test.py F

====================================== FAILURES ======================================
___________________________________ test_whatever ____________________________________

    def test_whatever():
        try:
            whatever()
        except ZeroDivisionError as exc:
>           pytest.fail(exc, pytrace=True)
E           Failed: integer division or modulo by zero

pytest_test.py:12: Failed
============================== 1 failed in 1.16 seconds ==============================
 
 How do I make pytest print traceback, so that I would see where in the  whatever  function that an exception was raised? 
","['python', 'unit-testing', 'exception', 'testing', 'pytest']",777
What is the difference between __init__ and __call__?,"I want to know the difference between  __init__  and  __call__  methods.   
 For example: 
 class test:

  def __init__(self):
    self.a = 10

  def __call__(self): 
    b = 20
 
","['python', 'class', 'oop', 'object', 'callable-object']",775
What is a &quot;slug&quot; in Django?,"When I read Django code I often see in models what is called a ""slug"". I am not quite sure what this is, but I do know it has something to do with URLs. How and when is this slug-thing supposed to be used? 
 I have read its definition below in  this glossary : 
 
 Slug 
A short label for something, containing only letters, numbers,
underscores or hyphens. They’re generally used in URLs. For example,
in a typical blog entry URL: 
 https://www.djangoproject.com/weblog/2008/apr/12/spring/  the last bit
(spring) is the slug. 
 
","['python', 'django', 'url', 'django-models', 'slug']",765
Changing the tick frequency on the x or y axis,"I am trying to fix how python plots my data. Say: 
 x = [0, 5, 9, 10, 15]
y = [0, 1, 2, 3, 4]

matplotlib.pyplot.plot(x, y)
matplotlib.pyplot.show()
 
 The x axis' ticks are plotted in intervals of 5. Is there a way to make it show intervals of 1? 
","['python', 'matplotlib', 'axis', 'xticks', 'yticks']",763
Import multiple CSV files into pandas and concatenate into one DataFrame,"I would like to read several CSV files from a directory into pandas and concatenate them into one big DataFrame. I have not been able to figure it out though. Here is what I have so far: 
 import glob
import pandas as pd

# Get data file names
path = r'C:\DRO\DCL_rawdata_files'
filenames = glob.glob(path + ""/*.csv"")

dfs = []
for filename in filenames:
    dfs.append(pd.read_csv(filename))

# Concatenate all data into one DataFrame
big_frame = pd.concat(dfs, ignore_index=True)
 
 I guess I need some help within the  for  loop? 
","['python', 'pandas', 'csv', 'dataframe', 'concatenation']",757
What does &#39;super&#39; do in Python? - difference between super().__init__() and explicit superclass __init__(),"What's the difference between: 
 class Child(SomeBaseClass):
    def __init__(self):
        super(Child, self).__init__()
        
 
 and: 
 class Child(SomeBaseClass):
    def __init__(self):
        SomeBaseClass.__init__(self)
        
 
 I've seen  super  being used quite a lot in classes with only single inheritance. I can see why you'd use it in multiple inheritance but am unclear as to what the advantages are of using it in this kind of situation. 
 
 This question is about technical implementation details and the distinction between different ways of accessing the base class  __init__  method. To close duplicate questions where OP is simply missing a  super  call and is asking why base class attributes aren't available, please use  Python class inheritance: AttributeError: '[SubClass]' object has no attribute 'xxx'  instead. 
","['python', 'oop', 'inheritance', 'multiple-inheritance', 'super']",744
Speed comparison with Project Euler: C vs Python vs Erlang vs Haskell,"I have taken  Problem #12  from  Project Euler  as a programming exercise and to compare my (surely not optimal) implementations in C, Python, Erlang and Haskell. In order to get some higher execution times, I search for the first triangle number with more than 1000 divisors instead of 500 as stated in the original problem. 
 The result is the following: 
 C: 
 lorenzo@enzo:~/erlang$ gcc -lm -o euler12.bin euler12.c
lorenzo@enzo:~/erlang$ time ./euler12.bin
842161320

real    0m11.074s
user    0m11.070s
sys 0m0.000s
 
 Python: 
 lorenzo@enzo:~/erlang$ time ./euler12.py 
842161320

real    1m16.632s
user    1m16.370s
sys 0m0.250s
 
 Python with PyPy: 
 lorenzo@enzo:~/Downloads/pypy-c-jit-43780-b590cf6de419-linux64/bin$ time ./pypy /home/lorenzo/erlang/euler12.py 
842161320

real    0m13.082s
user    0m13.050s
sys 0m0.020s
 
 Erlang: 
 lorenzo@enzo:~/erlang$ erlc euler12.erl 
lorenzo@enzo:~/erlang$ time erl -s euler12 solve
Erlang R13B03 (erts-5.7.4) [source] [64-bit] [smp:4:4] [rq:4] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.7.4  (abort with ^G)
1> 842161320

real    0m48.259s
user    0m48.070s
sys 0m0.020s
 
 Haskell: 
 lorenzo@enzo:~/erlang$ ghc euler12.hs -o euler12.hsx
[1 of 1] Compiling Main             ( euler12.hs, euler12.o )
Linking euler12.hsx ...
lorenzo@enzo:~/erlang$ time ./euler12.hsx 
842161320

real    2m37.326s
user    2m37.240s
sys 0m0.080s
 
 Summary: 
 
 C: 100% 
 Python: 692% (118% with PyPy) 
 Erlang: 436% (135% thanks to RichardC) 
 Haskell: 1421% 
 
 I suppose that C has a big advantage as it uses long for the calculations and not arbitrary length integers as the other three. Also it doesn't need to load a runtime first (Do the others?). 
 Question 1: 
Do Erlang, Python and Haskell lose speed due to using arbitrary length integers or don't they as long as the values are less than  MAXINT ? 
 Question 2: 
Why is Haskell so slow? Is there a compiler flag that turns off the brakes or is it my implementation? (The latter is quite probable as Haskell is a book with seven seals to me.) 
 Question 3: 
Can you offer me some hints how to optimize these implementations without changing the way I determine the factors? Optimization in any way: nicer, faster, more ""native"" to the language. 
 EDIT: 
 Question 4: 
Do my functional implementations permit LCO (last call optimization, a.k.a tail recursion elimination) and hence avoid adding unnecessary frames onto the call stack? 
 I really tried to implement the same algorithm as similar as possible in the four languages, although I have to admit that my Haskell and Erlang knowledge is very limited. 
 
 Source codes used: 
 #include <stdio.h>
#include <math.h>

int factorCount (long n)
{
    double square = sqrt (n);
    int isquare = (int) square;
    int count = isquare == square ? -1 : 0;
    long candidate;
    for (candidate = 1; candidate <= isquare; candidate ++)
        if (0 == n % candidate) count += 2;
    return count;
}

int main ()
{
    long triangle = 1;
    int index = 1;
    while (factorCount (triangle) < 1001)
    {
        index ++;
        triangle += index;
    }
    printf (""%ld\n"", triangle);
}
 
 
 #! /usr/bin/env python3.2

import math

def factorCount (n):
    square = math.sqrt (n)
    isquare = int (square)
    count = -1 if isquare == square else 0
    for candidate in range (1, isquare + 1):
        if not n % candidate: count += 2
    return count

triangle = 1
index = 1
while factorCount (triangle) < 1001:
    index += 1
    triangle += index

print (triangle)
 
 
 -module (euler12).
-compile (export_all).

factorCount (Number) -> factorCount (Number, math:sqrt (Number), 1, 0).

factorCount (_, Sqrt, Candidate, Count) when Candidate > Sqrt -> Count;

factorCount (_, Sqrt, Candidate, Count) when Candidate == Sqrt -> Count + 1;

factorCount (Number, Sqrt, Candidate, Count) ->
    case Number rem Candidate of
        0 -> factorCount (Number, Sqrt, Candidate + 1, Count + 2);
        _ -> factorCount (Number, Sqrt, Candidate + 1, Count)
    end.

nextTriangle (Index, Triangle) ->
    Count = factorCount (Triangle),
    if
        Count > 1000 -> Triangle;
        true -> nextTriangle (Index + 1, Triangle + Index + 1)  
    end.

solve () ->
    io:format (""~p~n"", [nextTriangle (1, 1) ] ),
    halt (0).
 
 
 factorCount number = factorCount' number isquare 1 0 - (fromEnum $ square == fromIntegral isquare)
    where square = sqrt $ fromIntegral number
          isquare = floor square

factorCount' number sqrt candidate count
    | fromIntegral candidate > sqrt = count
    | number `mod` candidate == 0 = factorCount' number sqrt (candidate + 1) (count + 2)
    | otherwise = factorCount' number sqrt (candidate + 1) count

nextTriangle index triangle
    | factorCount triangle > 1000 = triangle
    | otherwise = nextTriangle (index + 1) (triangle + index + 1)

main = print $ nextTriangle 1 1
 
","['python', 'c', 'performance', 'haskell', 'erlang']",740
Are dictionaries ordered in Python 3.6+?,"Dictionaries are insertion ordered as of Python 3.6. It is described as a CPython implementation detail rather than a language feature. The  documentation  states: 
 
 dict()  now uses a “compact” representation  pioneered by PyPy . The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5.  PEP 468  (Preserving the order of **kwargs in a function.) is implemented by this. The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5). (Contributed by INADA Naoki in  issue 27350 . Idea  originally suggested by Raymond Hettinger .) 
 
 How does the new dictionary implementation perform better than the older one while preserving element order? 
 
 Update December 2017:  dict s retaining insertion order is  guaranteed  for Python 3.7 
","['python', 'python-3.x', 'dictionary', 'python-internals', 'python-3.6']",740
How to apply a function to two columns of Pandas dataframe,"Suppose I have a function and a dataframe defined as below: 
 def get_sublist(sta, end):
    return mylist[sta:end+1]

df = pd.DataFrame({'ID':['1','2','3'], 'col_1': [0,2,3], 'col_2':[1,4,5]})
mylist = ['a','b','c','d','e','f']
 
 Now I want to apply  get_sublist  to  df 's two columns  'col_1', 'col_2'  to element-wise calculate a new column  'col_3'  to get an output that looks like: 
   ID  col_1  col_2            col_3
0  1      0      1       ['a', 'b']
1  2      2      4  ['c', 'd', 'e']
2  3      3      5  ['d', 'e', 'f']
 
 I tried 
 df['col_3'] = df[['col_1','col_2']].apply(get_sublist, axis=1)
 
 but this results in 
 TypeError: get_sublist() missing 1 required positional argument:
 
 How do I do it? 
","['python', 'pandas', 'dataframe', 'function', 'typeerror']",733
Decorators with parameters?,"I have a problem with the transfer of the variable  insurance_mode  by the decorator. I would do it by the following decorator statement: 
 @execute_complete_reservation(True)
def test_booking_gta_object(self):
    self.test_select_gta_object()
 
 but unfortunately, this statement does not work. Perhaps maybe there is better way to solve this problem. 
 def execute_complete_reservation(test_case,insurance_mode):
    def inner_function(self,*args,**kwargs):
        self.test_create_qsf_query()
        test_case(self,*args,**kwargs)
        self.test_select_room_option()
        if insurance_mode:
            self.test_accept_insurance_crosseling()
        else:
            self.test_decline_insurance_crosseling()
        self.test_configure_pax_details()
        self.test_configure_payer_details

    return inner_function
 
","['python', 'function', 'parameters', 'arguments', 'decorator']",705
How to check Django version,"I have to use  Python  and  Django  for our application. So, I have two versions of Python, 2.6 and 2.7. Now I have installed Django. I could run the sample application for testing Django successfully. But how do I check whether Django uses the 2.6 or 2.7 version and what version of modules Django uses? 
","['python', 'django', 'command-line', 'command', 'version']",705
Convert pandas dataframe to NumPy array,"How do I convert a pandas dataframe into a NumPy array? 
 DataFrame: 
 import numpy as np
import pandas as pd

index = [1, 2, 3, 4, 5, 6, 7]
a = [np.nan, np.nan, np.nan, 0.1, 0.1, 0.1, 0.1]
b = [0.2, np.nan, 0.2, 0.2, 0.2, np.nan, np.nan]
c = [np.nan, 0.5, 0.5, np.nan, 0.5, 0.5, np.nan]
df = pd.DataFrame({'A': a, 'B': b, 'C': c}, index=index)
df = df.rename_axis('ID')
 
 gives 
       A    B    C
ID                                 
1   NaN  0.2  NaN
2   NaN  NaN  0.5
3   NaN  0.2  0.5
4   0.1  0.2  NaN
5   0.1  0.2  0.5
6   0.1  NaN  0.5
7   0.1  NaN  NaN
 
 I would like to convert this to a NumPy array, like so: 
 array([[ nan,  0.2,  nan],
       [ nan,  nan,  0.5],
       [ nan,  0.2,  0.5],
       [ 0.1,  0.2,  nan],
       [ 0.1,  0.2,  0.5],
       [ 0.1,  nan,  0.5],
       [ 0.1,  nan,  nan]])
 
 
 Also, is it possible to preserve the dtypes, like this? 
 array([[ 1, nan,  0.2,  nan],
       [ 2, nan,  nan,  0.5],
       [ 3, nan,  0.2,  0.5],
       [ 4, 0.1,  0.2,  nan],
       [ 5, 0.1,  0.2,  0.5],
       [ 6, 0.1,  nan,  0.5],
       [ 7, 0.1,  nan,  nan]],
     dtype=[('ID', '<i4'), ('A', '<f8'), ('B', '<f8'), ('B', '<f8')])
 
","['python', 'arrays', 'pandas', 'numpy', 'dataframe']",698
UnicodeDecodeError when reading CSV file in Pandas,"I'm running a program which is processing 30,000 similar files. A random number of them are stopping and producing this error... 
   File ""C:\Importer\src\dfman\importer.py"", line 26, in import_chr
    data = pd.read_csv(filepath, names=fields)
  File ""C:\Python33\lib\site-packages\pandas\io\parsers.py"", line 400, in parser_f
    return _read(filepath_or_buffer, kwds)
  File ""C:\Python33\lib\site-packages\pandas\io\parsers.py"", line 205, in _read
    return parser.read()
  File ""C:\Python33\lib\site-packages\pandas\io\parsers.py"", line 608, in read
    ret = self._engine.read(nrows)
  File ""C:\Python33\lib\site-packages\pandas\io\parsers.py"", line 1028, in read
    data = self._reader.read(nrows)
  File ""parser.pyx"", line 706, in pandas.parser.TextReader.read (pandas\parser.c:6745)
  File ""parser.pyx"", line 728, in pandas.parser.TextReader._read_low_memory (pandas\parser.c:6964)
  File ""parser.pyx"", line 804, in pandas.parser.TextReader._read_rows (pandas\parser.c:7780)
  File ""parser.pyx"", line 890, in pandas.parser.TextReader._convert_column_data (pandas\parser.c:8793)
  File ""parser.pyx"", line 950, in pandas.parser.TextReader._convert_tokens (pandas\parser.c:9484)
  File ""parser.pyx"", line 1026, in pandas.parser.TextReader._convert_with_dtype (pandas\parser.c:10642)
  File ""parser.pyx"", line 1046, in pandas.parser.TextReader._string_convert (pandas\parser.c:10853)
  File ""parser.pyx"", line 1278, in pandas.parser._string_box_utf8 (pandas\parser.c:15657)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xda in position 6: invalid    continuation byte
 
 The source/creation of these files all come from the same place. What's the best way to correct this to proceed with the import? 
","['python', 'pandas', 'csv', 'dataframe', 'unicode']",697
Selecting multiple columns in a Pandas dataframe,"How do I select columns  a  and  b  from  df , and save them into a new dataframe  df1 ? 
 index  a   b   c
1      2   3   4
2      3   4   5
 
 Unsuccessful attempt: 
 df1 = df['a':'b']
df1 = df.ix[:, 'a':'b']
 
","['python', 'pandas', 'dataframe', 'select', 'indexing']",1726
Relative imports for the trilliоnth time,"I've been here: 
 
 PEP 328 – Imports: Multi-Line and Absolute/Relative 
 Modules, Packages 
 Python packages: relative imports 
 Python relative import example code does not work 
 Relative imports in Python 2.5 
 Relative imports in Python 
 Python: Disabling relative import 
 
 and plenty of URLs that I did not copy, some on SO, some on other sites, back when I thought I'd have the solution quickly. 
 The forever-recurring question is this: how do I solve this ""Attempted relative import in non-package"" message? 
 
 ImportError: attempted relative import with no known parent package 
 
 I built an exact replica of the package on pep-0328: 
 package/
    __init__.py
    subpackage1/
        __init__.py
        moduleX.py
        moduleY.py
    subpackage2/
        __init__.py
        moduleZ.py
    moduleA.py
 
 The imports were done from the console. 
 I did make functions named spam and eggs in their appropriate modules.  Naturally, it didn't work.  The answer is apparently in the 4th URL I listed, but it's all alumni to me. There was this response on one of the URLs I visited: 
 
 Relative imports use a module's name attribute to determine that module's position in the package hierarchy. If the module's name does not contain any package information (e.g. it is set to 'main') then relative imports are resolved as if the module were a top level module, regardless of where the module is actually located on the file system. 
 
 The above response looks promising, but it's all hieroglyphs to me. How do I make Python not return to me ""Attempted relative import in non-package""? It has an answer that involves  -m , supposedly. 
 Why does Python give that error message? What does by ""non-package"" mean? Why and how do you define a 'package'? 
","['python', 'import', 'relative-path', 'python-packaging', 'relative-import']",1721
How do I profile a Python script?,"Project Euler  and other coding contests often have a maximum time to run or people boast of how fast their particular solution runs. With Python, sometimes the approaches are somewhat kludgey - i.e., adding timing code to  __main__ . 
 What is a good way to profile how long a Python program takes to run? 
","['python', 'performance', 'optimization', 'time-complexity', 'profiling']",1682
Why do Python classes inherit object?,"Why does the following class declaration inherit from  object ? 
 class MyClass(object):
    ...
 
","['python', 'class', 'oop', 'object', 'inheritance']",1674
Creating a singleton in Python,"This question is not for the discussion of whether or not the  singleton design pattern  is desirable, is an anti-pattern, or for any religious wars, but to discuss how this pattern is best implemented in Python in such a way that is most pythonic. In this instance I define 'most pythonic' to mean that it follows the 'principle of least astonishment' . 
 I have multiple classes which would become singletons (my use-case is for a logger, but this is not important). I do not wish to clutter several classes with added gumph when I can simply inherit or decorate. 
 Best methods: 
 
 Method 1: A decorator 
 def singleton(class_):
    instances = {}
    def getinstance(*args, **kwargs):
        if class_ not in instances:
            instances[class_] = class_(*args, **kwargs)
        return instances[class_]
    return getinstance

@singleton
class MyClass(BaseClass):
    pass
 
 Pros 
 
 Decorators are additive in a way that is often more intuitive than multiple inheritance. 
 
 Cons 
 
 While objects created using  MyClass()  would be true singleton objects,  MyClass  itself is a function, not a class, so you cannot call class methods from it. Also for 
 x = MyClass();
y = MyClass();
t = type(n)();
 
 
 
 then  x == y  but  x != t && y != t 
 
 Method 2: A base class 
 class Singleton(object):
    _instance = None
    def __new__(class_, *args, **kwargs):
        if not isinstance(class_._instance, class_):
            class_._instance = object.__new__(class_, *args, **kwargs)
        return class_._instance

class MyClass(Singleton, BaseClass):
    pass
 
 Pros 
 
 It's a true class 
 
 Cons 
 
 Multiple inheritance - eugh!  __new__  could be overwritten during inheritance from a second base class? One has to think more than is necessary. 
 
 
 Method 3: A  metaclass 
 class Singleton(type):
    _instances = {}
    def __call__(cls, *args, **kwargs):
        if cls not in cls._instances:
            cls._instances[cls] = super(Singleton, cls).__call__(*args, **kwargs)
        return cls._instances[cls]

#Python2
class MyClass(BaseClass):
    __metaclass__ = Singleton

#Python3
class MyClass(BaseClass, metaclass=Singleton):
    pass
 
 Pros 
 
 It's a true class 
 Auto-magically covers inheritance 
 Uses  __metaclass__  for its proper purpose (and made me aware of it) 
 
 Cons 
 
 Are there any? 
 
 
 Method 4: decorator returning a class with the same name 
 def singleton(class_):
    class class_w(class_):
        _instance = None
        def __new__(class_, *args, **kwargs):
            if class_w._instance is None:
                class_w._instance = super(class_w,
                                    class_).__new__(class_,
                                                    *args,
                                                    **kwargs)
                class_w._instance._sealed = False
            return class_w._instance
        def __init__(self, *args, **kwargs):
            if self._sealed:
                return
            super(class_w, self).__init__(*args, **kwargs)
            self._sealed = True
    class_w.__name__ = class_.__name__
    return class_w

@singleton
class MyClass(BaseClass):
    pass
 
 Pros 
 
 It's a true class 
 Auto-magically covers inheritance 
 
 Cons 
 
 Is there not an overhead for creating each new class? Here we are creating two classes for each class we wish to make a singleton. While this is fine in my case, I worry that this might not scale. Of course there is a matter of debate as to whether it aught to be too easy to scale this pattern... 
 What is the point of the  _sealed  attribute 
 Can't call methods of the same name on base classes using  super()  because they will recurse. This means you can't customize  __new__  and can't subclass a class that needs you to call up to  __init__ . 
 
 
 Method 5: a module 
 a module file  singleton.py 
 Pros 
 
 Simple is better than complex 
 
 Cons 
 
 Not lazily instantiated 
 
","['python', 'singleton', 'decorator', 'base-class', 'metaclass']",1659
How to change the order of DataFrame columns?,"I have the following DataFrame ( df ): 
 import numpy as np
import pandas as pd

df = pd.DataFrame(np.random.rand(10, 5))
 
 I add more column(s) by assignment: 
 df['mean'] = df.mean(1)
 
 How can I move the column  mean  to the front, i.e. set it as first column leaving the order of the other columns untouched? 
","['python', 'pandas', 'dataframe', 'sorting', 'indexing']",1609
Change column type in pandas,"I created a DataFrame from a list of lists: 
 table = [
    ['a',  '1.2',  '4.2' ],
    ['b',  '70',   '0.03'],
    ['x',  '5',    '0'   ],
]

df = pd.DataFrame(table)
 
 How do I convert the columns to specific types? In this case, I want to convert columns 2 and 3 into floats. 
 Is there a way to specify the types while converting the list to DataFrame? Or is it better to create the DataFrame first and then loop through the columns to change the dtype for each column? Ideally I would like to do this in a dynamic way because there can be hundreds of columns, and I don't want to specify exactly which columns are of which type. All I can guarantee is that each column contains values of the same type. 
","['python', 'pandas', 'dataframe', 'types', 'casting']",1500
UnicodeEncodeError: &#39;ascii&#39; codec can&#39;t encode character u&#39;\xa0&#39; in position 20: ordinal not in range(128),"I'm having problems dealing with unicode characters from text fetched from different web pages (on different sites). I am using BeautifulSoup.  
 The problem is that the error is not always reproducible; it sometimes works with some pages, and sometimes, it barfs by throwing a  UnicodeEncodeError . I have tried just about everything I can think of, and yet I have not found anything that works consistently without throwing some kind of Unicode-related error. 
 One of the sections of code that is causing problems is shown below: 
 agent_telno = agent.find('div', 'agent_contact_number')
agent_telno = '' if agent_telno is None else agent_telno.contents[0]
p.agent_info = str(agent_contact + ' ' + agent_telno).strip()
 
 Here is a stack trace produced on SOME strings when the snippet above is run: 
 Traceback (most recent call last):
  File ""foobar.py"", line 792, in <module>
    p.agent_info = str(agent_contact + ' ' + agent_telno).strip()
UnicodeEncodeError: 'ascii' codec can't encode character u'\xa0' in position 20: ordinal not in range(128)
 
 I suspect that this is because some pages (or more specifically, pages from some of the sites) may be encoded, whilst others may be unencoded. All the sites are based in the UK and provide data meant for UK consumption - so there are no issues relating to internalization or dealing with text written in anything other than English. 
 Does anyone have any ideas as to how to solve this so that I can CONSISTENTLY fix this problem? 
","['python', 'unicode', 'beautifulsoup', 'python-2.x', 'python-unicode']",1495
Is there a built-in function to print all the current properties and values of an object?,"So what I'm looking for here is something like PHP's  print_r  function. 
 This is so I can debug my scripts by seeing what's the state of the object in question. 
","['python', 'debugging', 'introspection', 'pretty-print', 'python-datamodel']",1465
Removing duplicates in lists,"How can I check if a list has any duplicates and return a new list without duplicates? 
","['python', 'algorithm', 'list', 'duplicates', 'intersection']",1453
How to drop rows of Pandas DataFrame whose value in a certain column is NaN,"I have this DataFrame and want only the records whose EPS column is not NaN: 
                  STK_ID  EPS  cash
STK_ID RPT_Date                   
601166 20111231  601166  NaN   NaN
600036 20111231  600036  NaN    12
600016 20111231  600016  4.3   NaN
601009 20111231  601009  NaN   NaN
601939 20111231  601939  2.5   NaN
000001 20111231  000001  NaN   NaN
 
 ...i.e. something like  df.drop(....)  to get this resulting dataframe: 
                   STK_ID  EPS  cash
STK_ID RPT_Date                   
600016 20111231  600016  4.3   NaN
601939 20111231  601939  2.5   NaN
 
 How do I do that? 
","['python', 'pandas', 'dataframe', 'indexing', 'nan']",1424
How to deal with SettingWithCopyWarning in Pandas,"Background 
 I just upgraded my Pandas from 0.11 to 0.13.0rc1. Now, the application is popping out many new warnings. One of them like this: 
 E:\FinReporter\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_index,col_indexer] = value instead
  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE
 
 I want to know what exactly it means?  Do I need to change something? 
 How should I suspend the warning if I insist to use  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE ? 
 The function that gives warnings 
 def _decode_stock_quote(list_of_150_stk_str):
    """"""decode the webpage and return dataframe""""""

    from cStringIO import StringIO

    str_of_all = """".join(list_of_150_stk_str)

    quote_df = pd.read_csv(StringIO(str_of_all), sep=',', names=list('ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefg')) #dtype={'A': object, 'B': object, 'C': np.float64}
    quote_df.rename(columns={'A':'STK', 'B':'TOpen', 'C':'TPCLOSE', 'D':'TPrice', 'E':'THigh', 'F':'TLow', 'I':'TVol', 'J':'TAmt', 'e':'TDate', 'f':'TTime'}, inplace=True)
    quote_df = quote_df.ix[:,[0,3,2,1,4,5,8,9,30,31]]
    quote_df['TClose'] = quote_df['TPrice']
    quote_df['RT']     = 100 * (quote_df['TPrice']/quote_df['TPCLOSE'] - 1)
    quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE
    quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE
    quote_df['STK_ID'] = quote_df['STK'].str.slice(13,19)
    quote_df['STK_Name'] = quote_df['STK'].str.slice(21,30)#.decode('gb2312')
    quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])
    
    return quote_df
 
 More warning messages 
 E:\FinReporter\FM_EXT.py:449: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_index,col_indexer] = value instead
  quote_df['TVol']   = quote_df['TVol']/TVOL_SCALE
E:\FinReporter\FM_EXT.py:450: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_index,col_indexer] = value instead
  quote_df['TAmt']   = quote_df['TAmt']/TAMT_SCALE
E:\FinReporter\FM_EXT.py:453: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_index,col_indexer] = value instead
  quote_df['TDate']  = quote_df.TDate.map(lambda x: x[0:4]+x[5:7]+x[8:10])
 
","['python', 'pandas', 'dataframe', 'chained-assignment', 'pandas-settingwithcopy-warning']",1384
How does the @property decorator work in Python?,"I would like to understand how the built-in function  property  works. What confuses me is that  property  can also be used as a decorator, but it only takes arguments when used as a built-in function and not when used as a decorator. 
 This example is from the  documentation : 
 class C:
    def __init__(self):
        self._x = None

    def getx(self):
        return self._x
    def setx(self, value):
        self._x = value
    def delx(self):
        del self._x
    x = property(getx, setx, delx, ""I'm the 'x' property."")
 
 property 's arguments are  getx ,  setx ,  delx  and a doc string. 
 In the code below  property  is used as a decorator. The object of it is the  x  function, but in the code above there is no place for an object function in the arguments. 
 class C:
    def __init__(self):
        self._x = None

    @property
    def x(self):
        """"""I'm the 'x' property.""""""
        return self._x

    @x.setter
    def x(self, value):
        self._x = value

    @x.deleter
    def x(self):
        del self._x
 
 How are the  x.setter  and  x.deleter  decorators created in this case? 
","['python', 'properties', 'decorator', 'python-decorators', 'python-internals']",1353
Get a list from Pandas DataFrame column headers,"I want to get a list of the column headers from a Pandas DataFrame.  The DataFrame will come from user input, so I won't know how many columns there will be or what they will be called. 
 For example, if I'm given a DataFrame like this: 
     y  gdp  cap
0   1    2    5
1   2    3    9
2   8    7    2
3   3    4    7
4   6    7    7
5   4    8    3
6   8    2    8
7   9    9   10
8   6    6    4
9  10   10    7
 
 I would get a list like this: 
 ['y', 'gdp', 'cap']
 
","['python', 'pandas', 'dataframe', 'list', 'header']",1341
What is a mixin and why is it useful?,"In  Programming Python , Mark Lutz mentions the term  mixin . I am from a C/C++/C# background and I have not heard the term before. What is a mixin? 
 Reading between the lines of  this example  (which I have linked to because it is quite long), I am presuming it is a case of using multiple inheritance to extend a class as opposed to proper subclassing. Is this right? 
 Why would I want to do that rather than put the new functionality into a subclass? For that matter, why would a mixin/multiple inheritance approach be better than using composition? 
 What separates a mixin from multiple inheritance? Is it just a matter of semantics? 
","['python', 'oop', 'multiple-inheritance', 'mixins', 'python-class']",1335
Why does comparing strings using either &#39;==&#39; or &#39;is&#39; sometimes produce a different result?,"Two string variables are set to the same value.  s1 == s2  always returns  True , but  s1 is s2  sometimes returns  False . 
 If I open my Python interpreter and do the same  is  comparison, it succeeds: 
 >>> s1 = 'text'
>>> s2 = 'text'
>>> s1 is s2
True
 
 Why is this? 
","['python', 'string', 'comparison', 'identity', 'equality']",1314
Get difference between two lists with Unique Entries,"I have two lists in Python: 
 temp1 = ['One', 'Two', 'Three', 'Four']
temp2 = ['One', 'Two']
 
 Assuming the elements in each list are unique, I want to create a third list with items from the first list which are not in the second list: 
 temp3 = ['Three', 'Four']
 
 Are there any fast ways without cycles and checking? 
","['python', 'performance', 'list', 'set', 'set-difference']",1231
How do I type hint a method with the type of the enclosing class?,"I have the following code in Python 3: 
 class Position:

    def __init__(self, x: int, y: int):
        self.x = x
        self.y = y

    def __add__(self, other: Position) -> Position:
        return Position(self.x + other.x, self.y + other.y)
 
 But my editor (PyCharm) says that the reference  Position  can not be resolved (in the  __add__  method). How should I specify that I expect the return type to be of type  Position ? 
 Edit: I think this is actually a PyCharm issue. It actually uses the information in its warnings, and code completion. 
 
 But correct me if I'm wrong, and need to use some other syntax. 
","['python', 'python-3.x', 'pycharm', 'type-hinting', 'python-typing']",1224
How do I trim whitespace?,"Is there a Python function that will trim whitespace (spaces and tabs) from a string? 
 So that given input  ""  \t example string\t  ""  becomes  ""example string"" . 
","['python', 'string', 'whitespace', 'trim', 'strip']",1215
What are &quot;named tuples&quot; in Python?,"
 What are named tuples and how do I use them? 
 When should I use named tuples instead of normal tuples, or vice versa? 
 Are there ""named lists"" too? (i.e. mutable named tuples) 
 
 
 For the last question specifically, see also  Existence of mutable named tuple in Python? . 
","['python', 'types', 'tuples', 'terminology', 'namedtuple']",1207
&quot;Large data&quot; workflows using pandas,"I have tried to puzzle out an answer to this question for many months while learning pandas.  I use SAS for my day-to-day work and it is great for it's out-of-core support.  However, SAS is horrible as a piece of software for numerous other reasons. 
 One day I hope to replace my use of SAS with python and pandas, but I currently lack an out-of-core workflow for large datasets.  I'm not talking about ""big data"" that requires a distributed network, but rather files too large to fit in memory but small enough to fit on a hard-drive. 
 My first thought is to use  HDFStore  to hold large datasets on disk and pull only the pieces I need into dataframes for analysis.  Others have mentioned MongoDB as an easier to use alternative.  My question is this: 
 What are some best-practice workflows for accomplishing the following: 
 
 Loading flat files into a permanent, on-disk database structure 
 Querying that database to retrieve data to feed into a pandas data structure 
 Updating the database after manipulating pieces in pandas 
 
 Real-world examples would be much appreciated, especially from anyone who uses pandas on ""large data"". 
 Edit -- an example of how I would like this to work: 
 
 Iteratively import a large flat-file and store it in a permanent, on-disk database structure.  These files are typically too large to fit in memory. 
 In order to use Pandas, I would like to read subsets of this data (usually just a few columns at a time) that can fit in memory. 
 I would create new columns by performing various operations on the selected columns. 
 I would then have to append these new columns into the database structure. 
 
 I am trying to find a best-practice way of performing these steps. Reading links about pandas and pytables it seems that appending a new column could be a problem. 
 Edit -- Responding to Jeff's questions specifically: 
 
 I am building consumer credit risk models. The kinds of data include phone, SSN and address characteristics; property values; derogatory information like criminal records, bankruptcies, etc... The datasets I use every day have nearly 1,000 to 2,000 fields on average of mixed data types: continuous, nominal and ordinal variables of both numeric and character data.  I rarely append rows, but I do perform many operations that create new columns. 
 Typical operations involve combining several columns using conditional logic into a new, compound column. For example,  if var1 > 2 then newvar = 'A' elif var2 = 4 then newvar = 'B' .  The result of these operations is a new column for every record in my dataset. 
 Finally, I would like to append these new columns into the on-disk data structure.  I would repeat step 2, exploring the data with crosstabs and descriptive statistics trying to find interesting, intuitive relationships to model. 
 A typical project file is usually about 1GB.  Files are organized into such a manner where a row consists of a record of consumer data.  Each row has the same number of columns for every record.  This will always be the case. 
 It's pretty rare that I would subset by rows when creating a new column.  However, it's pretty common for me to subset on rows when creating reports or generating descriptive statistics.  For example, I might want to create a simple frequency for a specific line of business, say Retail credit cards.  To do this, I would select only those records where the line of business = retail in addition to whichever columns I want to report on.  When creating new columns, however, I would pull all rows of data and only the columns I need for the operations. 
 The modeling process requires that I analyze every column, look for interesting relationships with some outcome variable, and create new compound columns that describe those relationships.  The columns that I explore are usually done in small sets.  For example, I will focus on a set of say 20 columns just dealing with property values and observe how they relate to defaulting on a loan.  Once those are explored and new columns are created, I then move on to another group of columns, say college education, and repeat the process.  What I'm doing is creating candidate variables that explain the relationship between my data and some outcome.  At the very end of this process, I apply some learning techniques that create an equation out of those compound columns. 
 
 It is rare that I would ever add rows to the dataset.  I will nearly always be creating new columns (variables or features in statistics/machine learning parlance). 
","['python', 'mongodb', 'pandas', 'hdf5', 'large-data']",1182
What is the difference between old style and new style classes in Python?,"What is the difference between old style and new style classes in Python?  When should I use one or the other? 
","['python', 'class', 'oop', 'types', 'new-style-class']",1126
List comprehension vs. lambda + filter,"I have a list that I want to filter by an attribute of the items. 
 Which of the following is preferred (readability, performance, other reasons)? 
 xs = [x for x in xs if x.attribute == value]
 
 xs = filter(lambda x: x.attribute == value, xs)
 
","['python', 'list', 'functional-programming', 'filter', 'lambda']",1104
What is the difference between pip and conda?,"I know  pip  is a package manager for python packages. However, I saw the installation on IPython's website use  conda  to install IPython. 
 Can I use  pip  to install IPython? Why should I use  conda  as another python package manager when I already have  pip ? 
 What is the difference between  pip  and  conda ? 
","['python', 'pip', 'ipython', 'package-managers', 'conda']",1095
Importing modules from parent folder,"I am running Python 2.5. 
 This is my folder tree: 
 ptdraft/
  nib.py
  simulations/
    life/
      life.py
 
 (I also have  __init__.py  in each folder, omitted here for readability) 
 How do I import the  nib  module from inside the  life  module? I am hoping it is possible to do without tinkering with sys.path. 
 Note: The main module being run is in the  ptdraft  folder. 
","['python', 'module', 'path', 'directory', 'python-import']",1089
What is the naming convention in Python for variables and functions?,"Coming from a C# background the naming convention for variables and methods are usually either camelCase or PascalCase: 
 // C# example
string thisIsMyVariable = ""a""
public void ThisIsMyMethod()
 
 In Python, I have seen the above but I have also seen snake_case being used: 
 # python example
this_is_my_variable = 'a'
def this_is_my_function():
 
 Is there a more preferable, definitive coding style for Python? 
","['python', 'naming-conventions', 'camelcasing', 'pascalcasing', 'snakecasing']",1068
How do I determine the size of an object in Python?,"How do I get the size occupied in memory by an object in Python? 
","['python', 'object', 'memory', 'memory-management', 'sizeof']",1038
UnicodeDecodeError: &#39;charmap&#39; codec can&#39;t decode byte X in position Y: character maps to &lt;undefined&gt;,"I'm trying to get a Python 3 program to do some manipulations with a text file filled with information. However, when trying to read the file I get the following error: 
 Traceback (most recent call last):  
  File ""SCRIPT LOCATION"", line NUMBER, in <module>  
    text = file.read()
  File ""C:\Python31\lib\encodings\cp1252.py"", line 23, in decode  
    return codecs.charmap_decode(input,self.errors,decoding_table)[0]
UnicodeDecodeError: 'charmap' codec can't decode byte 0x90 in position 2907500: character maps to `<undefined>`  
 
 
 After reading this Q&A, see  How to determine the encoding of text  if you need help figuring out the encoding of the file you are trying to open. 
","['python', 'python-3.x', 'unicode', 'file-io', 'decode']",1033
"How do I remove duplicates from a list, while preserving order?","How do I remove duplicates from a list, while preserving order? Using a set to remove duplicates destroys the original order.
Is there a built-in or a Pythonic idiom? 
","['python', 'list', 'duplicates', 'list-comprehension', 'unique']",1033
"What are the differences between the urllib, urllib2, urllib3 and requests module?","In Python, what are the differences between the  urllib ,  urllib2 ,  urllib3  and  requests  modules? Why are there three? They seem to do the same thing... 
","['python', 'python-requests', 'urllib', 'urllib2', 'urllib3']",1030
How to use to find files recursively?,"I would like to list all files recursively in a directory. I currently have a directory structure like this: 
 
 src/main.c 
 src/dir/file1.c 
 src/another-dir/file2.c 
 src/another-dir/nested/files/file3.c 
 
 I've tried to do the following: 
 from glob import glob

glob(os.path.join('src','*.c'))
 
 But this will only get be files directly in the  src  subfolder, e.g. I get  main.c  but I will not get  file1.c ,  file2.c  etc. 
 from glob import glob

glob(os.path.join('src','*.c'))
glob(os.path.join('src','*','*.c'))
glob(os.path.join('src','*','*','*.c'))
glob(os.path.join('src','*','*','*','*.c'))
 
 But this is obviously limited and clunky, how can I do this properly? 
","['python', 'path', 'filesystems', 'glob', 'fnmatch']",1010
Deleting DataFrame row in Pandas based on column value,"I have the following DataFrame: 
              daysago  line_race rating        rw    wrating
 line_date                                                 
2007-03-31       62         11     56  1.000000  56.000000
2007-03-10       83         11     67  1.000000  67.000000
2007-02-10      111          9     66  1.000000  66.000000
2007-01-13      139         10     83  0.880678  73.096278
2006-12-23      160         10     88  0.793033  69.786942
2006-11-09      204          9     52  0.636655  33.106077
2006-10-22      222          8     66  0.581946  38.408408
2006-09-29      245          9     70  0.518825  36.317752
2006-09-16      258         11     68  0.486226  33.063381
2006-08-30      275          8     72  0.446667  32.160051
2006-02-11      475          5     65  0.164591  10.698423
2006-01-13      504          0     70  0.142409   9.968634
2006-01-02      515          0     64  0.134800   8.627219
2005-12-06      542          0     70  0.117803   8.246238
2005-11-29      549          0     70  0.113758   7.963072
2005-11-22      556          0     -1  0.109852  -0.109852
2005-11-01      577          0     -1  0.098919  -0.098919
2005-10-20      589          0     -1  0.093168  -0.093168
2005-09-27      612          0     -1  0.083063  -0.083063
2005-09-07      632          0     -1  0.075171  -0.075171
2005-06-12      719          0     69  0.048690   3.359623
2005-05-29      733          0     -1  0.045404  -0.045404
2005-05-02      760          0     -1  0.039679  -0.039679
2005-04-02      790          0     -1  0.034160  -0.034160
2005-03-13      810          0     -1  0.030915  -0.030915
2004-11-09      934          0     -1  0.016647  -0.016647
 
 I need to remove the rows where  line_race  is equal to  0 . What's the most efficient way to do this? 
","['python', 'pandas', 'dataframe', 'performance', 'delete-row']",1002
Is there any way to kill a Thread?,"Is it possible to terminate a running thread without setting/checking any flags/semaphores/etc.? 
","['python', 'multithreading', 'python-multithreading', 'kill', 'terminate']",988
Is there a list of Pytz Timezones?,"I would like to know what are all the possible values for the timezone argument in the Python library pytz. How to do it? 
","['python', 'django', 'datetime', 'timezone', 'pytz']",979
Why use pip over easy_install?,"A  tweet  reads:  
 
 Don't use easy_install, unless you
  like stabbing yourself in the face.
  Use pip. 
 
 Why use pip over easy_install? Doesn't the  fault lie with PyPI and package authors mostly ? If an author uploads crap source tarball (eg: missing files, no setup.py) to PyPI, then both pip and easy_install will fail. Other than cosmetic differences, why do Python people (like in the above tweet) seem to  strongly  favor pip over easy_install? 
 (Let's assume that we're talking about easy_install from the Distribute package, that is maintained by the community) 
","['python', 'pip', 'setuptools', 'easy-install', 'pypi']",975
"Writing a list to a file with Python, with newlines","How do I write a list to a file?  writelines()  doesn't insert newline characters, so I need to do: 
 f.writelines([f""{line}\n"" for line in lines])
 
","['python', 'file', 'list', 'file-io', 'newline']",961
Combine two columns of text in pandas dataframe,"I have a dataframe that looks like 
 Year  quarter
2000       q2
2001       q3
 
 How do I add a new column by combining these columns to get the following dataframe? 
 Year  quarter  period
2000       q2  2000q2
2001       q3  2001q3
 
","['python', 'pandas', 'string', 'dataframe', 'string-concatenation']",951
How to make IPython notebook matplotlib plot inline,"I am trying to use IPython notebook on MacOS X with Python 2.7.2 and IPython 1.1.0. 
 I cannot get matplotlib graphics to show up inline. 
 import matplotlib
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline  
 
 I have also tried  %pylab inline  and the ipython command line arguments  --pylab=inline  but this makes no difference. 
 x = np.linspace(0, 3*np.pi, 500)
plt.plot(x, np.sin(x**2))
plt.title('A simple chirp')
plt.show()
 
 Instead of inline graphics, I get this: 
 <matplotlib.figure.Figure at 0x110b9c450>
 
 And  matplotlib.get_backend()  shows that I have the  'module://IPython.kernel.zmq.pylab.backend_inline'  backend. 
","['python', 'matplotlib', 'jupyter-notebook', 'ipython', 'data-visualization']",946
How are iloc and loc different?,"Can someone explain how these two methods of slicing are different? I've seen  the docs 
and I've seen previous similar questions ( 1 ,  2 ), but I still find myself unable to understand how they are different. To me, they seem interchangeable in large part, because they are at the lower levels of slicing. 
 For example, say we want to get the first five rows of a  DataFrame .  How is it that these two work? 
 df.loc[:5]
df.iloc[:5]
 
 Can someone present cases where the distinction in uses are clearer? 
 
 Once upon a time, I also wanted to know how these two functions differed from  df.ix[:5]  but  ix  has been removed from pandas 1.0, so I don't care anymore. 
","['python', 'pandas', 'dataframe', 'indexing', 'pandas-loc']",939
Why does Python code run faster in a function?,"def main():
    for i in xrange(10**8):
        pass
main()
 
 This piece of code in Python runs in  (Note: The timing is done with the time function in BASH in Linux.) 
 real    0m1.841s
user    0m1.828s
sys     0m0.012s
 
 However, if the for loop isn't placed within a function,  
 for i in xrange(10**8):
    pass
 
 then it runs for a much longer time: 
 real    0m4.543s
user    0m4.524s
sys     0m0.012s
 
 Why is this? 
","['python', 'performance', 'profiling', 'benchmarking', 'cpython']",930
How do I parse an ISO 8601-formatted date?,"I need to parse  RFC 3339  strings like  ""2008-09-03T20:56:35.450686Z""  into Python's  datetime  type. 
 I have found  strptime  in the Python standard library, but it is not very convenient. 
 What is the best way to do this? 
","['python', 'datetime', 'iso8601', 'datetime-parsing', 'rfc3339']",917
Pandas Merging 101,"
 How can I perform a ( INNER | ( LEFT | RIGHT | FULL )  OUTER )  JOIN  with pandas? 
 How do I add NaNs for missing rows after a merge? 
 How do I get rid of NaNs after merging? 
 Can I merge on the index? 
 How do I merge multiple DataFrames? 
 Cross join with pandas 
 merge ?  join ?  concat ?  update ? Who? What? Why?! 
 
 ... and more. I've seen these recurring questions asking about various facets of the pandas merge functionality. Most of the information regarding merge and its various use cases today is fragmented across dozens of badly worded, unsearchable posts. The aim here is to collate some of the more important points for posterity. 
 This Q&A is meant to be the next installment in a series of helpful user guides on common pandas idioms (see  this post on pivoting , and  this post on concatenation , which I will be touching on, later). 
 Please note that this post is  not  meant to be a replacement for  the documentation , so please read that as well! Some of the examples are taken from there. 
 
 Table of Contents 
 For ease of access. 
 
 Merging basics - basic types of joins  (read this first) 
 
 Index-based joins 
 
 Generalizing to multiple DataFrames 
 
 Cross join 
 
 
","['python', 'pandas', 'join', 'merge', 'concatenation']",914
python exception message capturing,"import ftplib
import urllib2
import os
import logging
logger = logging.getLogger('ftpuploader')
hdlr = logging.FileHandler('ftplog.log')
formatter = logging.Formatter('%(asctime)s %(levelname)s %(message)s')
hdlr.setFormatter(formatter)
logger.addHandler(hdlr)
logger.setLevel(logging.INFO)
FTPADDR = ""some ftp address""

def upload_to_ftp(con, filepath):
    try:
        f = open(filepath,'rb')                # file to send
        con.storbinary('STOR '+ filepath, f)         # Send the file
        f.close()                                # Close file and FTP
        logger.info('File successfully uploaded to '+ FTPADDR)
    except, e:
        logger.error('Failed to upload to ftp: '+ str(e))
 
 This doesn't seem to work, I get syntax error, what is the proper way of doing this for logging all kind of exceptions to a file 
","['python', 'exception', 'logging', 'except', 'python-logging']",911
How do I update/upgrade pip itself from inside my virtual environment?,"I'm able to update pip-managed packages, but how do I update pip itself? According to  pip --version , I currently have pip 1.1 installed in my virtualenv and I want to update to the latest version.  
 What's the command for that? Do I need to use distribute or is there a native pip or virtualenv command? I've already tried  pip update  and  pip update pip  with no success. 
","['python', 'upgrade', 'virtualenv', 'pip', 'package-managers']",910
How do I get the day of week given a date?,"I want to find out the following:
given a date ( datetime  object), what is the corresponding day of the week? 
 For instance, Sunday is the first day, Monday: second day.. and so on 
 And then if the input is something like today's date. 
 Example 
 >>> today = datetime.datetime(2017, 10, 20)
>>> today.get_weekday()  # what I look for
 
 The output is maybe  6  (since it's Friday) 
","['python', 'date', 'datetime', 'time', 'weekday']",900
"&quot;TypeError: a bytes-like object is required, not &#39;str&#39;&quot; when handling file content in Python 3","I've very recently migrated to Python 3.5.
This code was working properly in Python 2.7: 
 with open(fname, 'rb') as f:
    lines = [x.strip() for x in f.readlines()]

for line in lines:
    tmp = line.strip().lower()
    if 'some-pattern' in tmp: continue
    # ... code
 
 But in 3.5, on the  if 'some-pattern' in tmp: continue  line, I get an error which says: 
 TypeError: a bytes-like object is required, not 'str'
 
 I was unable to fix the problem using  .decode()  on either side of the  in , nor could I fix it using 
     if tmp.find('some-pattern') != -1: continue
 
 What is wrong, and how do I fix it? 
","['python', 'python-3.x', 'string', 'file', 'byte']",891
How do I set the figure title and axes labels font size?,"I am creating a figure in Matplotlib like this: 
 from matplotlib import pyplot as plt

fig = plt.figure()
plt.plot(data)
fig.suptitle('test title')
plt.xlabel('xlabel')
plt.ylabel('ylabel')
fig.savefig('test.jpg')
 
 I want to specify font sizes for the figure title and the axis labels. I need all three to be different font sizes, so setting a global font size ( mpl.rcParams['font.size']=x ) is not what I want. How do I set font sizes for the figure title and the axis labels individually? 
","['python', 'matplotlib', 'axis', 'yaxis', 'x-axis']",889
error: Unable to find vcvarsall.bat,"I tried to install the Python package  dulwich : 
 pip install dulwich
 
 But I get a cryptic error message: 
 error: Unable to find vcvarsall.bat
 
 The same happens if I try installing the package manually: 
 > python setup.py install
running build_ext
building 'dulwich._objects' extension
error: Unable to find vcvarsall.bat
 
","['python', 'windows', 'pip', 'setup.py', 'failed-installation']",878
"Saving UTF-8 texts with json.dumps as UTF-8, not as a \u escape sequence","Sample code (in a  REPL ): 
 import json
json_string = json.dumps(""ברי צקלה"")
print(json_string)
 
 Output: 
 ""\u05d1\u05e8\u05d9 \u05e6\u05e7\u05dc\u05d4""
 
 The problem: it's not human readable. My (smart) users want to verify or even edit text files with JSON dumps (and I’d rather not use XML). 
 Is there a way to serialize objects into UTF-8 JSON strings (instead of  \uXXXX )? 
","['python', 'json', 'unicode', 'utf-8', 'escaping']",878
Filter pandas DataFrame by substring criteria,"I have a pandas DataFrame with a column of string values. I need to select rows based on partial string matches. 
 Something like this idiom: 
 re.search(pattern, cell_in_question) 
 
 returning a boolean. I am familiar with the syntax of  df[df['A'] == ""hello world""]  but can't seem to find a way to do the same with a partial string match, say  'hello' . 
","['python', 'pandas', 'regex', 'string', 'dataframe']",873
How to see normal print output created during pytest run?,"Sometimes I want to just insert some print statements in my code, and see what gets printed out when I exercise it. My usual way to ""exercise"" it is with existing pytest tests. But when I run these, I don't seem able to see any standard output (at least from within PyCharm, my IDE). 
 Is there a simple way to see standard output during a pytest run? 
","['python', 'logging', 'printing', 'pytest', 'flags']",854
"Truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()","I want to filter my dataframe with an  or  condition to keep rows with a particular column's values that are outside the range  [-0.25, 0.25] . I tried: 
 df = df[(df['col'] < -0.25) or (df['col'] > 0.25)]
 
 But I get the error: 
 
 ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all(). 
 
","['python', 'pandas', 'dataframe', 'boolean', 'filtering']",847
How to filter Pandas dataframe using &#39;in&#39; and &#39;not in&#39; like in SQL,"How can I achieve the equivalents of SQL's  IN  and  NOT IN ? 
 I have a list with the required values. Here's the scenario: 
 df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})
countries_to_keep = ['UK', 'China']

# pseudo-code:
df[df['country'] not in countries_to_keep]
 
 My current way of doing this is as follows: 
 df = pd.DataFrame({'country': ['US', 'UK', 'Germany', 'China']})
df2 = pd.DataFrame({'country': ['UK', 'China'], 'matched': True})

# IN
df.merge(df2, how='inner', on='country')

# NOT IN
not_in = df.merge(df2, how='left', on='country')
not_in = not_in[pd.isnull(not_in['matched'])]
 
 But this seems like a horrible kludge. Can anyone improve on it? 
","['python', 'pandas', 'dataframe', 'filtering', 'sql-function']",845
What is the difference between range and xrange functions in Python 2.X?,"Apparently xrange is faster but I have no idea why it's faster (and no proof besides the anecdotal so far that it is faster) or what besides that is different about 
 for i in range(0, 20):
for i in xrange(0, 20):
 
","['python', 'loops', 'range', 'python-2.x', 'xrange']",845
How to test multiple variables for equality against a single value?,"I'm trying to make a function that will compare multiple variables to an integer and output a string of three letters. I was wondering if there was a way to translate this into Python. So say: 
 x = 0
y = 1
z = 3
mylist = []

if x or y or z == 0:
    mylist.append(""c"")
if x or y or z == 1:
    mylist.append(""d"")
if x or y or z == 2:
    mylist.append(""e"")
if x or y or z == 3: 
    mylist.append(""f"")
 
 which would return a list of: 
 [""c"", ""d"", ""f""]
 
","['python', 'if-statement', 'comparison', 'match', 'boolean-logic']",842
What&#39;s the difference between a module and package in Python?,"What's the difference between a module and package in Python? 
 See also:  What's the difference between ""package"" and ""module""?  (for other languages) 
","['python', 'module', 'package', 'terminology', 'difference']",837
Shuffle DataFrame rows,"I have the following DataFrame: 
     Col1  Col2  Col3  Type
0      1     2     3     1
1      4     5     6     1
...
20     7     8     9     2
21    10    11    12     2
...
45    13    14    15     3
46    16    17    18     3
...
 
 The DataFrame is read from a CSV file. All rows which have  Type  1 are on top, followed by the rows with  Type  2, followed by the rows with  Type  3, etc. 
 I would like to shuffle the order of the DataFrame's rows so that all  Type 's are mixed. A possible result could be: 
     Col1  Col2  Col3  Type
0      7     8     9     2
1     13    14    15     3
...
20     1     2     3     1
21    10    11    12     2
...
45     4     5     6     1
46    16    17    18     3
...
 
 How can I achieve this? 
","['python', 'pandas', 'dataframe', 'permutation', 'shuffle']",835
How to fix &quot;Attempted relative import in non-package&quot; even with __init__.py,"I'm trying to follow  PEP 328 , with the following directory structure: 
 pkg/
  __init__.py
  components/
    core.py
    __init__.py
  tests/
    core_test.py
    __init__.py
 
 In  core_test.py  I have the following import statement 
 from ..components.core import GameLoopEvents
 
 However, when I run, I get the following error: 
 tests$ python core_test.py 
Traceback (most recent call last):
  File ""core_test.py"", line 3, in <module>
    from ..components.core import GameLoopEvents
ValueError: Attempted relative import in non-package
 
 Searching around I found "" relative path not working even with __init__.py "" and "" Import a module from a relative path "" but they didn't help. 
 Is there anything I'm missing here? 
","['python', 'package', 'python-import', 'importerror', 'init']",835
How to combine multiple QuerySets in Django?,"I'm trying to build the search for a Django site I am building, and in that search, I am searching across three different models. And to get pagination on the search result list, I would like to use a generic object_list view to display the results. But to do that, I have to merge three QuerySets into one. 
 How can I do that? I've tried this: 
 result_list = []
page_list = Page.objects.filter(
    Q(title__icontains=cleaned_search_term) |
    Q(body__icontains=cleaned_search_term))
article_list = Article.objects.filter(
    Q(title__icontains=cleaned_search_term) |
    Q(body__icontains=cleaned_search_term) |
    Q(tags__icontains=cleaned_search_term))
post_list = Post.objects.filter(
    Q(title__icontains=cleaned_search_term) |
    Q(body__icontains=cleaned_search_term) |
    Q(tags__icontains=cleaned_search_term))

for x in page_list:
    result_list.append(x)
for x in article_list:
    result_list.append(x)
for x in post_list:
    result_list.append(x)

return object_list(
    request,
    queryset=result_list,
    template_object_name='result',
    paginate_by=10,
    extra_context={
        'search_term': search_term},
    template_name=""search/result_list.html"")
 
 But this doesn't work. I get an error when I try to use that list in the generic view. The list is missing the clone attribute. 
 How can I merge the three lists,  page_list ,  article_list  and  post_list ? 
","['python', 'django', 'search', 'django-queryset', 'django-q']",829
How to convert index of a pandas dataframe into a column,"How to convert an index of a dataframe into a column? 
 For example: 
         gi       ptt_loc
 0  384444683      593  
 1  384444684      594 
 2  384444686      596  
 
 to 
     index1    gi       ptt_loc
 0  0     384444683      593  
 1  1     384444684      594 
 2  2     384444686      596  
 
","['python', 'pandas', 'dataframe', 'indexing', 'series']",816
How to change a string into uppercase?,"How can I convert a string into uppercase in Python? 
 When I tried to research the problem, I found something about  string.ascii_uppercase , but it couldn't solve the problem: 
 >>> s = 'sdsd'
>>> s.ascii_uppercase
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
AttributeError: 'str' object has no attribute 'ascii_uppercase'
 
 
 See  How do I lowercase a string in Python?  for the opposite. 
","['python', 'string', 'function', 'uppercase', 'string-conversion']",808
Why shouldn&#39;t I use PyPy over CPython if PyPy is 6.3 times faster?,"I've been hearing a lot about the  PyPy  project. They claim it is 6.3 times faster than the  CPython  interpreter on  their site . 
 Whenever we talk about dynamic languages like Python, speed is one of the top issues. To solve this, they say PyPy is 6.3 times faster. 
 The second issue is parallelism, the infamous  Global Interpreter Lock  (GIL). For this, PyPy says it  can give GIL-less Python . 
 If PyPy can solve these great challenges, what are its weaknesses that are preventing wider adoption? That is to say, what's preventing someone like me, a typical Python developer, from switching to PyPy  right now ?  
","['python', 'performance', 'jit', 'pypy', 'cpython']",801
TypeError: &#39;module&#39; object is not callable,"File ""C:\Users\Administrator\Documents\Mibot\oops\blinkserv.py"", line 82, in __init__
    self.serv = socket(AF_INET,SOCK_STREAM)
TypeError: 'module' object is not callable
 
 Why am I getting this error?
I'm confused. 
 How can I solve this error? 
","['python', 'sockets', 'typeerror', 'python-module', 'callable']",798
Why is [] faster than list()?,"I compared the processing speeds of  []  and  list()  on Python 3.11 
 $ python -m timeit '[]'
20000000 loops, best of 5: 11.3 nsec per loop
$ python -m timeit 'list()'
10000000 loops, best of 5: 26.1 nsec per loop
 
 and was surprised to discover that  []  runs about two times faster than  list() . I got very similar results for  {}  and  dict() 
 $ python -m timeit '{}'
20000000 loops, best of 5: 11.6 nsec per loop
$ python -m timeit 'dict()'
10000000 loops, best of 5: 27.1 nsec per loop
 
 Why is this? Do  []  and  {}  (and probably  ()  and  '' , too) immediately pass back a copies of some empty stock literal while their explicitly-named counterparts ( list() ,  dict() ,  tuple() ,  str() ) fully go about creating an object, whether or not they actually have elements? 
","['python', 'performance', 'list', 'instantiation', 'literals']",796
How do I call a parent class&#39;s method from a child class in Python?,"When creating a simple object hierarchy in Python, I'd like to be able to invoke methods of the parent class from a derived class.  In Perl and Java, there is a keyword for this ( super ).  In Perl, I might do this: 
 package Foo;

sub frotz {
    return ""Bamf"";
}

package Bar;
@ISA = qw(Foo);

sub frotz {
   my $str = SUPER::frotz();
   return uc($str);
}
 
 In Python, it appears that I have to name the parent class explicitly from the child.
In the example above, I'd have to do something like  Foo::frotz() .   
 This doesn't seem right since this behavior makes it hard to make deep hierarchies.  If children need to know what class defined an inherited method, then all sorts of information pain is created.   
 Is this an actual limitation in python, a gap in my understanding or both? 
","['python', 'class', 'oop', 'object', 'inheritance']",795
"Constructing pandas DataFrame from values in variables gives &quot;ValueError: If using all scalar values, you must pass an index&quot;","I have two variables as follows. 
 a = 2
b = 3
 
 I want to construct a DataFrame from this: 
 df2 = pd.DataFrame({'A':a, 'B':b})
 
 This generates an error: 
 ValueError: If using all scalar values, you must pass an index
 
 I tried this also: 
 df2 = (pd.DataFrame({'a':a, 'b':b})).reset_index()
 
 This gives the same error message. How do I do what I want? 
","['python', 'pandas', 'dataframe', 'valueerror', 'scalar']",790
What is the best way to remove accents (normalize) in a Python unicode string?,"I have a Unicode string in Python, and I would like to remove all the accents (diacritics). 
 I found on the web an elegant way to do this (in Java): 
 
 convert the Unicode string to its  long normalized form  (with a separate character for letters and diacritics) 
 remove all the characters whose Unicode type is ""diacritic"". 
 
 Do I need to install a library such as pyICU or is this possible with just the Python standard library?  And what about python 3? 
 Important note: I would like to avoid code with an explicit mapping from accented characters to their non-accented counterpart. 
","['python', 'python-3.x', 'unicode', 'python-2.x', 'diacritics']",790
What do ** (double star/asterisk) and * (star/asterisk) mean in a function call?,"In code like  zip(*x)  or  f(**k) , what do the  *  and  **  respectively mean? How does Python implement that behaviour, and what are the performance implications? 
 
 See also:  Expanding tuples into arguments . Please use that one to close questions where OP needs to use  *  on an argument and doesn't know it exists. Similarly, use  Converting Python dict to kwargs?  for the case of using  ** . 
 See  What does ** (double star/asterisk) and * (star/asterisk) do for parameters?  for the complementary question about parameters. 
","['python', 'syntax', 'parameter-passing', 'iterable-unpacking', 'argument-unpacking']",790
"Get statistics for each group (such as count, mean, etc) using pandas GroupBy?","I have a dataframe  df  and I use several columns from it to  groupby : 
 df['col1','col2','col3','col4'].groupby(['col1','col2']).mean()
 
 In the above way, I almost get the table (dataframe) that I need. What is missing is an additional column that contains number of rows in each group. In other words, I have mean but I also would like to know how many were used to get these means. For example in the first group there are 8 values and in the second one 10 and so on. 
 In short: How do I get  group-wise  statistics for a dataframe? 
","['python', 'pandas', 'dataframe', 'group-by', 'statistics']",788
How can I force division to be floating point? Division keeps rounding down to 0?,"I have two integer values  a  and  b , but I need their ratio in floating point.  I know that  a < b  and I want to calculate  a / b , so if I use integer division I'll always get 0 with a remainder of  a . 
 How can I force  c  to be a floating point number in Python 2 in the following? 
 c = a / b
 
 
 In 3.x, the behaviour is reversed; see  Why does integer division yield a float instead of another integer?  for the opposite, 3.x-specific problem. 
","['python', 'floating-point', 'integer', 'division', 'python-2.x']",784
Set value for particular cell in pandas DataFrame using index,"I have created a Pandas DataFrame 
 df = DataFrame(index=['A','B','C'], columns=['x','y'])
 
 Now, I would like to assign a value to particular cell, for example to row  C  and column  x . In other words, I would like to perform the following transformation: 
      x    y             x    y
A  NaN  NaN        A  NaN  NaN
B  NaN  NaN   ⟶   B  NaN  NaN
C  NaN  NaN        C   10  NaN
 
 with this code: 
 df.xs('C')['x'] = 10
 
 However, the contents of  df  has not changed. The dataframe contains yet again only  NaN s. How do I what I want? 
","['python', 'pandas', 'dataframe', 'cell', 'nan']",780
How do I properly assert that an exception gets raised in pytest?,"Code: 
 # coding=utf-8
import pytest


def whatever():
    return 9/0

def test_whatever():
    try:
        whatever()
    except ZeroDivisionError as exc:
        pytest.fail(exc, pytrace=True)
 
 Output: 
 ================================ test session starts =================================
platform linux2 -- Python 2.7.3 -- py-1.4.20 -- pytest-2.5.2
plugins: django, cov
collected 1 items 

pytest_test.py F

====================================== FAILURES ======================================
___________________________________ test_whatever ____________________________________

    def test_whatever():
        try:
            whatever()
        except ZeroDivisionError as exc:
>           pytest.fail(exc, pytrace=True)
E           Failed: integer division or modulo by zero

pytest_test.py:12: Failed
============================== 1 failed in 1.16 seconds ==============================
 
 How do I make pytest print traceback, so that I would see where in the  whatever  function that an exception was raised? 
","['python', 'unit-testing', 'exception', 'testing', 'pytest']",777
What is the difference between __init__ and __call__?,"I want to know the difference between  __init__  and  __call__  methods.   
 For example: 
 class test:

  def __init__(self):
    self.a = 10

  def __call__(self): 
    b = 20
 
","['python', 'class', 'oop', 'object', 'callable-object']",775
What is a &quot;slug&quot; in Django?,"When I read Django code I often see in models what is called a ""slug"". I am not quite sure what this is, but I do know it has something to do with URLs. How and when is this slug-thing supposed to be used? 
 I have read its definition below in  this glossary : 
 
 Slug 
A short label for something, containing only letters, numbers,
underscores or hyphens. They’re generally used in URLs. For example,
in a typical blog entry URL: 
 https://www.djangoproject.com/weblog/2008/apr/12/spring/  the last bit
(spring) is the slug. 
 
","['python', 'django', 'url', 'django-models', 'slug']",765
Changing the tick frequency on the x or y axis,"I am trying to fix how python plots my data. Say: 
 x = [0, 5, 9, 10, 15]
y = [0, 1, 2, 3, 4]

matplotlib.pyplot.plot(x, y)
matplotlib.pyplot.show()
 
 The x axis' ticks are plotted in intervals of 5. Is there a way to make it show intervals of 1? 
","['python', 'matplotlib', 'axis', 'xticks', 'yticks']",763
Import multiple CSV files into pandas and concatenate into one DataFrame,"I would like to read several CSV files from a directory into pandas and concatenate them into one big DataFrame. I have not been able to figure it out though. Here is what I have so far: 
 import glob
import pandas as pd

# Get data file names
path = r'C:\DRO\DCL_rawdata_files'
filenames = glob.glob(path + ""/*.csv"")

dfs = []
for filename in filenames:
    dfs.append(pd.read_csv(filename))

# Concatenate all data into one DataFrame
big_frame = pd.concat(dfs, ignore_index=True)
 
 I guess I need some help within the  for  loop? 
","['python', 'pandas', 'csv', 'dataframe', 'concatenation']",757
What does &#39;super&#39; do in Python? - difference between super().__init__() and explicit superclass __init__(),"What's the difference between: 
 class Child(SomeBaseClass):
    def __init__(self):
        super(Child, self).__init__()
        
 
 and: 
 class Child(SomeBaseClass):
    def __init__(self):
        SomeBaseClass.__init__(self)
        
 
 I've seen  super  being used quite a lot in classes with only single inheritance. I can see why you'd use it in multiple inheritance but am unclear as to what the advantages are of using it in this kind of situation. 
 
 This question is about technical implementation details and the distinction between different ways of accessing the base class  __init__  method. To close duplicate questions where OP is simply missing a  super  call and is asking why base class attributes aren't available, please use  Python class inheritance: AttributeError: '[SubClass]' object has no attribute 'xxx'  instead. 
","['python', 'oop', 'inheritance', 'multiple-inheritance', 'super']",744
Speed comparison with Project Euler: C vs Python vs Erlang vs Haskell,"I have taken  Problem #12  from  Project Euler  as a programming exercise and to compare my (surely not optimal) implementations in C, Python, Erlang and Haskell. In order to get some higher execution times, I search for the first triangle number with more than 1000 divisors instead of 500 as stated in the original problem. 
 The result is the following: 
 C: 
 lorenzo@enzo:~/erlang$ gcc -lm -o euler12.bin euler12.c
lorenzo@enzo:~/erlang$ time ./euler12.bin
842161320

real    0m11.074s
user    0m11.070s
sys 0m0.000s
 
 Python: 
 lorenzo@enzo:~/erlang$ time ./euler12.py 
842161320

real    1m16.632s
user    1m16.370s
sys 0m0.250s
 
 Python with PyPy: 
 lorenzo@enzo:~/Downloads/pypy-c-jit-43780-b590cf6de419-linux64/bin$ time ./pypy /home/lorenzo/erlang/euler12.py 
842161320

real    0m13.082s
user    0m13.050s
sys 0m0.020s
 
 Erlang: 
 lorenzo@enzo:~/erlang$ erlc euler12.erl 
lorenzo@enzo:~/erlang$ time erl -s euler12 solve
Erlang R13B03 (erts-5.7.4) [source] [64-bit] [smp:4:4] [rq:4] [async-threads:0] [hipe] [kernel-poll:false]

Eshell V5.7.4  (abort with ^G)
1> 842161320

real    0m48.259s
user    0m48.070s
sys 0m0.020s
 
 Haskell: 
 lorenzo@enzo:~/erlang$ ghc euler12.hs -o euler12.hsx
[1 of 1] Compiling Main             ( euler12.hs, euler12.o )
Linking euler12.hsx ...
lorenzo@enzo:~/erlang$ time ./euler12.hsx 
842161320

real    2m37.326s
user    2m37.240s
sys 0m0.080s
 
 Summary: 
 
 C: 100% 
 Python: 692% (118% with PyPy) 
 Erlang: 436% (135% thanks to RichardC) 
 Haskell: 1421% 
 
 I suppose that C has a big advantage as it uses long for the calculations and not arbitrary length integers as the other three. Also it doesn't need to load a runtime first (Do the others?). 
 Question 1: 
Do Erlang, Python and Haskell lose speed due to using arbitrary length integers or don't they as long as the values are less than  MAXINT ? 
 Question 2: 
Why is Haskell so slow? Is there a compiler flag that turns off the brakes or is it my implementation? (The latter is quite probable as Haskell is a book with seven seals to me.) 
 Question 3: 
Can you offer me some hints how to optimize these implementations without changing the way I determine the factors? Optimization in any way: nicer, faster, more ""native"" to the language. 
 EDIT: 
 Question 4: 
Do my functional implementations permit LCO (last call optimization, a.k.a tail recursion elimination) and hence avoid adding unnecessary frames onto the call stack? 
 I really tried to implement the same algorithm as similar as possible in the four languages, although I have to admit that my Haskell and Erlang knowledge is very limited. 
 
 Source codes used: 
 #include <stdio.h>
#include <math.h>

int factorCount (long n)
{
    double square = sqrt (n);
    int isquare = (int) square;
    int count = isquare == square ? -1 : 0;
    long candidate;
    for (candidate = 1; candidate <= isquare; candidate ++)
        if (0 == n % candidate) count += 2;
    return count;
}

int main ()
{
    long triangle = 1;
    int index = 1;
    while (factorCount (triangle) < 1001)
    {
        index ++;
        triangle += index;
    }
    printf (""%ld\n"", triangle);
}
 
 
 #! /usr/bin/env python3.2

import math

def factorCount (n):
    square = math.sqrt (n)
    isquare = int (square)
    count = -1 if isquare == square else 0
    for candidate in range (1, isquare + 1):
        if not n % candidate: count += 2
    return count

triangle = 1
index = 1
while factorCount (triangle) < 1001:
    index += 1
    triangle += index

print (triangle)
 
 
 -module (euler12).
-compile (export_all).

factorCount (Number) -> factorCount (Number, math:sqrt (Number), 1, 0).

factorCount (_, Sqrt, Candidate, Count) when Candidate > Sqrt -> Count;

factorCount (_, Sqrt, Candidate, Count) when Candidate == Sqrt -> Count + 1;

factorCount (Number, Sqrt, Candidate, Count) ->
    case Number rem Candidate of
        0 -> factorCount (Number, Sqrt, Candidate + 1, Count + 2);
        _ -> factorCount (Number, Sqrt, Candidate + 1, Count)
    end.

nextTriangle (Index, Triangle) ->
    Count = factorCount (Triangle),
    if
        Count > 1000 -> Triangle;
        true -> nextTriangle (Index + 1, Triangle + Index + 1)  
    end.

solve () ->
    io:format (""~p~n"", [nextTriangle (1, 1) ] ),
    halt (0).
 
 
 factorCount number = factorCount' number isquare 1 0 - (fromEnum $ square == fromIntegral isquare)
    where square = sqrt $ fromIntegral number
          isquare = floor square

factorCount' number sqrt candidate count
    | fromIntegral candidate > sqrt = count
    | number `mod` candidate == 0 = factorCount' number sqrt (candidate + 1) (count + 2)
    | otherwise = factorCount' number sqrt (candidate + 1) count

nextTriangle index triangle
    | factorCount triangle > 1000 = triangle
    | otherwise = nextTriangle (index + 1) (triangle + index + 1)

main = print $ nextTriangle 1 1
 
","['python', 'c', 'performance', 'haskell', 'erlang']",740
Are dictionaries ordered in Python 3.6+?,"Dictionaries are insertion ordered as of Python 3.6. It is described as a CPython implementation detail rather than a language feature. The  documentation  states: 
 
 dict()  now uses a “compact” representation  pioneered by PyPy . The memory usage of the new dict() is between 20% and 25% smaller compared to Python 3.5.  PEP 468  (Preserving the order of **kwargs in a function.) is implemented by this. The order-preserving aspect of this new implementation is considered an implementation detail and should not be relied upon (this may change in the future, but it is desired to have this new dict implementation in the language for a few releases before changing the language spec to mandate order-preserving semantics for all current and future Python implementations; this also helps preserve backwards-compatibility with older versions of the language where random iteration order is still in effect, e.g. Python 3.5). (Contributed by INADA Naoki in  issue 27350 . Idea  originally suggested by Raymond Hettinger .) 
 
 How does the new dictionary implementation perform better than the older one while preserving element order? 
 
 Update December 2017:  dict s retaining insertion order is  guaranteed  for Python 3.7 
","['python', 'python-3.x', 'dictionary', 'python-internals', 'python-3.6']",740
How to apply a function to two columns of Pandas dataframe,"Suppose I have a function and a dataframe defined as below: 
 def get_sublist(sta, end):
    return mylist[sta:end+1]

df = pd.DataFrame({'ID':['1','2','3'], 'col_1': [0,2,3], 'col_2':[1,4,5]})
mylist = ['a','b','c','d','e','f']
 
 Now I want to apply  get_sublist  to  df 's two columns  'col_1', 'col_2'  to element-wise calculate a new column  'col_3'  to get an output that looks like: 
   ID  col_1  col_2            col_3
0  1      0      1       ['a', 'b']
1  2      2      4  ['c', 'd', 'e']
2  3      3      5  ['d', 'e', 'f']
 
 I tried 
 df['col_3'] = df[['col_1','col_2']].apply(get_sublist, axis=1)
 
 but this results in 
 TypeError: get_sublist() missing 1 required positional argument:
 
 How do I do it? 
","['python', 'pandas', 'dataframe', 'function', 'typeerror']",733
Decorators with parameters?,"I have a problem with the transfer of the variable  insurance_mode  by the decorator. I would do it by the following decorator statement: 
 @execute_complete_reservation(True)
def test_booking_gta_object(self):
    self.test_select_gta_object()
 
 but unfortunately, this statement does not work. Perhaps maybe there is better way to solve this problem. 
 def execute_complete_reservation(test_case,insurance_mode):
    def inner_function(self,*args,**kwargs):
        self.test_create_qsf_query()
        test_case(self,*args,**kwargs)
        self.test_select_room_option()
        if insurance_mode:
            self.test_accept_insurance_crosseling()
        else:
            self.test_decline_insurance_crosseling()
        self.test_configure_pax_details()
        self.test_configure_payer_details

    return inner_function
 
","['python', 'function', 'parameters', 'arguments', 'decorator']",705
How to check Django version,"I have to use  Python  and  Django  for our application. So, I have two versions of Python, 2.6 and 2.7. Now I have installed Django. I could run the sample application for testing Django successfully. But how do I check whether Django uses the 2.6 or 2.7 version and what version of modules Django uses? 
","['python', 'django', 'command-line', 'command', 'version']",705
Convert pandas dataframe to NumPy array,"How do I convert a pandas dataframe into a NumPy array? 
 DataFrame: 
 import numpy as np
import pandas as pd

index = [1, 2, 3, 4, 5, 6, 7]
a = [np.nan, np.nan, np.nan, 0.1, 0.1, 0.1, 0.1]
b = [0.2, np.nan, 0.2, 0.2, 0.2, np.nan, np.nan]
c = [np.nan, 0.5, 0.5, np.nan, 0.5, 0.5, np.nan]
df = pd.DataFrame({'A': a, 'B': b, 'C': c}, index=index)
df = df.rename_axis('ID')
 
 gives 
       A    B    C
ID                                 
1   NaN  0.2  NaN
2   NaN  NaN  0.5
3   NaN  0.2  0.5
4   0.1  0.2  NaN
5   0.1  0.2  0.5
6   0.1  NaN  0.5
7   0.1  NaN  NaN
 
 I would like to convert this to a NumPy array, like so: 
 array([[ nan,  0.2,  nan],
       [ nan,  nan,  0.5],
       [ nan,  0.2,  0.5],
       [ 0.1,  0.2,  nan],
       [ 0.1,  0.2,  0.5],
       [ 0.1,  nan,  0.5],
       [ 0.1,  nan,  nan]])
 
 
 Also, is it possible to preserve the dtypes, like this? 
 array([[ 1, nan,  0.2,  nan],
       [ 2, nan,  nan,  0.5],
       [ 3, nan,  0.2,  0.5],
       [ 4, 0.1,  0.2,  nan],
       [ 5, 0.1,  0.2,  0.5],
       [ 6, 0.1,  nan,  0.5],
       [ 7, 0.1,  nan,  nan]],
     dtype=[('ID', '<i4'), ('A', '<f8'), ('B', '<f8'), ('B', '<f8')])
 
","['python', 'arrays', 'pandas', 'numpy', 'dataframe']",698
UnicodeDecodeError when reading CSV file in Pandas,"I'm running a program which is processing 30,000 similar files. A random number of them are stopping and producing this error... 
   File ""C:\Importer\src\dfman\importer.py"", line 26, in import_chr
    data = pd.read_csv(filepath, names=fields)
  File ""C:\Python33\lib\site-packages\pandas\io\parsers.py"", line 400, in parser_f
    return _read(filepath_or_buffer, kwds)
  File ""C:\Python33\lib\site-packages\pandas\io\parsers.py"", line 205, in _read
    return parser.read()
  File ""C:\Python33\lib\site-packages\pandas\io\parsers.py"", line 608, in read
    ret = self._engine.read(nrows)
  File ""C:\Python33\lib\site-packages\pandas\io\parsers.py"", line 1028, in read
    data = self._reader.read(nrows)
  File ""parser.pyx"", line 706, in pandas.parser.TextReader.read (pandas\parser.c:6745)
  File ""parser.pyx"", line 728, in pandas.parser.TextReader._read_low_memory (pandas\parser.c:6964)
  File ""parser.pyx"", line 804, in pandas.parser.TextReader._read_rows (pandas\parser.c:7780)
  File ""parser.pyx"", line 890, in pandas.parser.TextReader._convert_column_data (pandas\parser.c:8793)
  File ""parser.pyx"", line 950, in pandas.parser.TextReader._convert_tokens (pandas\parser.c:9484)
  File ""parser.pyx"", line 1026, in pandas.parser.TextReader._convert_with_dtype (pandas\parser.c:10642)
  File ""parser.pyx"", line 1046, in pandas.parser.TextReader._string_convert (pandas\parser.c:10853)
  File ""parser.pyx"", line 1278, in pandas.parser._string_box_utf8 (pandas\parser.c:15657)
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xda in position 6: invalid    continuation byte
 
 The source/creation of these files all come from the same place. What's the best way to correct this to proceed with the import? 
","['python', 'pandas', 'csv', 'dataframe', 'unicode']",697
How to iterate over a list in chunks,"I have a Python script which takes as input a list of integers, which I need to work with four integers at a time.  Unfortunately, I don't have control of the input, or I'd have it passed in as a list of four-element tuples.  Currently, I'm iterating over it this way: 
 for i in range(0, len(ints), 4):
    # dummy op for example code
    foo += ints[i] * ints[i + 1] + ints[i + 2] * ints[i + 3]
 
 It looks a lot like ""C-think"", though, which makes me suspect there's a more pythonic way of dealing with this situation.  The list is discarded after iterating, so it needn't be preserved.  Perhaps something like this would be better? 
 while ints:
    foo += ints[0] * ints[1] + ints[2] * ints[3]
    ints[0:4] = []
 
 Still doesn't quite ""feel"" right, though.  :-/ 
 Update:  With the release of Python 1.12, I've changed the accepted answer. For anyone who has not (or cannot) make the jump to 1.12 yet, I encourage you to check out the  previous accepted answer  or any of the other excellent, backwards-compatible answers below. 
 Related question:  How do you split a list into evenly sized chunks in Python? 
","['python', 'list', 'loops', 'optimization', 'chunks']",686
How to install pip with Python 3?,"I want to install  pip . It should support Python 3, but it requires setuptools, which is available only for Python 2. 
 How can I install pip with Python 3? 
","['python', 'python-3.x', 'pip', 'package', 'setuptools']",685
Converting a Pandas GroupBy multiindex output from Series back to DataFrame,"I have a dataframe: 
    City     Name
0   Seattle    Alice
1   Seattle      Bob
2  Portland  Mallory
3   Seattle  Mallory
4   Seattle      Bob
5  Portland  Mallory
 
 I perform the following grouping: 
 g1 = df1.groupby([""Name"", ""City""]).count()
 
 which when printed looks like: 
                   City  Name
Name    City
Alice   Seattle      1     1
Bob     Seattle      2     2
Mallory Portland     2     2
        Seattle      1     1
 
 But what I want eventually is another DataFrame object that contains all the rows in the GroupBy object. In other words I want to get the following result: 
                   City  Name
Name    City
Alice   Seattle      1     1
Bob     Seattle      2     2
Mallory Portland     2     2
Mallory Seattle      1     1
 
 How do I do it? 
","['python', 'pandas', 'dataframe', 'group-by', 'multi-index']",679
What is the difference between re.search and re.match?,"What is the difference between the  search()  and  match()  functions in the Python  re  module? 
 I've read the  Python 2 documentation  ( Python 3 documentation ), but I never seem to remember it. 
","['python', 'regex', 'search', 'match', 'string-matching']",676
Finding the average of a list,"How do I find the arithmetic mean of a list in Python? For example: 
 [1, 2, 3, 4]  ⟶  2.5
 
","['python', 'list', 'average', 'mean', 'reduce']",675
How to specify multiple return types using type-hints,"I have a function in python that can either return a  bool  or a  list . Is there a way to specify the return types using type hints? 
 For example, is this the correct way to do it? 
 def foo(id) -> list or bool:
    ...
 
","['python', 'python-3.x', 'type-hinting', 'return-type', 'python-typing']",665
Get HTML source of WebElement in Selenium WebDriver using Python,"I'm using the Python bindings to run Selenium WebDriver: 
 from selenium import webdriver
wd = webdriver.Firefox()
 
 I know I can grab a webelement like so: 
 elem = wd.find_element_by_css_selector('#my-id')
 
 And I know I can get the full page source with... 
 wd.page_source
 
 But is there a way to get the ""element source""? 
 elem.source   # <-- returns the HTML as a string
 
 The Selenium WebDriver documentation for Python are basically non-existent and I don't see anything in the code that seems to enable that functionality. 
 What is the best way to access the HTML of an element (and its children)? 
","['python', 'selenium', 'selenium-webdriver', 'webdriver', 'automated-tests']",655
How to sort pandas dataframe by one column,"I have a dataframe like this: 
         0          1     2
0   354.7      April   4.0
1    55.4     August   8.0
2   176.5   December  12.0
3    95.5   February   2.0
4    85.6    January   1.0
5     152       July   7.0
6   238.7       June   6.0
7   104.8      March   3.0
8   283.5        May   5.0
9   278.8   November  11.0
10  249.6    October  10.0
11  212.7  September   9.0
 
 As you can see, months are not in calendar order. So I created a second column to get the month number corresponding to each month (1-12). From there, how can I sort this dataframe according to  calendar months' order? 
","['python', 'pandas', 'dataframe', 'sorting', 'datetime']",647
Split string on whitespace in Python,"I'm looking for the Python equivalent of  
 String str = ""many   fancy word \nhello    \thi"";
String whiteSpaceRegex = ""\\s"";
String[] words = str.split(whiteSpaceRegex);

[""many"", ""fancy"", ""word"", ""hello"", ""hi""]
 
","['python', 'regex', 'string', 'split', 'whitespace']",645
logger configuration to log to file and print to stdout,"I'm using Python's logging module to log some debug strings to a file which works pretty well. Now in addition, I'd like to use this module to also print the strings out to stdout. How do I do this? In order to log my strings to a file I use following code: 
 import logging
import logging.handlers
logger = logging.getLogger("""")
logger.setLevel(logging.DEBUG)
handler = logging.handlers.RotatingFileHandler(
    LOGFILE, maxBytes=(1048576*5), backupCount=7
)
formatter = logging.Formatter(""%(asctime)s - %(name)s - %(levelname)s - %(message)s"")
handler.setFormatter(formatter)
logger.addHandler(handler)
 
 and then call a logger function like 
 logger.debug(""I am written to the file"")
 
 Thank you for some help here! 
","['python', 'file', 'logging', 'stdout', 'python-logging']",640
"Differences between distribute, distutils, setuptools and distutils2?","The Situation 
 I’m trying to port an open-source library to Python 3.  ( SymPy , if anyone is wondering.)  
 So, I need to run  2to3  automatically when building for Python 3. To do that, I need to use  distribute . Therefore, I need to port the current system, which (according to the doctest) is  distutils .  
 
 The Problem 
 Unfortunately, I’m not sure what’s the difference between these modules— distutils ,  distribute ,  setuptools . The documentation is sketchy as best, as they all seem to be a fork of one another, intended to be compatible in most circumstances (but actually, not all)…and so on, and so forth.  
 
 The Question 
 Could someone explain the differences?  What am I supposed to use?  What is the most modern solution? (As an aside, I’d also appreciate some guide on porting to  Distribute , but that’s a tad beyond the scope of the question…) 
","['python', 'packaging', 'setuptools', 'distutils', 'distribute']",639
How do I split a string into a list of words?,"How do I split a sentence and store each word in a list? e.g. 
 ""these are words""   ⟶   [""these"", ""are"", ""words""]
 
 
 To split on other delimiters, see  Split a string by a delimiter in python . 
 To split into individual characters, see  How do I split a string into a list of characters? . 
","['python', 'string', 'list', 'split', 'text-segmentation']",638
Selenium using Python - Geckodriver executable needs to be in PATH,"I am going over Sweigart's  Automate the Boring Stuff with Python  text. I'm using  IDLE  and already installed the Selenium module and the Firefox browser. 
 Whenever I tried to run the webdriver function, I get this: 
 from selenium import webdriver
browser = webdriver.Firefox()
 
 Exception: 
 Exception ignored in: <bound method Service.__del__ of <selenium.webdriver.firefox.service.Service object at 0x00000249C0DA1080>>
Traceback (most recent call last):
  File ""C:\Python\Python35\lib\site-packages\selenium\webdriver\common\service.py"", line 163, in __del__
    self.stop()
  File ""C:\Python\Python35\lib\site-packages\selenium\webdriver\common\service.py"", line 135, in stop
    if self.process is None:
AttributeError: 'Service' object has no attribute 'process'
Exception ignored in: <bound method Service.__del__ of <selenium.webdriver.firefox.service.Service object at 0x00000249C0E08128>>
Traceback (most recent call last):
  File ""C:\Python\Python35\lib\site-packages\selenium\webdriver\common\service.py"", line 163, in __del__
    self.stop()
  File ""C:\Python\Python35\lib\site-packages\selenium\webdriver\common\service.py"", line 135, in stop
    if self.process is None:
AttributeError: 'Service' object has no attribute 'process'
Traceback (most recent call last):
  File ""C:\Python\Python35\lib\site-packages\selenium\webdriver\common\service.py"", line 64, in start
    stdout=self.log_file, stderr=self.log_file)
  File ""C:\Python\Python35\lib\subprocess.py"", line 947, in __init__
    restore_signals, start_new_session)
  File ""C:\Python\Python35\lib\subprocess.py"", line 1224, in _execute_child
    startupinfo)
FileNotFoundError: [WinError 2] The system cannot find the file specified
 
 During handling of the above exception, another exception occurred: 
 Traceback (most recent call last):
  File ""<pyshell#11>"", line 1, in <module>
    browser = webdriver.Firefox()
  File ""C:\Python\Python35\lib\site-packages\selenium\webdriver\firefox\webdriver.py"", line 135, in __init__
    self.service.start()
  File ""C:\Python\Python35\lib\site-packages\selenium\webdriver\common\service.py"", line 71, in start
    os.path.basename(self.path), self.start_error_message)
selenium.common.exceptions.WebDriverException: Message: 'geckodriver' executable needs to be in PATH.
 
 I think I need to set the path for  geckodriver , but I am not sure how, so how would I do this? 
","['python', 'selenium', 'firefox', 'selenium-firefoxdriver', 'geckodriver']",637
How to get the return value from a thread?,"The function  foo  below returns a string  'foo' . How can I get the value  'foo'  which is returned from the thread's target? 
 from threading import Thread

def foo(bar):
    print('hello {}'.format(bar))
    return 'foo'
    
thread = Thread(target=foo, args=('world!',))
thread.start()
return_value = thread.join()
 
 The ""one obvious way to do it"", shown above, doesn't work:  thread.join()  returned  None . 
","['python', 'multithreading', 'function', 'return-value', 'python-multithreading']",634
How to replace NaN values in a dataframe column,"I have a Pandas Dataframe as below: 
       itm Date                  Amount 
67    420 2012-09-30 00:00:00   65211
68    421 2012-09-09 00:00:00   29424
69    421 2012-09-16 00:00:00   29877
70    421 2012-09-23 00:00:00   30990
71    421 2012-09-30 00:00:00   61303
72    485 2012-09-09 00:00:00   71781
73    485 2012-09-16 00:00:00     NaN
74    485 2012-09-23 00:00:00   11072
75    485 2012-09-30 00:00:00  113702
76    489 2012-09-09 00:00:00   64731
77    489 2012-09-16 00:00:00     NaN
 
 When I try to apply a function to the Amount column, I get the following error: 
 ValueError: cannot convert float NaN to integer
 
 I have tried applying a function using  math.isnan , pandas'  .replace  method,  .sparse  data attribute from pandas 0.9, if  NaN == NaN  statement in a function; I have also looked at  this Q/A ; none of them works. 
 How do I do it? 
","['python', 'pandas', 'dataframe', 'nan', 'fillna']",632
How to get GET request values in Django?,"I am currently defining regular expressions in order to capture parameters in a URL, as described in the tutorial. How do I access parameters from the URL as part the  HttpRequest  object? 
 My  HttpRequest.GET  currently returns an empty  QueryDict  object. 
 I'd like to learn how to do this without a library, so I can get to know Django better. 
","['python', 'django', 'url', 'get', 'url-parameters']",624
Can a website detect when you are using Selenium with chromedriver?,"I've been testing out Selenium with Chromedriver and I noticed that some pages can detect that you're using Selenium even though there's no automation at all. Even when I'm just browsing manually just using Chrome through Selenium and  Xephyr  I often get a page saying that suspicious activity was detected. I've checked my user agent, and my browser fingerprint, and they are all exactly identical to the normal Chrome browser. 
 When I browse to these sites in normal Chrome everything works fine, but the moment I use Selenium I'm detected. 
 In theory, chromedriver and Chrome should look literally exactly the same to any web server, but somehow they can detect it. 
 If you want some test code try out this: 
 from pyvirtualdisplay import Display
from selenium import webdriver

display = Display(visible=1, size=(1600, 902))
display.start()
chrome_options = webdriver.ChromeOptions()
chrome_options.add_argument('--disable-extensions')
chrome_options.add_argument('--profile-directory=Default')
chrome_options.add_argument(""--incognito"")
chrome_options.add_argument(""--disable-plugins-discovery"");
chrome_options.add_argument(""--start-maximized"")
driver = webdriver.Chrome(chrome_options=chrome_options)
driver.delete_all_cookies()
driver.set_window_size(800,800)
driver.set_window_position(0,0)
print 'arguments done'
driver.get('http://stubhub.com')
 
 If you browse around stubhub you'll get redirected and 'blocked' within one or two requests. I've been investigating this and I can't figure out how they can tell that a user is using Selenium. 
 How do they do it? 
 I installed the Selenium IDE plugin in Firefox and I got banned when I went to stubhub.com in the normal Firefox browser with only the additional plugin. 
 When I use  Fiddler  to view the HTTP requests being sent back and forth I've noticed that the 'fake browser's' requests often have 'no-cache' in the response header. 
 Results like this  Is there a way to detect that I'm in a Selenium Webdriver page from JavaScript?  suggest that there should be no way to detect when you are using a webdriver. But this evidence suggests otherwise. 
 The site uploads a fingerprint to their servers, but I checked and the fingerprint of Selenium is identical to the fingerprint when using Chrome. 
 This is one of the fingerprint payloads that they send to their servers: 
 {""appName"":""Netscape"",""platform"":""Linuxx86_64"",""cookies"":1,""syslang"":""en-US"",""userlang"":""en-
US"",""cpu"":"""",""productSub"":""20030107"",""setTimeout"":1,""setInterval"":1,""plugins"":
{""0"":""ChromePDFViewer"",""1"":""ShockwaveFlash"",""2"":""WidevineContentDecryptionMo
dule"",""3"":""NativeClient"",""4"":""ChromePDFViewer""},""mimeTypes"":
{""0"":""application/pdf"",""1"":""ShockwaveFlashapplication/x-shockwave-
flash"",""2"":""FutureSplashPlayerapplication/futuresplash"",""3"":""WidevineContent
DecryptionModuleapplication/x-ppapi-widevine-
cdm"",""4"":""NativeClientExecutableapplication/x-
nacl"",""5"":""PortableNativeClientExecutableapplication/x-
pnacl"",""6"":""PortableDocumentFormatapplication/x-google-chrome-
pdf""},""screen"":{""width"":1600,""height"":900,""colorDepth"":24},""fonts"":
{""0"":""monospace"",""1"":""DejaVuSerif"",""2"":""Georgia"",""3"":""DejaVuSans"",""4"":""Trebu
chetMS"",""5"":""Verdana"",""6"":""AndaleMono"",""7"":""DejaVuSansMono"",""8"":""LiberationM
ono"",""9"":""NimbusMonoL"",""10"":""CourierNew"",""11"":""Courier""}}
 
 It's identical in Selenium and in Chrome. 
 VPNs work for a single use, but they get detected after I load the first page. Clearly some JavaScript code is being run to detect Selenium. 
","['javascript', 'python', 'google-chrome', 'selenium', 'selenium-chromedriver']",621
&quot;is&quot; operator behaves unexpectedly with integers,"Why does the following behave unexpectedly in Python? 
 >>> a = 256
>>> b = 256
>>> a is b
True           # This is an expected result
>>> a = 257
>>> b = 257
>>> a is b
False          # What happened here? Why is this False?
>>> 257 is 257
True           # Yet the literal numbers compare properly
 
 I am using Python 2.5.2. Trying some different versions of Python, it appears that Python 2.3.3 shows the above behaviour between 99 and 100. 
 Based on the above, I can hypothesize that Python is internally implemented such that ""small"" integers are stored in a different way than larger integers and the  is  operator can tell the difference. Why the leaky abstraction? What is a better way of comparing two arbitrary objects to see whether they are the same when I don't know in advance whether they are numbers or not? 
","['python', 'int', 'operators', 'identity', 'python-internals']",617
How can I pivot a dataframe?,"
 What is pivot? 
 How do I pivot? 
 Long format to wide format? 
 
 I've seen a lot of questions that ask about pivot tables, even if they don't know it.  It is virtually impossible to write a  canonical question and answer  that encompasses all aspects of pivoting... But I'm going to give it a go. 
 
 The problem with existing questions and answers is that often the question is focused on a nuance that the OP has trouble generalizing in order to use a number of the existing good answers.  However, none of the answers attempt to give a comprehensive explanation (because it's a daunting task). Look at a few examples from my  Google search : 
 
 How to pivot a dataframe in Pandas?  - Good question and answer.  But the answer only answers the specific question with little explanation. 
 pandas pivot table to data frame  - OP is concerned with the output of the pivot, namely how the columns look.  OP wanted it to look like R.  This isn't very helpful for pandas users. 
 pandas pivoting a dataframe, duplicate rows  - Another decent question but the answer focuses on one method, namely  pd.DataFrame.pivot 
 
 
 Setup 
 I conspicuously named my columns and relevant column values to correspond with how I'm going to pivot in the answers below. 
 import numpy as np
import pandas as pd
from numpy.core.defchararray import add

np.random.seed([3,1415])
n = 20

cols = np.array(['key', 'row', 'item', 'col'])
arr1 = (np.random.randint(5, size=(n, 4)) // [2, 1, 2, 1]).astype(str)

df = pd.DataFrame(
    add(cols, arr1), columns=cols
).join(
    pd.DataFrame(np.random.rand(n, 2).round(2)).add_prefix('val')
)
print(df)
 
      key   row   item   col  val0  val1
0   key0  row3  item1  col3  0.81  0.04
1   key1  row2  item1  col2  0.44  0.07
2   key1  row0  item1  col0  0.77  0.01
3   key0  row4  item0  col2  0.15  0.59
4   key1  row0  item2  col1  0.81  0.64
5   key1  row2  item2  col4  0.13  0.88
6   key2  row4  item1  col3  0.88  0.39
7   key1  row4  item1  col1  0.10  0.07
8   key1  row0  item2  col4  0.65  0.02
9   key1  row2  item0  col2  0.35  0.61
10  key2  row0  item2  col1  0.40  0.85
11  key2  row4  item1  col2  0.64  0.25
12  key0  row2  item2  col3  0.50  0.44
13  key0  row4  item1  col4  0.24  0.46
14  key1  row3  item2  col3  0.28  0.11
15  key0  row3  item1  col1  0.31  0.23
16  key0  row0  item2  col3  0.86  0.01
17  key0  row4  item0  col3  0.64  0.21
18  key2  row2  item2  col0  0.13  0.45
19  key0  row2  item0  col4  0.37  0.70
 
 Questions 
 
 Why do I get  ValueError: Index contains duplicate entries, cannot reshape ? 
 
 How do I pivot  df  such that the  col  values are columns,  row  values are the index, and mean of  val0  are the values? 
 col   col0   col1   col2   col3  col4
row
row0  0.77  0.605    NaN  0.860  0.65
row2  0.13    NaN  0.395  0.500  0.25
row3   NaN  0.310    NaN  0.545   NaN
row4   NaN  0.100  0.395  0.760  0.24
 
 
 How do I make it so that missing values are  0 ? 
 col   col0   col1   col2   col3  col4
row
row0  0.77  0.605  0.000  0.860  0.65
row2  0.13  0.000  0.395  0.500  0.25
row3  0.00  0.310  0.000  0.545  0.00
row4  0.00  0.100  0.395  0.760  0.24
 
 
 Can I get something other than  mean , like maybe  sum ? 
 col   col0  col1  col2  col3  col4
row
row0  0.77  1.21  0.00  0.86  0.65
row2  0.13  0.00  0.79  0.50  0.50
row3  0.00  0.31  0.00  1.09  0.00
row4  0.00  0.10  0.79  1.52  0.24
 
 
 Can I do more that one aggregation at a time? 
        sum                          mean
col   col0  col1  col2  col3  col4  col0   col1   col2   col3  col4
row
row0  0.77  1.21  0.00  0.86  0.65  0.77  0.605  0.000  0.860  0.65
row2  0.13  0.00  0.79  0.50  0.50  0.13  0.000  0.395  0.500  0.25
row3  0.00  0.31  0.00  1.09  0.00  0.00  0.310  0.000  0.545  0.00
row4  0.00  0.10  0.79  1.52  0.24  0.00  0.100  0.395  0.760  0.24
 
 
 Can I aggregate over multiple value columns? 
       val0                             val1
col   col0   col1   col2   col3  col4  col0   col1  col2   col3  col4
row
row0  0.77  0.605  0.000  0.860  0.65  0.01  0.745  0.00  0.010  0.02
row2  0.13  0.000  0.395  0.500  0.25  0.45  0.000  0.34  0.440  0.79
row3  0.00  0.310  0.000  0.545  0.00  0.00  0.230  0.00  0.075  0.00
row4  0.00  0.100  0.395  0.760  0.24  0.00  0.070  0.42  0.300  0.46
 
 
 Can I subdivide by multiple columns? 
 item item0             item1                         item2
col   col2  col3  col4  col0  col1  col2  col3  col4  col0   col1  col3  col4
row
row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.605  0.86  0.65
row2  0.35  0.00  0.37  0.00  0.00  0.44  0.00  0.00  0.13  0.000  0.50  0.13
row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.000  0.28  0.00
row4  0.15  0.64  0.00  0.00  0.10  0.64  0.88  0.24  0.00  0.000  0.00  0.00
 
 
 Or 
 item      item0             item1                         item2
col        col2  col3  col4  col0  col1  col2  col3  col4  col0  col1  col3  col4
key  row
key0 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.86  0.00
     row2  0.00  0.00  0.37  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.50  0.00
     row3  0.00  0.00  0.00  0.00  0.31  0.00  0.81  0.00  0.00  0.00  0.00  0.00
     row4  0.15  0.64  0.00  0.00  0.00  0.00  0.00  0.24  0.00  0.00  0.00  0.00
key1 row0  0.00  0.00  0.00  0.77  0.00  0.00  0.00  0.00  0.00  0.81  0.00  0.65
     row2  0.35  0.00  0.00  0.00  0.00  0.44  0.00  0.00  0.00  0.00  0.00  0.13
     row3  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.28  0.00
     row4  0.00  0.00  0.00  0.00  0.10  0.00  0.00  0.00  0.00  0.00  0.00  0.00
key2 row0  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.40  0.00  0.00
     row2  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.00  0.13  0.00  0.00  0.00
     row4  0.00  0.00  0.00  0.00  0.00  0.64  0.88  0.00  0.00  0.00  0.00  0.00
 
 
 Can I aggregate the frequency in which the column and rows occur together, aka ""cross tabulation""? 
 col   col0  col1  col2  col3  col4
row
row0     1     2     0     1     1
row2     1     0     2     1     2
row3     0     1     0     2     0
row4     0     1     2     2     1
 
 
 How do I convert a DataFrame from long to wide by pivoting on ONLY two columns? Given, 
 np.random.seed([3, 1415])
df2 = pd.DataFrame({'A': list('aaaabbbc'), 'B': np.random.choice(15, 8)})
df2
   A   B
0  a   0
1  a  11
2  a   2
3  a  11
4  b  10
5  b  10
6  b  14
7  c   7
 
 The expected should look something like 
       a     b    c
0   0.0  10.0  7.0
1  11.0  10.0  NaN
2   2.0  14.0  NaN
3  11.0   NaN  NaN
 
 
 How do I flatten the multiple index to single index after  pivot ? 
 From 
    1  2
   1  1  2
a  2  1  1
b  2  1  0
c  1  0  0
 
 To 
    1|1  2|1  2|2
a    2    1    1
b    2    1    0
c    1    0    0
 
 
 
","['python', 'pandas', 'group-by', 'pivot', 'pivot-table']",617
"Create new column based on values from other columns / apply a function of multiple columns, row-wise in Pandas","I want to apply my custom function (it uses an if-else ladder) to these six columns ( ERI_Hispanic ,  ERI_AmerInd_AKNatv ,  ERI_Asian ,  ERI_Black_Afr.Amer ,  ERI_HI_PacIsl ,  ERI_White ) in each row of my dataframe. 
 I've tried different methods from other questions but still can't seem to find the right answer for my problem.  The critical piece of this is that if the person is counted as Hispanic they can't be counted as anything else.  Even if they have a ""1"" in another ethnicity column they still are counted as Hispanic not two or more races.  Similarly, if the sum of all the ERI columns is greater than 1 they are counted as two or more races and can't be counted as a unique ethnicity(except for Hispanic). 
 It's almost like doing a for loop through each row and if each record meets a criterion they are added to one list and eliminated from the original. 
 From the dataframe below I need to calculate a new column based on the following spec in SQL: 
 CRITERIA 
 IF [ERI_Hispanic] = 1 THEN RETURN “Hispanic”
ELSE IF SUM([ERI_AmerInd_AKNatv] + [ERI_Asian] + [ERI_Black_Afr.Amer] + [ERI_HI_PacIsl] + [ERI_White]) > 1 THEN RETURN “Two or More”
ELSE IF [ERI_AmerInd_AKNatv] = 1 THEN RETURN “A/I AK Native”
ELSE IF [ERI_Asian] = 1 THEN RETURN “Asian”
ELSE IF [ERI_Black_Afr.Amer] = 1 THEN RETURN “Black/AA”
ELSE IF [ERI_HI_PacIsl] = 1 THEN RETURN “Haw/Pac Isl.”
ELSE IF [ERI_White] = 1 THEN RETURN “White”
 
 Comment: If the ERI Flag for Hispanic is True (1), the employee is classified as “Hispanic” 
 Comment: If more than 1 non-Hispanic ERI Flag is true, return “Two or More” 
 DATAFRAME 
      lname          fname       rno_cd  eri_afr_amer    eri_asian   eri_hawaiian    eri_hispanic    eri_nat_amer    eri_white   rno_defined
0    MOST           JEFF        E       0               0           0               0               0               1           White
1    CRUISE         TOM         E       0               0           0               1               0               0           White
2    DEPP           JOHNNY              0               0           0               0               0               1           Unknown
3    DICAP          LEO                 0               0           0               0               0               1           Unknown
4    BRANDO         MARLON      E       0               0           0               0               0               0           White
5    HANKS          TOM         0                       0           0               0               0               1           Unknown
6    DENIRO         ROBERT      E       0               1           0               0               0               1           White
7    PACINO         AL          E       0               0           0               0               0               1           White
8    WILLIAMS       ROBIN       E       0               0           1               0               0               0           White
9    EASTWOOD       CLINT       E       0               0           0               0               0               1           White
 
","['python', 'pandas', 'dataframe', 'numpy', 'apply']",616
